Dataset: CUB
Shift type: confounder
Target name: waterbird_complete95
Confounder names: ['forest2water2']
Resume: False
Inference: True
Minority fraction: None
Imbalance ratio: None
Fraction: 1.0
Root dir: ./
Reweight groups: False
Augment data: False
Val fraction: 0.1
Robust: False
Alpha: 0.2
Generalization adjustment: 0.0
Automatic adjustment: False
Robust step size: 0.01
Use normalized loss: False
Btl: False
Hinge: False
Model: resnet50
Train from scratch: False
N epochs: 300
Batch size: 128
Lr: 0.001
Scheduler: False
Weight decay: 0.0001
Gamma: 0.1
Minimum variational weight: 0
Seed: 0
Show progress: True
Log dir: ./logs_metrics_tmp_3
Checkpoint dir: ./logs_metrics_tmp_2
Log every: 50
Save step: 1000
Save best: True
Save last: True

Training Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 3498
    waterbird_complete95 = 0, forest2water2 = 1: n = 184
    waterbird_complete95 = 1, forest2water2 = 0: n = 56
    waterbird_complete95 = 1, forest2water2 = 1: n = 1057
Validation Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 467
    waterbird_complete95 = 0, forest2water2 = 1: n = 466
    waterbird_complete95 = 1, forest2water2 = 0: n = 133
    waterbird_complete95 = 1, forest2water2 = 1: n = 133
Test Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 2255
    waterbird_complete95 = 0, forest2water2 = 1: n = 2255
    waterbird_complete95 = 1, forest2water2 = 0: n = 642
    waterbird_complete95 = 1, forest2water2 = 1: n = 642
Average incurred loss: 0.372  
Average sample loss: 0.369  
Average acc: 0.840  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2255]:	loss = 0.020  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 0, forest2water2 = 1  [n = 2255]:	loss = 0.534  exp loss = 0.519  adjusted loss = 0.519  adv prob = 0.250000   acc = 0.753
  waterbird_complete95 = 1, forest2water2 = 0  [n = 642]:	loss = 1.225  exp loss = 1.223  adjusted loss = 1.223  adv prob = 0.250000   acc = 0.502
  waterbird_complete95 = 1, forest2water2 = 1  [n = 642]:	loss = 0.183  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.935
