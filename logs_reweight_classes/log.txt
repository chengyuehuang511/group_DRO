Dataset: CUB
Shift type: confounder
Target name: waterbird_complete95
Confounder names: ['forest2water2']
Resume: False
Inference: False
Minority fraction: None
Imbalance ratio: None
Fraction: 1.0
Root dir: ./
Reweight groups: False
Reweight classes: True
Augment data: False
Val fraction: 0.1
Robust: False
Alpha: 0.2
Generalization adjustment: 0.0
Automatic adjustment: False
Robust step size: 0.01
Use normalized loss: False
Btl: False
Hinge: False
Print grad loss: True
Print feat: True
Uniform loss: True
Model: resnet50
Train from scratch: False
N epochs: 300
Batch size: 128
Lr: 0.001
Scheduler: False
Weight decay: 0.0001
Gamma: 0.1
Minimum variational weight: 0
Seed: 0
Show progress: True
Log dir: ./logs_reweight_classes
Checkpoint dir: ./logs_a40
Log every: 50
Save step: 1000
Save best: True
Save last: True

Training Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 3498
    waterbird_complete95 = 0, forest2water2 = 1: n = 184
    waterbird_complete95 = 1, forest2water2 = 0: n = 56
    waterbird_complete95 = 1, forest2water2 = 1: n = 1057
Validation Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 467
    waterbird_complete95 = 0, forest2water2 = 1: n = 466
    waterbird_complete95 = 1, forest2water2 = 0: n = 133
    waterbird_complete95 = 1, forest2water2 = 1: n = 133
Test Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 2255
    waterbird_complete95 = 0, forest2water2 = 1: n = 2255
    waterbird_complete95 = 1, forest2water2 = 0: n = 642
    waterbird_complete95 = 1, forest2water2 = 1: n = 642

Epoch [0]:
Training:
Average incurred loss: 0.352  
Average sample loss: 0.348  
Average acc: 0.859  
Average grad norm: 9.487  
Average grad norm uniform: 19.321  
Average loss each uniform: 2.134  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2283]:	loss = 0.326  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.887   grad norm = 8.956   grad norm uniform = 18.635   loss each uniform = 2.120   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 106]:	loss = 1.024  exp loss = 0.993  adjusted loss = 0.993  adv prob = 0.250000   acc = 0.358   grad norm = 21.218   grad norm uniform = 14.245   loss each uniform = 1.691   feat norm = 0.461  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.849  exp loss = 0.919  adjusted loss = 0.919  adv prob = 0.250000   acc = 0.500   grad norm = 18.680   grad norm uniform = 10.933   loss each uniform = 1.600   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2294]:	loss = 0.323  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.872   grad norm = 9.024   grad norm uniform = 20.648   loss each uniform = 2.193   feat norm = 0.458  

Validation:
Average incurred loss: 0.692  
Average sample loss: 0.681  
Average acc: 0.669  
Average grad norm: 12.650  
Average grad norm uniform: 25.320  
Average loss each uniform: 2.651  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.102  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 0.976   grad norm = 2.962   grad norm uniform = 30.330   loss each uniform = 3.272   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.313  exp loss = 1.330  adjusted loss = 1.330  adv prob = 0.250000   acc = 0.341   grad norm = 22.981   grad norm uniform = 20.110   loss each uniform = 2.011   feat norm = 0.460  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.173  exp loss = 1.304  adjusted loss = 1.304  adv prob = 0.250000   acc = 0.429   grad norm = 20.088   grad norm uniform = 19.030   loss each uniform = 2.005   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.106  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.977   grad norm = 3.028   grad norm uniform = 32.269   loss each uniform = 3.357   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.6688907146453857
Best model saved at epoch 0


Epoch [1]:
Training:
Average incurred loss: 0.127  
Average sample loss: 0.127  
Average acc: 0.957  
Average grad norm: 3.180  
Average grad norm uniform: 31.356  
Average loss each uniform: 3.792  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2208]:	loss = 0.078  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.985   grad norm = 2.328   grad norm uniform = 31.503   loss each uniform = 3.808   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 1.183  exp loss = 0.869  adjusted loss = 0.869  adv prob = 0.250000   acc = 0.442   grad norm = 20.706   grad norm uniform = 19.023   loss each uniform = 2.010   feat norm = 0.461  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 104]:	loss = 0.778  exp loss = 0.606  adjusted loss = 0.606  adv prob = 0.250000   acc = 0.596   grad norm = 15.632   grad norm uniform = 17.313   loss each uniform = 1.905   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2363]:	loss = 0.092  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.972   grad norm = 2.537   grad norm uniform = 32.464   loss each uniform = 3.951   feat norm = 0.454  

Validation:
Average incurred loss: 0.651  
Average sample loss: 0.640  
Average acc: 0.723  
Average grad norm: 11.022  
Average grad norm uniform: 27.077  
Average loss each uniform: 3.113  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.095  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 0.968   grad norm = 2.562   grad norm uniform = 31.847   loss each uniform = 3.844   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.303  exp loss = 1.360  adjusted loss = 1.360  adv prob = 0.250000   acc = 0.438   grad norm = 20.978   grad norm uniform = 21.295   loss each uniform = 2.183   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.899  exp loss = 1.024  adjusted loss = 1.024  adv prob = 0.250000   acc = 0.609   grad norm = 15.219   grad norm uniform = 22.932   loss each uniform = 2.357   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.069  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 0.977   grad norm = 1.645   grad norm uniform = 34.727   loss each uniform = 4.561   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.7231025695800781
Best model saved at epoch 1


Epoch [2]:
Training:
Average incurred loss: 0.095  
Average sample loss: 0.094  
Average acc: 0.971  
Average grad norm: 2.266  
Average grad norm uniform: 32.800  
Average loss each uniform: 4.387  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2315]:	loss = 0.049  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.994   grad norm = 1.529   grad norm uniform = 32.714   loss each uniform = 4.438   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 148]:	loss = 0.792  exp loss = 0.805  adjusted loss = 0.805  adv prob = 0.250000   acc = 0.655   grad norm = 14.536   grad norm uniform = 20.776   loss each uniform = 2.185   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.739  exp loss = 0.524  adjusted loss = 0.524  adv prob = 0.250000   acc = 0.728   grad norm = 12.519   grad norm uniform = 23.443   loss each uniform = 2.338   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2207]:	loss = 0.059  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.983   grad norm = 1.637   grad norm uniform = 34.227   loss each uniform = 4.596   feat norm = 0.456  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.533  
Average acc: 0.768  
Average grad norm: 9.352  
Average grad norm uniform: 27.686  
Average loss each uniform: 3.411  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.062  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 0.981   grad norm = 1.697   grad norm uniform = 32.721   loss each uniform = 4.469   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.033  exp loss = 1.081  adjusted loss = 1.081  adv prob = 0.250000   acc = 0.547   grad norm = 17.444   grad norm uniform = 21.684   loss each uniform = 2.242   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.986  exp loss = 1.138  adjusted loss = 1.138  adv prob = 0.250000   acc = 0.594   grad norm = 15.352   grad norm uniform = 24.116   loss each uniform = 2.514   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.088  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.970   grad norm = 1.885   grad norm uniform = 34.613   loss each uniform = 4.684   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.7681400775909424
Best model saved at epoch 2


Epoch [3]:
Training:
Average incurred loss: 0.058  
Average sample loss: 0.059  
Average acc: 0.986  
Average grad norm: 1.574  
Average grad norm uniform: 33.538  
Average loss each uniform: 4.849  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2229]:	loss = 0.033  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996   grad norm = 1.000   grad norm uniform = 33.757   loss each uniform = 5.096   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.499  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.767   grad norm = 10.828   grad norm uniform = 21.715   loss each uniform = 2.259   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 134]:	loss = 0.269  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.918   grad norm = 6.132   grad norm uniform = 26.544   loss each uniform = 2.668   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2303]:	loss = 0.045  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.992   grad norm = 1.347   grad norm uniform = 34.396   loss each uniform = 4.883   feat norm = 0.454  

Validation:
Average incurred loss: 0.429  
Average sample loss: 0.414  
Average acc: 0.827  
Average grad norm: 7.196  
Average grad norm uniform: 29.417  
Average loss each uniform: 4.097  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.994   grad norm = 0.632   grad norm uniform = 34.858   loss each uniform = 5.850   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.648  adjusted loss = 0.648  adv prob = 0.250000   acc = 0.723   grad norm = 11.416   grad norm uniform = 24.379   loss each uniform = 2.670   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.507  exp loss = 1.691  adjusted loss = 1.691  adv prob = 0.250000   acc = 0.466   grad norm = 19.566   grad norm uniform = 24.686   loss each uniform = 2.662   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.161  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.962   grad norm = 3.094   grad norm uniform = 32.696   loss each uniform = 4.374   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8265221118927002
Best model saved at epoch 3


Epoch [4]:
Training:
Average incurred loss: 0.043  
Average sample loss: 0.042  
Average acc: 0.990  
Average grad norm: 1.137  
Average grad norm uniform: 34.358  
Average loss each uniform: 5.318  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2282]:	loss = 0.025  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998   grad norm = 0.767   grad norm uniform = 34.068   loss each uniform = 5.426   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 109]:	loss = 0.510  exp loss = 0.543  adjusted loss = 0.543  adv prob = 0.250000   acc = 0.789   grad norm = 10.443   grad norm uniform = 23.859   loss each uniform = 2.499   feat norm = 0.460  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.197  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.934   grad norm = 4.429   grad norm uniform = 29.128   loss each uniform = 3.113   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2282]:	loss = 0.030  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.995   grad norm = 0.887   grad norm uniform = 35.429   loss each uniform = 5.462   feat norm = 0.456  

Validation:
Average incurred loss: 0.426  
Average sample loss: 0.412  
Average acc: 0.834  
Average grad norm: 6.945  
Average grad norm uniform: 29.501  
Average loss each uniform: 4.250  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.994   grad norm = 0.584   grad norm uniform = 34.382   loss each uniform = 6.024   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.616  exp loss = 0.656  adjusted loss = 0.656  adv prob = 0.250000   acc = 0.732   grad norm = 11.237   grad norm uniform = 24.671   loss each uniform = 2.754   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.458  exp loss = 1.629  adjusted loss = 1.629  adv prob = 0.250000   acc = 0.504   grad norm = 18.371   grad norm uniform = 25.285   loss each uniform = 2.788   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.962   grad norm = 2.820   grad norm uniform = 33.504   loss each uniform = 4.723   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8340283632278442
Best model saved at epoch 4


Epoch [5]:
Training:
Average incurred loss: 0.035  
Average sample loss: 0.035  
Average acc: 0.992  
Average grad norm: 0.957  
Average grad norm uniform: 34.644  
Average loss each uniform: 5.682  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2268]:	loss = 0.016  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.999   grad norm = 0.527   grad norm uniform = 34.512   loss each uniform = 5.949   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.411  exp loss = 0.298  adjusted loss = 0.298  adv prob = 0.250000   acc = 0.819   grad norm = 8.906   grad norm uniform = 25.092   loss each uniform = 2.729   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.136  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.952   grad norm = 3.730   grad norm uniform = 30.488   loss each uniform = 3.226   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2285]:	loss = 0.028  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.996   grad norm = 0.827   grad norm uniform = 35.490   loss each uniform = 5.702   feat norm = 0.455  

Validation:
Average incurred loss: 0.436  
Average sample loss: 0.424  
Average acc: 0.830  
Average grad norm: 6.902  
Average grad norm uniform: 29.696  
Average loss each uniform: 4.336  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.734   grad norm uniform = 34.127   loss each uniform = 5.991   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.707  exp loss = 0.757  adjusted loss = 0.757  adv prob = 0.250000   acc = 0.704   grad norm = 11.916   grad norm uniform = 24.844   loss each uniform = 2.787   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.232  exp loss = 1.377  adjusted loss = 1.377  adv prob = 0.250000   acc = 0.579   grad norm = 15.743   grad norm uniform = 26.421   loss each uniform = 2.956   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.127  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.970   grad norm = 2.156   grad norm uniform = 34.413   loss each uniform = 5.330   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8298581838607788


Epoch [6]:
Training:
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 0.996  
Average grad norm: 0.691  
Average grad norm uniform: 35.044  
Average loss each uniform: 6.035  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2239]:	loss = 0.016  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.999   grad norm = 0.489   grad norm uniform = 34.810   loss each uniform = 6.218   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.283  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.889   grad norm = 6.613   grad norm uniform = 27.065   loss each uniform = 2.852   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.070  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.976   grad norm = 1.947   grad norm uniform = 33.051   loss each uniform = 3.898   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2325]:	loss = 0.017  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.999   grad norm = 0.544   grad norm uniform = 35.745   loss each uniform = 6.119   feat norm = 0.452  

Validation:
Average incurred loss: 0.420  
Average sample loss: 0.406  
Average acc: 0.850  
Average grad norm: 6.332  
Average grad norm uniform: 30.791  
Average loss each uniform: 4.789  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.994   grad norm = 0.550   grad norm uniform = 34.867   loss each uniform = 6.717   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.618  exp loss = 0.682  adjusted loss = 0.682  adv prob = 0.250000   acc = 0.760   grad norm = 10.290   grad norm uniform = 26.871   loss each uniform = 3.148   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.395  exp loss = 1.536  adjusted loss = 1.536  adv prob = 0.250000   acc = 0.564   grad norm = 16.668   grad norm uniform = 26.629   loss each uniform = 3.075   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.947   grad norm = 2.431   grad norm uniform = 34.377   loss each uniform = 5.484   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8498749732971191
Best model saved at epoch 6


Epoch [7]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 0.996  
Average grad norm: 0.600  
Average grad norm uniform: 35.200  
Average loss each uniform: 6.296  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2306]:	loss = 0.011  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000   grad norm = 0.361   grad norm uniform = 34.821   loss each uniform = 6.519   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.217  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.886   grad norm = 5.450   grad norm uniform = 28.750   loss each uniform = 3.270   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.075  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.992   grad norm = 2.076   grad norm uniform = 32.248   loss each uniform = 3.787   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2242]:	loss = 0.016  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.999   grad norm = 0.512   grad norm uniform = 36.093   loss each uniform = 6.369   feat norm = 0.455  

Validation:
Average incurred loss: 0.456  
Average sample loss: 0.443  
Average acc: 0.832  
Average grad norm: 6.777  
Average grad norm uniform: 30.540  
Average loss each uniform: 4.701  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.987   grad norm = 0.739   grad norm uniform = 34.320   loss each uniform = 6.358   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.777  exp loss = 0.840  adjusted loss = 0.840  adv prob = 0.250000   acc = 0.700   grad norm = 12.096   grad norm uniform = 26.165   loss each uniform = 3.013   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.164  exp loss = 1.295  adjusted loss = 1.295  adv prob = 0.250000   acc = 0.609   grad norm = 14.309   grad norm uniform = 27.552   loss each uniform = 3.290   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.118  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 0.970   grad norm = 1.807   grad norm uniform = 35.585   loss each uniform = 6.207   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8315262794494629


Epoch [8]:
Training:
Average incurred loss: 0.012  
Average sample loss: 0.012  
Average acc: 0.999  
Average grad norm: 0.390  
Average grad norm uniform: 35.560  
Average loss each uniform: 6.575  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2280]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.999   grad norm = 0.241   grad norm uniform = 35.085   loss each uniform = 6.881   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.098  exp loss = 0.112  adjusted loss = 0.112  adv prob = 0.250000   acc = 0.983   grad norm = 2.902   grad norm uniform = 31.987   loss each uniform = 3.544   feat norm = 0.462  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 105]:	loss = 0.040  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 1.000   grad norm = 1.314   grad norm uniform = 34.152   loss each uniform = 4.121   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2292]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000   grad norm = 0.366   grad norm uniform = 36.281   loss each uniform = 6.538   feat norm = 0.454  

Validation:
Average incurred loss: 0.423  
Average sample loss: 0.409  
Average acc: 0.857  
Average grad norm: 5.992  
Average grad norm uniform: 31.303  
Average loss each uniform: 5.165  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.991   grad norm = 0.487   grad norm uniform = 34.915   loss each uniform = 7.145   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.624  exp loss = 0.678  adjusted loss = 0.678  adv prob = 0.250000   acc = 0.773   grad norm = 9.759   grad norm uniform = 27.729   loss each uniform = 3.406   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.412  exp loss = 1.551  adjusted loss = 1.551  adv prob = 0.250000   acc = 0.586   grad norm = 15.892   grad norm uniform = 27.644   loss each uniform = 3.367   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.151  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.955   grad norm = 2.222   grad norm uniform = 34.806   loss each uniform = 6.173   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8573811650276184
Best model saved at epoch 8


Epoch [9]:
Training:
Average incurred loss: 0.011  
Average sample loss: 0.011  
Average acc: 0.999  
Average grad norm: 0.362  
Average grad norm uniform: 35.629  
Average loss each uniform: 6.848  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.009  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.999   grad norm = 0.289   grad norm uniform = 35.023   loss each uniform = 7.019   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.096  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.966   grad norm = 2.904   grad norm uniform = 31.902   loss each uniform = 3.786   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.024  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000   grad norm = 0.815   grad norm uniform = 35.320   loss each uniform = 4.561   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2230]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.283   grad norm uniform = 36.474   loss each uniform = 6.950   feat norm = 0.454  

Validation:
Average incurred loss: 0.501  
Average sample loss: 0.488  
Average acc: 0.821  
Average grad norm: 7.032  
Average grad norm uniform: 30.659  
Average loss each uniform: 4.891  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.036  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.985   grad norm = 0.831   grad norm uniform = 34.088   loss each uniform = 6.478   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.926  exp loss = 1.001  adjusted loss = 1.001  adv prob = 0.250000   acc = 0.665   grad norm = 13.192   grad norm uniform = 26.389   loss each uniform = 3.093   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.046  exp loss = 1.161  adjusted loss = 1.161  adv prob = 0.250000   acc = 0.639   grad norm = 12.750   grad norm uniform = 27.917   loss each uniform = 3.533   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.103  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 0.970   grad norm = 1.508   grad norm uniform = 36.324   loss each uniform = 6.975   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8206839561462402


Epoch [10]:
Training:
Average incurred loss: 0.009  
Average sample loss: 0.009  
Average acc: 1.000  
Average grad norm: 0.302  
Average grad norm uniform: 35.775  
Average loss each uniform: 7.065  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2213]:	loss = 0.005  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.182   grad norm uniform = 35.369   loss each uniform = 7.491   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 101]:	loss = 0.050  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 1.000   grad norm = 1.607   grad norm uniform = 34.353   loss each uniform = 4.449   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.040  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000   grad norm = 1.276   grad norm uniform = 33.506   loss each uniform = 4.407   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2361]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.309   grad norm uniform = 36.332   loss each uniform = 6.913   feat norm = 0.453  

Validation:
Average incurred loss: 0.455  
Average sample loss: 0.440  
Average acc: 0.846  
Average grad norm: 6.173  
Average grad norm uniform: 31.546  
Average loss each uniform: 5.357  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.502   grad norm uniform = 35.204   loss each uniform = 7.420   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.718  exp loss = 0.798  adjusted loss = 0.798  adv prob = 0.250000   acc = 0.742   grad norm = 10.458   grad norm uniform = 28.029   loss each uniform = 3.484   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.371  exp loss = 1.483  adjusted loss = 1.483  adv prob = 0.250000   acc = 0.594   grad norm = 15.194   grad norm uniform = 27.885   loss each uniform = 3.446   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.147  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.955   grad norm = 2.053   grad norm uniform = 34.688   loss each uniform = 6.591   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8457047939300537


Epoch [11]:
Training:
Average incurred loss: 0.008  
Average sample loss: 0.008  
Average acc: 0.999  
Average grad norm: 0.244  
Average grad norm uniform: 35.903  
Average loss each uniform: 7.310  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2216]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.160   grad norm uniform = 35.463   loss each uniform = 7.584   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.085  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.968   grad norm = 2.297   grad norm uniform = 34.922   loss each uniform = 4.453   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 132]:	loss = 0.026  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000   grad norm = 0.821   grad norm uniform = 34.820   loss each uniform = 4.958   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2321]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.180   grad norm uniform = 36.438   loss each uniform = 7.338   feat norm = 0.451  

Validation:
Average incurred loss: 0.462  
Average sample loss: 0.447  
Average acc: 0.844  
Average grad norm: 6.207  
Average grad norm uniform: 31.408  
Average loss each uniform: 5.361  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.987   grad norm = 0.554   grad norm uniform = 34.756   loss each uniform = 7.344   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.753  exp loss = 0.844  adjusted loss = 0.844  adv prob = 0.250000   acc = 0.736   grad norm = 10.770   grad norm uniform = 27.901   loss each uniform = 3.482   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.309  exp loss = 1.420  adjusted loss = 1.420  adv prob = 0.250000   acc = 0.602   grad norm = 14.460   grad norm uniform = 28.144   loss each uniform = 3.518   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.135  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.962   grad norm = 1.820   grad norm uniform = 35.203   loss each uniform = 6.822   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8440366983413696


Epoch [12]:
Training:
Average incurred loss: 0.007  
Average sample loss: 0.006  
Average acc: 0.999  
Average grad norm: 0.206  
Average grad norm uniform: 35.975  
Average loss each uniform: 7.472  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2389]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.156   grad norm uniform = 35.055   loss each uniform = 7.659   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.070  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.983   grad norm = 2.067   grad norm uniform = 33.937   loss each uniform = 4.049   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.016  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000   grad norm = 0.526   grad norm uniform = 35.677   loss each uniform = 5.095   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2170]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.140   grad norm uniform = 37.117   loss each uniform = 7.583   feat norm = 0.458  

Validation:
Average incurred loss: 0.530  
Average sample loss: 0.517  
Average acc: 0.825  
Average grad norm: 6.895  
Average grad norm uniform: 31.198  
Average loss each uniform: 5.338  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.037  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.987   grad norm = 0.772   grad norm uniform = 34.082   loss each uniform = 7.086   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.976  exp loss = 1.075  adjusted loss = 1.075  adv prob = 0.250000   acc = 0.672   grad norm = 13.021   grad norm uniform = 27.420   loss each uniform = 3.360   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.115  exp loss = 1.227  adjusted loss = 1.227  adv prob = 0.250000   acc = 0.647   grad norm = 12.453   grad norm uniform = 28.655   loss each uniform = 3.810   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.113  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 0.970   grad norm = 1.368   grad norm uniform = 36.852   loss each uniform = 7.659   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8248540163040161


Epoch [13]:
Training:
Average incurred loss: 0.005  
Average sample loss: 0.005  
Average acc: 1.000  
Average grad norm: 0.168  
Average grad norm uniform: 36.065  
Average loss each uniform: 7.623  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2308]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.080   grad norm uniform = 35.323   loss each uniform = 8.159   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.063  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 0.984   grad norm = 1.486   grad norm uniform = 35.527   loss each uniform = 4.772   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 121]:	loss = 0.018  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000   grad norm = 0.583   grad norm uniform = 35.392   loss each uniform = 4.770   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2242]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.164   grad norm uniform = 36.896   loss each uniform = 7.382   feat norm = 0.456  

Validation:
Average incurred loss: 0.469  
Average sample loss: 0.454  
Average acc: 0.845  
Average grad norm: 6.046  
Average grad norm uniform: 31.611  
Average loss each uniform: 5.607  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.987   grad norm = 0.529   grad norm uniform = 34.430   loss each uniform = 7.625   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.764  exp loss = 0.836  adjusted loss = 0.836  adv prob = 0.250000   acc = 0.738   grad norm = 10.569   grad norm uniform = 28.494   loss each uniform = 3.644   feat norm = 0.458  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.327  exp loss = 1.463  adjusted loss = 1.463  adv prob = 0.250000   acc = 0.609   grad norm = 13.834   grad norm uniform = 28.428   loss each uniform = 3.722   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.142  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.955   grad norm = 1.785   grad norm uniform = 35.814   loss each uniform = 7.290   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8448706865310669


Epoch [14]:
Training:
Average incurred loss: 0.004  
Average sample loss: 0.004  
Average acc: 1.000  
Average grad norm: 0.144  
Average grad norm uniform: 36.084  
Average loss each uniform: 7.742  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2304]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.082   grad norm uniform = 35.420   loss each uniform = 8.170   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 106]:	loss = 0.024  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000   grad norm = 0.879   grad norm uniform = 36.717   loss each uniform = 5.028   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 111]:	loss = 0.019  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000   grad norm = 0.658   grad norm uniform = 35.428   loss each uniform = 4.965   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2274]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.148   grad norm uniform = 36.760   loss each uniform = 7.571   feat norm = 0.454  

Validation:
Average incurred loss: 0.480  
Average sample loss: 0.466  
Average acc: 0.842  
Average grad norm: 6.188  
Average grad norm uniform: 31.713  
Average loss each uniform: 5.589  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.987   grad norm = 0.558   grad norm uniform = 34.548   loss each uniform = 7.552   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.808  exp loss = 0.901  adjusted loss = 0.901  adv prob = 0.250000   acc = 0.730   grad norm = 10.988   grad norm uniform = 28.600   loss each uniform = 3.642   feat norm = 0.461  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.276  exp loss = 1.406  adjusted loss = 1.406  adv prob = 0.250000   acc = 0.609   grad norm = 13.619   grad norm uniform = 28.487   loss each uniform = 3.728   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.135  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.962   grad norm = 1.714   grad norm uniform = 35.886   loss each uniform = 7.383   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8423686027526855


Epoch [15]:
Training:
Average incurred loss: 0.004  
Average sample loss: 0.004  
Average acc: 1.000  
Average grad norm: 0.122  
Average grad norm uniform: 36.165  
Average loss each uniform: 7.919  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2257]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.081   grad norm uniform = 35.456   loss each uniform = 8.367   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.022  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.992   grad norm = 0.775   grad norm uniform = 36.654   loss each uniform = 5.048   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.010  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000   grad norm = 0.338   grad norm uniform = 35.707   loss each uniform = 5.276   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2288]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.114   grad norm uniform = 36.859   loss each uniform = 7.779   feat norm = 0.454  

Validation:
Average incurred loss: 0.454  
Average sample loss: 0.439  
Average acc: 0.859  
Average grad norm: 5.697  
Average grad norm uniform: 32.104  
Average loss each uniform: 5.870  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.403   grad norm uniform = 34.838   loss each uniform = 8.064   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.682  exp loss = 0.758  adjusted loss = 0.758  adv prob = 0.250000   acc = 0.777   grad norm = 9.434   grad norm uniform = 29.413   loss each uniform = 3.905   feat norm = 0.459  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.488  exp loss = 1.609  adjusted loss = 1.609  adv prob = 0.250000   acc = 0.594   grad norm = 14.917   grad norm uniform = 28.655   loss each uniform = 3.733   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.157  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.955   grad norm = 1.972   grad norm uniform = 35.382   loss each uniform = 7.192   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577
Best model saved at epoch 15


Epoch [16]:
Training:
Average incurred loss: 0.004  
Average sample loss: 0.004  
Average acc: 1.000  
Average grad norm: 0.142  
Average grad norm uniform: 36.141  
Average loss each uniform: 7.994  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2284]:	loss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.103   grad norm uniform = 35.344   loss each uniform = 8.347   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 141]:	loss = 0.032  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.993   grad norm = 1.020   grad norm uniform = 36.209   loss each uniform = 5.114   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 108]:	loss = 0.014  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.467   grad norm uniform = 36.062   loss each uniform = 5.466   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2262]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.112   grad norm uniform = 36.944   loss each uniform = 7.938   feat norm = 0.455  

Validation:
Average incurred loss: 0.594  
Average sample loss: 0.580  
Average acc: 0.815  
Average grad norm: 7.217  
Average grad norm uniform: 31.571  
Average loss each uniform: 5.552  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.049  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.983   grad norm = 0.965   grad norm uniform = 34.010   loss each uniform = 7.107   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.179  exp loss = 1.297  adjusted loss = 1.297  adv prob = 0.250000   acc = 0.627   grad norm = 14.283   grad norm uniform = 28.150   loss each uniform = 3.496   feat norm = 0.463  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.954  exp loss = 1.084  adjusted loss = 1.084  adv prob = 0.250000   acc = 0.729   grad norm = 10.538   grad norm uniform = 29.396   loss each uniform = 4.232   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.094  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.970   grad norm = 1.089   grad norm uniform = 37.169   loss each uniform = 8.615   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8148456811904907


Epoch [17]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.114  
Average grad norm uniform: 36.164  
Average loss each uniform: 8.106  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2287]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.065   grad norm uniform = 35.481   loss each uniform = 8.531   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.015  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000   grad norm = 0.566   grad norm uniform = 37.213   loss each uniform = 5.462   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.012  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000   grad norm = 0.405   grad norm uniform = 36.339   loss each uniform = 5.474   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2252]:	loss = 0.003  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.122   grad norm uniform = 36.786   loss each uniform = 7.974   feat norm = 0.453  

Validation:
Average incurred loss: 0.437  
Average sample loss: 0.421  
Average acc: 0.876  
Average grad norm: 5.156  
Average grad norm uniform: 32.621  
Average loss each uniform: 6.370  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.274   grad norm uniform = 35.116   loss each uniform = 8.895   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.546  exp loss = 0.616  adjusted loss = 0.616  adv prob = 0.250000   acc = 0.824   grad norm = 7.558   grad norm uniform = 30.950   loss each uniform = 4.416   feat norm = 0.460  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.787  exp loss = 1.928  adjusted loss = 1.928  adv prob = 0.250000   acc = 0.571   grad norm = 16.568   grad norm uniform = 27.786   loss each uniform = 3.762   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.205  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.947   grad norm = 2.469   grad norm uniform = 34.550   loss each uniform = 6.956   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299
Best model saved at epoch 17


Epoch [18]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.108  
Average grad norm uniform: 36.237  
Average loss each uniform: 8.240  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2289]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.080   grad norm uniform = 35.651   loss each uniform = 8.518   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.022  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000   grad norm = 0.816   grad norm uniform = 36.433   loss each uniform = 5.173   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.012  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.418   grad norm uniform = 35.233   loss each uniform = 5.399   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2279]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 36.865   loss each uniform = 8.256   feat norm = 0.453  

Validation:
Average incurred loss: 0.529  
Average sample loss: 0.514  
Average acc: 0.842  
Average grad norm: 6.283  
Average grad norm uniform: 32.180  
Average loss each uniform: 6.006  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.607   grad norm uniform = 34.876   loss each uniform = 8.061   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.935  exp loss = 1.021  adjusted loss = 1.021  adv prob = 0.250000   acc = 0.721   grad norm = 11.534   grad norm uniform = 29.231   loss each uniform = 3.853   feat norm = 0.462  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.260  exp loss = 1.386  adjusted loss = 1.386  adv prob = 0.250000   acc = 0.639   grad norm = 12.611   grad norm uniform = 28.849   loss each uniform = 4.074   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.132  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.962   grad norm = 1.486   grad norm uniform = 36.380   loss each uniform = 8.262   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8423686027526855


Epoch [19]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.087  
Average grad norm uniform: 36.290  
Average loss each uniform: 8.312  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2213]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 35.806   loss each uniform = 8.856   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.337   grad norm uniform = 37.681   loss each uniform = 5.532   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.295   grad norm uniform = 35.997   loss each uniform = 5.554   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2335]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.094   grad norm uniform = 36.690   loss each uniform = 8.089   feat norm = 0.452  

Validation:
Average incurred loss: 0.480  
Average sample loss: 0.464  
Average acc: 0.862  
Average grad norm: 5.617  
Average grad norm uniform: 32.473  
Average loss each uniform: 6.322  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.371   grad norm uniform = 35.190   loss each uniform = 8.765   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.708  exp loss = 0.776  adjusted loss = 0.776  adv prob = 0.250000   acc = 0.781   grad norm = 9.199   grad norm uniform = 30.125   loss each uniform = 4.199   feat norm = 0.463  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.616  exp loss = 1.772  adjusted loss = 1.772  adv prob = 0.250000   acc = 0.586   grad norm = 15.134   grad norm uniform = 28.440   loss each uniform = 3.889   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.170  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.962   grad norm = 1.971   grad norm uniform = 35.187   loss each uniform = 7.613   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [20]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.080  
Average grad norm uniform: 36.278  
Average loss each uniform: 8.533  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2254]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.059   grad norm uniform = 35.762   loss each uniform = 8.825   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.017  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000   grad norm = 0.628   grad norm uniform = 37.567   loss each uniform = 5.473   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.243   grad norm uniform = 35.771   loss each uniform = 5.904   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2295]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 36.740   loss each uniform = 8.552   feat norm = 0.451  

Validation:
Average incurred loss: 0.506  
Average sample loss: 0.491  
Average acc: 0.844  
Average grad norm: 6.004  
Average grad norm uniform: 32.433  
Average loss each uniform: 6.186  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.987   grad norm = 0.500   grad norm uniform = 35.183   loss each uniform = 8.434   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.838  exp loss = 0.934  adjusted loss = 0.934  adv prob = 0.250000   acc = 0.734   grad norm = 10.560   grad norm uniform = 29.733   loss each uniform = 4.034   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.405  exp loss = 1.541  adjusted loss = 1.541  adv prob = 0.250000   acc = 0.609   grad norm = 13.729   grad norm uniform = 28.860   loss each uniform = 4.013   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.142  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.962   grad norm = 1.645   grad norm uniform = 35.812   loss each uniform = 8.007   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8440366983413696


Epoch [21]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.086  
Average grad norm uniform: 36.275  
Average loss each uniform: 8.570  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2250]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.069   grad norm uniform = 35.716   loss each uniform = 8.863   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.017  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000   grad norm = 0.624   grad norm uniform = 37.849   loss each uniform = 5.634   feat norm = 0.489  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 121]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.256   grad norm uniform = 35.843   loss each uniform = 5.678   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2296]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.063   grad norm uniform = 36.758   loss each uniform = 8.598   feat norm = 0.451  

Validation:
Average incurred loss: 0.593  
Average sample loss: 0.578  
Average acc: 0.826  
Average grad norm: 6.803  
Average grad norm uniform: 32.118  
Average loss each uniform: 6.029  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.035  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.985   grad norm = 0.676   grad norm uniform = 34.722   loss each uniform = 8.028   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.108  exp loss = 1.213  adjusted loss = 1.213  adv prob = 0.250000   acc = 0.674   grad norm = 12.971   grad norm uniform = 28.995   loss each uniform = 3.795   feat norm = 0.462  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.227  exp loss = 1.375  adjusted loss = 1.375  adv prob = 0.250000   acc = 0.654   grad norm = 12.259   grad norm uniform = 29.362   loss each uniform = 4.198   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.117  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 0.970   grad norm = 1.254   grad norm uniform = 36.674   loss each uniform = 8.673   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8256880640983582


Epoch [22]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.074  
Average grad norm uniform: 36.319  
Average loss each uniform: 8.635  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2308]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.045   grad norm uniform = 35.641   loss each uniform = 9.037   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 89]:	loss = 0.025  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 0.989   grad norm = 0.738   grad norm uniform = 37.710   loss each uniform = 5.761   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 139]:	loss = 0.005  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.182   grad norm uniform = 36.443   loss each uniform = 6.111   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2259]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.070   grad norm uniform = 36.949   loss each uniform = 8.494   feat norm = 0.454  

Validation:
Average incurred loss: 0.469  
Average sample loss: 0.453  
Average acc: 0.869  
Average grad norm: 5.445  
Average grad norm uniform: 33.085  
Average loss each uniform: 6.542  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.362   grad norm uniform = 35.583   loss each uniform = 9.068   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.663  exp loss = 0.744  adjusted loss = 0.744  adv prob = 0.250000   acc = 0.805   grad norm = 8.634   grad norm uniform = 30.888   loss each uniform = 4.385   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.668  exp loss = 1.783  adjusted loss = 1.783  adv prob = 0.250000   acc = 0.594   grad norm = 15.465   grad norm uniform = 29.273   loss each uniform = 4.023   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.947   grad norm = 2.101   grad norm uniform = 35.818   loss each uniform = 7.752   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8690575957298279


Epoch [23]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.053  
Average grad norm uniform: 36.337  
Average loss each uniform: 8.718  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2284]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 35.623   loss each uniform = 9.144   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 105]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.296   grad norm uniform = 37.854   loss each uniform = 5.922   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.219   grad norm uniform = 36.233   loss each uniform = 5.646   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2291]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 36.985   loss each uniform = 8.576   feat norm = 0.454  

Validation:
Average incurred loss: 0.480  
Average sample loss: 0.464  
Average acc: 0.864  
Average grad norm: 5.534  
Average grad norm uniform: 33.158  
Average loss each uniform: 6.564  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.989   grad norm = 0.353   grad norm uniform = 35.703   loss each uniform = 9.085   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.702  exp loss = 0.790  adjusted loss = 0.790  adv prob = 0.250000   acc = 0.790   grad norm = 8.970   grad norm uniform = 30.988   loss each uniform = 4.406   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.638  exp loss = 1.758  adjusted loss = 1.758  adv prob = 0.250000   acc = 0.602   grad norm = 15.134   grad norm uniform = 29.269   loss each uniform = 4.013   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.947   grad norm = 2.084   grad norm uniform = 35.711   loss each uniform = 7.825   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8640534281730652


Epoch [24]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.057  
Average grad norm uniform: 36.349  
Average loss each uniform: 8.805  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2254]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 35.769   loss each uniform = 9.250   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 104]:	loss = 0.010  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.376   grad norm uniform = 37.643   loss each uniform = 5.905   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 131]:	loss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.215   grad norm uniform = 36.386   loss each uniform = 5.935   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2306]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 36.855   loss each uniform = 8.665   feat norm = 0.453  

Validation:
Average incurred loss: 0.499  
Average sample loss: 0.483  
Average acc: 0.856  
Average grad norm: 5.688  
Average grad norm uniform: 32.990  
Average loss each uniform: 6.571  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.374   grad norm uniform = 35.529   loss each uniform = 9.064   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.761  exp loss = 0.839  adjusted loss = 0.839  adv prob = 0.250000   acc = 0.768   grad norm = 9.497   grad norm uniform = 30.698   loss each uniform = 4.348   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.607  exp loss = 1.739  adjusted loss = 1.739  adv prob = 0.250000   acc = 0.594   grad norm = 14.790   grad norm uniform = 29.230   loss each uniform = 4.091   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.955   grad norm = 1.896   grad norm uniform = 35.872   loss each uniform = 8.083   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [25]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.058  
Average grad norm uniform: 36.340  
Average loss each uniform: 8.849  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2291]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.046   grad norm uniform = 35.684   loss each uniform = 9.095   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 143]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.447   grad norm uniform = 37.656   loss each uniform = 5.505   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.135   grad norm uniform = 36.293   loss each uniform = 6.430   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2241]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 36.929   loss each uniform = 8.939   feat norm = 0.452  

Validation:
Average incurred loss: 0.485  
Average sample loss: 0.468  
Average acc: 0.862  
Average grad norm: 5.490  
Average grad norm uniform: 32.496  
Average loss each uniform: 6.497  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.989   grad norm = 0.337   grad norm uniform = 35.035   loss each uniform = 8.981   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.713  exp loss = 0.785  adjusted loss = 0.785  adv prob = 0.250000   acc = 0.788   grad norm = 8.960   grad norm uniform = 30.215   loss each uniform = 4.320   feat norm = 0.461  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.638  exp loss = 1.777  adjusted loss = 1.777  adv prob = 0.250000   acc = 0.586   grad norm = 14.898   grad norm uniform = 28.761   loss each uniform = 4.034   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.955   grad norm = 2.023   grad norm uniform = 35.308   loss each uniform = 7.868   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8623853325843811


Epoch [26]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.067  
Average grad norm uniform: 36.304  
Average loss each uniform: 8.892  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2292]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 35.650   loss each uniform = 9.189   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000   grad norm = 0.465   grad norm uniform = 38.204   loss each uniform = 5.678   feat norm = 0.490  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.200   grad norm uniform = 36.317   loss each uniform = 6.363   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2254]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.056   grad norm uniform = 36.863   loss each uniform = 8.906   feat norm = 0.452  

Validation:
Average incurred loss: 0.520  
Average sample loss: 0.505  
Average acc: 0.847  
Average grad norm: 5.911  
Average grad norm uniform: 32.550  
Average loss each uniform: 6.411  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.512   grad norm uniform = 35.012   loss each uniform = 8.687   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.877  exp loss = 0.977  adjusted loss = 0.977  adv prob = 0.250000   acc = 0.732   grad norm = 10.574   grad norm uniform = 30.012   loss each uniform = 4.147   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.389  exp loss = 1.527  adjusted loss = 1.527  adv prob = 0.250000   acc = 0.632   grad norm = 12.909   grad norm uniform = 29.301   loss each uniform = 4.267   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.139  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.962   grad norm = 1.533   grad norm uniform = 36.041   loss each uniform = 8.500   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [27]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.059  
Average grad norm uniform: 36.326  
Average loss each uniform: 8.966  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2263]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 35.626   loss each uniform = 9.392   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.419   grad norm uniform = 37.714   loss each uniform = 5.791   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.198   grad norm uniform = 36.383   loss each uniform = 6.216   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2277]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.055   grad norm uniform = 36.942   loss each uniform = 8.874   feat norm = 0.453  

Validation:
Average incurred loss: 0.507  
Average sample loss: 0.492  
Average acc: 0.853  
Average grad norm: 5.717  
Average grad norm uniform: 32.729  
Average loss each uniform: 6.515  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.428   grad norm uniform = 35.112   loss each uniform = 8.889   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.811  exp loss = 0.898  adjusted loss = 0.898  adv prob = 0.250000   acc = 0.755   grad norm = 9.813   grad norm uniform = 30.290   loss each uniform = 4.283   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.504  exp loss = 1.650  adjusted loss = 1.650  adv prob = 0.250000   acc = 0.609   grad norm = 13.904   grad norm uniform = 29.725   loss each uniform = 4.198   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.157  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.962   grad norm = 1.749   grad norm uniform = 35.912   loss each uniform = 8.321   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8532110452651978


Epoch [28]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.041  
Average grad norm uniform: 36.383  
Average loss each uniform: 9.069  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2317]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 35.749   loss each uniform = 9.334   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.276   grad norm uniform = 38.397   loss each uniform = 5.989   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 106]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.134   grad norm uniform = 36.150   loss each uniform = 6.314   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2258]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 36.943   loss each uniform = 9.082   feat norm = 0.452  

Validation:
Average incurred loss: 0.553  
Average sample loss: 0.538  
Average acc: 0.844  
Average grad norm: 6.124  
Average grad norm uniform: 32.347  
Average loss each uniform: 6.440  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.987   grad norm = 0.577   grad norm uniform = 34.657   loss each uniform = 8.615   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.990  exp loss = 1.082  adjusted loss = 1.082  adv prob = 0.250000   acc = 0.717   grad norm = 11.391   grad norm uniform = 29.752   loss each uniform = 4.127   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.285  exp loss = 1.433  adjusted loss = 1.433  adv prob = 0.250000   acc = 0.662   grad norm = 11.954   grad norm uniform = 29.206   loss each uniform = 4.391   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.128  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.970   grad norm = 1.319   grad norm uniform = 36.471   loss each uniform = 8.955   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8440366983413696


Epoch [29]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.054  
Average grad norm uniform: 36.365  
Average loss each uniform: 9.093  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2306]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 35.754   loss each uniform = 9.430   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 100]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.265   grad norm uniform = 38.635   loss each uniform = 6.240   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.139   grad norm uniform = 37.337   loss each uniform = 6.637   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2277]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 36.836   loss each uniform = 8.997   feat norm = 0.452  

Validation:
Average incurred loss: 0.559  
Average sample loss: 0.544  
Average acc: 0.841  
Average grad norm: 6.196  
Average grad norm uniform: 32.418  
Average loss each uniform: 6.451  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.987   grad norm = 0.548   grad norm uniform = 34.737   loss each uniform = 8.708   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.984  exp loss = 1.076  adjusted loss = 1.076  adv prob = 0.250000   acc = 0.717   grad norm = 11.390   grad norm uniform = 29.913   loss each uniform = 4.134   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.359  exp loss = 1.493  adjusted loss = 1.493  adv prob = 0.250000   acc = 0.632   grad norm = 12.617   grad norm uniform = 29.234   loss each uniform = 4.319   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.133  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 0.970   grad norm = 1.407   grad norm uniform = 36.231   loss each uniform = 8.779   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.840700626373291


Epoch [30]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.051  
Average grad norm uniform: 36.365  
Average loss each uniform: 9.125  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2257]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 35.684   loss each uniform = 9.642   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.272   grad norm uniform = 38.167   loss each uniform = 6.421   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.171   grad norm uniform = 36.285   loss each uniform = 6.180   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2295]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 36.943   loss each uniform = 8.915   feat norm = 0.453  

Validation:
Average incurred loss: 0.517  
Average sample loss: 0.500  
Average acc: 0.859  
Average grad norm: 5.680  
Average grad norm uniform: 32.879  
Average loss each uniform: 6.740  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.391   grad norm uniform = 35.136   loss each uniform = 9.260   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.800  exp loss = 0.891  adjusted loss = 0.891  adv prob = 0.250000   acc = 0.777   grad norm = 9.595   grad norm uniform = 30.753   loss each uniform = 4.444   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.632  exp loss = 1.759  adjusted loss = 1.759  adv prob = 0.250000   acc = 0.594   grad norm = 14.481   grad norm uniform = 29.350   loss each uniform = 4.222   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.156  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.955   grad norm = 1.733   grad norm uniform = 35.930   loss each uniform = 8.458   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8590492606163025


Epoch [31]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.041  
Average grad norm uniform: 36.373  
Average loss each uniform: 9.224  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2263]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 35.723   loss each uniform = 9.737   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.006  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.230   grad norm uniform = 38.512   loss each uniform = 6.633   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.156   grad norm uniform = 36.642   loss each uniform = 6.415   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2295]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 36.889   loss each uniform = 8.997   feat norm = 0.453  

Validation:
Average incurred loss: 0.577  
Average sample loss: 0.561  
Average acc: 0.838  
Average grad norm: 6.297  
Average grad norm uniform: 32.577  
Average loss each uniform: 6.508  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.989   grad norm = 0.566   grad norm uniform = 34.831   loss each uniform = 8.743   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.030  exp loss = 1.137  adjusted loss = 1.137  adv prob = 0.250000   acc = 0.702   grad norm = 11.675   grad norm uniform = 30.098   loss each uniform = 4.167   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.363  exp loss = 1.513  adjusted loss = 1.513  adv prob = 0.250000   acc = 0.654   grad norm = 12.543   grad norm uniform = 29.528   loss each uniform = 4.381   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.128  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.970   grad norm = 1.332   grad norm uniform = 36.398   loss each uniform = 8.989   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8381985425949097


Epoch [32]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.062  
Average grad norm uniform: 36.370  
Average loss each uniform: 9.239  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2298]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 35.786   loss each uniform = 9.604   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 109]:	loss = 0.013  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000   grad norm = 0.488   grad norm uniform = 37.445   loss each uniform = 6.050   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.136   grad norm uniform = 36.582   loss each uniform = 6.858   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2271]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.056   grad norm uniform = 36.899   loss each uniform = 9.144   feat norm = 0.453  

Validation:
Average incurred loss: 0.521  
Average sample loss: 0.505  
Average acc: 0.856  
Average grad norm: 5.637  
Average grad norm uniform: 32.892  
Average loss each uniform: 6.809  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.411   grad norm uniform = 35.270   loss each uniform = 9.340   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.812  exp loss = 0.906  adjusted loss = 0.906  adv prob = 0.250000   acc = 0.766   grad norm = 9.573   grad norm uniform = 30.652   loss each uniform = 4.495   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.622  exp loss = 1.757  adjusted loss = 1.757  adv prob = 0.250000   acc = 0.602   grad norm = 14.120   grad norm uniform = 29.599   loss each uniform = 4.309   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.158  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.955   grad norm = 1.713   grad norm uniform = 35.678   loss each uniform = 8.529   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [33]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.032  
Average grad norm uniform: 36.413  
Average loss each uniform: 9.336  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2218]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 35.872   loss each uniform = 9.996   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.146   grad norm uniform = 38.704   loss each uniform = 6.831   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 128]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.121   grad norm uniform = 36.604   loss each uniform = 6.382   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2336]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 36.806   loss each uniform = 8.992   feat norm = 0.451  

Validation:
Average incurred loss: 0.486  
Average sample loss: 0.469  
Average acc: 0.872  
Average grad norm: 5.171  
Average grad norm uniform: 33.146  
Average loss each uniform: 7.059  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.295   grad norm uniform = 35.344   loss each uniform = 9.797   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.650  exp loss = 0.725  adjusted loss = 0.725  adv prob = 0.250000   acc = 0.813   grad norm = 7.897   grad norm uniform = 31.623   loss each uniform = 4.839   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.857  exp loss = 2.006  adjusted loss = 2.006  adv prob = 0.250000   acc = 0.579   grad norm = 15.680   grad norm uniform = 28.919   loss each uniform = 4.205   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.947   grad norm = 2.233   grad norm uniform = 34.992   loss each uniform = 8.080   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8723937273025513


Epoch [34]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.046  
Average grad norm uniform: 36.382  
Average loss each uniform: 9.397  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2306]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 35.743   loss each uniform = 9.650   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.009  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.340   grad norm uniform = 38.161   loss each uniform = 6.399   feat norm = 0.486  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.115   grad norm uniform = 36.530   loss each uniform = 6.665   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2243]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.933   loss each uniform = 9.451   feat norm = 0.452  

Validation:
Average incurred loss: 0.495  
Average sample loss: 0.478  
Average acc: 0.869  
Average grad norm: 5.295  
Average grad norm uniform: 33.257  
Average loss each uniform: 7.027  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.318   grad norm uniform = 35.489   loss each uniform = 9.727   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.683  exp loss = 0.757  adjusted loss = 0.757  adv prob = 0.250000   acc = 0.809   grad norm = 8.247   grad norm uniform = 31.634   loss each uniform = 4.793   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.817  exp loss = 1.948  adjusted loss = 1.948  adv prob = 0.250000   acc = 0.579   grad norm = 15.550   grad norm uniform = 29.033   loss each uniform = 4.216   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 0.940   grad norm = 2.173   grad norm uniform = 35.334   loss each uniform = 8.179   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [35]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.034  
Average grad norm uniform: 36.421  
Average loss each uniform: 9.427  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2261]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 35.679   loss each uniform = 9.951   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.151   grad norm uniform = 38.415   loss each uniform = 6.508   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 138]:	loss = 0.003  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.117   grad norm uniform = 36.796   loss each uniform = 6.456   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2272]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 37.028   loss each uniform = 9.245   feat norm = 0.454  

Validation:
Average incurred loss: 0.496  
Average sample loss: 0.479  
Average acc: 0.867  
Average grad norm: 5.235  
Average grad norm uniform: 32.872  
Average loss each uniform: 7.015  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.343   grad norm uniform = 34.931   loss each uniform = 9.626   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.711  exp loss = 0.784  adjusted loss = 0.784  adv prob = 0.250000   acc = 0.798   grad norm = 8.360   grad norm uniform = 31.255   loss each uniform = 4.782   feat norm = 0.461  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.735  exp loss = 1.891  adjusted loss = 1.891  adv prob = 0.250000   acc = 0.594   grad norm = 14.693   grad norm uniform = 29.030   loss each uniform = 4.276   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.955   grad norm = 2.007   grad norm uniform = 35.146   loss each uniform = 8.408   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8673895597457886


Epoch [36]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.036  
Average grad norm uniform: 36.435  
Average loss each uniform: 9.497  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2275]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 35.829   loss each uniform = 9.893   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.005  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.204   grad norm uniform = 38.092   loss each uniform = 6.587   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 108]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.171   grad norm uniform = 35.892   loss each uniform = 6.627   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2285]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 36.971   loss each uniform = 9.399   feat norm = 0.453  

Validation:
Average incurred loss: 0.573  
Average sample loss: 0.556  
Average acc: 0.844  
Average grad norm: 6.112  
Average grad norm uniform: 32.986  
Average loss each uniform: 6.757  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.989   grad norm = 0.530   grad norm uniform = 35.098   loss each uniform = 9.105   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.997  exp loss = 1.088  adjusted loss = 1.088  adv prob = 0.250000   acc = 0.723   grad norm = 11.097   grad norm uniform = 30.652   loss each uniform = 4.357   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.433  exp loss = 1.562  adjusted loss = 1.562  adv prob = 0.250000   acc = 0.639   grad norm = 12.874   grad norm uniform = 30.156   loss each uniform = 4.500   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.962   grad norm = 1.481   grad norm uniform = 36.572   loss each uniform = 9.185   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8440367579460144


Epoch [37]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.028  
Average grad norm uniform: 36.425  
Average loss each uniform: 9.549  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2312]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 35.712   loss each uniform = 9.816   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.192   grad norm uniform = 38.319   loss each uniform = 6.201   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 36.446   loss each uniform = 6.923   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2225]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 37.051   loss each uniform = 9.620   feat norm = 0.453  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.520  
Average acc: 0.850  
Average grad norm: 5.816  
Average grad norm uniform: 32.979  
Average loss each uniform: 6.822  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.991   grad norm = 0.421   grad norm uniform = 35.142   loss each uniform = 9.368   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.848  exp loss = 0.935  adjusted loss = 0.935  adv prob = 0.250000   acc = 0.749   grad norm = 9.937   grad norm uniform = 30.934   loss each uniform = 4.487   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.643  exp loss = 1.776  adjusted loss = 1.776  adv prob = 0.250000   acc = 0.594   grad norm = 14.428   grad norm uniform = 29.550   loss each uniform = 4.290   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.160  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.962   grad norm = 1.713   grad norm uniform = 35.977   loss each uniform = 8.601   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8498749136924744


Epoch [38]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.031  
Average grad norm uniform: 36.425  
Average loss each uniform: 9.581  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2208]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 35.929   loss each uniform = 10.265   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.154   grad norm uniform = 39.085   loss each uniform = 7.036   feat norm = 0.491  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.145   grad norm uniform = 35.960   loss each uniform = 6.302   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2340]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 36.778   loss each uniform = 9.242   feat norm = 0.451  

Validation:
Average incurred loss: 0.506  
Average sample loss: 0.490  
Average acc: 0.866  
Average grad norm: 5.326  
Average grad norm uniform: 33.218  
Average loss each uniform: 7.120  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.353   grad norm uniform = 35.308   loss each uniform = 9.761   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.750  exp loss = 0.829  adjusted loss = 0.829  adv prob = 0.250000   acc = 0.796   grad norm = 8.697   grad norm uniform = 31.557   loss each uniform = 4.805   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.696  exp loss = 1.841  adjusted loss = 1.841  adv prob = 0.250000   acc = 0.586   grad norm = 14.349   grad norm uniform = 29.333   loss each uniform = 4.390   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.947   grad norm = 1.956   grad norm uniform = 35.586   loss each uniform = 8.682   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [39]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.026  
Average grad norm uniform: 36.449  
Average loss each uniform: 9.662  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2305]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 35.801   loss each uniform = 9.891   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.146   grad norm uniform = 38.407   loss each uniform = 6.616   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 106]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.083   grad norm uniform = 36.384   loss each uniform = 6.807   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2252]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 37.000   loss each uniform = 9.740   feat norm = 0.452  

Validation:
Average incurred loss: 0.563  
Average sample loss: 0.546  
Average acc: 0.845  
Average grad norm: 5.980  
Average grad norm uniform: 33.198  
Average loss each uniform: 6.870  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.491   grad norm uniform = 35.374   loss each uniform = 9.260   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.953  exp loss = 1.049  adjusted loss = 1.049  adv prob = 0.250000   acc = 0.727   grad norm = 10.694   grad norm uniform = 30.945   loss each uniform = 4.461   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.499  exp loss = 1.636  adjusted loss = 1.636  adv prob = 0.250000   acc = 0.632   grad norm = 13.201   grad norm uniform = 29.982   loss each uniform = 4.549   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.150  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.962   grad norm = 1.522   grad norm uniform = 36.669   loss each uniform = 9.238   feat norm = 0.465  
Current lr: 0.001000
Current validation accuracy: 0.8448707461357117


Epoch [40]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.034  
Average grad norm uniform: 36.417  
Average loss each uniform: 9.665  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2287]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 35.736   loss each uniform = 10.015   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.006  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000   grad norm = 0.226   grad norm uniform = 39.582   loss each uniform = 7.074   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.129   grad norm uniform = 36.226   loss each uniform = 6.816   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2286]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.959   loss each uniform = 9.579   feat norm = 0.452  

Validation:
Average incurred loss: 0.637  
Average sample loss: 0.620  
Average acc: 0.832  
Average grad norm: 6.770  
Average grad norm uniform: 32.774  
Average loss each uniform: 6.632  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.036  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.983   grad norm = 0.674   grad norm uniform = 34.907   loss each uniform = 8.825   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.202  exp loss = 1.305  adjusted loss = 1.305  adv prob = 0.250000   acc = 0.685   grad norm = 13.058   grad norm uniform = 30.390   loss each uniform = 4.173   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.279  exp loss = 1.408  adjusted loss = 1.408  adv prob = 0.250000   acc = 0.677   grad norm = 11.751   grad norm uniform = 29.373   loss each uniform = 4.573   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.122  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.970   grad norm = 1.166   grad norm uniform = 37.036   loss each uniform = 9.608   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8315262794494629


Epoch [41]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.024  
Average grad norm uniform: 36.467  
Average loss each uniform: 9.726  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2254]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 35.901   loss each uniform = 10.207   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.112   grad norm uniform = 38.921   loss each uniform = 6.869   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.090   grad norm uniform = 36.339   loss each uniform = 6.756   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2301]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.895   loss each uniform = 9.558   feat norm = 0.451  

Validation:
Average incurred loss: 0.512  
Average sample loss: 0.495  
Average acc: 0.868  
Average grad norm: 5.339  
Average grad norm uniform: 33.526  
Average loss each uniform: 7.202  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.350   grad norm uniform = 35.620   loss each uniform = 9.907   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.747  exp loss = 0.841  adjusted loss = 0.841  adv prob = 0.250000   acc = 0.798   grad norm = 8.628   grad norm uniform = 31.848   loss each uniform = 4.887   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.754  exp loss = 1.917  adjusted loss = 1.917  adv prob = 0.250000   acc = 0.594   grad norm = 14.724   grad norm uniform = 29.902   loss each uniform = 4.403   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.185  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 0.955   grad norm = 1.946   grad norm uniform = 35.681   loss each uniform = 8.615   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [42]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.027  
Average grad norm uniform: 36.448  
Average loss each uniform: 9.743  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2273]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.757   loss each uniform = 10.141   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.144   grad norm uniform = 39.202   loss each uniform = 6.742   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 128]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 36.260   loss each uniform = 7.066   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2274]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 37.005   loss each uniform = 9.655   feat norm = 0.452  

Validation:
Average incurred loss: 0.570  
Average sample loss: 0.552  
Average acc: 0.847  
Average grad norm: 5.957  
Average grad norm uniform: 33.176  
Average loss each uniform: 7.014  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.465   grad norm uniform = 35.330   loss each uniform = 9.562   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.948  exp loss = 1.046  adjusted loss = 1.046  adv prob = 0.250000   acc = 0.740   grad norm = 10.547   grad norm uniform = 31.060   loss each uniform = 4.558   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.584  exp loss = 1.729  adjusted loss = 1.729  adv prob = 0.250000   acc = 0.609   grad norm = 13.626   grad norm uniform = 29.913   loss each uniform = 4.507   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.149  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.962   grad norm = 1.491   grad norm uniform = 36.292   loss each uniform = 9.181   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.847372829914093


Epoch [43]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.023  
Average grad norm uniform: 36.438  
Average loss each uniform: 9.800  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2253]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 35.898   loss each uniform = 10.253   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.111   grad norm uniform = 38.691   loss each uniform = 6.957   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.074   grad norm uniform = 36.923   loss each uniform = 7.134   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2310]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.825   loss each uniform = 9.634   feat norm = 0.451  

Validation:
Average incurred loss: 0.513  
Average sample loss: 0.497  
Average acc: 0.865  
Average grad norm: 5.286  
Average grad norm uniform: 33.367  
Average loss each uniform: 7.218  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.368   grad norm uniform = 35.389   loss each uniform = 9.892   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.755  exp loss = 0.842  adjusted loss = 0.842  adv prob = 0.250000   acc = 0.790   grad norm = 8.582   grad norm uniform = 31.775   loss each uniform = 4.886   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.727  exp loss = 1.880  adjusted loss = 1.880  adv prob = 0.250000   acc = 0.602   grad norm = 14.345   grad norm uniform = 29.649   loss each uniform = 4.457   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.955   grad norm = 1.951   grad norm uniform = 35.563   loss each uniform = 8.765   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8648874163627625


Epoch [44]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.486  
Average loss each uniform: 9.800  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2239]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.010   loss each uniform = 10.303   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.105   grad norm uniform = 39.074   loss each uniform = 7.108   feat norm = 0.490  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.087   grad norm uniform = 36.473   loss each uniform = 6.872   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2328]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.825   loss each uniform = 9.593   feat norm = 0.450  

Validation:
Average incurred loss: 0.556  
Average sample loss: 0.540  
Average acc: 0.848  
Average grad norm: 5.784  
Average grad norm uniform: 32.908  
Average loss each uniform: 7.012  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.414   grad norm uniform = 35.253   loss each uniform = 9.619   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.893  exp loss = 0.979  adjusted loss = 0.979  adv prob = 0.250000   acc = 0.747   grad norm = 10.009   grad norm uniform = 30.780   loss each uniform = 4.577   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.648  exp loss = 1.797  adjusted loss = 1.797  adv prob = 0.250000   acc = 0.594   grad norm = 13.977   grad norm uniform = 29.255   loss each uniform = 4.414   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.962   grad norm = 1.644   grad norm uniform = 35.788   loss each uniform = 8.994   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [45]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.027  
Average grad norm uniform: 36.443  
Average loss each uniform: 9.827  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2327]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 35.784   loss each uniform = 9.923   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.005  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.198   grad norm uniform = 38.238   loss each uniform = 6.596   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 131]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.061   grad norm uniform = 36.254   loss each uniform = 7.188   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2206]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 37.043   loss each uniform = 10.074   feat norm = 0.452  

Validation:
Average incurred loss: 0.618  
Average sample loss: 0.603  
Average acc: 0.837  
Average grad norm: 6.373  
Average grad norm uniform: 32.903  
Average loss each uniform: 6.826  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.987   grad norm = 0.629   grad norm uniform = 35.027   loss each uniform = 9.055   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.145  exp loss = 1.262  adjusted loss = 1.262  adv prob = 0.250000   acc = 0.700   grad norm = 12.087   grad norm uniform = 30.571   loss each uniform = 4.362   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.310  exp loss = 1.455  adjusted loss = 1.455  adv prob = 0.250000   acc = 0.654   grad norm = 11.721   grad norm uniform = 29.869   loss each uniform = 4.727   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.121  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.970   grad norm = 1.176   grad norm uniform = 36.652   loss each uniform = 9.733   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8365304470062256


Epoch [46]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.029  
Average grad norm uniform: 36.463  
Average loss each uniform: 9.906  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2297]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 35.768   loss each uniform = 10.249   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.005  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.190   grad norm uniform = 39.152   loss each uniform = 6.900   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.069   grad norm uniform = 36.297   loss each uniform = 7.067   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2271]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 37.041   loss each uniform = 9.851   feat norm = 0.453  

Validation:
Average incurred loss: 0.577  
Average sample loss: 0.561  
Average acc: 0.845  
Average grad norm: 5.966  
Average grad norm uniform: 32.678  
Average loss each uniform: 6.932  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.987   grad norm = 0.518   grad norm uniform = 34.867   loss each uniform = 9.338   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.010  exp loss = 1.119  adjusted loss = 1.119  adv prob = 0.250000   acc = 0.721   grad norm = 10.940   grad norm uniform = 30.434   loss each uniform = 4.466   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.416  exp loss = 1.566  adjusted loss = 1.566  adv prob = 0.250000   acc = 0.654   grad norm = 12.310   grad norm uniform = 29.330   loss each uniform = 4.595   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.136  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.970   grad norm = 1.321   grad norm uniform = 36.205   loss each uniform = 9.461   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8448707461357117


Epoch [47]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.469  
Average loss each uniform: 9.894  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2204]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.871   loss each uniform = 10.589   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 137]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.094   grad norm uniform = 39.719   loss each uniform = 7.391   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.082   grad norm uniform = 36.771   loss each uniform = 6.833   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2338]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.828   loss each uniform = 9.538   feat norm = 0.451  

Validation:
Average incurred loss: 0.509  
Average sample loss: 0.491  
Average acc: 0.873  
Average grad norm: 5.117  
Average grad norm uniform: 33.981  
Average loss each uniform: 7.513  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.265   grad norm uniform = 35.936   loss each uniform = 10.444   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.643  exp loss = 0.710  adjusted loss = 0.710  adv prob = 0.250000   acc = 0.815   grad norm = 7.556   grad norm uniform = 32.700   loss each uniform = 5.192   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.065  exp loss = 2.185  adjusted loss = 2.185  adv prob = 0.250000   acc = 0.579   grad norm = 16.302   grad norm uniform = 29.734   loss each uniform = 4.431   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.234  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.947   grad norm = 2.419   grad norm uniform = 35.854   loss each uniform = 8.434   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485


Epoch [48]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.031  
Average grad norm uniform: 36.433  
Average loss each uniform: 9.927  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2245]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.901   loss each uniform = 10.447   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.009  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000   grad norm = 0.326   grad norm uniform = 38.868   loss each uniform = 7.298   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.115   grad norm uniform = 36.160   loss each uniform = 6.717   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2307]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.839   loss each uniform = 9.729   feat norm = 0.451  

Validation:
Average incurred loss: 0.612  
Average sample loss: 0.595  
Average acc: 0.841  
Average grad norm: 6.220  
Average grad norm uniform: 32.561  
Average loss each uniform: 6.876  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.987   grad norm = 0.591   grad norm uniform = 34.661   loss each uniform = 9.125   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.128  exp loss = 1.228  adjusted loss = 1.228  adv prob = 0.250000   acc = 0.706   grad norm = 11.817   grad norm uniform = 30.271   loss each uniform = 4.383   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.320  exp loss = 1.469  adjusted loss = 1.469  adv prob = 0.250000   acc = 0.669   grad norm = 11.407   grad norm uniform = 29.514   loss each uniform = 4.764   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.970   grad norm = 1.188   grad norm uniform = 36.260   loss each uniform = 9.825   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.840700626373291


Epoch [49]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.032  
Average grad norm uniform: 36.396  
Average loss each uniform: 9.885  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2302]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 35.631   loss each uniform = 10.159   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 141]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.144   grad norm uniform = 39.348   loss each uniform = 7.174   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 121]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 36.368   loss each uniform = 7.315   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2231]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 37.001   loss each uniform = 9.914   feat norm = 0.453  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.528  
Average acc: 0.859  
Average grad norm: 5.578  
Average grad norm uniform: 33.135  
Average loss each uniform: 7.177  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.442   grad norm uniform = 35.136   loss each uniform = 9.715   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.887  exp loss = 0.972  adjusted loss = 0.972  adv prob = 0.250000   acc = 0.766   grad norm = 9.685   grad norm uniform = 31.251   loss each uniform = 4.770   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.562  exp loss = 1.710  adjusted loss = 1.710  adv prob = 0.250000   acc = 0.624   grad norm = 13.219   grad norm uniform = 29.637   loss each uniform = 4.581   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.962   grad norm = 1.580   grad norm uniform = 36.205   loss each uniform = 9.297   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [50]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.035  
Average grad norm uniform: 36.407  
Average loss each uniform: 9.907  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2274]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 35.693   loss each uniform = 10.334   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 139]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.093   grad norm uniform = 38.642   loss each uniform = 7.305   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 131]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.107   grad norm uniform = 36.124   loss each uniform = 6.922   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2251]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 37.008   loss each uniform = 9.809   feat norm = 0.452  

Validation:
Average incurred loss: 0.551  
Average sample loss: 0.534  
Average acc: 0.857  
Average grad norm: 5.634  
Average grad norm uniform: 33.393  
Average loss each uniform: 7.276  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.404   grad norm uniform = 35.528   loss each uniform = 9.953   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.863  exp loss = 0.944  adjusted loss = 0.944  adv prob = 0.250000   acc = 0.766   grad norm = 9.580   grad norm uniform = 31.538   loss each uniform = 4.833   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.702  exp loss = 1.855  adjusted loss = 1.855  adv prob = 0.250000   acc = 0.602   grad norm = 14.095   grad norm uniform = 29.877   loss each uniform = 4.546   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.164  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.962   grad norm = 1.715   grad norm uniform = 35.915   loss each uniform = 9.166   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [51]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.027  
Average grad norm uniform: 36.420  
Average loss each uniform: 9.983  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2311]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.743   loss each uniform = 10.329   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 109]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.113   grad norm uniform = 39.166   loss each uniform = 7.114   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 146]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.100   grad norm uniform = 36.302   loss each uniform = 6.945   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2229]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.996   loss each uniform = 9.963   feat norm = 0.453  

Validation:
Average incurred loss: 0.508  
Average sample loss: 0.491  
Average acc: 0.871  
Average grad norm: 5.106  
Average grad norm uniform: 33.487  
Average loss each uniform: 7.451  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.275   grad norm uniform = 35.426   loss each uniform = 10.286   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.683  exp loss = 0.754  adjusted loss = 0.754  adv prob = 0.250000   acc = 0.813   grad norm = 7.815   grad norm uniform = 32.204   loss each uniform = 5.136   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.925  exp loss = 2.080  adjusted loss = 2.080  adv prob = 0.250000   acc = 0.571   grad norm = 15.431   grad norm uniform = 29.261   loss each uniform = 4.432   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.218  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.940   grad norm = 2.256   grad norm uniform = 35.401   loss each uniform = 8.628   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [52]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.017  
Average grad norm uniform: 36.474  
Average loss each uniform: 10.060  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2286]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 35.807   loss each uniform = 10.432   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 40.203   loss each uniform = 7.482   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.055   grad norm uniform = 36.710   loss each uniform = 7.303   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2266]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.946   loss each uniform = 9.970   feat norm = 0.452  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.548  
Average acc: 0.848  
Average grad norm: 5.737  
Average grad norm uniform: 32.843  
Average loss each uniform: 7.156  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.445   grad norm uniform = 34.951   loss each uniform = 9.719   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.939  exp loss = 1.031  adjusted loss = 1.031  adv prob = 0.250000   acc = 0.738   grad norm = 10.126   grad norm uniform = 30.829   loss each uniform = 4.661   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.565  exp loss = 1.705  adjusted loss = 1.705  adv prob = 0.250000   acc = 0.617   grad norm = 13.186   grad norm uniform = 29.351   loss each uniform = 4.606   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.970   grad norm = 1.495   grad norm uniform = 35.991   loss each uniform = 9.446   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [53]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.020  
Average grad norm uniform: 36.472  
Average loss each uniform: 10.144  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.023   loss each uniform = 10.633   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 98]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.097   grad norm uniform = 38.688   loss each uniform = 7.268   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 36.424   loss each uniform = 7.198   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2301]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.822   loss each uniform = 9.950   feat norm = 0.450  

Validation:
Average incurred loss: 0.533  
Average sample loss: 0.516  
Average acc: 0.864  
Average grad norm: 5.367  
Average grad norm uniform: 33.271  
Average loss each uniform: 7.387  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.334   grad norm uniform = 35.426   loss each uniform = 10.177   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.788  exp loss = 0.872  adjusted loss = 0.872  adv prob = 0.250000   acc = 0.788   grad norm = 8.795   grad norm uniform = 31.613   loss each uniform = 4.965   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.801  exp loss = 1.969  adjusted loss = 1.969  adv prob = 0.250000   acc = 0.594   grad norm = 14.538   grad norm uniform = 29.461   loss each uniform = 4.523   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.955   grad norm = 1.863   grad norm uniform = 35.318   loss each uniform = 8.940   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [54]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.020  
Average grad norm uniform: 36.480  
Average loss each uniform: 10.133  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2265]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.001   loss each uniform = 10.571   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.139   grad norm uniform = 38.689   loss each uniform = 6.975   feat norm = 0.486  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.056   grad norm uniform = 36.735   loss each uniform = 7.473   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2303]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.831   loss each uniform = 9.989   feat norm = 0.450  

Validation:
Average incurred loss: 0.517  
Average sample loss: 0.500  
Average acc: 0.874  
Average grad norm: 5.130  
Average grad norm uniform: 33.942  
Average loss each uniform: 7.645  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.296   grad norm uniform = 35.991   loss each uniform = 10.560   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.716  exp loss = 0.790  adjusted loss = 0.790  adv prob = 0.250000   acc = 0.815   grad norm = 7.981   grad norm uniform = 32.657   loss each uniform = 5.269   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.904  exp loss = 2.071  adjusted loss = 2.071  adv prob = 0.250000   acc = 0.594   grad norm = 15.198   grad norm uniform = 29.672   loss each uniform = 4.528   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.203  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.947   grad norm = 2.044   grad norm uniform = 35.519   loss each uniform = 8.856   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8740617036819458


Epoch [55]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.453  
Average loss each uniform: 10.153  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2257]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 35.894   loss each uniform = 10.551   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.085   grad norm uniform = 39.534   loss each uniform = 7.360   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.056   grad norm uniform = 36.197   loss each uniform = 7.284   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.841   loss each uniform = 10.078   feat norm = 0.450  

Validation:
Average incurred loss: 0.515  
Average sample loss: 0.498  
Average acc: 0.869  
Average grad norm: 5.150  
Average grad norm uniform: 33.213  
Average loss each uniform: 7.389  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.322   grad norm uniform = 35.076   loss each uniform = 10.119   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.746  exp loss = 0.823  adjusted loss = 0.823  adv prob = 0.250000   acc = 0.800   grad norm = 8.268   grad norm uniform = 31.886   loss each uniform = 5.029   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.778  exp loss = 1.926  adjusted loss = 1.926  adv prob = 0.250000   acc = 0.586   grad norm = 14.391   grad norm uniform = 29.265   loss each uniform = 4.538   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.962   grad norm = 1.943   grad norm uniform = 35.266   loss each uniform = 8.925   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [56]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.018  
Average grad norm uniform: 36.500  
Average loss each uniform: 10.187  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2224]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.978   loss each uniform = 10.685   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 136]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.092   grad norm uniform = 39.567   loss each uniform = 7.766   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 111]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.068   grad norm uniform = 36.606   loss each uniform = 7.224   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2324]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.814   loss each uniform = 9.993   feat norm = 0.450  

Validation:
Average incurred loss: 0.582  
Average sample loss: 0.564  
Average acc: 0.852  
Average grad norm: 5.833  
Average grad norm uniform: 33.834  
Average loss each uniform: 7.405  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.470   grad norm uniform = 35.819   loss each uniform = 10.057   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.959  exp loss = 1.057  adjusted loss = 1.057  adv prob = 0.250000   acc = 0.749   grad norm = 10.254   grad norm uniform = 32.021   loss each uniform = 4.871   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.635  exp loss = 1.799  adjusted loss = 1.799  adv prob = 0.250000   acc = 0.624   grad norm = 13.485   grad norm uniform = 30.507   loss each uniform = 4.750   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.962   grad norm = 1.522   grad norm uniform = 36.545   loss each uniform = 9.628   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8523770570755005


Epoch [57]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.018  
Average grad norm uniform: 36.462  
Average loss each uniform: 10.199  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2207]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.014   loss each uniform = 10.802   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 39.671   loss each uniform = 7.536   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 111]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 36.809   loss each uniform = 7.210   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2353]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 36.698   loss each uniform = 9.915   feat norm = 0.449  

Validation:
Average incurred loss: 0.496  
Average sample loss: 0.478  
Average acc: 0.881  
Average grad norm: 4.784  
Average grad norm uniform: 33.931  
Average loss each uniform: 7.791  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.996   grad norm = 0.223   grad norm uniform = 35.721   loss each uniform = 10.762   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.593  exp loss = 0.655  adjusted loss = 0.655  adv prob = 0.250000   acc = 0.839   grad norm = 6.738   grad norm uniform = 33.018   loss each uniform = 5.540   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.110  exp loss = 2.279  adjusted loss = 2.279  adv prob = 0.250000   acc = 0.564   grad norm = 16.230   grad norm uniform = 29.467   loss each uniform = 4.526   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.252  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.940   grad norm = 2.507   grad norm uniform = 35.305   loss each uniform = 8.516   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8807339668273926
Best model saved at epoch 57


Epoch [58]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.029  
Average grad norm uniform: 36.442  
Average loss each uniform: 10.240  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 35.792   loss each uniform = 10.347   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.268   grad norm uniform = 39.079   loss each uniform = 7.049   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 37.026   loss each uniform = 7.827   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2226]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.946   loss each uniform = 10.436   feat norm = 0.451  

Validation:
Average incurred loss: 0.536  
Average sample loss: 0.519  
Average acc: 0.865  
Average grad norm: 5.396  
Average grad norm uniform: 33.002  
Average loss each uniform: 7.303  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.366   grad norm uniform = 35.046   loss each uniform = 9.995   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.812  exp loss = 0.910  adjusted loss = 0.910  adv prob = 0.250000   acc = 0.788   grad norm = 8.951   grad norm uniform = 31.219   loss each uniform = 4.878   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.746  exp loss = 1.886  adjusted loss = 1.886  adv prob = 0.250000   acc = 0.609   grad norm = 14.213   grad norm uniform = 29.609   loss each uniform = 4.550   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.955   grad norm = 1.784   grad norm uniform = 35.467   loss each uniform = 9.100   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8648874163627625


Epoch [59]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.020  
Average grad norm uniform: 36.468  
Average loss each uniform: 10.220  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2281]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 35.739   loss each uniform = 10.587   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.161   grad norm uniform = 39.614   loss each uniform = 7.262   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.070   grad norm uniform = 36.733   loss each uniform = 7.268   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2269]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 37.004   loss each uniform = 10.169   feat norm = 0.452  

Validation:
Average incurred loss: 0.526  
Average sample loss: 0.510  
Average acc: 0.869  
Average grad norm: 5.201  
Average grad norm uniform: 33.466  
Average loss each uniform: 7.514  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.319   grad norm uniform = 35.313   loss each uniform = 10.304   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.752  exp loss = 0.830  adjusted loss = 0.830  adv prob = 0.250000   acc = 0.803   grad norm = 8.287   grad norm uniform = 32.117   loss each uniform = 5.138   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.865  exp loss = 2.033  adjusted loss = 2.033  adv prob = 0.250000   acc = 0.586   grad norm = 14.790   grad norm uniform = 29.780   loss each uniform = 4.566   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.955   grad norm = 1.944   grad norm uniform = 35.396   loss each uniform = 8.986   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [60]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.479  
Average loss each uniform: 10.279  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2291]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.704   loss each uniform = 10.562   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 143]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 39.450   loss each uniform = 7.507   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.047   grad norm uniform = 36.448   loss each uniform = 7.449   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2247]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 37.082   loss each uniform = 10.311   feat norm = 0.453  

Validation:
Average incurred loss: 0.529  
Average sample loss: 0.513  
Average acc: 0.867  
Average grad norm: 5.304  
Average grad norm uniform: 33.194  
Average loss each uniform: 7.418  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.354   grad norm uniform = 35.214   loss each uniform = 10.130   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.796  exp loss = 0.875  adjusted loss = 0.875  adv prob = 0.250000   acc = 0.790   grad norm = 8.756   grad norm uniform = 31.514   loss each uniform = 5.004   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.737  exp loss = 1.878  adjusted loss = 1.878  adv prob = 0.250000   acc = 0.617   grad norm = 14.044   grad norm uniform = 29.475   loss each uniform = 4.594   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.962   grad norm = 1.843   grad norm uniform = 35.711   loss each uniform = 9.180   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8673895597457886


Epoch [61]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.016  
Average grad norm uniform: 36.492  
Average loss each uniform: 10.281  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2239]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 35.956   loss each uniform = 10.924   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 96]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.065   grad norm uniform = 40.036   loss each uniform = 7.971   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.084   grad norm uniform = 35.861   loss each uniform = 6.920   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2347]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 36.888   loss each uniform = 9.925   feat norm = 0.452  

Validation:
Average incurred loss: 0.589  
Average sample loss: 0.573  
Average acc: 0.845  
Average grad norm: 5.806  
Average grad norm uniform: 33.025  
Average loss each uniform: 7.298  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.487   grad norm uniform = 34.959   loss each uniform = 9.773   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.015  exp loss = 1.108  adjusted loss = 1.108  adv prob = 0.250000   acc = 0.723   grad norm = 10.555   grad norm uniform = 30.977   loss each uniform = 4.725   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.510  exp loss = 1.673  adjusted loss = 1.673  adv prob = 0.250000   acc = 0.647   grad norm = 12.278   grad norm uniform = 29.968   loss each uniform = 4.926   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.145  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 0.962   grad norm = 1.373   grad norm uniform = 36.470   loss each uniform = 9.998   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8448706865310669


Epoch [62]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.470  
Average loss each uniform: 10.337  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2300]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 35.836   loss each uniform = 10.649   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.203   grad norm uniform = 39.502   loss each uniform = 7.401   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 36.377   loss each uniform = 7.627   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2258]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.955   loss each uniform = 10.316   feat norm = 0.451  

Validation:
Average incurred loss: 0.541  
Average sample loss: 0.524  
Average acc: 0.868  
Average grad norm: 5.333  
Average grad norm uniform: 33.203  
Average loss each uniform: 7.454  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.350   grad norm uniform = 35.146   loss each uniform = 10.170   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.818  exp loss = 0.900  adjusted loss = 0.900  adv prob = 0.250000   acc = 0.794   grad norm = 8.836   grad norm uniform = 31.523   loss each uniform = 5.012   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.770  exp loss = 1.923  adjusted loss = 1.923  adv prob = 0.250000   acc = 0.602   grad norm = 14.102   grad norm uniform = 29.800   loss each uniform = 4.640   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.962   grad norm = 1.790   grad norm uniform = 35.671   loss each uniform = 9.289   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [63]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.486  
Average loss each uniform: 10.412  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2296]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.791   loss each uniform = 10.767   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 39.186   loss each uniform = 7.807   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.047   grad norm uniform = 37.159   loss each uniform = 7.339   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2273]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 37.018   loss each uniform = 10.334   feat norm = 0.452  

Validation:
Average incurred loss: 0.528  
Average sample loss: 0.511  
Average acc: 0.871  
Average grad norm: 5.174  
Average grad norm uniform: 33.196  
Average loss each uniform: 7.523  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.314   grad norm uniform = 35.098   loss each uniform = 10.333   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.756  exp loss = 0.830  adjusted loss = 0.830  adv prob = 0.250000   acc = 0.805   grad norm = 8.281   grad norm uniform = 31.590   loss each uniform = 5.080   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.863  exp loss = 2.015  adjusted loss = 2.015  adv prob = 0.250000   acc = 0.594   grad norm = 14.592   grad norm uniform = 29.868   loss each uniform = 4.624   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.955   grad norm = 1.938   grad norm uniform = 35.468   loss each uniform = 9.120   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [64]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.017  
Average grad norm uniform: 36.454  
Average loss each uniform: 10.385  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2338]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 35.660   loss each uniform = 10.489   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 137]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.110   grad norm uniform = 40.006   loss each uniform = 7.676   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 36.677   loss each uniform = 7.836   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2206]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 37.063   loss each uniform = 10.574   feat norm = 0.452  

Validation:
Average incurred loss: 0.551  
Average sample loss: 0.534  
Average acc: 0.859  
Average grad norm: 5.497  
Average grad norm uniform: 32.855  
Average loss each uniform: 7.291  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.377   grad norm uniform = 34.875   loss each uniform = 9.953   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.859  exp loss = 0.948  adjusted loss = 0.948  adv prob = 0.250000   acc = 0.773   grad norm = 9.305   grad norm uniform = 30.964   loss each uniform = 4.812   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.718  exp loss = 1.855  adjusted loss = 1.855  adv prob = 0.250000   acc = 0.602   grad norm = 13.958   grad norm uniform = 29.616   loss each uniform = 4.590   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.168  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.962   grad norm = 1.666   grad norm uniform = 35.624   loss each uniform = 9.328   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [65]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.016  
Average grad norm uniform: 36.479  
Average loss each uniform: 10.380  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2297]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.860   loss each uniform = 10.756   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 39.643   loss each uniform = 8.234   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.057   grad norm uniform = 36.264   loss each uniform = 7.370   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2265]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.968   loss each uniform = 10.268   feat norm = 0.452  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.519  
Average acc: 0.867  
Average grad norm: 5.258  
Average grad norm uniform: 34.022  
Average loss each uniform: 7.732  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.348   grad norm uniform = 35.722   loss each uniform = 10.568   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.772  exp loss = 0.850  adjusted loss = 0.850  adv prob = 0.250000   acc = 0.796   grad norm = 8.384   grad norm uniform = 32.702   loss each uniform = 5.303   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.874  exp loss = 2.024  adjusted loss = 2.024  adv prob = 0.250000   acc = 0.594   grad norm = 14.786   grad norm uniform = 30.458   loss each uniform = 4.694   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.955   grad norm = 2.019   grad norm uniform = 36.246   loss each uniform = 9.317   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8665555119514465


Epoch [66]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.487  
Average loss each uniform: 10.369  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.796   loss each uniform = 10.867   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.071   grad norm uniform = 39.605   loss each uniform = 7.950   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 36.531   loss each uniform = 7.347   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2291]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.009   loss each uniform = 10.154   feat norm = 0.452  

Validation:
Average incurred loss: 0.522  
Average sample loss: 0.504  
Average acc: 0.869  
Average grad norm: 5.049  
Average grad norm uniform: 33.499  
Average loss each uniform: 7.705  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.285   grad norm uniform = 35.284   loss each uniform = 10.608   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.712  exp loss = 0.786  adjusted loss = 0.786  adv prob = 0.250000   acc = 0.807   grad norm = 7.825   grad norm uniform = 32.364   loss each uniform = 5.312   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.957  exp loss = 2.127  adjusted loss = 2.127  adv prob = 0.250000   acc = 0.579   grad norm = 15.014   grad norm uniform = 29.337   loss each uniform = 4.608   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.209  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947   grad norm = 2.089   grad norm uniform = 35.368   loss each uniform = 8.997   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [67]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.493  
Average loss each uniform: 10.477  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2340]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.722   loss each uniform = 10.660   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.071   grad norm uniform = 38.838   loss each uniform = 7.355   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.902   loss each uniform = 8.265   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2226]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 37.159   loss each uniform = 10.559   feat norm = 0.453  

Validation:
Average incurred loss: 0.556  
Average sample loss: 0.538  
Average acc: 0.859  
Average grad norm: 5.460  
Average grad norm uniform: 33.310  
Average loss each uniform: 7.472  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.383   grad norm uniform = 35.122   loss each uniform = 10.189   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.866  exp loss = 0.955  adjusted loss = 0.955  adv prob = 0.250000   acc = 0.768   grad norm = 9.230   grad norm uniform = 31.698   loss each uniform = 4.999   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.732  exp loss = 1.886  adjusted loss = 1.886  adv prob = 0.250000   acc = 0.609   grad norm = 13.818   grad norm uniform = 29.862   loss each uniform = 4.660   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.962   grad norm = 1.720   grad norm uniform = 36.047   loss each uniform = 9.413   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [68]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.470  
Average loss each uniform: 10.488  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2290]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 35.793   loss each uniform = 10.886   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.071   grad norm uniform = 39.512   loss each uniform = 7.610   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 104]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 35.975   loss each uniform = 7.592   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 37.013   loss each uniform = 10.370   feat norm = 0.453  

Validation:
Average incurred loss: 0.605  
Average sample loss: 0.588  
Average acc: 0.847  
Average grad norm: 5.945  
Average grad norm uniform: 32.987  
Average loss each uniform: 7.248  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.502   grad norm uniform = 34.943   loss each uniform = 9.713   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.056  exp loss = 1.154  adjusted loss = 1.154  adv prob = 0.250000   acc = 0.723   grad norm = 10.894   grad norm uniform = 31.012   loss each uniform = 4.721   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.509  exp loss = 1.680  adjusted loss = 1.680  adv prob = 0.250000   acc = 0.654   grad norm = 12.401   grad norm uniform = 29.886   loss each uniform = 4.808   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.141  exp loss = 0.120  adjusted loss = 0.120  adv prob = 0.250000   acc = 0.970   grad norm = 1.256   grad norm uniform = 36.141   loss each uniform = 9.891   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [69]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.475  
Average loss each uniform: 10.473  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2297]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.721   loss each uniform = 10.827   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.076   grad norm uniform = 39.517   loss each uniform = 7.590   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 36.956   loss each uniform = 7.623   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2258]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 37.049   loss each uniform = 10.418   feat norm = 0.453  

Validation:
Average incurred loss: 0.556  
Average sample loss: 0.539  
Average acc: 0.862  
Average grad norm: 5.361  
Average grad norm uniform: 33.523  
Average loss each uniform: 7.660  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.389   grad norm uniform = 35.280   loss each uniform = 10.393   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.865  exp loss = 0.955  adjusted loss = 0.955  adv prob = 0.250000   acc = 0.777   grad norm = 9.028   grad norm uniform = 32.040   loss each uniform = 5.168   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.723  exp loss = 1.866  adjusted loss = 1.866  adv prob = 0.250000   acc = 0.617   grad norm = 13.593   grad norm uniform = 30.137   loss each uniform = 4.795   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.955   grad norm = 1.740   grad norm uniform = 35.936   loss each uniform = 9.659   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [70]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.480  
Average loss each uniform: 10.482  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2303]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.914   loss each uniform = 10.826   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 39.077   loss each uniform = 7.535   feat norm = 0.491  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.069   grad norm uniform = 36.486   loss each uniform = 7.442   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2268]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.927   loss each uniform = 10.428   feat norm = 0.451  

Validation:
Average incurred loss: 0.553  
Average sample loss: 0.536  
Average acc: 0.862  
Average grad norm: 5.343  
Average grad norm uniform: 33.326  
Average loss each uniform: 7.588  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.364   grad norm uniform = 35.113   loss each uniform = 10.344   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.834  exp loss = 0.924  adjusted loss = 0.924  adv prob = 0.250000   acc = 0.781   grad norm = 8.843   grad norm uniform = 31.878   loss each uniform = 5.128   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.819  exp loss = 1.983  adjusted loss = 1.983  adv prob = 0.250000   acc = 0.594   grad norm = 14.164   grad norm uniform = 29.759   loss each uniform = 4.697   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 0.962   grad norm = 1.743   grad norm uniform = 35.691   loss each uniform = 9.419   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8623853325843811


Epoch [71]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.501  
Average loss each uniform: 10.524  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2253]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.079   loss each uniform = 11.014   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 38.845   loss each uniform = 8.086   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 36.641   loss each uniform = 7.656   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2292]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.781   loss each uniform = 10.331   feat norm = 0.449  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.548  
Average acc: 0.861  
Average grad norm: 5.431  
Average grad norm uniform: 33.378  
Average loss each uniform: 7.585  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.453   grad norm uniform = 35.163   loss each uniform = 10.204   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.931  exp loss = 1.034  adjusted loss = 1.034  adv prob = 0.250000   acc = 0.766   grad norm = 9.520   grad norm uniform = 31.687   loss each uniform = 5.016   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.580  exp loss = 1.749  adjusted loss = 1.749  adv prob = 0.250000   acc = 0.639   grad norm = 12.492   grad norm uniform = 30.108   loss each uniform = 4.974   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.962   grad norm = 1.525   grad norm uniform = 36.303   loss each uniform = 9.999   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [72]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.454  
Average loss each uniform: 10.475  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2289]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.891   loss each uniform = 10.819   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.098   grad norm uniform = 39.189   loss each uniform = 7.352   feat norm = 0.492  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 36.758   loss each uniform = 7.841   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2258]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.851   loss each uniform = 10.443   feat norm = 0.450  

Validation:
Average incurred loss: 0.510  
Average sample loss: 0.491  
Average acc: 0.883  
Average grad norm: 4.744  
Average grad norm uniform: 34.097  
Average loss each uniform: 8.049  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.996   grad norm = 0.192   grad norm uniform = 35.805   loss each uniform = 11.187   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.595  exp loss = 0.662  adjusted loss = 0.662  adv prob = 0.250000   acc = 0.845   grad norm = 6.578   grad norm uniform = 33.344   loss each uniform = 5.691   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.224  exp loss = 2.368  adjusted loss = 2.368  adv prob = 0.250000   acc = 0.564   grad norm = 16.507   grad norm uniform = 29.463   loss each uniform = 4.628   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.262  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.940   grad norm = 2.536   grad norm uniform = 35.370   loss each uniform = 8.716   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8832360506057739
Best model saved at epoch 72


Epoch [73]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.490  
Average loss each uniform: 10.587  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2250]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.984   loss each uniform = 11.121   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 39.477   loss each uniform = 8.081   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 36.606   loss each uniform = 7.727   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2312]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.827   loss each uniform = 10.339   feat norm = 0.450  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.533  
Average acc: 0.866  
Average grad norm: 5.287  
Average grad norm uniform: 33.846  
Average loss each uniform: 7.809  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.384   grad norm uniform = 35.781   loss each uniform = 10.682   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.838  exp loss = 0.923  adjusted loss = 0.923  adv prob = 0.250000   acc = 0.788   grad norm = 8.782   grad norm uniform = 32.472   loss each uniform = 5.287   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.755  exp loss = 1.914  adjusted loss = 1.914  adv prob = 0.250000   acc = 0.609   grad norm = 13.730   grad norm uniform = 29.879   loss each uniform = 4.771   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.192  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.962   grad norm = 1.809   grad norm uniform = 35.831   loss each uniform = 9.599   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [74]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.489  
Average loss each uniform: 10.537  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2281]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.792   loss each uniform = 10.844   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 144]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.064   grad norm uniform = 39.127   loss each uniform = 7.663   feat norm = 0.490  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 37.446   loss each uniform = 7.967   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2254]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.977   loss each uniform = 10.542   feat norm = 0.452  

Validation:
Average incurred loss: 0.603  
Average sample loss: 0.586  
Average acc: 0.847  
Average grad norm: 5.746  
Average grad norm uniform: 33.020  
Average loss each uniform: 7.424  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.518   grad norm uniform = 34.829   loss each uniform = 9.873   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.059  exp loss = 1.163  adjusted loss = 1.163  adv prob = 0.250000   acc = 0.727   grad norm = 10.531   grad norm uniform = 31.098   loss each uniform = 4.842   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.466  exp loss = 1.631  adjusted loss = 1.631  adv prob = 0.250000   acc = 0.654   grad norm = 11.769   grad norm uniform = 30.117   loss each uniform = 5.051   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.148  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.970   grad norm = 1.312   grad norm uniform = 36.302   loss each uniform = 10.243   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [75]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.017  
Average grad norm uniform: 36.469  
Average loss each uniform: 10.531  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2294]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 35.883   loss each uniform = 10.802   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.079   grad norm uniform = 39.536   loss each uniform = 7.698   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.059   grad norm uniform = 35.900   loss each uniform = 7.656   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2244]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.920   loss each uniform = 10.580   feat norm = 0.450  

Validation:
Average incurred loss: 0.543  
Average sample loss: 0.525  
Average acc: 0.867  
Average grad norm: 5.176  
Average grad norm uniform: 33.333  
Average loss each uniform: 7.713  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.306   grad norm uniform = 35.184   loss each uniform = 10.595   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.775  exp loss = 0.848  adjusted loss = 0.848  adv prob = 0.250000   acc = 0.800   grad norm = 8.246   grad norm uniform = 32.052   loss each uniform = 5.251   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.929  exp loss = 2.104  adjusted loss = 2.104  adv prob = 0.250000   acc = 0.586   grad norm = 14.724   grad norm uniform = 29.581   loss each uniform = 4.674   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.947   grad norm = 1.971   grad norm uniform = 35.076   loss each uniform = 9.262   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.867389440536499


Epoch [76]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.507  
Average loss each uniform: 10.654  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2308]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 35.785   loss each uniform = 10.925   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.064   grad norm uniform = 39.601   loss each uniform = 7.560   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 101]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 37.374   loss each uniform = 7.925   feat norm = 0.455  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 37.037   loss each uniform = 10.667   feat norm = 0.452  

Validation:
Average incurred loss: 0.608  
Average sample loss: 0.591  
Average acc: 0.844  
Average grad norm: 5.892  
Average grad norm uniform: 33.031  
Average loss each uniform: 7.373  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.987   grad norm = 0.507   grad norm uniform = 34.826   loss each uniform = 9.888   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.059  exp loss = 1.160  adjusted loss = 1.160  adv prob = 0.250000   acc = 0.723   grad norm = 10.747   grad norm uniform = 31.137   loss each uniform = 4.764   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.520  exp loss = 1.681  adjusted loss = 1.681  adv prob = 0.250000   acc = 0.647   grad norm = 12.322   grad norm uniform = 29.945   loss each uniform = 4.936   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.150  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.962   grad norm = 1.357   grad norm uniform = 36.450   loss each uniform = 10.124   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8440366983413696


Epoch [77]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.506  
Average loss each uniform: 10.679  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2223]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.056   loss each uniform = 11.357   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 103]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 39.629   loss each uniform = 8.652   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 151]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.055   grad norm uniform = 36.477   loss each uniform = 7.646   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2318]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.801   loss each uniform = 10.317   feat norm = 0.450  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.527  
Average acc: 0.868  
Average grad norm: 5.109  
Average grad norm uniform: 34.017  
Average loss each uniform: 7.966  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.341   grad norm uniform = 35.864   loss each uniform = 10.910   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.786  exp loss = 0.872  adjusted loss = 0.872  adv prob = 0.250000   acc = 0.798   grad norm = 8.146   grad norm uniform = 32.868   loss each uniform = 5.499   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.899  exp loss = 2.069  adjusted loss = 2.069  adv prob = 0.250000   acc = 0.602   grad norm = 14.415   grad norm uniform = 29.998   loss each uniform = 4.778   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.200  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.955   grad norm = 1.902   grad norm uniform = 35.576   loss each uniform = 9.459   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [78]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.485  
Average loss each uniform: 10.617  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2278]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 35.990   loss each uniform = 10.980   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 39.229   loss each uniform = 7.939   feat norm = 0.492  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 36.109   loss each uniform = 7.767   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.861   loss each uniform = 10.527   feat norm = 0.450  

Validation:
Average incurred loss: 0.579  
Average sample loss: 0.561  
Average acc: 0.862  
Average grad norm: 5.465  
Average grad norm uniform: 33.966  
Average loss each uniform: 7.798  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.398   grad norm uniform = 35.719   loss each uniform = 10.578   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.918  exp loss = 1.001  adjusted loss = 1.001  adv prob = 0.250000   acc = 0.775   grad norm = 9.334   grad norm uniform = 32.471   loss each uniform = 5.214   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.738  exp loss = 1.882  adjusted loss = 1.882  adv prob = 0.250000   acc = 0.624   grad norm = 13.456   grad norm uniform = 30.585   loss each uniform = 4.934   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.962   grad norm = 1.707   grad norm uniform = 36.431   loss each uniform = 9.952   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [79]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.498  
Average loss each uniform: 10.668  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2287]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.932   loss each uniform = 11.007   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 39.492   loss each uniform = 7.820   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.402   loss each uniform = 8.025   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.923   loss each uniform = 10.621   feat norm = 0.450  

Validation:
Average incurred loss: 0.529  
Average sample loss: 0.511  
Average acc: 0.872  
Average grad norm: 4.937  
Average grad norm uniform: 34.218  
Average loss each uniform: 8.118  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.278   grad norm uniform = 36.018   loss each uniform = 11.206   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.696  exp loss = 0.773  adjusted loss = 0.773  adv prob = 0.250000   acc = 0.815   grad norm = 7.399   grad norm uniform = 33.380   loss each uniform = 5.681   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.057  exp loss = 2.202  adjusted loss = 2.202  adv prob = 0.250000   acc = 0.586   grad norm = 15.363   grad norm uniform = 29.683   loss each uniform = 4.752   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.229  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.940   grad norm = 2.244   grad norm uniform = 35.368   loss each uniform = 9.177   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8723936080932617


Epoch [80]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.504  
Average loss each uniform: 10.715  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.024   loss each uniform = 11.197   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 105]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 39.437   loss each uniform = 8.128   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 36.660   loss each uniform = 7.742   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2308]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.833   loss each uniform = 10.512   feat norm = 0.450  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.518  
Average acc: 0.872  
Average grad norm: 4.945  
Average grad norm uniform: 33.891  
Average loss each uniform: 8.095  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.271   grad norm uniform = 35.668   loss each uniform = 11.185   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.709  exp loss = 0.778  adjusted loss = 0.778  adv prob = 0.250000   acc = 0.815   grad norm = 7.452   grad norm uniform = 32.928   loss each uniform = 5.612   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.074  exp loss = 2.216  adjusted loss = 2.216  adv prob = 0.250000   acc = 0.579   grad norm = 15.233   grad norm uniform = 29.624   loss each uniform = 4.772   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.234  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.940   grad norm = 2.283   grad norm uniform = 35.297   loss each uniform = 9.266   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [81]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.504  
Average loss each uniform: 10.701  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2315]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.970   loss each uniform = 10.933   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.127   grad norm uniform = 39.449   loss each uniform = 7.623   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 35.735   loss each uniform = 7.797   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2238]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.944   loss each uniform = 10.784   feat norm = 0.450  

Validation:
Average incurred loss: 0.522  
Average sample loss: 0.503  
Average acc: 0.881  
Average grad norm: 4.761  
Average grad norm uniform: 34.446  
Average loss each uniform: 8.316  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.996   grad norm = 0.176   grad norm uniform = 36.220   loss each uniform = 11.579   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.587  exp loss = 0.650  adjusted loss = 0.650  adv prob = 0.250000   acc = 0.848   grad norm = 6.423   grad norm uniform = 33.936   loss each uniform = 5.972   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.352  exp loss = 2.508  adjusted loss = 2.508  adv prob = 0.250000   acc = 0.541   grad norm = 17.072   grad norm uniform = 29.272   loss each uniform = 4.679   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.276  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.932   grad norm = 2.723   grad norm uniform = 35.179   loss each uniform = 8.707   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8807339668273926


Epoch [82]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.490  
Average loss each uniform: 10.813  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2240]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.979   loss each uniform = 11.317   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 39.901   loss each uniform = 8.027   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 36.836   loss each uniform = 7.844   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2305]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.772   loss each uniform = 10.634   feat norm = 0.449  

Validation:
Average incurred loss: 0.562  
Average sample loss: 0.543  
Average acc: 0.864  
Average grad norm: 5.330  
Average grad norm uniform: 33.408  
Average loss each uniform: 7.755  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.349   grad norm uniform = 35.328   loss each uniform = 10.648   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.847  exp loss = 0.925  adjusted loss = 0.925  adv prob = 0.250000   acc = 0.788   grad norm = 8.832   grad norm uniform = 31.728   loss each uniform = 5.164   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.848  exp loss = 1.988  adjusted loss = 1.988  adv prob = 0.250000   acc = 0.594   grad norm = 14.131   grad norm uniform = 30.191   loss each uniform = 4.807   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.962   grad norm = 1.750   grad norm uniform = 35.771   loss each uniform = 9.622   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8640534281730652


Epoch [83]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.018  
Average grad norm uniform: 36.456  
Average loss each uniform: 10.697  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2313]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 35.756   loss each uniform = 10.909   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.003  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.135   grad norm uniform = 39.798   loss each uniform = 7.946   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 36.697   loss each uniform = 7.731   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2221]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.978   loss each uniform = 10.812   feat norm = 0.451  

Validation:
Average incurred loss: 0.607  
Average sample loss: 0.589  
Average acc: 0.848  
Average grad norm: 5.756  
Average grad norm uniform: 33.352  
Average loss each uniform: 7.613  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.987   grad norm = 0.498   grad norm uniform = 35.119   loss each uniform = 10.236   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.035  exp loss = 1.133  adjusted loss = 1.133  adv prob = 0.250000   acc = 0.734   grad norm = 10.338   grad norm uniform = 31.552   loss each uniform = 4.972   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.583  exp loss = 1.749  adjusted loss = 1.749  adv prob = 0.250000   acc = 0.647   grad norm = 12.540   grad norm uniform = 30.313   loss each uniform = 5.003   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.157  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.962   grad norm = 1.383   grad norm uniform = 36.496   loss each uniform = 10.267   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [84]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.519  
Average loss each uniform: 10.752  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2276]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.983   loss each uniform = 11.232   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 39.234   loss each uniform = 8.275   feat norm = 0.489  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 36.410   loss each uniform = 7.770   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.930   loss each uniform = 10.547   feat norm = 0.451  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.608  
Average acc: 0.847  
Average grad norm: 5.923  
Average grad norm uniform: 33.367  
Average loss each uniform: 7.605  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.480   grad norm uniform = 35.267   loss each uniform = 10.258   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.070  exp loss = 1.176  adjusted loss = 1.176  adv prob = 0.250000   acc = 0.727   grad norm = 10.694   grad norm uniform = 31.394   loss each uniform = 4.915   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.642  exp loss = 1.778  adjusted loss = 1.778  adv prob = 0.250000   acc = 0.647   grad norm = 12.852   grad norm uniform = 30.355   loss each uniform = 4.995   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.962   grad norm = 1.391   grad norm uniform = 36.625   loss each uniform = 10.326   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [85]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.501  
Average loss each uniform: 10.725  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2329]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.785   loss each uniform = 10.962   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.069   grad norm uniform = 39.263   loss each uniform = 7.908   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 121]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 36.618   loss each uniform = 7.985   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2227]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 37.096   loss each uniform = 10.774   feat norm = 0.452  

Validation:
Average incurred loss: 0.567  
Average sample loss: 0.549  
Average acc: 0.864  
Average grad norm: 5.299  
Average grad norm uniform: 33.382  
Average loss each uniform: 7.826  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.991   grad norm = 0.377   grad norm uniform = 35.179   loss each uniform = 10.688   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.872  exp loss = 0.965  adjusted loss = 0.965  adv prob = 0.250000   acc = 0.785   grad norm = 8.896   grad norm uniform = 31.903   loss each uniform = 5.217   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.799  exp loss = 1.956  adjusted loss = 1.956  adv prob = 0.250000   acc = 0.594   grad norm = 13.611   grad norm uniform = 29.932   loss each uniform = 4.896   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.962   grad norm = 1.666   grad norm uniform = 35.706   loss each uniform = 9.851   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [86]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.499  
Average loss each uniform: 10.754  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.856   loss each uniform = 11.258   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 40.008   loss each uniform = 8.107   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 127]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.045   grad norm uniform = 37.090   loss each uniform = 8.000   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2280]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.913   loss each uniform = 10.552   feat norm = 0.451  

Validation:
Average incurred loss: 0.530  
Average sample loss: 0.512  
Average acc: 0.874  
Average grad norm: 4.858  
Average grad norm uniform: 33.973  
Average loss each uniform: 8.168  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.242   grad norm uniform = 35.636   loss each uniform = 11.307   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.663  exp loss = 0.730  adjusted loss = 0.730  adv prob = 0.250000   acc = 0.824   grad norm = 7.067   grad norm uniform = 33.149   loss each uniform = 5.721   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.177  exp loss = 2.334  adjusted loss = 2.334  adv prob = 0.250000   acc = 0.564   grad norm = 15.825   grad norm uniform = 29.692   loss each uniform = 4.765   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.240  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.940   grad norm = 2.355   grad norm uniform = 35.297   loss each uniform = 9.124   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8740617036819458


Epoch [87]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.481  
Average loss each uniform: 10.760  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2229]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.932   loss each uniform = 11.458   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 39.977   loss each uniform = 8.461   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.045   grad norm uniform = 36.481   loss each uniform = 7.524   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2332]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.844   loss each uniform = 10.373   feat norm = 0.451  

Validation:
Average incurred loss: 0.543  
Average sample loss: 0.525  
Average acc: 0.872  
Average grad norm: 5.020  
Average grad norm uniform: 34.111  
Average loss each uniform: 8.123  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.295   grad norm uniform = 35.659   loss each uniform = 11.169   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.744  exp loss = 0.825  adjusted loss = 0.825  adv prob = 0.250000   acc = 0.811   grad norm = 7.759   grad norm uniform = 33.275   loss each uniform = 5.635   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.025  exp loss = 2.193  adjusted loss = 2.193  adv prob = 0.250000   acc = 0.586   grad norm = 15.001   grad norm uniform = 29.992   loss each uniform = 4.822   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.219  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.947   grad norm = 2.029   grad norm uniform = 35.722   loss each uniform = 9.448   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [88]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.467  
Average loss each uniform: 10.841  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.729   loss each uniform = 11.029   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.112   grad norm uniform = 39.706   loss each uniform = 7.586   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 36.885   loss each uniform = 8.014   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2221]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 37.039   loss each uniform = 10.976   feat norm = 0.452  

Validation:
Average incurred loss: 0.722  
Average sample loss: 0.704  
Average acc: 0.832  
Average grad norm: 6.700  
Average grad norm uniform: 32.633  
Average loss each uniform: 7.226  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.050  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.983   grad norm = 0.733   grad norm uniform = 34.249   loss each uniform = 9.335   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.431  exp loss = 1.561  adjusted loss = 1.561  adv prob = 0.250000   acc = 0.663   grad norm = 13.387   grad norm uniform = 30.382   loss each uniform = 4.528   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.210  exp loss = 1.356  adjusted loss = 1.356  adv prob = 0.250000   acc = 0.744   grad norm = 10.000   grad norm uniform = 30.483   loss each uniform = 5.353   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.108  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.977   grad norm = 0.922   grad norm uniform = 36.992   loss each uniform = 11.150   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8315262794494629


Epoch [89]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.468  
Average loss each uniform: 10.783  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2307]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.705   loss each uniform = 11.061   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 39.486   loss each uniform = 8.001   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 37.502   loss each uniform = 8.331   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2223]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 37.015   loss each uniform = 10.806   feat norm = 0.451  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.526  
Average acc: 0.871  
Average grad norm: 5.052  
Average grad norm uniform: 33.344  
Average loss each uniform: 7.855  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.313   grad norm uniform = 34.888   loss each uniform = 10.739   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.777  exp loss = 0.862  adjusted loss = 0.862  adv prob = 0.250000   acc = 0.807   grad norm = 8.016   grad norm uniform = 32.228   loss each uniform = 5.383   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.923  exp loss = 2.064  adjusted loss = 2.064  adv prob = 0.250000   acc = 0.594   grad norm = 14.362   grad norm uniform = 29.774   loss each uniform = 4.771   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947   grad norm = 1.998   grad norm uniform = 35.405   loss each uniform = 9.475   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [90]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.485  
Average loss each uniform: 10.844  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2238]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.873   loss each uniform = 11.472   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.045   grad norm uniform = 39.396   loss each uniform = 8.624   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 36.618   loss each uniform = 7.763   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2313]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.912   loss each uniform = 10.515   feat norm = 0.451  

Validation:
Average incurred loss: 0.602  
Average sample loss: 0.584  
Average acc: 0.855  
Average grad norm: 5.595  
Average grad norm uniform: 33.287  
Average loss each uniform: 7.766  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.444   grad norm uniform = 35.058   loss each uniform = 10.487   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.997  exp loss = 1.085  adjusted loss = 1.085  adv prob = 0.250000   acc = 0.753   grad norm = 9.875   grad norm uniform = 31.639   loss each uniform = 5.129   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.674  exp loss = 1.828  adjusted loss = 1.828  adv prob = 0.250000   acc = 0.632   grad norm = 12.760   grad norm uniform = 30.024   loss each uniform = 4.993   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.170  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.962   grad norm = 1.519   grad norm uniform = 36.100   loss each uniform = 10.226   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8548790812492371


Epoch [91]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.467  
Average loss each uniform: 10.892  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2285]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.850   loss each uniform = 11.335   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.054   grad norm uniform = 40.152   loss each uniform = 8.383   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 36.649   loss each uniform = 7.876   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2273]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.892   loss each uniform = 10.736   feat norm = 0.451  

Validation:
Average incurred loss: 0.538  
Average sample loss: 0.519  
Average acc: 0.879  
Average grad norm: 4.821  
Average grad norm uniform: 34.283  
Average loss each uniform: 8.367  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.996   grad norm = 0.214   grad norm uniform = 35.912   loss each uniform = 11.583   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.667  exp loss = 0.755  adjusted loss = 0.755  adv prob = 0.250000   acc = 0.835   grad norm = 6.917   grad norm uniform = 33.687   loss each uniform = 5.917   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.232  exp loss = 2.398  adjusted loss = 2.398  adv prob = 0.250000   acc = 0.564   grad norm = 16.055   grad norm uniform = 29.667   loss each uniform = 4.794   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.250  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.940   grad norm = 2.422   grad norm uniform = 35.270   loss each uniform = 9.237   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8790658712387085


Epoch [92]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.505  
Average loss each uniform: 10.869  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2229]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.039   loss each uniform = 11.522   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 39.738   loss each uniform = 8.207   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 36.321   loss each uniform = 7.753   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2322]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.785   loss each uniform = 10.546   feat norm = 0.449  

Validation:
Average incurred loss: 0.576  
Average sample loss: 0.559  
Average acc: 0.859  
Average grad norm: 5.464  
Average grad norm uniform: 33.364  
Average loss each uniform: 7.705  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.442   grad norm uniform = 35.210   loss each uniform = 10.384   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.945  exp loss = 1.058  adjusted loss = 1.058  adv prob = 0.250000   acc = 0.764   grad norm = 9.529   grad norm uniform = 31.674   loss each uniform = 5.136   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.625  exp loss = 1.758  adjusted loss = 1.758  adv prob = 0.250000   acc = 0.632   grad norm = 12.779   grad norm uniform = 29.945   loss each uniform = 4.931   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 0.962   grad norm = 1.545   grad norm uniform = 36.223   loss each uniform = 10.078   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [93]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.501  
Average loss each uniform: 10.952  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.018   loss each uniform = 11.422   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 39.680   loss each uniform = 8.139   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 127]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 35.803   loss each uniform = 8.011   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2279]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.862   loss each uniform = 10.788   feat norm = 0.450  

Validation:
Average incurred loss: 0.567  
Average sample loss: 0.549  
Average acc: 0.870  
Average grad norm: 5.238  
Average grad norm uniform: 33.318  
Average loss each uniform: 7.911  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.991   grad norm = 0.369   grad norm uniform = 35.027   loss each uniform = 10.774   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.865  exp loss = 0.957  adjusted loss = 0.957  adv prob = 0.250000   acc = 0.794   grad norm = 8.714   grad norm uniform = 31.966   loss each uniform = 5.344   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.815  exp loss = 1.984  adjusted loss = 1.984  adv prob = 0.250000   acc = 0.617   grad norm = 13.598   grad norm uniform = 29.800   loss each uniform = 4.902   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.197  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.962   grad norm = 1.794   grad norm uniform = 35.571   loss each uniform = 9.859   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8698916435241699


Epoch [94]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.472  
Average loss each uniform: 10.857  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2248]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.819   loss each uniform = 11.330   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 147]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 40.151   loss each uniform = 8.205   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.001  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 36.894   loss each uniform = 7.905   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2287]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.855   loss each uniform = 10.708   feat norm = 0.450  

Validation:
Average incurred loss: 0.529  
Average sample loss: 0.511  
Average acc: 0.881  
Average grad norm: 4.760  
Average grad norm uniform: 33.829  
Average loss each uniform: 8.252  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.253   grad norm uniform = 35.467   loss each uniform = 11.347   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.683  exp loss = 0.758  adjusted loss = 0.758  adv prob = 0.250000   acc = 0.839   grad norm = 6.986   grad norm uniform = 32.979   loss each uniform = 5.809   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.089  exp loss = 2.228  adjusted loss = 2.228  adv prob = 0.250000   acc = 0.571   grad norm = 15.249   grad norm uniform = 29.543   loss each uniform = 4.819   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.248  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.940   grad norm = 2.302   grad norm uniform = 35.336   loss each uniform = 9.370   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8807339668273926


Epoch [95]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.511  
Average loss each uniform: 11.000  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2314]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.801   loss each uniform = 11.192   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 39.421   loss each uniform = 8.202   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 37.576   loss each uniform = 8.497   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2238]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 37.021   loss each uniform = 11.091   feat norm = 0.451  

Validation:
Average incurred loss: 0.581  
Average sample loss: 0.564  
Average acc: 0.862  
Average grad norm: 5.492  
Average grad norm uniform: 33.251  
Average loss each uniform: 7.679  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.420   grad norm uniform = 35.010   loss each uniform = 10.370   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.951  exp loss = 1.044  adjusted loss = 1.044  adv prob = 0.250000   acc = 0.768   grad norm = 9.615   grad norm uniform = 31.515   loss each uniform = 5.073   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.663  exp loss = 1.829  adjusted loss = 1.829  adv prob = 0.250000   acc = 0.639   grad norm = 12.858   grad norm uniform = 30.312   loss each uniform = 4.974   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.164  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.962   grad norm = 1.489   grad norm uniform = 36.095   loss each uniform = 10.064   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [96]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.505  
Average loss each uniform: 10.989  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2260]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.945   loss each uniform = 11.443   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 39.729   loss each uniform = 8.358   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.220   loss each uniform = 8.020   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2288]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.887   loss each uniform = 10.842   feat norm = 0.450  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.548  
Average acc: 0.871  
Average grad norm: 5.239  
Average grad norm uniform: 33.782  
Average loss each uniform: 8.032  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.342   grad norm uniform = 35.601   loss each uniform = 10.995   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.847  exp loss = 0.945  adjusted loss = 0.945  adv prob = 0.250000   acc = 0.798   grad norm = 8.583   grad norm uniform = 32.375   loss each uniform = 5.431   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.875  exp loss = 2.047  adjusted loss = 2.047  adv prob = 0.250000   acc = 0.609   grad norm = 14.167   grad norm uniform = 30.126   loss each uniform = 4.906   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.192  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.962   grad norm = 1.788   grad norm uniform = 35.978   loss each uniform = 9.869   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [97]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.018  
Average grad norm uniform: 36.471  
Average loss each uniform: 10.998  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2379]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 35.659   loss each uniform = 11.056   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.133   grad norm uniform = 39.101   loss each uniform = 7.732   feat norm = 0.493  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.793   loss each uniform = 8.449   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2186]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 37.200   loss each uniform = 11.241   feat norm = 0.453  

Validation:
Average incurred loss: 0.625  
Average sample loss: 0.608  
Average acc: 0.843  
Average grad norm: 5.854  
Average grad norm uniform: 33.214  
Average loss each uniform: 7.619  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.987   grad norm = 0.508   grad norm uniform = 34.852   loss each uniform = 10.188   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.099  exp loss = 1.203  adjusted loss = 1.203  adv prob = 0.250000   acc = 0.719   grad norm = 10.761   grad norm uniform = 31.501   loss each uniform = 4.938   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.524  exp loss = 1.683  adjusted loss = 1.683  adv prob = 0.250000   acc = 0.654   grad norm = 11.956   grad norm uniform = 30.208   loss each uniform = 5.112   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.149  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.962   grad norm = 1.335   grad norm uniform = 36.476   loss each uniform = 10.503   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8432027101516724


Epoch [98]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.475  
Average loss each uniform: 10.958  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2333]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 35.678   loss each uniform = 11.335   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 102]:	loss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.104   grad norm uniform = 39.710   loss each uniform = 8.171   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 141]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 36.507   loss each uniform = 8.002   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2219]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 37.162   loss each uniform = 10.877   feat norm = 0.453  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.595  
Average acc: 0.850  
Average grad norm: 5.714  
Average grad norm uniform: 33.155  
Average loss each uniform: 7.725  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.440   grad norm uniform = 34.836   loss each uniform = 10.419   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.024  exp loss = 1.122  adjusted loss = 1.122  adv prob = 0.250000   acc = 0.736   grad norm = 10.182   grad norm uniform = 31.431   loss each uniform = 5.042   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.691  exp loss = 1.870  adjusted loss = 1.870  adv prob = 0.250000   acc = 0.647   grad norm = 12.857   grad norm uniform = 30.135   loss each uniform = 5.050   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.160  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.962   grad norm = 1.434   grad norm uniform = 36.309   loss each uniform = 10.339   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8498749732971191


Epoch [99]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.485  
Average loss each uniform: 11.003  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2336]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.664   loss each uniform = 11.362   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 39.830   loss each uniform = 8.165   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.586   loss each uniform = 8.156   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2227]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 37.178   loss each uniform = 10.922   feat norm = 0.454  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.595  
Average acc: 0.851  
Average grad norm: 5.723  
Average grad norm uniform: 33.358  
Average loss each uniform: 7.716  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.455   grad norm uniform = 34.961   loss each uniform = 10.389   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.028  exp loss = 1.127  adjusted loss = 1.127  adv prob = 0.250000   acc = 0.745   grad norm = 10.212   grad norm uniform = 31.689   loss each uniform = 5.070   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.669  exp loss = 1.839  adjusted loss = 1.839  adv prob = 0.250000   acc = 0.624   grad norm = 12.760   grad norm uniform = 30.551   loss each uniform = 5.027   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.962   grad norm = 1.459   grad norm uniform = 36.384   loss each uniform = 10.292   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8507089614868164


Epoch [100]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.450  
Average loss each uniform: 10.905  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2278]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.802   loss each uniform = 11.534   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 98]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 39.813   loss each uniform = 8.627   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 36.747   loss each uniform = 7.564   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2296]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.934   loss each uniform = 10.558   feat norm = 0.452  

Validation:
Average incurred loss: 0.577  
Average sample loss: 0.559  
Average acc: 0.862  
Average grad norm: 5.386  
Average grad norm uniform: 33.516  
Average loss each uniform: 7.906  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.347   grad norm uniform = 35.109   loss each uniform = 10.795   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.878  exp loss = 0.967  adjusted loss = 0.967  adv prob = 0.250000   acc = 0.781   grad norm = 8.980   grad norm uniform = 32.230   loss each uniform = 5.309   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.868  exp loss = 2.020  adjusted loss = 2.020  adv prob = 0.250000   acc = 0.586   grad norm = 14.051   grad norm uniform = 29.870   loss each uniform = 4.887   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.197  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.962   grad norm = 1.820   grad norm uniform = 36.072   loss each uniform = 9.887   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [101]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.507  
Average loss each uniform: 11.043  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2278]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.750   loss each uniform = 11.529   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 40.063   loss each uniform = 8.823   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 144]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 37.138   loss each uniform = 7.986   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2251]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 37.040   loss each uniform = 10.868   feat norm = 0.452  

Validation:
Average incurred loss: 0.546  
Average sample loss: 0.528  
Average acc: 0.872  
Average grad norm: 4.963  
Average grad norm uniform: 33.253  
Average loss each uniform: 8.009  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.293   grad norm uniform = 34.772   loss each uniform = 10.983   feat norm = 0.414  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.751  exp loss = 0.833  adjusted loss = 0.833  adv prob = 0.250000   acc = 0.811   grad norm = 7.703   grad norm uniform = 32.267   loss each uniform = 5.516   feat norm = 0.462  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.027  exp loss = 2.204  adjusted loss = 2.204  adv prob = 0.250000   acc = 0.586   grad norm = 14.703   grad norm uniform = 29.549   loss each uniform = 4.820   feat norm = 0.420  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.955   grad norm = 2.019   grad norm uniform = 35.080   loss each uniform = 9.486   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8723936676979065


Epoch [102]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.491  
Average loss each uniform: 11.038  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2317]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.724   loss each uniform = 11.367   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 39.083   loss each uniform = 8.324   feat norm = 0.491  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.077   grad norm uniform = 36.630   loss each uniform = 7.918   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2232]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 37.140   loss each uniform = 11.018   feat norm = 0.453  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.527  
Average acc: 0.884  
Average grad norm: 4.559  
Average grad norm uniform: 34.993  
Average loss each uniform: 8.943  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.088   grad norm uniform = 36.383   loss each uniform = 12.493   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.475  exp loss = 0.527  adjusted loss = 0.527  adv prob = 0.250000   acc = 0.884   grad norm = 5.164   grad norm uniform = 35.197   loss each uniform = 6.690   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.922  exp loss = 3.136  adjusted loss = 3.136  adv prob = 0.250000   acc = 0.451   grad norm = 19.306   grad norm uniform = 29.538   loss each uniform = 4.894   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.363  exp loss = 0.338  adjusted loss = 0.338  adv prob = 0.250000   acc = 0.910   grad norm = 3.392   grad norm uniform = 34.853   loss each uniform = 8.419   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8840700387954712
Best model saved at epoch 102


Epoch [103]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.511  
Average loss each uniform: 11.075  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2306]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.813   loss each uniform = 11.368   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 39.389   loss each uniform = 7.989   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 135]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.962   loss each uniform = 8.550   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2227]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 37.043   loss each uniform = 11.101   feat norm = 0.451  

Validation:
Average incurred loss: 0.688  
Average sample loss: 0.670  
Average acc: 0.839  
Average grad norm: 6.269  
Average grad norm uniform: 33.265  
Average loss each uniform: 7.641  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.042  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.985   grad norm = 0.633   grad norm uniform = 34.883   loss each uniform = 10.034   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.300  exp loss = 1.415  adjusted loss = 1.415  adv prob = 0.250000   acc = 0.695   grad norm = 12.119   grad norm uniform = 31.338   loss each uniform = 4.877   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.364  exp loss = 1.538  adjusted loss = 1.538  adv prob = 0.250000   acc = 0.699   grad norm = 10.740   grad norm uniform = 30.632   loss each uniform = 5.409   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.133  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.970   grad norm = 1.093   grad norm uniform = 36.964   loss each uniform = 11.158   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8390325307846069


Epoch [104]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.504  
Average loss each uniform: 11.092  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2290]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.777   loss each uniform = 11.439   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 40.394   loss each uniform = 8.357   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 37.028   loss each uniform = 8.374   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2248]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.994   loss each uniform = 11.049   feat norm = 0.451  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.527  
Average acc: 0.874  
Average grad norm: 4.927  
Average grad norm uniform: 34.313  
Average loss each uniform: 8.353  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.254   grad norm uniform = 36.011   loss each uniform = 11.539   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.721  exp loss = 0.797  adjusted loss = 0.797  adv prob = 0.250000   acc = 0.815   grad norm = 7.415   grad norm uniform = 33.402   loss each uniform = 5.814   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.118  exp loss = 2.277  adjusted loss = 2.277  adv prob = 0.250000   acc = 0.586   grad norm = 15.343   grad norm uniform = 30.069   loss each uniform = 4.883   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.227  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.947   grad norm = 2.207   grad norm uniform = 35.783   loss each uniform = 9.527   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8740618228912354


Epoch [105]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.471  
Average loss each uniform: 11.118  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2289]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.841   loss each uniform = 11.510   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 40.024   loss each uniform = 8.386   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.427   loss each uniform = 8.353   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2263]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.924   loss each uniform = 11.017   feat norm = 0.451  

Validation:
Average incurred loss: 0.599  
Average sample loss: 0.580  
Average acc: 0.857  
Average grad norm: 5.542  
Average grad norm uniform: 33.504  
Average loss each uniform: 7.904  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.396   grad norm uniform = 35.368   loss each uniform = 10.755   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.962  exp loss = 1.049  adjusted loss = 1.049  adv prob = 0.250000   acc = 0.764   grad norm = 9.573   grad norm uniform = 31.716   loss each uniform = 5.192   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.773  exp loss = 1.921  adjusted loss = 1.921  adv prob = 0.250000   acc = 0.617   grad norm = 13.405   grad norm uniform = 30.297   loss each uniform = 5.029   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 0.962   grad norm = 1.626   grad norm uniform = 36.428   loss each uniform = 10.271   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8573811650276184


Epoch [106]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.494  
Average loss each uniform: 11.086  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2271]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.852   loss each uniform = 11.552   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 38.864   loss each uniform = 8.533   feat norm = 0.486  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.001  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 36.803   loss each uniform = 8.243   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2285]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.991   loss each uniform = 10.906   feat norm = 0.452  

Validation:
Average incurred loss: 0.544  
Average sample loss: 0.523  
Average acc: 0.883  
Average grad norm: 4.592  
Average grad norm uniform: 34.965  
Average loss each uniform: 8.853  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.099   grad norm uniform = 36.424   loss each uniform = 12.347   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.505  exp loss = 0.578  adjusted loss = 0.578  adv prob = 0.250000   acc = 0.880   grad norm = 5.378   grad norm uniform = 35.211   loss each uniform = 6.598   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.786  exp loss = 2.991  adjusted loss = 2.991  adv prob = 0.250000   acc = 0.459   grad norm = 18.906   grad norm uniform = 29.284   loss each uniform = 4.841   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.341  exp loss = 0.313  adjusted loss = 0.313  adv prob = 0.250000   acc = 0.910   grad norm = 3.297   grad norm uniform = 34.658   loss each uniform = 8.495   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8832360506057739


Epoch [107]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.497  
Average loss each uniform: 11.141  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2279]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.983   loss each uniform = 11.500   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 39.614   loss each uniform = 8.312   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.340   loss each uniform = 8.147   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.851   loss each uniform = 11.100   feat norm = 0.449  

Validation:
Average incurred loss: 0.569  
Average sample loss: 0.551  
Average acc: 0.872  
Average grad norm: 5.162  
Average grad norm uniform: 33.713  
Average loss each uniform: 8.087  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.991   grad norm = 0.380   grad norm uniform = 35.347   loss each uniform = 10.974   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.874  exp loss = 0.961  adjusted loss = 0.961  adv prob = 0.250000   acc = 0.794   grad norm = 8.597   grad norm uniform = 32.491   loss each uniform = 5.477   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.804  exp loss = 1.963  adjusted loss = 1.963  adv prob = 0.250000   acc = 0.632   grad norm = 13.353   grad norm uniform = 30.068   loss each uniform = 5.046   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.962   grad norm = 1.721   grad norm uniform = 35.904   loss each uniform = 10.137   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [108]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.491  
Average loss each uniform: 11.174  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2317]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.930   loss each uniform = 11.355   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 39.862   loss each uniform = 8.260   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.392   loss each uniform = 8.465   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2247]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.900   loss each uniform = 11.277   feat norm = 0.450  

Validation:
Average incurred loss: 0.576  
Average sample loss: 0.557  
Average acc: 0.864  
Average grad norm: 5.239  
Average grad norm uniform: 33.176  
Average loss each uniform: 7.913  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.335   grad norm uniform = 34.891   loss each uniform = 10.804   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.882  exp loss = 0.973  adjusted loss = 0.973  adv prob = 0.250000   acc = 0.779   grad norm = 8.721   grad norm uniform = 31.747   loss each uniform = 5.293   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.845  exp loss = 1.997  adjusted loss = 1.997  adv prob = 0.250000   acc = 0.617   grad norm = 13.722   grad norm uniform = 29.846   loss each uniform = 4.920   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.962   grad norm = 1.777   grad norm uniform = 35.488   loss each uniform = 9.934   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [109]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.488  
Average loss each uniform: 11.103  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2288]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.895   loss each uniform = 11.399   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.428   loss each uniform = 8.353   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 37.405   loss each uniform = 8.464   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.879   loss each uniform = 11.086   feat norm = 0.450  

Validation:
Average incurred loss: 0.675  
Average sample loss: 0.657  
Average acc: 0.840  
Average grad norm: 6.170  
Average grad norm uniform: 33.022  
Average loss each uniform: 7.589  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.985   grad norm = 0.613   grad norm uniform = 34.664   loss each uniform = 10.020   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.264  exp loss = 1.395  adjusted loss = 1.395  adv prob = 0.250000   acc = 0.697   grad norm = 11.802   grad norm uniform = 31.343   loss each uniform = 4.900   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.382  exp loss = 1.556  adjusted loss = 1.556  adv prob = 0.250000   acc = 0.692   grad norm = 11.014   grad norm uniform = 29.776   loss each uniform = 5.210   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.136  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.977   grad norm = 1.103   grad norm uniform = 36.383   loss each uniform = 10.853   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8398665189743042


Epoch [110]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.498  
Average loss each uniform: 11.121  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2286]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.918   loss each uniform = 11.409   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 134]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.055   grad norm uniform = 39.800   loss each uniform = 8.176   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.718   loss each uniform = 8.485   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2260]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.877   loss each uniform = 11.138   feat norm = 0.450  

Validation:
Average incurred loss: 0.633  
Average sample loss: 0.616  
Average acc: 0.847  
Average grad norm: 5.732  
Average grad norm uniform: 33.115  
Average loss each uniform: 7.799  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.987   grad norm = 0.536   grad norm uniform = 34.844   loss each uniform = 10.388   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.125  exp loss = 1.235  adjusted loss = 1.235  adv prob = 0.250000   acc = 0.719   grad norm = 10.585   grad norm uniform = 31.321   loss each uniform = 5.072   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.500  exp loss = 1.671  adjusted loss = 1.671  adv prob = 0.250000   acc = 0.677   grad norm = 11.424   grad norm uniform = 30.219   loss each uniform = 5.287   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.970   grad norm = 1.277   grad norm uniform = 36.225   loss each uniform = 10.773   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [111]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.497  
Average loss each uniform: 11.182  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2248]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.089   loss each uniform = 11.716   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 39.611   loss each uniform = 8.497   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 100]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.147   loss each uniform = 8.472   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2331]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.751   loss each uniform = 10.918   feat norm = 0.449  

Validation:
Average incurred loss: 0.581  
Average sample loss: 0.563  
Average acc: 0.865  
Average grad norm: 5.307  
Average grad norm uniform: 33.278  
Average loss each uniform: 7.998  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.366   grad norm uniform = 35.085   loss each uniform = 10.886   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.911  exp loss = 1.013  adjusted loss = 1.013  adv prob = 0.250000   acc = 0.783   grad norm = 8.994   grad norm uniform = 31.824   loss each uniform = 5.367   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.796  exp loss = 1.979  adjusted loss = 1.979  adv prob = 0.250000   acc = 0.617   grad norm = 13.396   grad norm uniform = 29.685   loss each uniform = 4.974   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.962   grad norm = 1.651   grad norm uniform = 35.623   loss each uniform = 10.101   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8648874163627625


Epoch [112]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.512  
Average loss each uniform: 11.207  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.935   loss each uniform = 11.452   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 39.633   loss each uniform = 8.179   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.318   loss each uniform = 8.427   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2247]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.929   loss each uniform = 11.275   feat norm = 0.450  

Validation:
Average incurred loss: 0.669  
Average sample loss: 0.651  
Average acc: 0.839  
Average grad norm: 6.121  
Average grad norm uniform: 32.993  
Average loss each uniform: 7.651  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.035  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.987   grad norm = 0.539   grad norm uniform = 34.641   loss each uniform = 10.202   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.208  exp loss = 1.321  adjusted loss = 1.321  adv prob = 0.250000   acc = 0.704   grad norm = 11.482   grad norm uniform = 31.061   loss each uniform = 4.882   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.545  exp loss = 1.703  adjusted loss = 1.703  adv prob = 0.250000   acc = 0.654   grad norm = 11.943   grad norm uniform = 30.450   loss each uniform = 5.210   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.133  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.977   grad norm = 1.118   grad norm uniform = 36.515   loss each uniform = 10.837   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8390325307846069


Epoch [113]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.498  
Average loss each uniform: 11.206  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2251]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.926   loss each uniform = 11.709   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.843   loss each uniform = 8.477   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.814   loss each uniform = 8.234   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2298]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.857   loss each uniform = 11.019   feat norm = 0.450  

Validation:
Average incurred loss: 0.558  
Average sample loss: 0.540  
Average acc: 0.873  
Average grad norm: 4.968  
Average grad norm uniform: 34.313  
Average loss each uniform: 8.420  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.291   grad norm uniform = 35.978   loss each uniform = 11.579   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.781  exp loss = 0.870  adjusted loss = 0.870  adv prob = 0.250000   acc = 0.811   grad norm = 7.715   grad norm uniform = 33.412   loss each uniform = 5.838   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.024  exp loss = 2.181  adjusted loss = 2.181  adv prob = 0.250000   acc = 0.602   grad norm = 14.670   grad norm uniform = 30.208   loss each uniform = 4.957   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.222  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.947   grad norm = 2.064   grad norm uniform = 35.729   loss each uniform = 9.835   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485


Epoch [114]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.522  
Average loss each uniform: 11.166  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2211]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.129   loss each uniform = 11.906   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 39.522   loss each uniform = 8.560   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 121]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.385   loss each uniform = 8.131   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2351]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.756   loss each uniform = 10.750   feat norm = 0.449  

Validation:
Average incurred loss: 0.617  
Average sample loss: 0.600  
Average acc: 0.854  
Average grad norm: 5.662  
Average grad norm uniform: 33.524  
Average loss each uniform: 7.878  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.428   grad norm uniform = 35.382   loss each uniform = 10.651   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.035  exp loss = 1.117  adjusted loss = 1.117  adv prob = 0.250000   acc = 0.749   grad norm = 10.091   grad norm uniform = 31.745   loss each uniform = 5.137   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.686  exp loss = 1.849  adjusted loss = 1.849  adv prob = 0.250000   acc = 0.639   grad norm = 12.705   grad norm uniform = 30.453   loss each uniform = 5.147   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.168  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.962   grad norm = 1.480   grad norm uniform = 36.302   loss each uniform = 10.476   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8540450930595398


Epoch [115]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.482  
Average loss each uniform: 11.230  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2209]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.160   loss each uniform = 11.900   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.872   loss each uniform = 8.877   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 142]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.414   loss each uniform = 8.104   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2319]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.609   loss each uniform = 10.910   feat norm = 0.447  

Validation:
Average incurred loss: 0.543  
Average sample loss: 0.524  
Average acc: 0.882  
Average grad norm: 4.680  
Average grad norm uniform: 34.217  
Average loss each uniform: 8.609  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.996   grad norm = 0.217   grad norm uniform = 35.911   loss each uniform = 11.958   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.675  exp loss = 0.751  adjusted loss = 0.751  adv prob = 0.250000   acc = 0.839   grad norm = 6.734   grad norm uniform = 33.712   loss each uniform = 6.088   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.248  exp loss = 2.429  adjusted loss = 2.429  adv prob = 0.250000   acc = 0.579   grad norm = 15.538   grad norm uniform = 29.464   loss each uniform = 4.916   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.251  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.940   grad norm = 2.296   grad norm uniform = 34.791   loss each uniform = 9.373   feat norm = 0.448  
Current lr: 0.001000
Current validation accuracy: 0.8824020028114319


Epoch [116]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.511  
Average loss each uniform: 11.265  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2271]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.168   loss each uniform = 11.670   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 109]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 39.838   loss each uniform = 8.545   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.079   loss each uniform = 8.395   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2301]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.714   loss each uniform = 11.137   feat norm = 0.448  

Validation:
Average incurred loss: 0.718  
Average sample loss: 0.700  
Average acc: 0.838  
Average grad norm: 6.489  
Average grad norm uniform: 33.130  
Average loss each uniform: 7.570  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.046  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.983   grad norm = 0.684   grad norm uniform = 34.743   loss each uniform = 9.857   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.394  exp loss = 1.503  adjusted loss = 1.503  adv prob = 0.250000   acc = 0.687   grad norm = 12.728   grad norm uniform = 31.099   loss each uniform = 4.799   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.309  exp loss = 1.487  adjusted loss = 1.487  adv prob = 0.250000   acc = 0.722   grad norm = 10.502   grad norm uniform = 30.675   loss each uniform = 5.492   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.977   grad norm = 0.999   grad norm uniform = 37.036   loss each uniform = 11.326   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8381984829902649


Epoch [117]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.504  
Average loss each uniform: 11.308  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2290]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.031   loss each uniform = 11.645   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 39.578   loss each uniform = 8.143   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 96]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 37.144   loss each uniform = 8.626   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2298]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.799   loss each uniform = 11.238   feat norm = 0.449  

Validation:
Average incurred loss: 0.557  
Average sample loss: 0.538  
Average acc: 0.877  
Average grad norm: 4.907  
Average grad norm uniform: 34.462  
Average loss each uniform: 8.516  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.246   grad norm uniform = 36.119   loss each uniform = 11.759   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.731  exp loss = 0.808  adjusted loss = 0.808  adv prob = 0.250000   acc = 0.824   grad norm = 7.339   grad norm uniform = 33.797   loss each uniform = 5.973   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.177  exp loss = 2.342  adjusted loss = 2.342  adv prob = 0.250000   acc = 0.586   grad norm = 15.442   grad norm uniform = 29.958   loss each uniform = 4.939   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.240  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.947   grad norm = 2.220   grad norm uniform = 35.482   loss each uniform = 9.613   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8773978352546692


Epoch [118]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.459  
Average loss each uniform: 11.229  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.044   loss each uniform = 11.570   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 40.261   loss each uniform = 8.755   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.501   loss each uniform = 8.471   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.680   loss each uniform = 11.149   feat norm = 0.447  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.526  
Average acc: 0.881  
Average grad norm: 4.771  
Average grad norm uniform: 34.055  
Average loss each uniform: 8.453  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.996   grad norm = 0.195   grad norm uniform = 35.763   loss each uniform = 11.758   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.655  exp loss = 0.718  adjusted loss = 0.718  adv prob = 0.250000   acc = 0.841   grad norm = 6.714   grad norm uniform = 33.344   loss each uniform = 5.945   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.333  exp loss = 2.502  adjusted loss = 2.502  adv prob = 0.250000   acc = 0.556   grad norm = 16.301   grad norm uniform = 29.682   loss each uniform = 4.861   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.258  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.940   grad norm = 2.496   grad norm uniform = 34.926   loss each uniform = 9.230   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8807339668273926


Epoch [119]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.483  
Average loss each uniform: 11.251  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2314]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.894   loss each uniform = 11.426   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.061   grad norm uniform = 39.942   loss each uniform = 8.207   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 127]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 37.048   loss each uniform = 8.449   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2237]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.880   loss each uniform = 11.389   feat norm = 0.449  

Validation:
Average incurred loss: 0.731  
Average sample loss: 0.713  
Average acc: 0.829  
Average grad norm: 6.535  
Average grad norm uniform: 32.845  
Average loss each uniform: 7.539  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.049  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 0.983   grad norm = 0.708   grad norm uniform = 34.559   loss each uniform = 9.798   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.431  exp loss = 1.574  adjusted loss = 1.574  adv prob = 0.250000   acc = 0.665   grad norm = 12.929   grad norm uniform = 30.721   loss each uniform = 4.772   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.278  exp loss = 1.451  adjusted loss = 1.451  adv prob = 0.250000   acc = 0.714   grad norm = 10.175   grad norm uniform = 30.419   loss each uniform = 5.498   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.123  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.977   grad norm = 0.950   grad norm uniform = 36.692   loss each uniform = 11.346   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8290241956710815


Epoch [120]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.479  
Average loss each uniform: 11.286  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2265]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.019   loss each uniform = 11.666   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 39.620   loss each uniform = 8.392   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.687   loss each uniform = 8.300   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2277]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.755   loss each uniform = 11.235   feat norm = 0.449  

Validation:
Average incurred loss: 0.548  
Average sample loss: 0.526  
Average acc: 0.887  
Average grad norm: 4.479  
Average grad norm uniform: 34.930  
Average loss each uniform: 9.053  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.996   grad norm = 0.122   grad norm uniform = 36.461   loss each uniform = 12.584   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.537  exp loss = 0.599  adjusted loss = 0.599  adv prob = 0.250000   acc = 0.882   grad norm = 5.377   grad norm uniform = 35.042   loss each uniform = 6.746   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.698  exp loss = 2.891  adjusted loss = 2.891  adv prob = 0.250000   acc = 0.489   grad norm = 18.078   grad norm uniform = 29.375   loss each uniform = 4.937   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.343  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 0.925   grad norm = 3.036   grad norm uniform = 34.711   loss each uniform = 8.858   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8874061703681946
Best model saved at epoch 120


Epoch [121]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.486  
Average loss each uniform: 11.370  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2299]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.919   loss each uniform = 11.522   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 39.833   loss each uniform = 8.594   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 109]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.303   loss each uniform = 8.310   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2259]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.882   loss each uniform = 11.520   feat norm = 0.450  

Validation:
Average incurred loss: 0.650  
Average sample loss: 0.632  
Average acc: 0.846  
Average grad norm: 5.867  
Average grad norm uniform: 33.591  
Average loss each uniform: 7.951  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.987   grad norm = 0.536   grad norm uniform = 35.412   loss each uniform = 10.635   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.151  exp loss = 1.267  adjusted loss = 1.267  adv prob = 0.250000   acc = 0.721   grad norm = 10.803   grad norm uniform = 31.772   loss each uniform = 5.156   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.557  exp loss = 1.721  adjusted loss = 1.721  adv prob = 0.250000   acc = 0.662   grad norm = 11.870   grad norm uniform = 30.703   loss each uniform = 5.330   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.970   grad norm = 1.293   grad norm uniform = 36.457   loss each uniform = 10.940   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8457047939300537


Epoch [122]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.511  
Average loss each uniform: 11.332  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2269]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.070   loss each uniform = 11.687   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 39.656   loss each uniform = 8.398   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 37.203   loss each uniform = 8.669   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2301]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.757   loss each uniform = 11.255   feat norm = 0.448  

Validation:
Average incurred loss: 0.594  
Average sample loss: 0.574  
Average acc: 0.863  
Average grad norm: 5.257  
Average grad norm uniform: 33.695  
Average loss each uniform: 8.241  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.320   grad norm uniform = 35.562   loss each uniform = 11.397   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.873  exp loss = 0.964  adjusted loss = 0.964  adv prob = 0.250000   acc = 0.785   grad norm = 8.578   grad norm uniform = 32.304   loss each uniform = 5.491   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.029  exp loss = 2.189  adjusted loss = 2.189  adv prob = 0.250000   acc = 0.594   grad norm = 14.373   grad norm uniform = 30.362   loss each uniform = 5.015   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.208  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.955   grad norm = 1.841   grad norm uniform = 35.347   loss each uniform = 10.016   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8632192611694336


Epoch [123]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.514  
Average loss each uniform: 11.400  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.014   loss each uniform = 11.617   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 39.916   loss each uniform = 8.150   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.568   loss each uniform = 8.709   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.834   loss each uniform = 11.486   feat norm = 0.449  

Validation:
Average incurred loss: 0.649  
Average sample loss: 0.632  
Average acc: 0.845  
Average grad norm: 5.867  
Average grad norm uniform: 33.609  
Average loss each uniform: 7.887  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.523   grad norm uniform = 35.374   loss each uniform = 10.559   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.149  exp loss = 1.254  adjusted loss = 1.254  adv prob = 0.250000   acc = 0.721   grad norm = 10.828   grad norm uniform = 31.831   loss each uniform = 5.095   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.565  exp loss = 1.728  adjusted loss = 1.728  adv prob = 0.250000   acc = 0.662   grad norm = 11.845   grad norm uniform = 30.772   loss each uniform = 5.304   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.151  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.962   grad norm = 1.268   grad norm uniform = 36.478   loss each uniform = 10.873   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8448708057403564


Epoch [124]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.505  
Average loss each uniform: 11.353  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2229]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.169   loss each uniform = 11.863   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 39.494   loss each uniform = 8.626   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.410   loss each uniform = 8.419   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2317]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.679   loss each uniform = 11.166   feat norm = 0.448  

Validation:
Average incurred loss: 0.583  
Average sample loss: 0.565  
Average acc: 0.867  
Average grad norm: 5.225  
Average grad norm uniform: 33.513  
Average loss each uniform: 8.143  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.355   grad norm uniform = 35.389   loss each uniform = 11.125   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.891  exp loss = 0.978  adjusted loss = 0.978  adv prob = 0.250000   acc = 0.792   grad norm = 8.688   grad norm uniform = 32.156   loss each uniform = 5.466   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.879  exp loss = 2.034  adjusted loss = 2.034  adv prob = 0.250000   acc = 0.609   grad norm = 13.656   grad norm uniform = 29.632   loss each uniform = 5.030   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.955   grad norm = 1.763   grad norm uniform = 35.562   loss each uniform = 10.168   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8673895001411438


Epoch [125]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.481  
Average loss each uniform: 11.326  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2289]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.128   loss each uniform = 11.574   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 40.434   loss each uniform = 8.343   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.661   loss each uniform = 8.301   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.631   loss each uniform = 11.397   feat norm = 0.447  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.531  
Average acc: 0.879  
Average grad norm: 4.817  
Average grad norm uniform: 33.800  
Average loss each uniform: 8.372  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.251   grad norm uniform = 35.479   loss each uniform = 11.515   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.723  exp loss = 0.795  adjusted loss = 0.795  adv prob = 0.250000   acc = 0.826   grad norm = 7.253   grad norm uniform = 32.791   loss each uniform = 5.822   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.134  exp loss = 2.286  adjusted loss = 2.286  adv prob = 0.250000   acc = 0.594   grad norm = 14.886   grad norm uniform = 30.026   loss each uniform = 4.992   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.249  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.947   grad norm = 2.244   grad norm uniform = 35.213   loss each uniform = 9.651   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8790659308433533


Epoch [126]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.518  
Average loss each uniform: 11.406  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2242]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.184   loss each uniform = 11.871   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 40.013   loss each uniform = 8.685   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 37.039   loss each uniform = 8.566   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2321]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.636   loss each uniform = 11.235   feat norm = 0.447  

Validation:
Average incurred loss: 0.569  
Average sample loss: 0.551  
Average acc: 0.872  
Average grad norm: 5.017  
Average grad norm uniform: 33.853  
Average loss each uniform: 8.425  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.303   grad norm uniform = 35.755   loss each uniform = 11.586   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.809  exp loss = 0.895  adjusted loss = 0.895  adv prob = 0.250000   acc = 0.809   grad norm = 7.906   grad norm uniform = 32.781   loss each uniform = 5.794   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.018  exp loss = 2.192  adjusted loss = 2.192  adv prob = 0.250000   acc = 0.602   grad norm = 14.476   grad norm uniform = 29.574   loss each uniform = 4.994   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.221  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947   grad norm = 1.988   grad norm uniform = 35.207   loss each uniform = 9.976   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8723936080932617


Epoch [127]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.489  
Average loss each uniform: 11.418  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2287]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.062   loss each uniform = 11.639   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 39.893   loss each uniform = 8.723   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.922   loss each uniform = 8.834   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2271]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.715   loss each uniform = 11.472   feat norm = 0.448  

Validation:
Average incurred loss: 0.558  
Average sample loss: 0.539  
Average acc: 0.879  
Average grad norm: 4.810  
Average grad norm uniform: 34.081  
Average loss each uniform: 8.588  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.991   grad norm = 0.240   grad norm uniform = 35.924   loss each uniform = 11.929   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.704  exp loss = 0.774  adjusted loss = 0.774  adv prob = 0.250000   acc = 0.830   grad norm = 6.994   grad norm uniform = 33.323   loss each uniform = 6.023   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.264  exp loss = 2.420  adjusted loss = 2.420  adv prob = 0.250000   acc = 0.586   grad norm = 15.629   grad norm uniform = 29.479   loss each uniform = 4.937   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.265  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.947   grad norm = 2.385   grad norm uniform = 34.870   loss each uniform = 9.494   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8790659308433533


Epoch [128]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.522  
Average loss each uniform: 11.426  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2277]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.124   loss each uniform = 11.711   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.046   grad norm uniform = 39.263   loss each uniform = 7.907   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.960   loss each uniform = 8.611   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2272]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.744   loss each uniform = 11.486   feat norm = 0.447  

Validation:
Average incurred loss: 0.746  
Average sample loss: 0.729  
Average acc: 0.834  
Average grad norm: 6.571  
Average grad norm uniform: 33.160  
Average loss each uniform: 7.686  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.056  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.985   grad norm = 0.726   grad norm uniform = 34.770   loss each uniform = 9.916   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.475  exp loss = 1.605  adjusted loss = 1.605  adv prob = 0.250000   acc = 0.667   grad norm = 13.130   grad norm uniform = 30.922   loss each uniform = 4.796   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.245  exp loss = 1.436  adjusted loss = 1.436  adv prob = 0.250000   acc = 0.744   grad norm = 9.717   grad norm uniform = 31.341   loss each uniform = 5.811   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.118  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.977   grad norm = 0.968   grad norm uniform = 37.166   loss each uniform = 11.854   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8340283036231995


Epoch [129]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.458  
Average loss each uniform: 11.377  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2278]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.896   loss each uniform = 11.635   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 39.550   loss each uniform = 8.284   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.501   loss each uniform = 8.593   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2266]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.836   loss each uniform = 11.445   feat norm = 0.449  

Validation:
Average incurred loss: 0.585  
Average sample loss: 0.567  
Average acc: 0.867  
Average grad norm: 5.195  
Average grad norm uniform: 33.942  
Average loss each uniform: 8.351  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.347   grad norm uniform = 35.702   loss each uniform = 11.395   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.887  exp loss = 0.983  adjusted loss = 0.983  adv prob = 0.250000   acc = 0.790   grad norm = 8.587   grad norm uniform = 32.616   loss each uniform = 5.641   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.899  exp loss = 2.054  adjusted loss = 2.054  adv prob = 0.250000   acc = 0.609   grad norm = 13.703   grad norm uniform = 30.582   loss each uniform = 5.159   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.955   grad norm = 1.828   grad norm uniform = 35.767   loss each uniform = 10.348   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [130]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.520  
Average loss each uniform: 11.401  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2230]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.118   loss each uniform = 11.944   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 40.041   loss each uniform = 8.745   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 100]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.946   loss each uniform = 8.484   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2347]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.706   loss each uniform = 11.142   feat norm = 0.448  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.532  
Average acc: 0.882  
Average grad norm: 4.782  
Average grad norm uniform: 34.167  
Average loss each uniform: 8.573  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.240   grad norm uniform = 35.853   loss each uniform = 11.844   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.707  exp loss = 0.776  adjusted loss = 0.776  adv prob = 0.250000   acc = 0.837   grad norm = 7.056   grad norm uniform = 33.364   loss each uniform = 5.998   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.199  exp loss = 2.367  adjusted loss = 2.367  adv prob = 0.250000   acc = 0.594   grad norm = 15.225   grad norm uniform = 30.050   loss each uniform = 5.019   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.244  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.940   grad norm = 2.320   grad norm uniform = 35.175   loss each uniform = 9.669   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8824020028114319


Epoch [131]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.493  
Average loss each uniform: 11.393  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.017   loss each uniform = 11.761   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.048   grad norm uniform = 40.181   loss each uniform = 8.236   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.910   loss each uniform = 8.599   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2298]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.764   loss each uniform = 11.315   feat norm = 0.448  

Validation:
Average incurred loss: 0.570  
Average sample loss: 0.552  
Average acc: 0.869  
Average grad norm: 5.099  
Average grad norm uniform: 33.681  
Average loss each uniform: 8.257  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.294   grad norm uniform = 35.483   loss each uniform = 11.362   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.825  exp loss = 0.908  adjusted loss = 0.908  adv prob = 0.250000   acc = 0.800   grad norm = 8.154   grad norm uniform = 32.490   loss each uniform = 5.605   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.990  exp loss = 2.137  adjusted loss = 2.137  adv prob = 0.250000   acc = 0.594   grad norm = 14.368   grad norm uniform = 29.903   loss each uniform = 4.979   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.208  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.955   grad norm = 1.993   grad norm uniform = 35.305   loss each uniform = 9.929   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [132]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.488  
Average loss each uniform: 11.408  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.157   loss each uniform = 11.750   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 39.098   loss each uniform = 8.377   feat norm = 0.489  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 139]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 37.087   loss each uniform = 8.603   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2263]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.647   loss each uniform = 11.396   feat norm = 0.447  

Validation:
Average incurred loss: 0.581  
Average sample loss: 0.563  
Average acc: 0.867  
Average grad norm: 5.172  
Average grad norm uniform: 33.641  
Average loss each uniform: 8.207  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.334   grad norm uniform = 35.340   loss each uniform = 11.190   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.878  exp loss = 0.967  adjusted loss = 0.967  adv prob = 0.250000   acc = 0.794   grad norm = 8.540   grad norm uniform = 32.454   loss each uniform = 5.549   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.903  exp loss = 2.088  adjusted loss = 2.088  adv prob = 0.250000   acc = 0.602   grad norm = 13.726   grad norm uniform = 29.971   loss each uniform = 5.090   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.195  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.955   grad norm = 1.807   grad norm uniform = 35.507   loss each uniform = 10.166   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8673895597457886


Epoch [133]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.510  
Average loss each uniform: 11.450  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2239]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.305   loss each uniform = 11.994   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 103]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 40.089   loss each uniform = 9.215   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 108]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 37.332   loss each uniform = 8.266   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2345]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.509   loss each uniform = 11.175   feat norm = 0.446  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.573  
Average acc: 0.867  
Average grad norm: 5.278  
Average grad norm uniform: 33.861  
Average loss each uniform: 8.246  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.382   grad norm uniform = 35.598   loss each uniform = 11.190   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.936  exp loss = 1.039  adjusted loss = 1.039  adv prob = 0.250000   acc = 0.785   grad norm = 8.974   grad norm uniform = 32.454   loss each uniform = 5.527   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.789  exp loss = 1.959  adjusted loss = 1.959  adv prob = 0.250000   acc = 0.632   grad norm = 13.140   grad norm uniform = 30.529   loss each uniform = 5.185   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.962   grad norm = 1.661   grad norm uniform = 36.019   loss each uniform = 10.492   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8673895001411438


Epoch [134]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.476  
Average loss each uniform: 11.374  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2215]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.098   loss each uniform = 11.990   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 40.117   loss each uniform = 8.963   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.796   loss each uniform = 8.304   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2337]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.634   loss each uniform = 11.076   feat norm = 0.448  

Validation:
Average incurred loss: 0.561  
Average sample loss: 0.540  
Average acc: 0.884  
Average grad norm: 4.718  
Average grad norm uniform: 34.527  
Average loss each uniform: 8.845  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.996   grad norm = 0.183   grad norm uniform = 36.250   loss each uniform = 12.329   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.644  exp loss = 0.712  adjusted loss = 0.712  adv prob = 0.250000   acc = 0.850   grad norm = 6.424   grad norm uniform = 34.196   loss each uniform = 6.354   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.488  exp loss = 2.653  adjusted loss = 2.653  adv prob = 0.250000   acc = 0.556   grad norm = 16.778   grad norm uniform = 29.375   loss each uniform = 4.945   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.285  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.940   grad norm = 2.600   grad norm uniform = 34.786   loss each uniform = 9.241   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8840700387954712


Epoch [135]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.500  
Average loss each uniform: 11.491  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2281]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.004   loss each uniform = 11.775   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 40.041   loss each uniform = 8.492   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.710   loss each uniform = 8.639   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.792   loss each uniform = 11.514   feat norm = 0.448  

Validation:
Average incurred loss: 0.692  
Average sample loss: 0.676  
Average acc: 0.841  
Average grad norm: 6.115  
Average grad norm uniform: 33.057  
Average loss each uniform: 7.779  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.044  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.985   grad norm = 0.635   grad norm uniform = 34.520   loss each uniform = 10.152   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.305  exp loss = 1.415  adjusted loss = 1.415  adv prob = 0.250000   acc = 0.702   grad norm = 11.756   grad norm uniform = 31.273   loss each uniform = 4.984   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.375  exp loss = 1.558  adjusted loss = 1.558  adv prob = 0.250000   acc = 0.692   grad norm = 10.569   grad norm uniform = 30.496   loss each uniform = 5.566   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.140  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.970   grad norm = 1.140   grad norm uniform = 36.731   loss each uniform = 11.448   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8407005667686462


Epoch [136]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.506  
Average loss each uniform: 11.487  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.083   loss each uniform = 11.748   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 40.191   loss each uniform = 8.367   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 104]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.749   loss each uniform = 8.783   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.701   loss each uniform = 11.534   feat norm = 0.447  

Validation:
Average incurred loss: 0.594  
Average sample loss: 0.575  
Average acc: 0.863  
Average grad norm: 5.227  
Average grad norm uniform: 33.627  
Average loss each uniform: 8.274  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.351   grad norm uniform = 35.547   loss each uniform = 11.332   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.906  exp loss = 1.009  adjusted loss = 1.009  adv prob = 0.250000   acc = 0.785   grad norm = 8.689   grad norm uniform = 32.190   loss each uniform = 5.553   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.916  exp loss = 2.081  adjusted loss = 2.081  adv prob = 0.250000   acc = 0.602   grad norm = 13.674   grad norm uniform = 30.148   loss each uniform = 5.108   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.195  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.955   grad norm = 1.769   grad norm uniform = 35.401   loss each uniform = 10.240   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [137]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.510  
Average loss each uniform: 11.499  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2286]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.119   loss each uniform = 11.893   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 99]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 39.952   loss each uniform = 8.186   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 135]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.410   loss each uniform = 8.646   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.759   loss each uniform = 11.417   feat norm = 0.448  

Validation:
Average incurred loss: 0.614  
Average sample loss: 0.595  
Average acc: 0.856  
Average grad norm: 5.503  
Average grad norm uniform: 33.392  
Average loss each uniform: 8.141  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.383   grad norm uniform = 35.318   loss each uniform = 11.100   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.997  exp loss = 1.100  adjusted loss = 1.100  adv prob = 0.250000   acc = 0.762   grad norm = 9.582   grad norm uniform = 31.850   loss each uniform = 5.397   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.790  exp loss = 1.949  adjusted loss = 1.949  adv prob = 0.250000   acc = 0.609   grad norm = 13.125   grad norm uniform = 29.790   loss each uniform = 5.090   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.962   grad norm = 1.571   grad norm uniform = 35.635   loss each uniform = 10.418   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [138]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.484  
Average loss each uniform: 11.467  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2253]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.994   loss each uniform = 11.915   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 39.623   loss each uniform = 8.620   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 35.844   loss each uniform = 8.258   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2308]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.824   loss each uniform = 11.336   feat norm = 0.449  

Validation:
Average incurred loss: 0.578  
Average sample loss: 0.559  
Average acc: 0.869  
Average grad norm: 5.086  
Average grad norm uniform: 33.505  
Average loss each uniform: 8.279  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.315   grad norm uniform = 35.194   loss each uniform = 11.383   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.833  exp loss = 0.922  adjusted loss = 0.922  adv prob = 0.250000   acc = 0.803   grad norm = 8.139   grad norm uniform = 32.346   loss each uniform = 5.631   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.032  exp loss = 2.190  adjusted loss = 2.190  adv prob = 0.250000   acc = 0.594   grad norm = 14.376   grad norm uniform = 29.951   loss each uniform = 5.004   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.947   grad norm = 1.853   grad norm uniform = 35.190   loss each uniform = 9.932   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [139]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.496  
Average loss each uniform: 11.561  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.945   loss each uniform = 11.843   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 39.903   loss each uniform = 8.623   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 99]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.846   loss each uniform = 8.926   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2287]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.860   loss each uniform = 11.541   feat norm = 0.449  

Validation:
Average incurred loss: 0.605  
Average sample loss: 0.586  
Average acc: 0.863  
Average grad norm: 5.367  
Average grad norm uniform: 33.826  
Average loss each uniform: 8.231  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.349   grad norm uniform = 35.676   loss each uniform = 11.260   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.958  exp loss = 1.053  adjusted loss = 1.053  adv prob = 0.250000   acc = 0.777   grad norm = 9.171   grad norm uniform = 32.398   loss each uniform = 5.464   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.840  exp loss = 1.995  adjusted loss = 1.995  adv prob = 0.250000   acc = 0.624   grad norm = 13.345   grad norm uniform = 30.352   loss each uniform = 5.133   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.962   grad norm = 1.678   grad norm uniform = 35.812   loss each uniform = 10.387   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [140]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.496  
Average loss each uniform: 11.596  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.960   loss each uniform = 11.807   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 98]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 39.334   loss each uniform = 8.467   feat norm = 0.493  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 108]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.354   loss each uniform = 8.839   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2265]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.931   loss each uniform = 11.645   feat norm = 0.450  

Validation:
Average incurred loss: 0.678  
Average sample loss: 0.660  
Average acc: 0.839  
Average grad norm: 6.069  
Average grad norm uniform: 33.772  
Average loss each uniform: 7.986  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.985   grad norm = 0.551   grad norm uniform = 35.322   loss each uniform = 10.657   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.219  exp loss = 1.333  adjusted loss = 1.333  adv prob = 0.250000   acc = 0.708   grad norm = 11.305   grad norm uniform = 32.106   loss each uniform = 5.139   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.570  exp loss = 1.739  adjusted loss = 1.739  adv prob = 0.250000   acc = 0.654   grad norm = 11.920   grad norm uniform = 30.967   loss each uniform = 5.403   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.970   grad norm = 1.249   grad norm uniform = 36.975   loss each uniform = 11.165   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8390325307846069


Epoch [141]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.485  
Average loss each uniform: 11.484  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2279]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.976   loss each uniform = 11.908   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 107]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.087   grad norm uniform = 39.770   loss each uniform = 8.308   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 132]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.583   loss each uniform = 8.836   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2277]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.775   loss each uniform = 11.363   feat norm = 0.449  

Validation:
Average incurred loss: 0.711  
Average sample loss: 0.692  
Average acc: 0.837  
Average grad norm: 6.323  
Average grad norm uniform: 33.267  
Average loss each uniform: 7.769  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.985   grad norm = 0.614   grad norm uniform = 34.808   loss each uniform = 10.260   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.337  exp loss = 1.470  adjusted loss = 1.470  adv prob = 0.250000   acc = 0.691   grad norm = 12.180   grad norm uniform = 31.560   loss each uniform = 4.940   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.451  exp loss = 1.625  adjusted loss = 1.625  adv prob = 0.250000   acc = 0.692   grad norm = 11.106   grad norm uniform = 30.283   loss each uniform = 5.414   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.137  exp loss = 0.120  adjusted loss = 0.120  adv prob = 0.250000   acc = 0.977   grad norm = 1.059   grad norm uniform = 36.819   loss each uniform = 11.292   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8373644351959229


Epoch [142]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.507  
Average loss each uniform: 11.506  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.083   loss each uniform = 11.946   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 39.713   loss each uniform = 8.776   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.257   loss each uniform = 8.279   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2280]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.771   loss each uniform = 11.393   feat norm = 0.448  

Validation:
Average incurred loss: 0.556  
Average sample loss: 0.536  
Average acc: 0.883  
Average grad norm: 4.698  
Average grad norm uniform: 34.635  
Average loss each uniform: 8.909  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.996   grad norm = 0.198   grad norm uniform = 36.326   loss each uniform = 12.363   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.674  exp loss = 0.747  adjusted loss = 0.747  adv prob = 0.250000   acc = 0.841   grad norm = 6.672   grad norm uniform = 34.198   loss each uniform = 6.373   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.343  exp loss = 2.519  adjusted loss = 2.519  adv prob = 0.250000   acc = 0.579   grad norm = 15.769   grad norm uniform = 29.838   loss each uniform = 5.030   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.278  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.940   grad norm = 2.513   grad norm uniform = 35.024   loss each uniform = 9.540   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8832360506057739


Epoch [143]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.471  
Average loss each uniform: 11.518  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2297]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.836   loss each uniform = 11.819   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 40.038   loss each uniform = 8.763   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.798   loss each uniform = 8.652   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2266]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.910   loss each uniform = 11.500   feat norm = 0.450  

Validation:
Average incurred loss: 0.577  
Average sample loss: 0.559  
Average acc: 0.874  
Average grad norm: 5.015  
Average grad norm uniform: 34.403  
Average loss each uniform: 8.582  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.332   grad norm uniform = 36.030   loss each uniform = 11.728   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.847  exp loss = 0.939  adjusted loss = 0.939  adv prob = 0.250000   acc = 0.807   grad norm = 8.093   grad norm uniform = 33.376   loss each uniform = 5.893   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.957  exp loss = 2.139  adjusted loss = 2.139  adv prob = 0.250000   acc = 0.617   grad norm = 13.785   grad norm uniform = 30.830   loss each uniform = 5.211   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.215  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.955   grad norm = 1.898   grad norm uniform = 35.858   loss each uniform = 10.331   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8740617036819458


Epoch [144]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.462  
Average loss each uniform: 11.499  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2244]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.022   loss each uniform = 12.044   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 40.323   loss each uniform = 9.076   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 136]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.430   loss each uniform = 8.466   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2296]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.693   loss each uniform = 11.273   feat norm = 0.448  

Validation:
Average incurred loss: 0.566  
Average sample loss: 0.546  
Average acc: 0.877  
Average grad norm: 4.835  
Average grad norm uniform: 34.286  
Average loss each uniform: 8.728  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.994   grad norm = 0.212   grad norm uniform = 35.990   loss each uniform = 12.082   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.704  exp loss = 0.784  adjusted loss = 0.784  adv prob = 0.250000   acc = 0.830   grad norm = 6.959   grad norm uniform = 33.649   loss each uniform = 6.154   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.333  exp loss = 2.525  adjusted loss = 2.525  adv prob = 0.250000   acc = 0.564   grad norm = 15.976   grad norm uniform = 29.675   loss each uniform = 5.016   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.272  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.940   grad norm = 2.483   grad norm uniform = 35.142   loss each uniform = 9.681   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8765637874603271


Epoch [145]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.472  
Average loss each uniform: 11.606  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2313]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.919   loss each uniform = 11.857   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 40.309   loss each uniform = 8.907   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.773   loss each uniform = 8.902   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2249]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.840   loss each uniform = 11.628   feat norm = 0.449  

Validation:
Average incurred loss: 0.715  
Average sample loss: 0.696  
Average acc: 0.838  
Average grad norm: 6.256  
Average grad norm uniform: 33.121  
Average loss each uniform: 7.889  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.985   grad norm = 0.599   grad norm uniform = 34.875   loss each uniform = 10.484   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.341  exp loss = 1.470  adjusted loss = 1.470  adv prob = 0.250000   acc = 0.697   grad norm = 12.038   grad norm uniform = 31.187   loss each uniform = 4.974   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.461  exp loss = 1.611  adjusted loss = 1.611  adv prob = 0.250000   acc = 0.684   grad norm = 11.004   grad norm uniform = 30.256   loss each uniform = 5.455   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.142  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.970   grad norm = 1.116   grad norm uniform = 36.604   loss each uniform = 11.423   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8381985425949097


Epoch [146]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.468  
Average loss each uniform: 11.506  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2263]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.070   loss each uniform = 11.990   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 107]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 40.285   loss each uniform = 8.937   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 142]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 36.950   loss each uniform = 8.377   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2283]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.655   loss each uniform = 11.342   feat norm = 0.448  

Validation:
Average incurred loss: 0.625  
Average sample loss: 0.607  
Average acc: 0.857  
Average grad norm: 5.551  
Average grad norm uniform: 33.950  
Average loss each uniform: 8.240  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.482   grad norm uniform = 35.595   loss each uniform = 11.071   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.061  exp loss = 1.180  adjusted loss = 1.180  adv prob = 0.250000   acc = 0.751   grad norm = 9.899   grad norm uniform = 32.526   loss each uniform = 5.452   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.647  exp loss = 1.840  adjusted loss = 1.840  adv prob = 0.250000   acc = 0.654   grad norm = 12.221   grad norm uniform = 30.765   loss each uniform = 5.382   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.970   grad norm = 1.444   grad norm uniform = 36.349   loss each uniform = 10.928   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8573811054229736


Epoch [147]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.515  
Average loss each uniform: 11.602  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2253]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.209   loss each uniform = 12.118   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 110]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.656   loss each uniform = 9.404   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 121]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.900   loss each uniform = 8.443   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2311]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.645   loss each uniform = 11.370   feat norm = 0.446  

Validation:
Average incurred loss: 0.569  
Average sample loss: 0.549  
Average acc: 0.876  
Average grad norm: 4.840  
Average grad norm uniform: 34.406  
Average loss each uniform: 8.709  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.996   grad norm = 0.202   grad norm uniform = 36.006   loss each uniform = 12.083   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.708  exp loss = 0.780  adjusted loss = 0.780  adv prob = 0.250000   acc = 0.824   grad norm = 7.020   grad norm uniform = 33.875   loss each uniform = 6.125   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.349  exp loss = 2.501  adjusted loss = 2.501  adv prob = 0.250000   acc = 0.571   grad norm = 15.974   grad norm uniform = 29.590   loss each uniform = 4.988   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.268  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.940   grad norm = 2.358   grad norm uniform = 35.460   loss each uniform = 9.636   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8757297396659851


Epoch [148]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.466  
Average loss each uniform: 11.581  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.995   loss each uniform = 12.034   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.004  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000   grad norm = 0.142   grad norm uniform = 39.612   loss each uniform = 8.621   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 132]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 36.333   loss each uniform = 8.459   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2285]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.789   loss each uniform = 11.456   feat norm = 0.449  

Validation:
Average incurred loss: 0.770  
Average sample loss: 0.752  
Average acc: 0.827  
Average grad norm: 6.683  
Average grad norm uniform: 33.046  
Average loss each uniform: 7.676  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.056  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.981   grad norm = 0.778   grad norm uniform = 34.492   loss each uniform = 9.839   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.543  exp loss = 1.700  adjusted loss = 1.700  adv prob = 0.250000   acc = 0.659   grad norm = 13.440   grad norm uniform = 30.925   loss each uniform = 4.809   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.221  exp loss = 1.411  adjusted loss = 1.411  adv prob = 0.250000   acc = 0.729   grad norm = 9.468   grad norm uniform = 31.144   loss each uniform = 5.814   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.118  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 0.977   grad norm = 0.960   grad norm uniform = 37.303   loss each uniform = 11.986   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8273561000823975


Epoch [149]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.491  
Average loss each uniform: 11.543  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2255]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.987   loss each uniform = 12.046   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 40.102   loss each uniform = 8.534   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 147]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 36.814   loss each uniform = 8.633   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.767   loss each uniform = 11.404   feat norm = 0.448  

Validation:
Average incurred loss: 0.617  
Average sample loss: 0.599  
Average acc: 0.859  
Average grad norm: 5.455  
Average grad norm uniform: 33.899  
Average loss each uniform: 8.297  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.413   grad norm uniform = 35.596   loss each uniform = 11.226   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.005  exp loss = 1.106  adjusted loss = 1.106  adv prob = 0.250000   acc = 0.760   grad norm = 9.519   grad norm uniform = 32.497   loss each uniform = 5.533   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.772  exp loss = 1.919  adjusted loss = 1.919  adv prob = 0.250000   acc = 0.647   grad norm = 12.782   grad norm uniform = 30.550   loss each uniform = 5.277   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.962   grad norm = 1.594   grad norm uniform = 36.206   loss each uniform = 10.720   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [150]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.465  
Average loss each uniform: 11.528  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2248]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.935   loss each uniform = 12.038   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 40.062   loss each uniform = 9.286   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.985   loss each uniform = 8.651   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2285]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.754   loss each uniform = 11.321   feat norm = 0.448  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.530  
Average acc: 0.885  
Average grad norm: 4.579  
Average grad norm uniform: 33.864  
Average loss each uniform: 8.725  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.996   grad norm = 0.193   grad norm uniform = 35.349   loss each uniform = 12.034   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.635  exp loss = 0.706  adjusted loss = 0.706  adv prob = 0.250000   acc = 0.852   grad norm = 6.287   grad norm uniform = 33.393   loss each uniform = 6.258   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.416  exp loss = 2.579  adjusted loss = 2.579  adv prob = 0.250000   acc = 0.564   grad norm = 16.042   grad norm uniform = 29.336   loss each uniform = 5.022   feat norm = 0.421  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.286  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.932   grad norm = 2.533   grad norm uniform = 34.828   loss each uniform = 9.456   feat norm = 0.447  
Current lr: 0.001000
Current validation accuracy: 0.884904146194458


Epoch [151]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.481  
Average loss each uniform: 11.590  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2276]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.952   loss each uniform = 12.043   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 110]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 40.083   loss each uniform = 9.039   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.853   loss each uniform = 8.777   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.815   loss each uniform = 11.406   feat norm = 0.449  

Validation:
Average incurred loss: 0.571  
Average sample loss: 0.552  
Average acc: 0.872  
Average grad norm: 4.936  
Average grad norm uniform: 33.859  
Average loss each uniform: 8.554  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.292   grad norm uniform = 35.581   loss each uniform = 11.743   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.801  exp loss = 0.873  adjusted loss = 0.873  adv prob = 0.250000   acc = 0.811   grad norm = 7.725   grad norm uniform = 32.915   loss each uniform = 5.913   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.074  exp loss = 2.233  adjusted loss = 2.233  adv prob = 0.250000   acc = 0.594   grad norm = 14.450   grad norm uniform = 29.687   loss each uniform = 5.076   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.221  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947   grad norm = 1.958   grad norm uniform = 35.290   loss each uniform = 10.085   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8723936676979065


Epoch [152]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.468  
Average loss each uniform: 11.552  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2238]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.897   loss each uniform = 12.091   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 40.636   loss each uniform = 9.387   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 131]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.773   loss each uniform = 8.531   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2298]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.775   loss each uniform = 11.320   feat norm = 0.449  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.573  
Average acc: 0.867  
Average grad norm: 5.230  
Average grad norm uniform: 33.349  
Average loss each uniform: 8.199  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.386   grad norm uniform = 35.020   loss each uniform = 11.081   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.934  exp loss = 1.040  adjusted loss = 1.040  adv prob = 0.250000   acc = 0.783   grad norm = 8.888   grad norm uniform = 31.885   loss each uniform = 5.475   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.790  exp loss = 1.940  adjusted loss = 1.940  adv prob = 0.250000   acc = 0.639   grad norm = 12.956   grad norm uniform = 30.099   loss each uniform = 5.232   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.962   grad norm = 1.693   grad norm uniform = 35.862   loss each uniform = 10.598   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8673895001411438


Epoch [153]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.461  
Average loss each uniform: 11.565  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.905   loss each uniform = 11.666   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 39.788   loss each uniform = 8.478   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 103]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.126   loss each uniform = 8.612   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2231]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.888   loss each uniform = 11.756   feat norm = 0.449  

Validation:
Average incurred loss: 0.605  
Average sample loss: 0.588  
Average acc: 0.861  
Average grad norm: 5.393  
Average grad norm uniform: 33.573  
Average loss each uniform: 8.236  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.432   grad norm uniform = 35.358   loss each uniform = 11.159   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.987  exp loss = 1.104  adjusted loss = 1.104  adv prob = 0.250000   acc = 0.770   grad norm = 9.367   grad norm uniform = 32.141   loss each uniform = 5.505   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.735  exp loss = 1.902  adjusted loss = 1.902  adv prob = 0.250000   acc = 0.624   grad norm = 12.742   grad norm uniform = 30.225   loss each uniform = 5.207   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 0.962   grad norm = 1.540   grad norm uniform = 35.671   loss each uniform = 10.565   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [154]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.465  
Average loss each uniform: 11.611  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2304]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.938   loss each uniform = 11.930   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 109]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 40.027   loss each uniform = 8.884   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 104]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.087   loss each uniform = 8.607   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2278]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.845   loss each uniform = 11.556   feat norm = 0.449  

Validation:
Average incurred loss: 0.616  
Average sample loss: 0.598  
Average acc: 0.862  
Average grad norm: 5.411  
Average grad norm uniform: 33.911  
Average loss each uniform: 8.357  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.397   grad norm uniform = 35.619   loss each uniform = 11.353   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.990  exp loss = 1.092  adjusted loss = 1.092  adv prob = 0.250000   acc = 0.773   grad norm = 9.319   grad norm uniform = 32.598   loss each uniform = 5.571   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.809  exp loss = 1.972  adjusted loss = 1.972  adv prob = 0.250000   acc = 0.639   grad norm = 13.018   grad norm uniform = 30.353   loss each uniform = 5.246   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.955   grad norm = 1.716   grad norm uniform = 36.069   loss each uniform = 10.712   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [155]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.480  
Average loss each uniform: 11.540  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.982   loss each uniform = 11.943   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 40.226   loss each uniform = 8.523   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 37.378   loss each uniform = 8.889   feat norm = 0.455  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2272]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.738   loss each uniform = 11.436   feat norm = 0.447  

Validation:
Average incurred loss: 0.639  
Average sample loss: 0.621  
Average acc: 0.852  
Average grad norm: 5.608  
Average grad norm uniform: 33.497  
Average loss each uniform: 8.095  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.987   grad norm = 0.503   grad norm uniform = 34.958   loss each uniform = 10.789   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.116  exp loss = 1.238  adjusted loss = 1.238  adv prob = 0.250000   acc = 0.738   grad norm = 10.242   grad norm uniform = 32.028   loss each uniform = 5.289   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.581  exp loss = 1.752  adjusted loss = 1.752  adv prob = 0.250000   acc = 0.662   grad norm = 11.560   grad norm uniform = 30.622   loss each uniform = 5.463   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.161  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.962   grad norm = 1.345   grad norm uniform = 36.389   loss each uniform = 11.103   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8515430092811584


Epoch [156]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.486  
Average loss each uniform: 11.614  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.850   loss each uniform = 11.899   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 40.378   loss each uniform = 8.988   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.958   loss each uniform = 8.822   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2250]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.905   loss each uniform = 11.615   feat norm = 0.449  

Validation:
Average incurred loss: 0.633  
Average sample loss: 0.617  
Average acc: 0.852  
Average grad norm: 5.562  
Average grad norm uniform: 33.583  
Average loss each uniform: 8.153  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.499   grad norm uniform = 35.135   loss each uniform = 10.877   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.100  exp loss = 1.218  adjusted loss = 1.218  adv prob = 0.250000   acc = 0.740   grad norm = 10.116   grad norm uniform = 32.148   loss each uniform = 5.396   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.578  exp loss = 1.753  adjusted loss = 1.753  adv prob = 0.250000   acc = 0.662   grad norm = 11.616   grad norm uniform = 30.451   loss each uniform = 5.398   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.962   grad norm = 1.329   grad norm uniform = 36.296   loss each uniform = 11.002   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8523769974708557


Epoch [157]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.466  
Average loss each uniform: 11.562  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.983   loss each uniform = 12.024   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 39.364   loss each uniform = 8.756   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.190   loss each uniform = 8.643   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2279]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.823   loss each uniform = 11.404   feat norm = 0.449  

Validation:
Average incurred loss: 0.576  
Average sample loss: 0.558  
Average acc: 0.870  
Average grad norm: 4.989  
Average grad norm uniform: 34.150  
Average loss each uniform: 8.584  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.314   grad norm uniform = 35.710   loss each uniform = 11.740   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.819  exp loss = 0.923  adjusted loss = 0.923  adv prob = 0.250000   acc = 0.805   grad norm = 7.890   grad norm uniform = 33.289   loss each uniform = 5.963   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.051  exp loss = 2.240  adjusted loss = 2.240  adv prob = 0.250000   acc = 0.594   grad norm = 14.260   grad norm uniform = 30.437   loss each uniform = 5.145   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.218  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.947   grad norm = 1.966   grad norm uniform = 35.399   loss each uniform = 10.125   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8698915839195251


Epoch [158]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.459  
Average loss each uniform: 11.620  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2281]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.006   loss each uniform = 11.982   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 40.335   loss each uniform = 9.283   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.368   loss each uniform = 8.809   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2269]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.713   loss each uniform = 11.534   feat norm = 0.447  

Validation:
Average incurred loss: 0.563  
Average sample loss: 0.544  
Average acc: 0.874  
Average grad norm: 4.787  
Average grad norm uniform: 34.226  
Average loss each uniform: 8.701  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.994   grad norm = 0.227   grad norm uniform = 35.693   loss each uniform = 11.997   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.736  exp loss = 0.830  adjusted loss = 0.830  adv prob = 0.250000   acc = 0.820   grad norm = 7.160   grad norm uniform = 33.568   loss each uniform = 6.088   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.206  exp loss = 2.371  adjusted loss = 2.371  adv prob = 0.250000   acc = 0.579   grad norm = 14.991   grad norm uniform = 30.236   loss each uniform = 5.090   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.252  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.940   grad norm = 2.275   grad norm uniform = 35.370   loss each uniform = 9.891   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8740617632865906


Epoch [159]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.447  
Average loss each uniform: 11.599  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.890   loss each uniform = 12.037   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.878   loss each uniform = 8.754   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.585   loss each uniform = 8.715   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.805   loss each uniform = 11.483   feat norm = 0.449  

Validation:
Average incurred loss: 0.637  
Average sample loss: 0.619  
Average acc: 0.850  
Average grad norm: 5.588  
Average grad norm uniform: 33.057  
Average loss each uniform: 8.028  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.472   grad norm uniform = 34.570   loss each uniform = 10.715   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.100  exp loss = 1.218  adjusted loss = 1.218  adv prob = 0.250000   acc = 0.736   grad norm = 10.130   grad norm uniform = 31.494   loss each uniform = 5.231   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.620  exp loss = 1.785  adjusted loss = 1.785  adv prob = 0.250000   acc = 0.647   grad norm = 11.806   grad norm uniform = 30.245   loss each uniform = 5.396   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.962   grad norm = 1.415   grad norm uniform = 36.037   loss each uniform = 11.020   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8498749732971191


Epoch [160]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.424  
Average loss each uniform: 11.583  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2261]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.868   loss each uniform = 12.037   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.001  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 39.462   loss each uniform = 9.038   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.422   loss each uniform = 8.948   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2289]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.754   loss each uniform = 11.411   feat norm = 0.449  

Validation:
Average incurred loss: 0.671  
Average sample loss: 0.654  
Average acc: 0.847  
Average grad norm: 5.878  
Average grad norm uniform: 33.336  
Average loss each uniform: 8.032  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.985   grad norm = 0.569   grad norm uniform = 34.790   loss each uniform = 10.621   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.221  exp loss = 1.342  adjusted loss = 1.342  adv prob = 0.250000   acc = 0.717   grad norm = 11.078   grad norm uniform = 31.667   loss each uniform = 5.182   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.478  exp loss = 1.643  adjusted loss = 1.643  adv prob = 0.250000   acc = 0.692   grad norm = 10.924   grad norm uniform = 30.710   loss each uniform = 5.564   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.970   grad norm = 1.252   grad norm uniform = 36.705   loss each uniform = 11.397   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [161]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.453  
Average loss each uniform: 11.583  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2259]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.912   loss each uniform = 12.039   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 138]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 40.374   loss each uniform = 9.198   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 37.123   loss each uniform = 8.601   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2269]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.715   loss each uniform = 11.444   feat norm = 0.448  

Validation:
Average incurred loss: 0.571  
Average sample loss: 0.552  
Average acc: 0.876  
Average grad norm: 4.853  
Average grad norm uniform: 33.422  
Average loss each uniform: 8.536  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.223   grad norm uniform = 34.960   loss each uniform = 11.790   feat norm = 0.415  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.747  exp loss = 0.827  adjusted loss = 0.827  adv prob = 0.250000   acc = 0.824   grad norm = 7.254   grad norm uniform = 32.662   loss each uniform = 5.904   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.252  exp loss = 2.408  adjusted loss = 2.408  adv prob = 0.250000   acc = 0.571   grad norm = 15.353   grad norm uniform = 29.272   loss each uniform = 5.003   feat norm = 0.419  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.238  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.947   grad norm = 2.200   grad norm uniform = 34.831   loss each uniform = 9.868   feat norm = 0.447  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [162]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.442  
Average loss each uniform: 11.664  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.889   loss each uniform = 12.172   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 109]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 39.719   loss each uniform = 9.477   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 36.741   loss each uniform = 8.749   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2298]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.817   loss each uniform = 11.415   feat norm = 0.449  

Validation:
Average incurred loss: 0.566  
Average sample loss: 0.548  
Average acc: 0.876  
Average grad norm: 4.887  
Average grad norm uniform: 34.333  
Average loss each uniform: 8.627  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.293   grad norm uniform = 35.774   loss each uniform = 11.755   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.791  exp loss = 0.878  adjusted loss = 0.878  adv prob = 0.250000   acc = 0.813   grad norm = 7.597   grad norm uniform = 33.463   loss each uniform = 6.009   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.048  exp loss = 2.204  adjusted loss = 2.204  adv prob = 0.250000   acc = 0.617   grad norm = 14.280   grad norm uniform = 30.638   loss each uniform = 5.207   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.237  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.947   grad norm = 2.126   grad norm uniform = 36.014   loss each uniform = 10.237   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [163]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.433  
Average loss each uniform: 11.643  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2303]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.843   loss each uniform = 12.000   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.961   loss each uniform = 9.080   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 128]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 37.099   loss each uniform = 8.978   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2256]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.830   loss each uniform = 11.553   feat norm = 0.449  

Validation:
Average incurred loss: 0.574  
Average sample loss: 0.555  
Average acc: 0.874  
Average grad norm: 4.875  
Average grad norm uniform: 34.677  
Average loss each uniform: 8.819  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.272   grad norm uniform = 36.112   loss each uniform = 12.087   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.789  exp loss = 0.864  adjusted loss = 0.864  adv prob = 0.250000   acc = 0.818   grad norm = 7.478   grad norm uniform = 33.992   loss each uniform = 6.145   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.120  exp loss = 2.287  adjusted loss = 2.287  adv prob = 0.250000   acc = 0.586   grad norm = 14.607   grad norm uniform = 30.684   loss each uniform = 5.235   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.248  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.940   grad norm = 2.187   grad norm uniform = 36.031   loss each uniform = 10.299   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8740618228912354


Epoch [164]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.463  
Average loss each uniform: 11.650  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2316]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.853   loss each uniform = 11.917   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 40.084   loss each uniform = 8.446   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 102]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 37.100   loss each uniform = 9.042   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2256]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.866   loss each uniform = 11.666   feat norm = 0.449  

Validation:
Average incurred loss: 0.578  
Average sample loss: 0.560  
Average acc: 0.872  
Average grad norm: 5.009  
Average grad norm uniform: 33.949  
Average loss each uniform: 8.475  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.307   grad norm uniform = 35.415   loss each uniform = 11.537   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.846  exp loss = 0.947  adjusted loss = 0.947  adv prob = 0.250000   acc = 0.807   grad norm = 8.048   grad norm uniform = 32.975   loss each uniform = 5.792   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.978  exp loss = 2.127  adjusted loss = 2.127  adv prob = 0.250000   acc = 0.609   grad norm = 13.911   grad norm uniform = 30.286   loss each uniform = 5.183   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947   grad norm = 1.963   grad norm uniform = 35.879   loss each uniform = 10.413   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8723936676979065


Epoch [165]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.461  
Average loss each uniform: 11.664  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2288]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.805   loss each uniform = 12.023   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 40.404   loss each uniform = 9.082   feat norm = 0.508  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 111]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 37.180   loss each uniform = 8.937   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2269]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.866   loss each uniform = 11.580   feat norm = 0.449  

Validation:
Average incurred loss: 0.642  
Average sample loss: 0.625  
Average acc: 0.848  
Average grad norm: 5.602  
Average grad norm uniform: 33.180  
Average loss each uniform: 8.140  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.987   grad norm = 0.481   grad norm uniform = 34.735   loss each uniform = 10.875   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.111  exp loss = 1.221  adjusted loss = 1.221  adv prob = 0.250000   acc = 0.732   grad norm = 10.184   grad norm uniform = 31.602   loss each uniform = 5.335   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.624  exp loss = 1.782  adjusted loss = 1.782  adv prob = 0.250000   acc = 0.654   grad norm = 11.800   grad norm uniform = 30.234   loss each uniform = 5.410   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.962   grad norm = 1.326   grad norm uniform = 36.192   loss each uniform = 11.093   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8482068181037903


Epoch [166]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.474  
Average loss each uniform: 11.694  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.894   loss each uniform = 12.140   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 40.651   loss each uniform = 9.101   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 37.206   loss each uniform = 8.912   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2280]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.788   loss each uniform = 11.532   feat norm = 0.448  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.573  
Average acc: 0.872  
Average grad norm: 5.042  
Average grad norm uniform: 34.158  
Average loss each uniform: 8.678  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.301   grad norm uniform = 35.722   loss each uniform = 11.906   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.858  exp loss = 0.942  adjusted loss = 0.942  adv prob = 0.250000   acc = 0.805   grad norm = 8.108   grad norm uniform = 33.078   loss each uniform = 5.916   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.047  exp loss = 2.198  adjusted loss = 2.198  adv prob = 0.250000   acc = 0.609   grad norm = 14.062   grad norm uniform = 30.673   loss each uniform = 5.246   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.929   grad norm uniform = 35.933   loss each uniform = 10.455   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8723936676979065


Epoch [167]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.460  
Average loss each uniform: 11.666  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2235]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.010   loss each uniform = 12.332   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 40.529   loss each uniform = 9.476   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.904   loss each uniform = 8.932   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2334]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.676   loss each uniform = 11.267   feat norm = 0.448  

Validation:
Average incurred loss: 0.590  
Average sample loss: 0.571  
Average acc: 0.873  
Average grad norm: 4.983  
Average grad norm uniform: 34.294  
Average loss each uniform: 8.818  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.272   grad norm uniform = 35.768   loss each uniform = 12.120   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.819  exp loss = 0.908  adjusted loss = 0.908  adv prob = 0.250000   acc = 0.809   grad norm = 7.755   grad norm uniform = 33.633   loss each uniform = 6.142   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.167  exp loss = 2.344  adjusted loss = 2.344  adv prob = 0.250000   acc = 0.594   grad norm = 14.736   grad norm uniform = 30.217   loss each uniform = 5.164   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.241  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.955   grad norm = 2.058   grad norm uniform = 35.514   loss each uniform = 10.255   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8732276558876038


Epoch [168]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.451  
Average loss each uniform: 11.654  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.820   loss each uniform = 12.088   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 40.389   loss each uniform = 9.439   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.381   loss each uniform = 8.431   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.875   loss each uniform = 11.523   feat norm = 0.449  

Validation:
Average incurred loss: 0.638  
Average sample loss: 0.619  
Average acc: 0.856  
Average grad norm: 5.540  
Average grad norm uniform: 33.672  
Average loss each uniform: 8.304  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.415   grad norm uniform = 35.445   loss each uniform = 11.247   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.073  exp loss = 1.183  adjusted loss = 1.183  adv prob = 0.250000   acc = 0.753   grad norm = 9.870   grad norm uniform = 32.200   loss each uniform = 5.487   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.730  exp loss = 1.894  adjusted loss = 1.894  adv prob = 0.250000   acc = 0.639   grad norm = 12.443   grad norm uniform = 30.360   loss each uniform = 5.300   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.962   grad norm = 1.459   grad norm uniform = 35.912   loss each uniform = 10.848   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [169]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.466  
Average loss each uniform: 11.751  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2248]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.920   loss each uniform = 12.285   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 40.493   loss each uniform = 8.990   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.341   loss each uniform = 8.669   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2298]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.779   loss each uniform = 11.543   feat norm = 0.448  

Validation:
Average incurred loss: 0.624  
Average sample loss: 0.604  
Average acc: 0.859  
Average grad norm: 5.441  
Average grad norm uniform: 33.418  
Average loss each uniform: 8.255  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.383   grad norm uniform = 35.157   loss each uniform = 11.239   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.995  exp loss = 1.097  adjusted loss = 1.097  adv prob = 0.250000   acc = 0.770   grad norm = 9.340   grad norm uniform = 31.946   loss each uniform = 5.481   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.882  exp loss = 2.026  adjusted loss = 2.026  adv prob = 0.250000   acc = 0.609   grad norm = 13.384   grad norm uniform = 30.236   loss each uniform = 5.198   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.962   grad norm = 1.593   grad norm uniform = 35.650   loss each uniform = 10.554   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [170]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.445  
Average loss each uniform: 11.749  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2307]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.842   loss each uniform = 11.981   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 40.455   loss each uniform = 9.290   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 37.328   loss each uniform = 8.954   feat norm = 0.456  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2251]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.803   loss each uniform = 11.787   feat norm = 0.448  

Validation:
Average incurred loss: 0.559  
Average sample loss: 0.539  
Average acc: 0.885  
Average grad norm: 4.555  
Average grad norm uniform: 34.141  
Average loss each uniform: 8.957  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.996   grad norm = 0.168   grad norm uniform = 35.671   loss each uniform = 12.412   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.638  exp loss = 0.716  adjusted loss = 0.716  adv prob = 0.250000   acc = 0.856   grad norm = 6.105   grad norm uniform = 33.862   loss each uniform = 6.450   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.492  exp loss = 2.644  adjusted loss = 2.644  adv prob = 0.250000   acc = 0.556   grad norm = 16.473   grad norm uniform = 29.214   loss each uniform = 5.043   feat norm = 0.421  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.289  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.925   grad norm = 2.604   grad norm uniform = 34.671   loss each uniform = 9.523   feat norm = 0.446  
Current lr: 0.001000
Current validation accuracy: 0.8849040865898132


Epoch [171]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.454  
Average loss each uniform: 11.669  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2246]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.003   loss each uniform = 12.204   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 40.433   loss each uniform = 9.334   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.751   loss each uniform = 8.680   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2298]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.667   loss each uniform = 11.438   feat norm = 0.447  

Validation:
Average incurred loss: 0.564  
Average sample loss: 0.543  
Average acc: 0.884  
Average grad norm: 4.663  
Average grad norm uniform: 34.273  
Average loss each uniform: 8.877  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.996   grad norm = 0.192   grad norm uniform = 35.657   loss each uniform = 12.225   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.674  exp loss = 0.748  adjusted loss = 0.748  adv prob = 0.250000   acc = 0.848   grad norm = 6.493   grad norm uniform = 34.030   loss each uniform = 6.355   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.406  exp loss = 2.557  adjusted loss = 2.557  adv prob = 0.250000   acc = 0.564   grad norm = 16.126   grad norm uniform = 29.402   loss each uniform = 5.080   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.284  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.940   grad norm = 2.489   grad norm uniform = 35.133   loss each uniform = 9.750   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8840700387954712


Epoch [172]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.456  
Average loss each uniform: 11.713  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2229]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.045   loss each uniform = 12.320   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 40.534   loss each uniform = 9.322   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.314   loss each uniform = 8.376   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2322]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.641   loss each uniform = 11.430   feat norm = 0.447  

Validation:
Average incurred loss: 0.627  
Average sample loss: 0.608  
Average acc: 0.860  
Average grad norm: 5.458  
Average grad norm uniform: 33.561  
Average loss each uniform: 8.272  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.413   grad norm uniform = 35.182   loss each uniform = 11.209   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.028  exp loss = 1.131  adjusted loss = 1.131  adv prob = 0.250000   acc = 0.766   grad norm = 9.573   grad norm uniform = 32.151   loss each uniform = 5.467   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.778  exp loss = 1.921  adjusted loss = 1.921  adv prob = 0.250000   acc = 0.632   grad norm = 12.682   grad norm uniform = 30.399   loss each uniform = 5.288   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.962   grad norm = 1.528   grad norm uniform = 35.974   loss each uniform = 10.773   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8598832488059998


Epoch [173]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.481  
Average loss each uniform: 11.728  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2283]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.001   loss each uniform = 12.127   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 102]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 40.161   loss each uniform = 9.351   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.867   loss each uniform = 8.808   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2292]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.776   loss each uniform = 11.586   feat norm = 0.449  

Validation:
Average incurred loss: 0.579  
Average sample loss: 0.560  
Average acc: 0.874  
Average grad norm: 4.897  
Average grad norm uniform: 33.400  
Average loss each uniform: 8.548  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.275   grad norm uniform = 35.013   loss each uniform = 11.740   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.812  exp loss = 0.901  adjusted loss = 0.901  adv prob = 0.250000   acc = 0.811   grad norm = 7.672   grad norm uniform = 32.473   loss each uniform = 5.908   feat norm = 0.462  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.094  exp loss = 2.259  adjusted loss = 2.259  adv prob = 0.250000   acc = 0.602   grad norm = 14.270   grad norm uniform = 29.459   loss each uniform = 5.074   feat norm = 0.417  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.236  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.955   grad norm = 2.025   grad norm uniform = 34.925   loss each uniform = 10.061   feat norm = 0.444  
Current lr: 0.001000
Current validation accuracy: 0.8740617036819458


Epoch [174]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.421  
Average loss each uniform: 11.722  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2298]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.843   loss each uniform = 12.030   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 40.036   loss each uniform = 8.744   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 144]:	loss = 0.001  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.046   grad norm uniform = 36.479   loss each uniform = 8.817   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2235]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.821   loss each uniform = 11.750   feat norm = 0.449  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.544  
Average acc: 0.882  
Average grad norm: 4.541  
Average grad norm uniform: 34.446  
Average loss each uniform: 9.132  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.996   grad norm = 0.130   grad norm uniform = 35.904   loss each uniform = 12.733   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.564  exp loss = 0.626  adjusted loss = 0.626  adv prob = 0.250000   acc = 0.873   grad norm = 5.615   grad norm uniform = 34.497   loss each uniform = 6.679   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.758  exp loss = 2.911  adjusted loss = 2.911  adv prob = 0.250000   acc = 0.481   grad norm = 17.799   grad norm uniform = 28.869   loss each uniform = 5.035   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.346  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.917   grad norm = 3.005   grad norm uniform = 34.728   loss each uniform = 9.177   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8824020028114319


Epoch [175]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.452  
Average loss each uniform: 11.802  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2292]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.932   loss each uniform = 12.058   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 40.401   loss each uniform = 8.991   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.557   loss each uniform = 8.851   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2252]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.756   loss each uniform = 11.862   feat norm = 0.448  

Validation:
Average incurred loss: 0.599  
Average sample loss: 0.581  
Average acc: 0.865  
Average grad norm: 5.190  
Average grad norm uniform: 33.844  
Average loss each uniform: 8.514  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.395   grad norm uniform = 35.552   loss each uniform = 11.551   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.931  exp loss = 1.039  adjusted loss = 1.039  adv prob = 0.250000   acc = 0.783   grad norm = 8.699   grad norm uniform = 32.729   loss each uniform = 5.783   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.865  exp loss = 2.048  adjusted loss = 2.048  adv prob = 0.250000   acc = 0.624   grad norm = 13.207   grad norm uniform = 30.081   loss each uniform = 5.280   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 0.955   grad norm = 1.712   grad norm uniform = 35.515   loss each uniform = 10.653   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8648874163627625


Epoch [176]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.427  
Average loss each uniform: 11.726  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.846   loss each uniform = 11.835   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 39.844   loss each uniform = 8.702   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 36.719   loss each uniform = 9.242   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2222]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.813   loss each uniform = 11.931   feat norm = 0.448  

Validation:
Average incurred loss: 0.632  
Average sample loss: 0.614  
Average acc: 0.857  
Average grad norm: 5.493  
Average grad norm uniform: 33.325  
Average loss each uniform: 8.216  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.468   grad norm uniform = 34.906   loss each uniform = 10.994   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.081  exp loss = 1.193  adjusted loss = 1.193  adv prob = 0.250000   acc = 0.753   grad norm = 9.869   grad norm uniform = 31.746   loss each uniform = 5.406   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.641  exp loss = 1.808  adjusted loss = 1.808  adv prob = 0.250000   acc = 0.654   grad norm = 11.933   grad norm uniform = 30.363   loss each uniform = 5.418   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.164  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.962   grad norm = 1.365   grad norm uniform = 36.267   loss each uniform = 11.105   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8573811650276184


Epoch [177]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.448  
Average loss each uniform: 11.795  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2265]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.986   loss each uniform = 12.175   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 40.324   loss each uniform = 9.049   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.229   loss each uniform = 8.915   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2286]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.700   loss each uniform = 11.718   feat norm = 0.447  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.553  
Average acc: 0.877  
Average grad norm: 4.843  
Average grad norm uniform: 33.894  
Average loss each uniform: 8.654  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.991   grad norm = 0.261   grad norm uniform = 35.324   loss each uniform = 11.865   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.793  exp loss = 0.880  adjusted loss = 0.880  adv prob = 0.250000   acc = 0.818   grad norm = 7.489   grad norm uniform = 33.219   loss each uniform = 6.029   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.100  exp loss = 2.250  adjusted loss = 2.250  adv prob = 0.250000   acc = 0.602   grad norm = 14.473   grad norm uniform = 29.802   loss each uniform = 5.098   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.955   grad norm = 2.033   grad norm uniform = 35.333   loss each uniform = 10.136   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8765637874603271


Epoch [178]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.437  
Average loss each uniform: 11.740  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2310]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.769   loss each uniform = 11.909   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 40.501   loss each uniform = 8.663   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 131]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 37.194   loss each uniform = 9.031   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2225]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.851   loss each uniform = 11.903   feat norm = 0.449  

Validation:
Average incurred loss: 0.695  
Average sample loss: 0.678  
Average acc: 0.849  
Average grad norm: 5.949  
Average grad norm uniform: 33.749  
Average loss each uniform: 8.222  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.985   grad norm = 0.605   grad norm uniform = 35.331   loss each uniform = 10.872   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.291  exp loss = 1.433  adjusted loss = 1.433  adv prob = 0.250000   acc = 0.717   grad norm = 11.349   grad norm uniform = 32.123   loss each uniform = 5.300   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.450  exp loss = 1.624  adjusted loss = 1.624  adv prob = 0.250000   acc = 0.707   grad norm = 10.619   grad norm uniform = 30.807   loss each uniform = 5.710   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.977   grad norm = 1.127   grad norm uniform = 36.830   loss each uniform = 11.664   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8490408658981323


Epoch [179]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.455  
Average loss each uniform: 11.774  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.023   loss each uniform = 12.122   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 134]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 40.042   loss each uniform = 9.139   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.107   loss each uniform = 8.938   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.695   loss each uniform = 11.737   feat norm = 0.447  

Validation:
Average incurred loss: 0.552  
Average sample loss: 0.534  
Average acc: 0.877  
Average grad norm: 4.633  
Average grad norm uniform: 34.090  
Average loss each uniform: 8.772  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.991   grad norm = 0.251   grad norm uniform = 35.513   loss each uniform = 11.962   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.730  exp loss = 0.817  adjusted loss = 0.817  adv prob = 0.250000   acc = 0.828   grad norm = 6.885   grad norm uniform = 33.527   loss each uniform = 6.225   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.131  exp loss = 2.314  adjusted loss = 2.314  adv prob = 0.250000   acc = 0.586   grad norm = 14.514   grad norm uniform = 29.939   loss each uniform = 5.185   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.247  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.940   grad norm = 2.247   grad norm uniform = 35.219   loss each uniform = 10.078   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.877397894859314


Epoch [180]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.462  
Average loss each uniform: 11.814  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2300]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.915   loss each uniform = 12.104   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 40.021   loss each uniform = 8.907   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 107]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.494   loss each uniform = 9.118   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.836   loss each uniform = 11.793   feat norm = 0.449  

Validation:
Average incurred loss: 0.611  
Average sample loss: 0.594  
Average acc: 0.865  
Average grad norm: 5.330  
Average grad norm uniform: 34.141  
Average loss each uniform: 8.473  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.989   grad norm = 0.449   grad norm uniform = 35.734   loss each uniform = 11.354   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.014  exp loss = 1.112  adjusted loss = 1.112  adv prob = 0.250000   acc = 0.773   grad norm = 9.363   grad norm uniform = 32.813   loss each uniform = 5.676   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.685  exp loss = 1.884  adjusted loss = 1.884  adv prob = 0.250000   acc = 0.654   grad norm = 12.197   grad norm uniform = 30.797   loss each uniform = 5.510   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.962   grad norm = 1.476   grad norm uniform = 36.542   loss each uniform = 11.123   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8648874163627625


Epoch [181]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.455  
Average loss each uniform: 11.800  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2285]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.878   loss each uniform = 12.150   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.948   loss each uniform = 8.946   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 37.028   loss each uniform = 9.073   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.819   loss each uniform = 11.743   feat norm = 0.449  

Validation:
Average incurred loss: 0.570  
Average sample loss: 0.549  
Average acc: 0.887  
Average grad norm: 4.560  
Average grad norm uniform: 34.939  
Average loss each uniform: 9.346  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.996   grad norm = 0.153   grad norm uniform = 36.496   loss each uniform = 12.981   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.608  exp loss = 0.671  adjusted loss = 0.671  adv prob = 0.250000   acc = 0.865   grad norm = 5.874   grad norm uniform = 34.721   loss each uniform = 6.831   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.666  exp loss = 2.837  adjusted loss = 2.837  adv prob = 0.250000   acc = 0.541   grad norm = 17.168   grad norm uniform = 29.959   loss each uniform = 5.175   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.323  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 0.925   grad norm = 2.824   grad norm uniform = 35.216   loss each uniform = 9.564   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8865721225738525


Epoch [182]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.458  
Average loss each uniform: 11.861  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2308]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.988   loss each uniform = 12.093   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 39.575   loss each uniform = 8.694   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.904   loss each uniform = 9.318   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2246]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.751   loss each uniform = 11.929   feat norm = 0.447  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.553  
Average acc: 0.876  
Average grad norm: 4.857  
Average grad norm uniform: 34.123  
Average loss each uniform: 8.760  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.991   grad norm = 0.267   grad norm uniform = 35.651   loss each uniform = 12.019   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.778  exp loss = 0.866  adjusted loss = 0.866  adv prob = 0.250000   acc = 0.820   grad norm = 7.441   grad norm uniform = 33.399   loss each uniform = 6.126   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.150  exp loss = 2.313  adjusted loss = 2.313  adv prob = 0.250000   acc = 0.602   grad norm = 14.640   grad norm uniform = 30.102   loss each uniform = 5.174   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.236  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.940   grad norm = 2.141   grad norm uniform = 35.314   loss each uniform = 10.129   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [183]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.471  
Average loss each uniform: 11.853  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2284]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.089   loss each uniform = 12.230   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 40.409   loss each uniform = 8.810   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.361   loss each uniform = 8.962   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2288]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.667   loss each uniform = 11.767   feat norm = 0.447  

Validation:
Average incurred loss: 0.652  
Average sample loss: 0.634  
Average acc: 0.848  
Average grad norm: 5.733  
Average grad norm uniform: 33.544  
Average loss each uniform: 8.167  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.989   grad norm = 0.513   grad norm uniform = 35.217   loss each uniform = 10.931   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.143  exp loss = 1.272  adjusted loss = 1.272  adv prob = 0.250000   acc = 0.732   grad norm = 10.453   grad norm uniform = 31.908   loss each uniform = 5.334   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.606  exp loss = 1.779  adjusted loss = 1.779  adv prob = 0.250000   acc = 0.647   grad norm = 11.965   grad norm uniform = 30.617   loss each uniform = 5.419   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.962   grad norm = 1.294   grad norm uniform = 36.331   loss each uniform = 11.133   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [184]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.467  
Average loss each uniform: 11.871  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.055   loss each uniform = 12.229   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 39.439   loss each uniform = 8.848   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 35.935   loss each uniform = 8.899   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2279]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.753   loss each uniform = 11.820   feat norm = 0.448  

Validation:
Average incurred loss: 0.633  
Average sample loss: 0.614  
Average acc: 0.861  
Average grad norm: 5.394  
Average grad norm uniform: 33.757  
Average loss each uniform: 8.472  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.410   grad norm uniform = 35.382   loss each uniform = 11.475   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.030  exp loss = 1.142  adjusted loss = 1.142  adv prob = 0.250000   acc = 0.766   grad norm = 9.362   grad norm uniform = 32.488   loss each uniform = 5.658   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.827  exp loss = 1.991  adjusted loss = 1.991  adv prob = 0.250000   acc = 0.639   grad norm = 12.863   grad norm uniform = 30.380   loss each uniform = 5.343   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.962   grad norm = 1.526   grad norm uniform = 35.869   loss each uniform = 10.917   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [185]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.447  
Average loss each uniform: 11.883  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2304]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.982   loss each uniform = 12.196   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.754   loss each uniform = 8.720   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.618   loss each uniform = 9.234   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.755   loss each uniform = 11.851   feat norm = 0.448  

Validation:
Average incurred loss: 0.575  
Average sample loss: 0.557  
Average acc: 0.875  
Average grad norm: 4.826  
Average grad norm uniform: 34.264  
Average loss each uniform: 8.840  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.297   grad norm uniform = 35.788   loss each uniform = 12.087   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.803  exp loss = 0.899  adjusted loss = 0.899  adv prob = 0.250000   acc = 0.813   grad norm = 7.508   grad norm uniform = 33.511   loss each uniform = 6.180   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.083  exp loss = 2.269  adjusted loss = 2.269  adv prob = 0.250000   acc = 0.602   grad norm = 14.180   grad norm uniform = 30.266   loss each uniform = 5.247   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.236  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.955   grad norm = 1.979   grad norm uniform = 35.545   loss each uniform = 10.353   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8748958110809326


Epoch [186]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.443  
Average loss each uniform: 11.861  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2291]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.933   loss each uniform = 12.217   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 109]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 39.985   loss each uniform = 9.024   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.414   loss each uniform = 8.958   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2277]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.789   loss each uniform = 11.788   feat norm = 0.449  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.607  
Average acc: 0.864  
Average grad norm: 5.389  
Average grad norm uniform: 33.865  
Average loss each uniform: 8.521  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.411   grad norm uniform = 35.567   loss each uniform = 11.581   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.006  exp loss = 1.120  adjusted loss = 1.120  adv prob = 0.250000   acc = 0.779   grad norm = 9.272   grad norm uniform = 32.591   loss each uniform = 5.714   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.838  exp loss = 1.999  adjusted loss = 1.999  adv prob = 0.250000   acc = 0.624   grad norm = 13.023   grad norm uniform = 30.482   loss each uniform = 5.321   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.962   grad norm = 1.630   grad norm uniform = 35.734   loss each uniform = 10.815   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [187]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.448  
Average loss each uniform: 11.923  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2262]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.973   loss each uniform = 12.413   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.925   loss each uniform = 9.421   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.625   loss each uniform = 9.073   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2287]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.735   loss each uniform = 11.728   feat norm = 0.448  

Validation:
Average incurred loss: 0.584  
Average sample loss: 0.565  
Average acc: 0.870  
Average grad norm: 4.987  
Average grad norm uniform: 34.267  
Average loss each uniform: 8.724  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.314   grad norm uniform = 35.868   loss each uniform = 11.947   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.840  exp loss = 0.934  adjusted loss = 0.934  adv prob = 0.250000   acc = 0.800   grad norm = 7.938   grad norm uniform = 33.324   loss each uniform = 6.005   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.054  exp loss = 2.215  adjusted loss = 2.215  adv prob = 0.250000   acc = 0.609   grad norm = 14.127   grad norm uniform = 30.656   loss each uniform = 5.248   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.947   grad norm = 1.917   grad norm uniform = 35.562   loss each uniform = 10.411   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8698915243148804


Epoch [188]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.468  
Average loss each uniform: 11.857  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2245]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.102   loss each uniform = 12.435   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.624   loss each uniform = 9.332   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.863   loss each uniform = 8.969   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2325]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.651   loss each uniform = 11.560   feat norm = 0.447  

Validation:
Average incurred loss: 0.590  
Average sample loss: 0.570  
Average acc: 0.872  
Average grad norm: 4.995  
Average grad norm uniform: 34.048  
Average loss each uniform: 8.715  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.280   grad norm uniform = 35.548   loss each uniform = 11.978   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.830  exp loss = 0.929  adjusted loss = 0.929  adv prob = 0.250000   acc = 0.809   grad norm = 7.845   grad norm uniform = 33.318   loss each uniform = 6.006   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.134  exp loss = 2.281  adjusted loss = 2.281  adv prob = 0.250000   acc = 0.594   grad norm = 14.570   grad norm uniform = 30.006   loss each uniform = 5.169   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.231  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.947   grad norm = 1.988   grad norm uniform = 35.380   loss each uniform = 10.297   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [189]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.474  
Average loss each uniform: 11.904  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2320]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.819   loss each uniform = 12.096   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 39.815   loss each uniform = 8.699   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.826   loss each uniform = 9.530   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2235]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.950   loss each uniform = 12.007   feat norm = 0.450  

Validation:
Average incurred loss: 0.672  
Average sample loss: 0.655  
Average acc: 0.847  
Average grad norm: 5.815  
Average grad norm uniform: 33.512  
Average loss each uniform: 8.239  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.499   grad norm uniform = 35.163   loss each uniform = 11.023   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.196  exp loss = 1.320  adjusted loss = 1.320  adv prob = 0.250000   acc = 0.723   grad norm = 10.775   grad norm uniform = 32.020   loss each uniform = 5.362   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.602  exp loss = 1.770  adjusted loss = 1.770  adv prob = 0.250000   acc = 0.662   grad norm = 11.680   grad norm uniform = 30.210   loss each uniform = 5.463   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.970   grad norm = 1.233   grad norm uniform = 36.247   loss each uniform = 11.319   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [190]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.449  
Average loss each uniform: 11.912  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2310]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.957   loss each uniform = 12.205   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.444   loss each uniform = 8.964   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.458   loss each uniform = 9.265   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2258]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.809   loss each uniform = 11.893   feat norm = 0.448  

Validation:
Average incurred loss: 0.643  
Average sample loss: 0.624  
Average acc: 0.855  
Average grad norm: 5.532  
Average grad norm uniform: 33.483  
Average loss each uniform: 8.314  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.465   grad norm uniform = 34.931   loss each uniform = 11.190   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.085  exp loss = 1.201  adjusted loss = 1.201  adv prob = 0.250000   acc = 0.749   grad norm = 9.868   grad norm uniform = 32.235   loss each uniform = 5.478   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.728  exp loss = 1.883  adjusted loss = 1.883  adv prob = 0.250000   acc = 0.647   grad norm = 12.229   grad norm uniform = 30.023   loss each uniform = 5.380   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.962   grad norm = 1.440   grad norm uniform = 36.235   loss each uniform = 11.089   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8548791408538818


Epoch [191]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.421  
Average loss each uniform: 11.877  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2285]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.818   loss each uniform = 12.196   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 40.653   loss each uniform = 9.455   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 37.177   loss each uniform = 9.023   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2271]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.754   loss each uniform = 11.833   feat norm = 0.448  

Validation:
Average incurred loss: 0.577  
Average sample loss: 0.558  
Average acc: 0.872  
Average grad norm: 4.849  
Average grad norm uniform: 34.140  
Average loss each uniform: 8.816  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.274   grad norm uniform = 35.665   loss each uniform = 12.082   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.793  exp loss = 0.875  adjusted loss = 0.875  adv prob = 0.250000   acc = 0.809   grad norm = 7.455   grad norm uniform = 33.387   loss each uniform = 6.144   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.137  exp loss = 2.308  adjusted loss = 2.308  adv prob = 0.250000   acc = 0.594   grad norm = 14.478   grad norm uniform = 30.105   loss each uniform = 5.253   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.241  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.947   grad norm = 2.151   grad norm uniform = 35.459   loss each uniform = 10.272   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [192]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.432  
Average loss each uniform: 11.849  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2340]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.775   loss each uniform = 11.905   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 40.032   loss each uniform = 8.916   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.986   loss each uniform = 9.430   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2212]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.887   loss each uniform = 12.086   feat norm = 0.449  

Validation:
Average incurred loss: 0.642  
Average sample loss: 0.624  
Average acc: 0.857  
Average grad norm: 5.600  
Average grad norm uniform: 33.250  
Average loss each uniform: 8.190  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.420   grad norm uniform = 34.771   loss each uniform = 11.083   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.065  exp loss = 1.184  adjusted loss = 1.184  adv prob = 0.250000   acc = 0.760   grad norm = 9.906   grad norm uniform = 31.787   loss each uniform = 5.351   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.795  exp loss = 1.950  adjusted loss = 1.950  adv prob = 0.250000   acc = 0.624   grad norm = 12.858   grad norm uniform = 30.247   loss each uniform = 5.273   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.962   grad norm = 1.440   grad norm uniform = 36.039   loss each uniform = 10.896   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [193]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.444  
Average loss each uniform: 11.891  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2321]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.910   loss each uniform = 12.102   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 39.910   loss each uniform = 8.887   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.534   loss each uniform = 9.053   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2234]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.811   loss each uniform = 11.985   feat norm = 0.448  

Validation:
Average incurred loss: 0.606  
Average sample loss: 0.587  
Average acc: 0.869  
Average grad norm: 5.156  
Average grad norm uniform: 33.654  
Average loss each uniform: 8.490  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.386   grad norm uniform = 35.088   loss each uniform = 11.500   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.950  exp loss = 1.047  adjusted loss = 1.047  adv prob = 0.250000   acc = 0.788   grad norm = 8.742   grad norm uniform = 32.541   loss each uniform = 5.724   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.857  exp loss = 2.011  adjusted loss = 2.011  adv prob = 0.250000   acc = 0.639   grad norm = 12.858   grad norm uniform = 30.231   loss each uniform = 5.301   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.201  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.962   grad norm = 1.636   grad norm uniform = 35.939   loss each uniform = 10.796   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8690575957298279


Epoch [194]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.396  
Average loss each uniform: 11.848  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.858   loss each uniform = 12.313   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 40.473   loss each uniform = 9.119   feat norm = 0.509  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 140]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.815   loss each uniform = 8.966   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.690   loss each uniform = 11.705   feat norm = 0.448  

Validation:
Average incurred loss: 0.576  
Average sample loss: 0.556  
Average acc: 0.872  
Average grad norm: 4.825  
Average grad norm uniform: 34.188  
Average loss each uniform: 8.881  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.247   grad norm uniform = 35.730   loss each uniform = 12.272   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.760  exp loss = 0.861  adjusted loss = 0.861  adv prob = 0.250000   acc = 0.815   grad norm = 7.242   grad norm uniform = 33.527   loss each uniform = 6.208   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.246  exp loss = 2.407  adjusted loss = 2.407  adv prob = 0.250000   acc = 0.579   grad norm = 15.055   grad norm uniform = 30.126   loss each uniform = 5.145   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.249  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.940   grad norm = 2.195   grad norm uniform = 35.153   loss each uniform = 10.080   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8723936676979065


Epoch [195]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.450  
Average loss each uniform: 11.913  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2254]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.946   loss each uniform = 12.442   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 40.046   loss each uniform = 9.479   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 35.821   loss each uniform = 8.610   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2304]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.786   loss each uniform = 11.689   feat norm = 0.448  

Validation:
Average incurred loss: 0.622  
Average sample loss: 0.603  
Average acc: 0.862  
Average grad norm: 5.338  
Average grad norm uniform: 33.702  
Average loss each uniform: 8.514  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.349   grad norm uniform = 35.392   loss each uniform = 11.665   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.965  exp loss = 1.069  adjusted loss = 1.069  adv prob = 0.250000   acc = 0.781   grad norm = 9.004   grad norm uniform = 32.426   loss each uniform = 5.680   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.960  exp loss = 2.115  adjusted loss = 2.115  adv prob = 0.250000   acc = 0.602   grad norm = 13.622   grad norm uniform = 30.317   loss each uniform = 5.244   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.962   grad norm = 1.730   grad norm uniform = 35.627   loss each uniform = 10.651   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [196]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.443  
Average loss each uniform: 11.882  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.990   loss each uniform = 12.352   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 40.579   loss each uniform = 9.689   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.318   loss each uniform = 8.716   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2287]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.689   loss each uniform = 11.701   feat norm = 0.447  

Validation:
Average incurred loss: 0.589  
Average sample loss: 0.570  
Average acc: 0.873  
Average grad norm: 4.940  
Average grad norm uniform: 34.171  
Average loss each uniform: 8.835  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.275   grad norm uniform = 35.749   loss each uniform = 12.141   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.805  exp loss = 0.892  adjusted loss = 0.892  adv prob = 0.250000   acc = 0.813   grad norm = 7.587   grad norm uniform = 33.362   loss each uniform = 6.152   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.202  exp loss = 2.367  adjusted loss = 2.367  adv prob = 0.250000   acc = 0.594   grad norm = 14.908   grad norm uniform = 30.241   loss each uniform = 5.212   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.246  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.947   grad norm = 2.081   grad norm uniform = 35.393   loss each uniform = 10.254   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485


Epoch [197]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.431  
Average loss each uniform: 11.885  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2228]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.043   loss each uniform = 12.461   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 141]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.856   loss each uniform = 9.447   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.515   loss each uniform = 8.714   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.592   loss each uniform = 11.659   feat norm = 0.446  

Validation:
Average incurred loss: 0.709  
Average sample loss: 0.690  
Average acc: 0.842  
Average grad norm: 6.009  
Average grad norm uniform: 33.705  
Average loss each uniform: 8.233  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.044  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.985   grad norm = 0.590   grad norm uniform = 35.271   loss each uniform = 10.903   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.315  exp loss = 1.439  adjusted loss = 1.439  adv prob = 0.250000   acc = 0.702   grad norm = 11.436   grad norm uniform = 32.210   loss each uniform = 5.292   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.486  exp loss = 1.669  adjusted loss = 1.669  adv prob = 0.250000   acc = 0.692   grad norm = 10.902   grad norm uniform = 30.499   loss each uniform = 5.698   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.144  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.977   grad norm = 1.124   grad norm uniform = 36.648   loss each uniform = 11.698   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8415346145629883


Epoch [198]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.426  
Average loss each uniform: 11.961  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.858   loss each uniform = 12.282   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 40.080   loss each uniform = 9.565   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 142]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.567   loss each uniform = 9.255   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2241]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.805   loss each uniform = 11.932   feat norm = 0.448  

Validation:
Average incurred loss: 0.566  
Average sample loss: 0.548  
Average acc: 0.875  
Average grad norm: 4.756  
Average grad norm uniform: 34.087  
Average loss each uniform: 8.788  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.989   grad norm = 0.278   grad norm uniform = 35.467   loss each uniform = 12.011   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.772  exp loss = 0.855  adjusted loss = 0.855  adv prob = 0.250000   acc = 0.820   grad norm = 7.263   grad norm uniform = 33.296   loss each uniform = 6.155   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.104  exp loss = 2.257  adjusted loss = 2.257  adv prob = 0.250000   acc = 0.594   grad norm = 14.303   grad norm uniform = 30.310   loss each uniform = 5.207   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.248  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.947   grad norm = 2.147   grad norm uniform = 35.791   loss each uniform = 10.280   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8748957514762878


Epoch [199]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.409  
Average loss each uniform: 11.921  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2360]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.689   loss each uniform = 11.947   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 40.297   loss each uniform = 8.883   feat norm = 0.509  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.569   loss each uniform = 9.356   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2201]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.966   loss each uniform = 12.192   feat norm = 0.450  

Validation:
Average incurred loss: 0.730  
Average sample loss: 0.711  
Average acc: 0.842  
Average grad norm: 6.265  
Average grad norm uniform: 33.773  
Average loss each uniform: 8.148  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.985   grad norm = 0.620   grad norm uniform = 35.239   loss each uniform = 10.769   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.377  exp loss = 1.527  adjusted loss = 1.527  adv prob = 0.250000   acc = 0.697   grad norm = 12.081   grad norm uniform = 32.229   loss each uniform = 5.220   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.467  exp loss = 1.652  adjusted loss = 1.652  adv prob = 0.250000   acc = 0.707   grad norm = 10.932   grad norm uniform = 30.779   loss each uniform = 5.640   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.142  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 0.977   grad norm = 1.048   grad norm uniform = 37.030   loss each uniform = 11.714   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8415346145629883


Epoch [200]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.454  
Average loss each uniform: 11.892  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2287]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.912   loss each uniform = 12.268   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 40.607   loss each uniform = 9.244   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.824   loss each uniform = 8.994   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2263]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.768   loss each uniform = 11.814   feat norm = 0.448  

Validation:
Average incurred loss: 0.646  
Average sample loss: 0.628  
Average acc: 0.857  
Average grad norm: 5.483  
Average grad norm uniform: 33.672  
Average loss each uniform: 8.449  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.402   grad norm uniform = 35.240   loss each uniform = 11.424   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.068  exp loss = 1.163  adjusted loss = 1.163  adv prob = 0.250000   acc = 0.760   grad norm = 9.631   grad norm uniform = 32.231   loss each uniform = 5.560   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.811  exp loss = 1.963  adjusted loss = 1.963  adv prob = 0.250000   acc = 0.624   grad norm = 12.731   grad norm uniform = 30.596   loss each uniform = 5.403   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.962   grad norm = 1.540   grad norm uniform = 36.284   loss each uniform = 11.165   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [201]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.425  
Average loss each uniform: 11.915  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2272]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.894   loss each uniform = 12.305   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 40.792   loss each uniform = 9.571   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.516   loss each uniform = 8.857   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.707   loss each uniform = 11.809   feat norm = 0.447  

Validation:
Average incurred loss: 0.657  
Average sample loss: 0.638  
Average acc: 0.851  
Average grad norm: 5.588  
Average grad norm uniform: 33.302  
Average loss each uniform: 8.349  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.467   grad norm uniform = 34.783   loss each uniform = 11.188   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.134  exp loss = 1.240  adjusted loss = 1.240  adv prob = 0.250000   acc = 0.738   grad norm = 10.123   grad norm uniform = 31.976   loss each uniform = 5.464   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.675  exp loss = 1.844  adjusted loss = 1.844  adv prob = 0.250000   acc = 0.647   grad norm = 11.912   grad norm uniform = 29.878   loss each uniform = 5.498   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.962   grad norm = 1.357   grad norm uniform = 36.176   loss each uniform = 11.340   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8507089614868164


Epoch [202]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.464  
Average loss each uniform: 11.932  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.965   loss each uniform = 12.371   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 40.171   loss each uniform = 9.693   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 36.872   loss each uniform = 8.782   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2290]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.740   loss each uniform = 11.776   feat norm = 0.447  

Validation:
Average incurred loss: 0.604  
Average sample loss: 0.585  
Average acc: 0.869  
Average grad norm: 5.058  
Average grad norm uniform: 33.897  
Average loss each uniform: 8.720  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.318   grad norm uniform = 35.509   loss each uniform = 11.969   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.895  exp loss = 0.995  adjusted loss = 0.995  adv prob = 0.250000   acc = 0.794   grad norm = 8.228   grad norm uniform = 32.927   loss each uniform = 5.934   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.031  exp loss = 2.188  adjusted loss = 2.188  adv prob = 0.250000   acc = 0.609   grad norm = 13.830   grad norm uniform = 30.178   loss each uniform = 5.256   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.962   grad norm = 1.827   grad norm uniform = 35.353   loss each uniform = 10.538   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [203]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.420  
Average loss each uniform: 11.948  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2265]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.993   loss each uniform = 12.408   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.851   loss each uniform = 9.237   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 127]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.942   loss each uniform = 9.101   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2280]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.631   loss each uniform = 11.796   feat norm = 0.447  

Validation:
Average incurred loss: 0.563  
Average sample loss: 0.542  
Average acc: 0.890  
Average grad norm: 4.491  
Average grad norm uniform: 34.895  
Average loss each uniform: 9.291  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.151   grad norm uniform = 36.132   loss each uniform = 12.796   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.615  exp loss = 0.681  adjusted loss = 0.681  adv prob = 0.250000   acc = 0.869   grad norm = 5.851   grad norm uniform = 34.870   loss each uniform = 6.811   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.581  exp loss = 2.750  adjusted loss = 2.750  adv prob = 0.250000   acc = 0.549   grad norm = 16.645   grad norm uniform = 30.173   loss each uniform = 5.224   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.322  exp loss = 0.280  adjusted loss = 0.280  adv prob = 0.250000   acc = 0.925   grad norm = 2.813   grad norm uniform = 35.365   loss each uniform = 9.739   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8899082541465759
Best model saved at epoch 203


Epoch [204]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.420  
Average loss each uniform: 11.925  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2211]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.096   loss each uniform = 12.626   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 39.935   loss each uniform = 9.803   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.500   loss each uniform = 8.740   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2341]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.536   loss each uniform = 11.537   feat norm = 0.446  

Validation:
Average incurred loss: 0.559  
Average sample loss: 0.538  
Average acc: 0.888  
Average grad norm: 4.490  
Average grad norm uniform: 35.007  
Average loss each uniform: 9.319  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.996   grad norm = 0.148   grad norm uniform = 36.410   loss each uniform = 12.923   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.611  exp loss = 0.686  adjusted loss = 0.686  adv prob = 0.250000   acc = 0.869   grad norm = 5.879   grad norm uniform = 34.912   loss each uniform = 6.787   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.569  exp loss = 2.735  adjusted loss = 2.735  adv prob = 0.250000   acc = 0.541   grad norm = 16.623   grad norm uniform = 30.173   loss each uniform = 5.182   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.308  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.925   grad norm = 2.733   grad norm uniform = 35.247   loss each uniform = 9.677   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8882402181625366


Epoch [205]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.453  
Average loss each uniform: 11.931  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2236]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.088   loss each uniform = 12.512   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 40.418   loss each uniform = 9.489   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 106]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.836   loss each uniform = 8.857   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2326]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.570   loss each uniform = 11.645   feat norm = 0.446  

Validation:
Average incurred loss: 0.576  
Average sample loss: 0.557  
Average acc: 0.879  
Average grad norm: 4.763  
Average grad norm uniform: 34.363  
Average loss each uniform: 8.976  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.281   grad norm uniform = 35.941   loss each uniform = 12.321   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.774  exp loss = 0.858  adjusted loss = 0.858  adv prob = 0.250000   acc = 0.826   grad norm = 7.198   grad norm uniform = 33.675   loss each uniform = 6.319   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.185  exp loss = 2.364  adjusted loss = 2.364  adv prob = 0.250000   acc = 0.602   grad norm = 14.605   grad norm uniform = 30.379   loss each uniform = 5.245   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.241  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.947   grad norm = 2.129   grad norm uniform = 35.218   loss each uniform = 10.272   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8790659308433533


Epoch [206]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.398  
Average loss each uniform: 11.904  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2225]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.021   loss each uniform = 12.482   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 40.548   loss each uniform = 9.505   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.331   loss each uniform = 8.709   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.524   loss each uniform = 11.671   feat norm = 0.445  

Validation:
Average incurred loss: 0.621  
Average sample loss: 0.601  
Average acc: 0.867  
Average grad norm: 5.236  
Average grad norm uniform: 34.118  
Average loss each uniform: 8.699  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.340   grad norm uniform = 35.749   loss each uniform = 11.925   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.934  exp loss = 1.042  adjusted loss = 1.042  adv prob = 0.250000   acc = 0.796   grad norm = 8.632   grad norm uniform = 33.042   loss each uniform = 5.871   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.052  exp loss = 2.226  adjusted loss = 2.226  adv prob = 0.250000   acc = 0.594   grad norm = 13.926   grad norm uniform = 30.528   loss each uniform = 5.307   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.208  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.955   grad norm = 1.836   grad norm uniform = 35.756   loss each uniform = 10.673   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [207]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.433  
Average loss each uniform: 11.975  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.895   loss each uniform = 12.350   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 140]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.988   loss each uniform = 9.262   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.697   loss each uniform = 9.348   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2272]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.736   loss each uniform = 11.907   feat norm = 0.447  

Validation:
Average incurred loss: 0.593  
Average sample loss: 0.574  
Average acc: 0.871  
Average grad norm: 4.956  
Average grad norm uniform: 34.043  
Average loss each uniform: 8.790  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.323   grad norm uniform = 35.546   loss each uniform = 11.994   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.856  exp loss = 0.942  adjusted loss = 0.942  adv prob = 0.250000   acc = 0.805   grad norm = 7.910   grad norm uniform = 33.250   loss each uniform = 6.071   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.057  exp loss = 2.254  adjusted loss = 2.254  adv prob = 0.250000   acc = 0.602   grad norm = 13.909   grad norm uniform = 30.204   loss each uniform = 5.315   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.225  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947   grad norm = 1.924   grad norm uniform = 35.385   loss each uniform = 10.544   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [208]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.410  
Average loss each uniform: 11.939  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2273]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.010   loss each uniform = 12.435   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 92]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 40.060   loss each uniform = 9.754   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 111]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 37.181   loss each uniform = 9.163   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2319]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.621   loss each uniform = 11.673   feat norm = 0.446  

Validation:
Average incurred loss: 0.714  
Average sample loss: 0.696  
Average acc: 0.843  
Average grad norm: 6.001  
Average grad norm uniform: 33.277  
Average loss each uniform: 8.219  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.037  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.985   grad norm = 0.553   grad norm uniform = 34.736   loss each uniform = 10.867   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.334  exp loss = 1.467  adjusted loss = 1.467  adv prob = 0.250000   acc = 0.704   grad norm = 11.490   grad norm uniform = 31.790   loss each uniform = 5.283   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.489  exp loss = 1.666  adjusted loss = 1.666  adv prob = 0.250000   acc = 0.699   grad norm = 10.801   grad norm uniform = 30.190   loss each uniform = 5.650   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.145  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.977   grad norm = 1.098   grad norm uniform = 36.452   loss each uniform = 11.779   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8432025909423828


Epoch [209]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.450  
Average loss each uniform: 12.036  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2313]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.939   loss each uniform = 12.262   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 40.089   loss each uniform = 8.642   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 135]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.408   loss each uniform = 9.653   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2226]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.786   loss each uniform = 12.130   feat norm = 0.447  

Validation:
Average incurred loss: 0.679  
Average sample loss: 0.661  
Average acc: 0.847  
Average grad norm: 5.766  
Average grad norm uniform: 33.187  
Average loss each uniform: 8.204  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.037  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.987   grad norm = 0.557   grad norm uniform = 34.585   loss each uniform = 10.838   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.243  exp loss = 1.361  adjusted loss = 1.361  adv prob = 0.250000   acc = 0.719   grad norm = 10.873   grad norm uniform = 31.656   loss each uniform = 5.317   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.491  exp loss = 1.681  adjusted loss = 1.681  adv prob = 0.250000   acc = 0.684   grad norm = 10.830   grad norm uniform = 30.374   loss each uniform = 5.666   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.147  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.970   grad norm = 1.103   grad norm uniform = 36.458   loss each uniform = 11.612   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.847372829914093


Epoch [210]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.412  
Average loss each uniform: 11.981  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.905   loss each uniform = 12.222   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 40.148   loss each uniform = 8.937   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 37.016   loss each uniform = 9.237   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2245]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.684   loss each uniform = 12.055   feat norm = 0.447  

Validation:
Average incurred loss: 0.578  
Average sample loss: 0.559  
Average acc: 0.873  
Average grad norm: 4.827  
Average grad norm uniform: 34.086  
Average loss each uniform: 8.835  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.281   grad norm uniform = 35.524   loss each uniform = 12.109   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.788  exp loss = 0.875  adjusted loss = 0.875  adv prob = 0.250000   acc = 0.813   grad norm = 7.393   grad norm uniform = 33.375   loss each uniform = 6.146   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.157  exp loss = 2.329  adjusted loss = 2.329  adv prob = 0.250000   acc = 0.594   grad norm = 14.526   grad norm uniform = 30.195   loss each uniform = 5.246   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.246  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.947   grad norm = 2.100   grad norm uniform = 35.419   loss each uniform = 10.355   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485


Epoch [211]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.437  
Average loss each uniform: 11.988  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.878   loss each uniform = 12.210   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 102]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 40.015   loss each uniform = 8.766   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 37.377   loss each uniform = 9.621   feat norm = 0.454  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2244]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.806   loss each uniform = 12.028   feat norm = 0.448  

Validation:
Average incurred loss: 0.577  
Average sample loss: 0.558  
Average acc: 0.879  
Average grad norm: 4.702  
Average grad norm uniform: 34.387  
Average loss each uniform: 9.137  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.991   grad norm = 0.238   grad norm uniform = 35.877   loss each uniform = 12.593   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.736  exp loss = 0.818  adjusted loss = 0.818  adv prob = 0.250000   acc = 0.835   grad norm = 6.881   grad norm uniform = 33.994   loss each uniform = 6.492   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.321  exp loss = 2.495  adjusted loss = 2.495  adv prob = 0.250000   acc = 0.579   grad norm = 15.187   grad norm uniform = 29.824   loss each uniform = 5.243   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.261  exp loss = 0.234  adjusted loss = 0.234  adv prob = 0.250000   acc = 0.940   grad norm = 2.254   grad norm uniform = 35.091   loss each uniform = 10.165   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8790659308433533


Epoch [212]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.432  
Average loss each uniform: 11.950  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2232]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.978   loss each uniform = 12.541   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 40.769   loss each uniform = 9.440   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 128]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.992   loss each uniform = 9.094   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2305]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.596   loss each uniform = 11.677   feat norm = 0.446  

Validation:
Average incurred loss: 0.567  
Average sample loss: 0.548  
Average acc: 0.877  
Average grad norm: 4.762  
Average grad norm uniform: 33.963  
Average loss each uniform: 8.800  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.283   grad norm uniform = 35.405   loss each uniform = 12.048   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.769  exp loss = 0.848  adjusted loss = 0.848  adv prob = 0.250000   acc = 0.822   grad norm = 7.250   grad norm uniform = 33.323   loss each uniform = 6.188   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.131  exp loss = 2.304  adjusted loss = 2.304  adv prob = 0.250000   acc = 0.594   grad norm = 14.448   grad norm uniform = 29.889   loss each uniform = 5.173   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.237  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.947   grad norm = 2.088   grad norm uniform = 35.220   loss each uniform = 10.174   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8765638470649719


Epoch [213]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.422  
Average loss each uniform: 12.042  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2316]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.909   loss each uniform = 12.293   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 106]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 40.297   loss each uniform = 9.222   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.782   loss each uniform = 9.066   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2256]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.748   loss each uniform = 12.072   feat norm = 0.447  

Validation:
Average incurred loss: 0.657  
Average sample loss: 0.638  
Average acc: 0.853  
Average grad norm: 5.582  
Average grad norm uniform: 33.602  
Average loss each uniform: 8.459  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.452   grad norm uniform = 35.135   loss each uniform = 11.444   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.104  exp loss = 1.214  adjusted loss = 1.214  adv prob = 0.250000   acc = 0.745   grad norm = 9.948   grad norm uniform = 32.265   loss each uniform = 5.563   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.776  exp loss = 1.941  adjusted loss = 1.941  adv prob = 0.250000   acc = 0.639   grad norm = 12.487   grad norm uniform = 30.466   loss each uniform = 5.424   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.970   grad norm = 1.397   grad norm uniform = 36.036   loss each uniform = 11.159   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8532110452651978


Epoch [214]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.447  
Average loss each uniform: 12.013  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2268]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.011   loss each uniform = 12.534   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 102]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.200   loss each uniform = 9.392   feat norm = 0.491  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 132]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.933   loss each uniform = 8.917   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.728   loss each uniform = 11.792   feat norm = 0.448  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.595  
Average acc: 0.867  
Average grad norm: 5.178  
Average grad norm uniform: 33.472  
Average loss each uniform: 8.522  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.374   grad norm uniform = 35.006   loss each uniform = 11.521   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.970  exp loss = 1.065  adjusted loss = 1.065  adv prob = 0.250000   acc = 0.779   grad norm = 8.851   grad norm uniform = 32.215   loss each uniform = 5.709   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.853  exp loss = 2.028  adjusted loss = 2.028  adv prob = 0.250000   acc = 0.647   grad norm = 12.703   grad norm uniform = 30.173   loss each uniform = 5.399   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.195  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.962   grad norm = 1.656   grad norm uniform = 35.792   loss each uniform = 10.973   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [215]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.411  
Average loss each uniform: 11.982  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2294]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.898   loss each uniform = 12.307   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 40.206   loss each uniform = 9.072   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.745   loss each uniform = 9.487   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2257]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.710   loss each uniform = 11.944   feat norm = 0.447  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.609  
Average acc: 0.862  
Average grad norm: 5.349  
Average grad norm uniform: 33.531  
Average loss each uniform: 8.452  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.421   grad norm uniform = 35.122   loss each uniform = 11.378   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.028  exp loss = 1.159  adjusted loss = 1.159  adv prob = 0.250000   acc = 0.768   grad norm = 9.337   grad norm uniform = 32.252   loss each uniform = 5.639   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.774  exp loss = 1.954  adjusted loss = 1.954  adv prob = 0.250000   acc = 0.639   grad norm = 12.564   grad norm uniform = 29.853   loss each uniform = 5.411   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.962   grad norm = 1.465   grad norm uniform = 36.103   loss each uniform = 11.075   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [216]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.417  
Average loss each uniform: 12.091  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2290]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.905   loss each uniform = 12.451   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.632   loss each uniform = 9.214   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 37.221   loss each uniform = 9.270   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2258]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.724   loss each uniform = 12.036   feat norm = 0.447  

Validation:
Average incurred loss: 0.634  
Average sample loss: 0.617  
Average acc: 0.860  
Average grad norm: 5.430  
Average grad norm uniform: 34.019  
Average loss each uniform: 8.524  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.989   grad norm = 0.464   grad norm uniform = 35.518   loss each uniform = 11.490   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.047  exp loss = 1.178  adjusted loss = 1.178  adv prob = 0.250000   acc = 0.764   grad norm = 9.512   grad norm uniform = 32.958   loss each uniform = 5.696   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.769  exp loss = 1.941  adjusted loss = 1.941  adv prob = 0.250000   acc = 0.647   grad norm = 12.440   grad norm uniform = 30.508   loss each uniform = 5.466   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.187  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.955   grad norm = 1.555   grad norm uniform = 35.987   loss each uniform = 11.073   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8598832488059998


Epoch [217]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.413  
Average loss each uniform: 12.031  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2276]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.929   loss each uniform = 12.413   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.754   loss each uniform = 9.372   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.511   loss each uniform = 9.399   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2266]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.704   loss each uniform = 11.941   feat norm = 0.447  

Validation:
Average incurred loss: 0.621  
Average sample loss: 0.604  
Average acc: 0.863  
Average grad norm: 5.273  
Average grad norm uniform: 33.550  
Average loss each uniform: 8.503  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.436   grad norm uniform = 35.173   loss each uniform = 11.463   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.029  exp loss = 1.134  adjusted loss = 1.134  adv prob = 0.250000   acc = 0.770   grad norm = 9.244   grad norm uniform = 32.264   loss each uniform = 5.670   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.716  exp loss = 1.858  adjusted loss = 1.858  adv prob = 0.250000   acc = 0.647   grad norm = 12.104   grad norm uniform = 30.142   loss each uniform = 5.447   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.962   grad norm = 1.511   grad norm uniform = 35.762   loss each uniform = 11.095   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [218]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.445  
Average loss each uniform: 11.989  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2309]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.938   loss each uniform = 12.307   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 98]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 40.610   loss each uniform = 9.430   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 102]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.760   loss each uniform = 9.115   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2286]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.765   loss each uniform = 11.905   feat norm = 0.448  

Validation:
Average incurred loss: 0.716  
Average sample loss: 0.698  
Average acc: 0.845  
Average grad norm: 5.993  
Average grad norm uniform: 33.391  
Average loss each uniform: 8.276  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.040  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.985   grad norm = 0.563   grad norm uniform = 34.867   loss each uniform = 10.971   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.324  exp loss = 1.452  adjusted loss = 1.452  adv prob = 0.250000   acc = 0.706   grad norm = 11.471   grad norm uniform = 31.801   loss each uniform = 5.291   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.521  exp loss = 1.692  adjusted loss = 1.692  adv prob = 0.250000   acc = 0.707   grad norm = 10.748   grad norm uniform = 30.591   loss each uniform = 5.713   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.150  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.977   grad norm = 1.108   grad norm uniform = 36.575   loss each uniform = 11.837   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8448706865310669


Epoch [219]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.426  
Average loss each uniform: 12.080  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.981   loss each uniform = 12.529   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.817   loss each uniform = 9.056   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 103]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.998   loss each uniform = 9.187   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2299]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.667   loss each uniform = 11.921   feat norm = 0.447  

Validation:
Average incurred loss: 0.653  
Average sample loss: 0.634  
Average acc: 0.859  
Average grad norm: 5.493  
Average grad norm uniform: 33.608  
Average loss each uniform: 8.552  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.432   grad norm uniform = 35.223   loss each uniform = 11.558   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.083  exp loss = 1.198  adjusted loss = 1.198  adv prob = 0.250000   acc = 0.762   grad norm = 9.678   grad norm uniform = 32.122   loss each uniform = 5.629   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.811  exp loss = 1.985  adjusted loss = 1.985  adv prob = 0.250000   acc = 0.639   grad norm = 12.604   grad norm uniform = 30.642   loss each uniform = 5.509   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.962   grad norm = 1.492   grad norm uniform = 36.116   loss each uniform = 11.282   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8590492606163025


Epoch [220]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.411  
Average loss each uniform: 12.071  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.802   loss each uniform = 12.225   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 40.216   loss each uniform = 9.174   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 117]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 37.116   loss each uniform = 9.675   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2225]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.778   loss each uniform = 12.212   feat norm = 0.447  

Validation:
Average incurred loss: 0.648  
Average sample loss: 0.631  
Average acc: 0.857  
Average grad norm: 5.510  
Average grad norm uniform: 33.753  
Average loss each uniform: 8.477  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.422   grad norm uniform = 35.405   loss each uniform = 11.448   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.089  exp loss = 1.201  adjusted loss = 1.201  adv prob = 0.250000   acc = 0.753   grad norm = 9.807   grad norm uniform = 32.361   loss each uniform = 5.608   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.754  exp loss = 1.938  adjusted loss = 1.938  adv prob = 0.250000   acc = 0.647   grad norm = 12.380   grad norm uniform = 30.412   loss each uniform = 5.430   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.962   grad norm = 1.455   grad norm uniform = 36.165   loss each uniform = 11.140   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [221]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.392  
Average loss each uniform: 12.039  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2285]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.840   loss each uniform = 12.413   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 40.121   loss each uniform = 8.972   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 102]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.840   loss each uniform = 9.386   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.720   loss each uniform = 11.953   feat norm = 0.447  

Validation:
Average incurred loss: 0.696  
Average sample loss: 0.677  
Average acc: 0.842  
Average grad norm: 5.875  
Average grad norm uniform: 33.145  
Average loss each uniform: 8.187  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.043  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.985   grad norm = 0.599   grad norm uniform = 34.465   loss each uniform = 10.752   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.285  exp loss = 1.409  adjusted loss = 1.409  adv prob = 0.250000   acc = 0.708   grad norm = 11.133   grad norm uniform = 31.596   loss each uniform = 5.281   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.474  exp loss = 1.659  adjusted loss = 1.659  adv prob = 0.250000   acc = 0.677   grad norm = 10.727   grad norm uniform = 30.457   loss each uniform = 5.754   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.970   grad norm = 1.123   grad norm uniform = 36.629   loss each uniform = 11.795   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8415346145629883


Epoch [222]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.434  
Average loss each uniform: 12.105  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2341]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.789   loss each uniform = 12.265   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 40.131   loss each uniform = 9.077   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 37.183   loss each uniform = 9.561   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2227]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.886   loss each uniform = 12.221   feat norm = 0.449  

Validation:
Average incurred loss: 0.606  
Average sample loss: 0.587  
Average acc: 0.867  
Average grad norm: 5.080  
Average grad norm uniform: 33.980  
Average loss each uniform: 8.656  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.329   grad norm uniform = 35.318   loss each uniform = 11.760   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.912  exp loss = 1.001  adjusted loss = 1.001  adv prob = 0.250000   acc = 0.790   grad norm = 8.360   grad norm uniform = 33.095   loss each uniform = 5.903   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.992  exp loss = 2.152  adjusted loss = 2.152  adv prob = 0.250000   acc = 0.617   grad norm = 13.497   grad norm uniform = 30.524   loss each uniform = 5.349   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.955   grad norm = 1.848   grad norm uniform = 35.835   loss each uniform = 10.715   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8665555119514465


Epoch [223]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.431  
Average loss each uniform: 12.058  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2269]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.961   loss each uniform = 12.478   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 134]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.996   loss each uniform = 9.604   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.260   loss each uniform = 9.109   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.698   loss each uniform = 11.926   feat norm = 0.447  

Validation:
Average incurred loss: 0.603  
Average sample loss: 0.583  
Average acc: 0.868  
Average grad norm: 5.046  
Average grad norm uniform: 34.064  
Average loss each uniform: 8.786  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.332   grad norm uniform = 35.538   loss each uniform = 12.022   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.883  exp loss = 0.990  adjusted loss = 0.990  adv prob = 0.250000   acc = 0.798   grad norm = 8.157   grad norm uniform = 33.109   loss each uniform = 5.962   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.064  exp loss = 2.228  adjusted loss = 2.228  adv prob = 0.250000   acc = 0.602   grad norm = 13.901   grad norm uniform = 30.378   loss each uniform = 5.375   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.955   grad norm = 1.841   grad norm uniform = 35.915   loss each uniform = 10.729   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [224]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.417  
Average loss each uniform: 12.071  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2317]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.901   loss each uniform = 12.389   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 106]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 40.385   loss each uniform = 9.223   feat norm = 0.508  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.078   loss each uniform = 9.160   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2242]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.783   loss each uniform = 12.046   feat norm = 0.448  

Validation:
Average incurred loss: 0.612  
Average sample loss: 0.593  
Average acc: 0.867  
Average grad norm: 5.142  
Average grad norm uniform: 34.079  
Average loss each uniform: 8.775  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.350   grad norm uniform = 35.631   loss each uniform = 11.953   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.932  exp loss = 1.046  adjusted loss = 1.046  adv prob = 0.250000   acc = 0.792   grad norm = 8.526   grad norm uniform = 33.022   loss each uniform = 5.964   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.977  exp loss = 2.173  adjusted loss = 2.173  adv prob = 0.250000   acc = 0.609   grad norm = 13.512   grad norm uniform = 30.588   loss each uniform = 5.372   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.955   grad norm = 1.746   grad norm uniform = 35.822   loss each uniform = 10.871   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8673895001411438


Epoch [225]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.401  
Average loss each uniform: 12.052  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2321]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.903   loss each uniform = 12.344   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 100]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 40.079   loss each uniform = 9.486   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.762   loss each uniform = 9.384   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2260]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.732   loss each uniform = 11.999   feat norm = 0.447  

Validation:
Average incurred loss: 0.615  
Average sample loss: 0.598  
Average acc: 0.862  
Average grad norm: 5.169  
Average grad norm uniform: 33.365  
Average loss each uniform: 8.549  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.397   grad norm uniform = 34.869   loss each uniform = 11.538   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.986  exp loss = 1.095  adjusted loss = 1.095  adv prob = 0.250000   acc = 0.773   grad norm = 8.897   grad norm uniform = 32.081   loss each uniform = 5.710   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.813  exp loss = 1.991  adjusted loss = 1.991  adv prob = 0.250000   acc = 0.639   grad norm = 12.364   grad norm uniform = 30.199   loss each uniform = 5.499   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.955   grad norm = 1.664   grad norm uniform = 35.748   loss each uniform = 11.053   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [226]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.404  
Average loss each uniform: 12.013  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2239]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.913   loss each uniform = 12.584   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 40.728   loss each uniform = 9.861   feat norm = 0.514  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.799   loss each uniform = 8.889   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.613   loss each uniform = 11.747   feat norm = 0.446  

Validation:
Average incurred loss: 0.630  
Average sample loss: 0.611  
Average acc: 0.862  
Average grad norm: 5.355  
Average grad norm uniform: 33.919  
Average loss each uniform: 8.564  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.377   grad norm uniform = 35.453   loss each uniform = 11.629   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.004  exp loss = 1.124  adjusted loss = 1.124  adv prob = 0.250000   acc = 0.773   grad norm = 9.208   grad norm uniform = 32.785   loss each uniform = 5.726   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.893  exp loss = 2.065  adjusted loss = 2.065  adv prob = 0.250000   acc = 0.624   grad norm = 13.114   grad norm uniform = 30.504   loss each uniform = 5.373   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.195  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.962   grad norm = 1.581   grad norm uniform = 35.919   loss each uniform = 10.940   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [227]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.425  
Average loss each uniform: 12.078  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.922   loss each uniform = 12.610   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 100]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.223   loss each uniform = 9.663   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.397   loss each uniform = 9.224   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2297]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.716   loss each uniform = 11.810   feat norm = 0.448  

Validation:
Average incurred loss: 0.590  
Average sample loss: 0.571  
Average acc: 0.875  
Average grad norm: 4.899  
Average grad norm uniform: 33.988  
Average loss each uniform: 8.815  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.341   grad norm uniform = 35.388   loss each uniform = 12.001   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.848  exp loss = 0.945  adjusted loss = 0.945  adv prob = 0.250000   acc = 0.809   grad norm = 7.770   grad norm uniform = 33.116   loss each uniform = 6.101   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.055  exp loss = 2.218  adjusted loss = 2.218  adv prob = 0.250000   acc = 0.624   grad norm = 13.781   grad norm uniform = 30.414   loss each uniform = 5.346   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.227  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.955   grad norm = 1.958   grad norm uniform = 35.703   loss each uniform = 10.606   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8748956918716431


Epoch [228]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.416  
Average loss each uniform: 12.113  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.798   loss each uniform = 12.599   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 40.709   loss each uniform = 9.710   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 131]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.574   loss each uniform = 9.262   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2278]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.814   loss each uniform = 11.908   feat norm = 0.448  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.594  
Average acc: 0.866  
Average grad norm: 5.217  
Average grad norm uniform: 33.682  
Average loss each uniform: 8.572  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.370   grad norm uniform = 35.158   loss each uniform = 11.622   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.964  exp loss = 1.058  adjusted loss = 1.058  adv prob = 0.250000   acc = 0.785   grad norm = 8.824   grad norm uniform = 32.612   loss each uniform = 5.788   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.873  exp loss = 2.030  adjusted loss = 2.030  adv prob = 0.250000   acc = 0.624   grad norm = 13.079   grad norm uniform = 30.159   loss each uniform = 5.313   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.200  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.955   grad norm = 1.732   grad norm uniform = 35.766   loss each uniform = 10.874   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8657214045524597


Epoch [229]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.397  
Average loss each uniform: 12.118  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.628   loss each uniform = 12.241   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 136]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.061   grad norm uniform = 40.103   loss each uniform = 9.090   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.811   loss each uniform = 9.563   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2214]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.959   loss each uniform = 12.306   feat norm = 0.450  

Validation:
Average incurred loss: 0.636  
Average sample loss: 0.617  
Average acc: 0.857  
Average grad norm: 5.412  
Average grad norm uniform: 33.718  
Average loss each uniform: 8.500  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.409   grad norm uniform = 35.257   loss each uniform = 11.522   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.041  exp loss = 1.165  adjusted loss = 1.165  adv prob = 0.250000   acc = 0.762   grad norm = 9.463   grad norm uniform = 32.514   loss each uniform = 5.664   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.821  exp loss = 2.023  adjusted loss = 2.023  adv prob = 0.250000   acc = 0.624   grad norm = 12.682   grad norm uniform = 30.480   loss each uniform = 5.379   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.962   grad norm = 1.519   grad norm uniform = 35.769   loss each uniform = 10.946   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [230]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.388  
Average loss each uniform: 12.058  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.719   loss each uniform = 12.242   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 39.761   loss each uniform = 8.971   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 100]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.742   loss each uniform = 9.704   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2236]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.900   loss each uniform = 12.129   feat norm = 0.449  

Validation:
Average incurred loss: 0.569  
Average sample loss: 0.549  
Average acc: 0.883  
Average grad norm: 4.545  
Average grad norm uniform: 34.034  
Average loss each uniform: 9.059  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.241   grad norm uniform = 35.308   loss each uniform = 12.392   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.715  exp loss = 0.792  adjusted loss = 0.792  adv prob = 0.250000   acc = 0.841   grad norm = 6.571   grad norm uniform = 33.537   loss each uniform = 6.452   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.306  exp loss = 2.479  adjusted loss = 2.479  adv prob = 0.250000   acc = 0.579   grad norm = 14.823   grad norm uniform = 30.135   loss each uniform = 5.318   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.273  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.947   grad norm = 2.283   grad norm uniform = 35.201   loss each uniform = 10.232   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8832360506057739


Epoch [231]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.402  
Average loss each uniform: 12.089  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2284]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.793   loss each uniform = 12.560   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 40.288   loss each uniform = 9.675   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.665   loss each uniform = 9.016   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.803   loss each uniform = 11.902   feat norm = 0.448  

Validation:
Average incurred loss: 0.645  
Average sample loss: 0.625  
Average acc: 0.861  
Average grad norm: 5.482  
Average grad norm uniform: 33.606  
Average loss each uniform: 8.446  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.440   grad norm uniform = 35.053   loss each uniform = 11.357   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.074  exp loss = 1.205  adjusted loss = 1.205  adv prob = 0.250000   acc = 0.766   grad norm = 9.700   grad norm uniform = 32.324   loss each uniform = 5.585   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.779  exp loss = 1.947  adjusted loss = 1.947  adv prob = 0.250000   acc = 0.639   grad norm = 12.451   grad norm uniform = 30.560   loss each uniform = 5.505   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.962   grad norm = 1.442   grad norm uniform = 36.068   loss each uniform = 11.192   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [232]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.435  
Average loss each uniform: 12.110  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.795   loss each uniform = 12.549   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 40.002   loss each uniform = 9.760   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 37.263   loss each uniform = 9.261   feat norm = 0.453  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2266]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.820   loss each uniform = 11.961   feat norm = 0.448  

Validation:
Average incurred loss: 0.636  
Average sample loss: 0.618  
Average acc: 0.862  
Average grad norm: 5.284  
Average grad norm uniform: 33.398  
Average loss each uniform: 8.531  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.989   grad norm = 0.421   grad norm uniform = 34.821   loss each uniform = 11.485   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.048  exp loss = 1.161  adjusted loss = 1.161  adv prob = 0.250000   acc = 0.766   grad norm = 9.235   grad norm uniform = 32.199   loss each uniform = 5.694   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.777  exp loss = 1.950  adjusted loss = 1.950  adv prob = 0.250000   acc = 0.647   grad norm = 12.235   grad norm uniform = 30.080   loss each uniform = 5.464   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.193  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.962   grad norm = 1.568   grad norm uniform = 35.922   loss each uniform = 11.166   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [233]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.403  
Average loss each uniform: 12.074  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2262]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.882   loss each uniform = 12.657   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 40.348   loss each uniform = 9.649   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.744   loss each uniform = 9.002   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2297]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.704   loss each uniform = 11.784   feat norm = 0.447  

Validation:
Average incurred loss: 0.557  
Average sample loss: 0.537  
Average acc: 0.885  
Average grad norm: 4.528  
Average grad norm uniform: 34.158  
Average loss each uniform: 9.087  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.996   grad norm = 0.189   grad norm uniform = 35.519   loss each uniform = 12.480   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.655  exp loss = 0.727  adjusted loss = 0.727  adv prob = 0.250000   acc = 0.852   grad norm = 6.232   grad norm uniform = 33.760   loss each uniform = 6.561   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.410  exp loss = 2.577  adjusted loss = 2.577  adv prob = 0.250000   acc = 0.564   grad norm = 15.738   grad norm uniform = 29.871   loss each uniform = 5.224   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.287  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.932   grad norm = 2.579   grad norm uniform = 35.061   loss each uniform = 9.891   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.884904146194458


Epoch [234]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.379  
Average loss each uniform: 12.048  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.770   loss each uniform = 12.569   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 40.433   loss each uniform = 9.546   feat norm = 0.508  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.517   loss each uniform = 9.255   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2278]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.755   loss each uniform = 11.820   feat norm = 0.448  

Validation:
Average incurred loss: 0.615  
Average sample loss: 0.595  
Average acc: 0.868  
Average grad norm: 5.054  
Average grad norm uniform: 33.893  
Average loss each uniform: 8.786  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.321   grad norm uniform = 35.313   loss each uniform = 12.016   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.900  exp loss = 1.003  adjusted loss = 1.003  adv prob = 0.250000   acc = 0.798   grad norm = 8.172   grad norm uniform = 33.006   loss each uniform = 6.000   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.107  exp loss = 2.271  adjusted loss = 2.271  adv prob = 0.250000   acc = 0.609   grad norm = 13.926   grad norm uniform = 30.297   loss each uniform = 5.322   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947   grad norm = 1.881   grad norm uniform = 35.609   loss each uniform = 10.669   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [235]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.391  
Average loss each uniform: 12.123  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2313]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.749   loss each uniform = 12.445   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 40.150   loss each uniform = 9.486   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.709   loss each uniform = 9.217   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2256]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.840   loss each uniform = 12.070   feat norm = 0.449  

Validation:
Average incurred loss: 0.691  
Average sample loss: 0.673  
Average acc: 0.843  
Average grad norm: 5.797  
Average grad norm uniform: 33.040  
Average loss each uniform: 8.277  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.035  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.985   grad norm = 0.516   grad norm uniform = 34.318   loss each uniform = 10.959   feat norm = 0.414  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.245  exp loss = 1.361  adjusted loss = 1.361  adv prob = 0.250000   acc = 0.712   grad norm = 10.822   grad norm uniform = 31.598   loss each uniform = 5.345   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.589  exp loss = 1.740  adjusted loss = 1.740  adv prob = 0.250000   acc = 0.677   grad norm = 11.283   grad norm uniform = 30.225   loss each uniform = 5.656   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.160  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.970   grad norm = 1.245   grad norm uniform = 36.416   loss each uniform = 11.750   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8432027101516724


Epoch [236]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.372  
Average loss each uniform: 12.024  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2246]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.857   loss each uniform = 12.643   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.001  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 40.451   loss each uniform = 9.699   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.947   loss each uniform = 9.115   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2296]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.614   loss each uniform = 11.705   feat norm = 0.446  

Validation:
Average incurred loss: 0.733  
Average sample loss: 0.715  
Average acc: 0.842  
Average grad norm: 6.102  
Average grad norm uniform: 33.174  
Average loss each uniform: 8.246  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.047  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.985   grad norm = 0.622   grad norm uniform = 34.492   loss each uniform = 10.786   feat norm = 0.415  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.390  exp loss = 1.525  adjusted loss = 1.525  adv prob = 0.250000   acc = 0.697   grad norm = 11.806   grad norm uniform = 31.612   loss each uniform = 5.279   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.431  exp loss = 1.590  adjusted loss = 1.590  adv prob = 0.250000   acc = 0.714   grad norm = 10.395   grad norm uniform = 30.405   loss each uniform = 5.838   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 0.977   grad norm = 1.065   grad norm uniform = 36.784   loss each uniform = 12.128   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8423686027526855


Epoch [237]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.429  
Average loss each uniform: 12.131  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.670   loss each uniform = 12.388   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 40.222   loss each uniform = 9.283   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 111]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 37.666   loss each uniform = 9.560   feat norm = 0.458  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2236]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.959   loss each uniform = 12.140   feat norm = 0.450  

Validation:
Average incurred loss: 0.604  
Average sample loss: 0.584  
Average acc: 0.868  
Average grad norm: 5.028  
Average grad norm uniform: 33.759  
Average loss each uniform: 8.689  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.356   grad norm uniform = 35.193   loss each uniform = 11.767   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.930  exp loss = 1.042  adjusted loss = 1.042  adv prob = 0.250000   acc = 0.792   grad norm = 8.388   grad norm uniform = 32.713   loss each uniform = 5.899   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.909  exp loss = 2.070  adjusted loss = 2.070  adv prob = 0.250000   acc = 0.617   grad norm = 12.950   grad norm uniform = 30.287   loss each uniform = 5.425   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.962   grad norm = 1.741   grad norm uniform = 35.861   loss each uniform = 10.917   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8682236075401306


Epoch [238]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.374  
Average loss each uniform: 12.013  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2229]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.864   loss each uniform = 12.756   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 40.758   loss each uniform = 10.251   feat norm = 0.512  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 132]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.637   loss each uniform = 8.676   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2317]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.629   loss each uniform = 11.576   feat norm = 0.447  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.572  
Average acc: 0.872  
Average grad norm: 4.850  
Average grad norm uniform: 33.532  
Average loss each uniform: 8.810  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.280   grad norm uniform = 34.972   loss each uniform = 12.039   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.836  exp loss = 0.923  adjusted loss = 0.923  adv prob = 0.250000   acc = 0.811   grad norm = 7.613   grad norm uniform = 32.796   loss each uniform = 6.111   feat norm = 0.464  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.105  exp loss = 2.300  adjusted loss = 2.300  adv prob = 0.250000   acc = 0.594   grad norm = 13.994   grad norm uniform = 29.653   loss each uniform = 5.261   feat norm = 0.419  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.238  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.940   grad norm = 2.072   grad norm uniform = 34.932   loss each uniform = 10.481   feat norm = 0.448  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [239]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.393  
Average loss each uniform: 12.070  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2273]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.737   loss each uniform = 12.503   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 40.102   loss each uniform = 9.843   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 91]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 37.642   loss each uniform = 9.322   feat norm = 0.459  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2296]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.775   loss each uniform = 11.881   feat norm = 0.448  

Validation:
Average incurred loss: 0.575  
Average sample loss: 0.553  
Average acc: 0.886  
Average grad norm: 4.541  
Average grad norm uniform: 34.615  
Average loss each uniform: 9.337  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.996   grad norm = 0.166   grad norm uniform = 36.037   loss each uniform = 12.905   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.651  exp loss = 0.723  adjusted loss = 0.723  adv prob = 0.250000   acc = 0.856   grad norm = 6.060   grad norm uniform = 34.449   loss each uniform = 6.771   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.570  exp loss = 2.745  adjusted loss = 2.745  adv prob = 0.250000   acc = 0.556   grad norm = 16.424   grad norm uniform = 29.935   loss each uniform = 5.275   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.305  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.932   grad norm = 2.697   grad norm uniform = 34.880   loss each uniform = 9.858   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8857381343841553


Epoch [240]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.420  
Average loss each uniform: 12.129  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2288]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.873   loss each uniform = 12.564   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.998   loss each uniform = 9.631   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 37.276   loss each uniform = 9.359   feat norm = 0.455  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2273]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.741   loss each uniform = 11.961   feat norm = 0.447  

Validation:
Average incurred loss: 0.639  
Average sample loss: 0.620  
Average acc: 0.861  
Average grad norm: 5.363  
Average grad norm uniform: 33.449  
Average loss each uniform: 8.502  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.421   grad norm uniform = 34.848   loss each uniform = 11.438   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.052  exp loss = 1.168  adjusted loss = 1.168  adv prob = 0.250000   acc = 0.764   grad norm = 9.435   grad norm uniform = 32.134   loss each uniform = 5.620   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.793  exp loss = 1.958  adjusted loss = 1.958  adv prob = 0.250000   acc = 0.647   grad norm = 12.318   grad norm uniform = 30.351   loss each uniform = 5.534   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.185  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.962   grad norm = 1.494   grad norm uniform = 36.241   loss each uniform = 11.263   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [241]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.396  
Average loss each uniform: 12.169  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2288]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.840   loss each uniform = 12.587   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 40.458   loss each uniform = 9.823   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 128]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.207   loss each uniform = 9.268   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2261]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.757   loss each uniform = 12.033   feat norm = 0.447  

Validation:
Average incurred loss: 0.612  
Average sample loss: 0.593  
Average acc: 0.867  
Average grad norm: 5.113  
Average grad norm uniform: 33.701  
Average loss each uniform: 8.668  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.353   grad norm uniform = 35.095   loss each uniform = 11.737   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.941  exp loss = 1.048  adjusted loss = 1.048  adv prob = 0.250000   acc = 0.785   grad norm = 8.578   grad norm uniform = 32.568   loss each uniform = 5.857   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.943  exp loss = 2.119  adjusted loss = 2.119  adv prob = 0.250000   acc = 0.624   grad norm = 13.043   grad norm uniform = 30.598   loss each uniform = 5.470   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.962   grad norm = 1.755   grad norm uniform = 35.875   loss each uniform = 10.940   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [242]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.379  
Average loss each uniform: 12.086  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2279]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.809   loss each uniform = 12.573   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 40.288   loss each uniform = 9.557   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 104]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.732   loss each uniform = 9.283   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2295]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.731   loss each uniform = 11.858   feat norm = 0.448  

Validation:
Average incurred loss: 0.574  
Average sample loss: 0.554  
Average acc: 0.881  
Average grad norm: 4.633  
Average grad norm uniform: 34.234  
Average loss each uniform: 9.109  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.991   grad norm = 0.241   grad norm uniform = 35.646   loss each uniform = 12.471   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.747  exp loss = 0.836  adjusted loss = 0.836  adv prob = 0.250000   acc = 0.837   grad norm = 6.804   grad norm uniform = 33.742   loss each uniform = 6.461   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.256  exp loss = 2.429  adjusted loss = 2.429  adv prob = 0.250000   acc = 0.586   grad norm = 14.800   grad norm uniform = 29.940   loss each uniform = 5.343   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.259  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.940   grad norm = 2.285   grad norm uniform = 35.291   loss each uniform = 10.350   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8807339668273926


Epoch [243]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.388  
Average loss each uniform: 12.099  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2274]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.909   loss each uniform = 12.603   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 40.302   loss each uniform = 9.858   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 107]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.248   loss each uniform = 8.801   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2300]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.673   loss each uniform = 11.864   feat norm = 0.447  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.572  
Average acc: 0.878  
Average grad norm: 4.739  
Average grad norm uniform: 34.278  
Average loss each uniform: 9.151  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.994   grad norm = 0.217   grad norm uniform = 35.598   loss each uniform = 12.586   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.756  exp loss = 0.826  adjusted loss = 0.826  adv prob = 0.250000   acc = 0.830   grad norm = 6.911   grad norm uniform = 33.860   loss each uniform = 6.451   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.381  exp loss = 2.534  adjusted loss = 2.534  adv prob = 0.250000   acc = 0.571   grad norm = 15.401   grad norm uniform = 29.963   loss each uniform = 5.309   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.272  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.947   grad norm = 2.341   grad norm uniform = 35.426   loss each uniform = 10.392   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8782318830490112


Epoch [244]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.421  
Average loss each uniform: 12.145  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2259]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.021   loss each uniform = 12.698   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.468   loss each uniform = 9.854   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 129]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.370   loss each uniform = 8.936   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2293]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.666   loss each uniform = 11.896   feat norm = 0.447  

Validation:
Average incurred loss: 0.659  
Average sample loss: 0.640  
Average acc: 0.854  
Average grad norm: 5.523  
Average grad norm uniform: 33.381  
Average loss each uniform: 8.475  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.987   grad norm = 0.447   grad norm uniform = 34.731   loss each uniform = 11.349   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.117  exp loss = 1.238  adjusted loss = 1.238  adv prob = 0.250000   acc = 0.749   grad norm = 9.857   grad norm uniform = 32.072   loss each uniform = 5.582   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.758  exp loss = 1.916  adjusted loss = 1.916  adv prob = 0.250000   acc = 0.647   grad norm = 12.305   grad norm uniform = 30.295   loss each uniform = 5.536   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.962   grad norm = 1.376   grad norm uniform = 36.314   loss each uniform = 11.458   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [245]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.399  
Average loss each uniform: 12.111  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2278]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.938   loss each uniform = 12.564   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 40.472   loss each uniform = 9.577   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.140   loss each uniform = 8.713   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.667   loss each uniform = 11.975   feat norm = 0.446  

Validation:
Average incurred loss: 0.732  
Average sample loss: 0.712  
Average acc: 0.845  
Average grad norm: 6.021  
Average grad norm uniform: 33.640  
Average loss each uniform: 8.409  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.037  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.985   grad norm = 0.555   grad norm uniform = 34.861   loss each uniform = 11.113   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.355  exp loss = 1.475  adjusted loss = 1.475  adv prob = 0.250000   acc = 0.710   grad norm = 11.455   grad norm uniform = 32.412   loss each uniform = 5.432   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.562  exp loss = 1.751  adjusted loss = 1.751  adv prob = 0.250000   acc = 0.692   grad norm = 11.049   grad norm uniform = 30.507   loss each uniform = 5.765   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.162  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.977   grad norm = 1.144   grad norm uniform = 36.783   loss each uniform = 11.985   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8448706865310669


Epoch [246]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.397  
Average loss each uniform: 12.180  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2217]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 36.011   loss each uniform = 12.870   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 40.668   loss each uniform = 10.025   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.965   loss each uniform = 9.069   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2321]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.540   loss each uniform = 11.810   feat norm = 0.445  

Validation:
Average incurred loss: 0.624  
Average sample loss: 0.605  
Average acc: 0.868  
Average grad norm: 5.110  
Average grad norm uniform: 34.217  
Average loss each uniform: 8.929  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.376   grad norm uniform = 35.759   loss each uniform = 12.139   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.956  exp loss = 1.052  adjusted loss = 1.052  adv prob = 0.250000   acc = 0.794   grad norm = 8.464   grad norm uniform = 33.226   loss each uniform = 6.074   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.983  exp loss = 2.166  adjusted loss = 2.166  adv prob = 0.250000   acc = 0.617   grad norm = 13.346   grad norm uniform = 30.566   loss each uniform = 5.520   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.212  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.955   grad norm = 1.746   grad norm uniform = 35.928   loss each uniform = 11.074   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [247]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.396  
Average loss each uniform: 12.175  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2311]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.757   loss each uniform = 12.456   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.745   loss each uniform = 9.549   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.824   loss each uniform = 9.608   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2251]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.860   loss each uniform = 12.154   feat norm = 0.449  

Validation:
Average incurred loss: 0.633  
Average sample loss: 0.615  
Average acc: 0.861  
Average grad norm: 5.249  
Average grad norm uniform: 33.425  
Average loss each uniform: 8.645  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.398   grad norm uniform = 35.042   loss each uniform = 11.717   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.023  exp loss = 1.135  adjusted loss = 1.135  adv prob = 0.250000   acc = 0.768   grad norm = 9.097   grad norm uniform = 32.174   loss each uniform = 5.772   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.833  exp loss = 2.028  adjusted loss = 2.028  adv prob = 0.250000   acc = 0.632   grad norm = 12.433   grad norm uniform = 29.828   loss each uniform = 5.464   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.197  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.962   grad norm = 1.619   grad norm uniform = 35.727   loss each uniform = 11.102   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [248]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.376  
Average loss each uniform: 12.085  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2168]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 36.123   loss each uniform = 13.118   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 40.548   loss each uniform = 10.301   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 142]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.502   loss each uniform = 8.644   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2377]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.409   loss each uniform = 11.429   feat norm = 0.445  

Validation:
Average incurred loss: 0.664  
Average sample loss: 0.646  
Average acc: 0.850  
Average grad norm: 5.570  
Average grad norm uniform: 33.610  
Average loss each uniform: 8.492  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.480   grad norm uniform = 35.167   loss each uniform = 11.395   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.151  exp loss = 1.273  adjusted loss = 1.273  adv prob = 0.250000   acc = 0.734   grad norm = 10.116   grad norm uniform = 32.281   loss each uniform = 5.588   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.677  exp loss = 1.859  adjusted loss = 1.859  adv prob = 0.250000   acc = 0.654   grad norm = 11.755   grad norm uniform = 30.199   loss each uniform = 5.564   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.962   grad norm = 1.332   grad norm uniform = 36.210   loss each uniform = 11.397   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8498749136924744


Epoch [249]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.403  
Average loss each uniform: 12.203  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2333]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.821   loss each uniform = 12.347   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 40.507   loss each uniform = 9.482   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.243   loss each uniform = 9.258   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2224]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 36.810   loss each uniform = 12.355   feat norm = 0.448  

Validation:
Average incurred loss: 0.664  
Average sample loss: 0.646  
Average acc: 0.854  
Average grad norm: 5.626  
Average grad norm uniform: 33.526  
Average loss each uniform: 8.440  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.989   grad norm = 0.514   grad norm uniform = 35.033   loss each uniform = 11.254   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.158  exp loss = 1.283  adjusted loss = 1.283  adv prob = 0.250000   acc = 0.740   grad norm = 10.267   grad norm uniform = 32.148   loss each uniform = 5.557   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.648  exp loss = 1.842  adjusted loss = 1.842  adv prob = 0.250000   acc = 0.662   grad norm = 11.642   grad norm uniform = 30.341   loss each uniform = 5.606   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.161  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.970   grad norm = 1.301   grad norm uniform = 36.253   loss each uniform = 11.492   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8540450930595398


Epoch [250]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.354  
Average loss each uniform: 12.109  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2199]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.933   loss each uniform = 12.881   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 40.486   loss each uniform = 9.897   feat norm = 0.508  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 134]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.661   loss each uniform = 9.054   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2331]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.502   loss each uniform = 11.681   feat norm = 0.446  

Validation:
Average incurred loss: 0.577  
Average sample loss: 0.558  
Average acc: 0.884  
Average grad norm: 4.662  
Average grad norm uniform: 34.378  
Average loss each uniform: 9.163  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.234   grad norm uniform = 35.857   loss each uniform = 12.608   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.718  exp loss = 0.808  adjusted loss = 0.808  adv prob = 0.250000   acc = 0.845   grad norm = 6.663   grad norm uniform = 33.886   loss each uniform = 6.522   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.372  exp loss = 2.540  adjusted loss = 2.540  adv prob = 0.250000   acc = 0.571   grad norm = 15.486   grad norm uniform = 30.045   loss each uniform = 5.263   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.277  exp loss = 0.237  adjusted loss = 0.237  adv prob = 0.250000   acc = 0.947   grad norm = 2.370   grad norm uniform = 35.238   loss each uniform = 10.214   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.884070098400116


Epoch [251]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.400  
Average loss each uniform: 12.193  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2277]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.775   loss each uniform = 12.593   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 40.116   loss each uniform = 9.790   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 127]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.724   loss each uniform = 9.595   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.806   loss each uniform = 12.068   feat norm = 0.448  

Validation:
Average incurred loss: 0.576  
Average sample loss: 0.556  
Average acc: 0.882  
Average grad norm: 4.574  
Average grad norm uniform: 34.714  
Average loss each uniform: 9.338  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.228   grad norm uniform = 36.104   loss each uniform = 12.818   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.713  exp loss = 0.790  adjusted loss = 0.790  adv prob = 0.250000   acc = 0.841   grad norm = 6.461   grad norm uniform = 34.453   loss each uniform = 6.722   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.366  exp loss = 2.522  adjusted loss = 2.522  adv prob = 0.250000   acc = 0.571   grad norm = 15.332   grad norm uniform = 30.212   loss each uniform = 5.333   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.286  exp loss = 0.247  adjusted loss = 0.247  adv prob = 0.250000   acc = 0.940   grad norm = 2.464   grad norm uniform = 35.248   loss each uniform = 10.289   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8815680146217346


Epoch [252]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.396  
Average loss each uniform: 12.168  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2256]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 36.041   loss each uniform = 12.723   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 40.015   loss each uniform = 9.558   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.335   loss each uniform = 9.220   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2305]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.570   loss each uniform = 11.907   feat norm = 0.446  

Validation:
Average incurred loss: 0.627  
Average sample loss: 0.607  
Average acc: 0.867  
Average grad norm: 5.154  
Average grad norm uniform: 33.610  
Average loss each uniform: 8.722  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.361   grad norm uniform = 35.109   loss each uniform = 11.785   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.990  exp loss = 1.092  adjusted loss = 1.092  adv prob = 0.250000   acc = 0.785   grad norm = 8.769   grad norm uniform = 32.497   loss each uniform = 5.884   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.910  exp loss = 2.100  adjusted loss = 2.100  adv prob = 0.250000   acc = 0.632   grad norm = 12.830   grad norm uniform = 30.065   loss each uniform = 5.477   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.195  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.962   grad norm = 1.645   grad norm uniform = 35.790   loss each uniform = 11.151   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.867389440536499


Epoch [253]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.383  
Average loss each uniform: 12.207  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2241]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 36.079   loss each uniform = 12.793   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.767   loss each uniform = 9.930   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 115]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.976   loss each uniform = 9.136   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2321]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.475   loss each uniform = 11.910   feat norm = 0.445  

Validation:
Average incurred loss: 0.627  
Average sample loss: 0.608  
Average acc: 0.868  
Average grad norm: 5.153  
Average grad norm uniform: 33.504  
Average loss each uniform: 8.658  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.385   grad norm uniform = 35.006   loss each uniform = 11.706   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.994  exp loss = 1.106  adjusted loss = 1.106  adv prob = 0.250000   acc = 0.790   grad norm = 8.793   grad norm uniform = 32.268   loss each uniform = 5.795   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.893  exp loss = 2.090  adjusted loss = 2.090  adv prob = 0.250000   acc = 0.624   grad norm = 12.761   grad norm uniform = 30.259   loss each uniform = 5.493   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.193  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.962   grad norm = 1.531   grad norm uniform = 35.801   loss each uniform = 11.149   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [254]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.401  
Average loss each uniform: 12.225  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2296]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.893   loss each uniform = 12.553   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.003  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000   grad norm = 0.099   grad norm uniform = 40.147   loss each uniform = 9.718   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.478   loss each uniform = 9.074   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2262]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.730   loss each uniform = 12.190   feat norm = 0.448  

Validation:
Average incurred loss: 0.779  
Average sample loss: 0.761  
Average acc: 0.839  
Average grad norm: 6.381  
Average grad norm uniform: 33.238  
Average loss each uniform: 8.180  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.053  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.985   grad norm = 0.666   grad norm uniform = 34.542   loss each uniform = 10.572   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.525  exp loss = 1.674  adjusted loss = 1.674  adv prob = 0.250000   acc = 0.687   grad norm = 12.635   grad norm uniform = 31.466   loss each uniform = 5.179   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.364  exp loss = 1.546  adjusted loss = 1.546  adv prob = 0.250000   acc = 0.722   grad norm = 9.946   grad norm uniform = 30.996   loss each uniform = 6.029   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.128  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 0.977   grad norm = 0.969   grad norm uniform = 37.107   loss each uniform = 12.452   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8390325307846069


Epoch [255]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.364  
Average loss each uniform: 12.142  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.829   loss each uniform = 12.527   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.803   loss each uniform = 9.590   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.648   loss each uniform = 9.467   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2252]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.729   loss each uniform = 12.028   feat norm = 0.448  

Validation:
Average incurred loss: 0.631  
Average sample loss: 0.613  
Average acc: 0.867  
Average grad norm: 5.224  
Average grad norm uniform: 33.909  
Average loss each uniform: 8.690  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.428   grad norm uniform = 35.124   loss each uniform = 11.577   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.030  exp loss = 1.150  adjusted loss = 1.150  adv prob = 0.250000   acc = 0.783   grad norm = 9.051   grad norm uniform = 32.867   loss each uniform = 5.878   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.795  exp loss = 1.991  adjusted loss = 1.991  adv prob = 0.250000   acc = 0.639   grad norm = 12.305   grad norm uniform = 30.938   loss each uniform = 5.682   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.962   grad norm = 1.570   grad norm uniform = 36.268   loss each uniform = 11.411   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8673895001411438


Epoch [256]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.307  
Average loss each uniform: 12.112  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2322]:	loss = 0.000  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 35.499   loss each uniform = 12.380   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.003  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 39.445   loss each uniform = 9.272   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 137]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.739   loss each uniform = 9.264   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2216]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.958   loss each uniform = 12.162   feat norm = 0.451  

Validation:
Average incurred loss: 0.750  
Average sample loss: 0.731  
Average acc: 0.842  
Average grad norm: 6.154  
Average grad norm uniform: 33.272  
Average loss each uniform: 8.226  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.051  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.985   grad norm = 0.662   grad norm uniform = 34.310   loss each uniform = 10.608   feat norm = 0.415  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.437  exp loss = 1.589  adjusted loss = 1.589  adv prob = 0.250000   acc = 0.693   grad norm = 12.015   grad norm uniform = 31.717   loss each uniform = 5.260   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.411  exp loss = 1.604  adjusted loss = 1.604  adv prob = 0.250000   acc = 0.729   grad norm = 10.052   grad norm uniform = 31.201   loss each uniform = 6.097   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.139  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.977   grad norm = 1.005   grad norm uniform = 37.146   loss each uniform = 12.382   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8423686027526855


Epoch [257]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.361  
Average loss each uniform: 12.149  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2249]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.594   loss each uniform = 12.852   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 40.358   loss each uniform = 10.334   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 111]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.852   loss each uniform = 9.082   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2306]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.861   loss each uniform = 11.712   feat norm = 0.449  

Validation:
Average incurred loss: 0.579  
Average sample loss: 0.560  
Average acc: 0.881  
Average grad norm: 4.665  
Average grad norm uniform: 34.073  
Average loss each uniform: 9.038  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.265   grad norm uniform = 35.200   loss each uniform = 12.294   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.762  exp loss = 0.860  adjusted loss = 0.860  adv prob = 0.250000   acc = 0.830   grad norm = 6.962   grad norm uniform = 33.569   loss each uniform = 6.375   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.246  exp loss = 2.422  adjusted loss = 2.422  adv prob = 0.250000   acc = 0.602   grad norm = 14.550   grad norm uniform = 30.138   loss each uniform = 5.413   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.260  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.947   grad norm = 2.179   grad norm uniform = 35.816   loss each uniform = 10.561   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8807339668273926


Epoch [258]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.344  
Average loss each uniform: 12.105  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2239]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.633   loss each uniform = 12.922   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 40.701   loss each uniform = 10.468   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 105]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.403   loss each uniform = 8.850   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2335]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.761   loss each uniform = 11.550   feat norm = 0.448  

Validation:
Average incurred loss: 0.605  
Average sample loss: 0.586  
Average acc: 0.871  
Average grad norm: 5.011  
Average grad norm uniform: 33.684  
Average loss each uniform: 8.699  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.326   grad norm uniform = 34.799   loss each uniform = 11.731   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.913  exp loss = 1.021  adjusted loss = 1.021  adv prob = 0.250000   acc = 0.796   grad norm = 8.274   grad norm uniform = 32.866   loss each uniform = 5.942   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.979  exp loss = 2.155  adjusted loss = 2.155  adv prob = 0.250000   acc = 0.624   grad norm = 13.219   grad norm uniform = 30.378   loss each uniform = 5.451   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.215  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.955   grad norm = 1.825   grad norm uniform = 35.941   loss each uniform = 10.958   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [259]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.346  
Average loss each uniform: 12.140  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2300]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.561   loss each uniform = 12.592   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.607   loss each uniform = 9.992   feat norm = 0.496  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 108]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.717   loss each uniform = 8.984   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2260]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.943   loss each uniform = 11.951   feat norm = 0.450  

Validation:
Average incurred loss: 0.629  
Average sample loss: 0.611  
Average acc: 0.863  
Average grad norm: 5.301  
Average grad norm uniform: 33.321  
Average loss each uniform: 8.463  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.417   grad norm uniform = 34.659   loss each uniform = 11.327   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.026  exp loss = 1.142  adjusted loss = 1.142  adv prob = 0.250000   acc = 0.773   grad norm = 9.252   grad norm uniform = 31.922   loss each uniform = 5.596   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.797  exp loss = 2.008  adjusted loss = 2.008  adv prob = 0.250000   acc = 0.639   grad norm = 12.308   grad norm uniform = 30.590   loss each uniform = 5.594   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.962   grad norm = 1.600   grad norm uniform = 36.253   loss each uniform = 11.321   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [260]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.322  
Average loss each uniform: 12.139  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.496   loss each uniform = 12.656   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 110]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 40.502   loss each uniform = 9.778   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.651   loss each uniform = 9.294   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.941   loss each uniform = 11.871   feat norm = 0.450  

Validation:
Average incurred loss: 0.600  
Average sample loss: 0.581  
Average acc: 0.873  
Average grad norm: 4.922  
Average grad norm uniform: 34.183  
Average loss each uniform: 8.920  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.334   grad norm uniform = 35.364   loss each uniform = 12.061   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.884  exp loss = 0.991  adjusted loss = 0.991  adv prob = 0.250000   acc = 0.803   grad norm = 7.970   grad norm uniform = 33.334   loss each uniform = 6.113   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.029  exp loss = 2.232  adjusted loss = 2.232  adv prob = 0.250000   acc = 0.624   grad norm = 13.450   grad norm uniform = 30.886   loss each uniform = 5.577   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.216  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.955   grad norm = 1.819   grad norm uniform = 36.304   loss each uniform = 11.071   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485


Epoch [261]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.373  
Average loss each uniform: 12.199  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2258]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.775   loss each uniform = 12.985   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 94]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 40.882   loss each uniform = 10.512   feat norm = 0.512  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 37.038   loss each uniform = 9.061   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2321]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.737   loss each uniform = 11.668   feat norm = 0.448  

Validation:
Average incurred loss: 0.602  
Average sample loss: 0.583  
Average acc: 0.873  
Average grad norm: 4.917  
Average grad norm uniform: 33.604  
Average loss each uniform: 8.794  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.319   grad norm uniform = 34.943   loss each uniform = 11.874   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.888  exp loss = 0.979  adjusted loss = 0.979  adv prob = 0.250000   acc = 0.805   grad norm = 7.977   grad norm uniform = 32.631   loss each uniform = 6.031   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.021  exp loss = 2.235  adjusted loss = 2.235  adv prob = 0.250000   acc = 0.617   grad norm = 13.410   grad norm uniform = 30.040   loss each uniform = 5.474   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.226  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 1.846   grad norm uniform = 35.875   loss each uniform = 10.979   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485


Epoch [262]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.358  
Average loss each uniform: 12.212  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2311]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.636   loss each uniform = 12.652   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 40.234   loss each uniform = 9.792   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.595   loss each uniform = 9.267   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2251]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.892   loss each uniform = 12.039   feat norm = 0.449  

Validation:
Average incurred loss: 0.609  
Average sample loss: 0.590  
Average acc: 0.867  
Average grad norm: 5.097  
Average grad norm uniform: 33.710  
Average loss each uniform: 8.668  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.341   grad norm uniform = 34.954   loss each uniform = 11.722   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.919  exp loss = 1.012  adjusted loss = 1.012  adv prob = 0.250000   acc = 0.792   grad norm = 8.426   grad norm uniform = 32.693   loss each uniform = 5.896   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.986  exp loss = 2.174  adjusted loss = 2.174  adv prob = 0.250000   acc = 0.617   grad norm = 13.423   grad norm uniform = 30.511   loss each uniform = 5.424   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.947   grad norm = 1.811   grad norm uniform = 36.099   loss each uniform = 10.897   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8673895597457886


Epoch [263]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.376  
Average loss each uniform: 12.263  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2280]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.646   loss each uniform = 12.794   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 40.618   loss each uniform = 10.352   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.723   loss each uniform = 9.047   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2279]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.868   loss each uniform = 11.996   feat norm = 0.449  

Validation:
Average incurred loss: 0.589  
Average sample loss: 0.569  
Average acc: 0.879  
Average grad norm: 4.662  
Average grad norm uniform: 33.912  
Average loss each uniform: 9.102  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.996   grad norm = 0.204   grad norm uniform = 35.174   loss each uniform = 12.529   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.712  exp loss = 0.802  adjusted loss = 0.802  adv prob = 0.250000   acc = 0.841   grad norm = 6.577   grad norm uniform = 33.504   loss each uniform = 6.451   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.509  exp loss = 2.696  adjusted loss = 2.696  adv prob = 0.250000   acc = 0.541   grad norm = 15.876   grad norm uniform = 29.606   loss each uniform = 5.313   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.277  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.940   grad norm = 2.396   grad norm uniform = 35.215   loss each uniform = 10.149   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8790658712387085


Epoch [264]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.347  
Average loss each uniform: 12.097  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2294]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.548   loss each uniform = 12.499   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 40.724   loss each uniform = 10.084   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 119]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.975   loss each uniform = 9.754   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2252]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.875   loss each uniform = 11.928   feat norm = 0.449  

Validation:
Average incurred loss: 0.615  
Average sample loss: 0.595  
Average acc: 0.871  
Average grad norm: 5.000  
Average grad norm uniform: 34.115  
Average loss each uniform: 8.937  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.306   grad norm uniform = 35.440   loss each uniform = 12.159   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.891  exp loss = 0.974  adjusted loss = 0.974  adv prob = 0.250000   acc = 0.803   grad norm = 7.990   grad norm uniform = 33.253   loss each uniform = 6.148   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.142  exp loss = 2.339  adjusted loss = 2.339  adv prob = 0.250000   acc = 0.609   grad norm = 14.076   grad norm uniform = 30.618   loss each uniform = 5.438   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.947   grad norm = 1.928   grad norm uniform = 35.981   loss each uniform = 10.898   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [265]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.343  
Average loss each uniform: 12.120  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2240]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.705   loss each uniform = 12.841   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 40.288   loss each uniform = 10.418   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 113]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.558   loss each uniform = 8.829   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2326]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.750   loss each uniform = 11.670   feat norm = 0.449  

Validation:
Average incurred loss: 0.635  
Average sample loss: 0.615  
Average acc: 0.867  
Average grad norm: 5.238  
Average grad norm uniform: 33.877  
Average loss each uniform: 8.764  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.991   grad norm = 0.374   grad norm uniform = 35.237   loss each uniform = 11.847   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.995  exp loss = 1.118  adjusted loss = 1.118  adv prob = 0.250000   acc = 0.788   grad norm = 8.897   grad norm uniform = 32.868   loss each uniform = 5.918   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.968  exp loss = 2.175  adjusted loss = 2.175  adv prob = 0.250000   acc = 0.617   grad norm = 13.157   grad norm uniform = 30.406   loss each uniform = 5.512   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.962   grad norm = 1.578   grad norm uniform = 36.112   loss each uniform = 11.158   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8673895597457886


Epoch [266]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.345  
Average loss each uniform: 12.139  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2223]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.765   loss each uniform = 12.836   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 136]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 40.376   loss each uniform = 10.540   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 36.351   loss each uniform = 9.108   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2311]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.666   loss each uniform = 11.726   feat norm = 0.447  

Validation:
Average incurred loss: 0.599  
Average sample loss: 0.580  
Average acc: 0.872  
Average grad norm: 4.820  
Average grad norm uniform: 33.967  
Average loss each uniform: 9.010  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.266   grad norm uniform = 35.209   loss each uniform = 12.282   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.827  exp loss = 0.913  adjusted loss = 0.913  adv prob = 0.250000   acc = 0.811   grad norm = 7.462   grad norm uniform = 33.228   loss each uniform = 6.246   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.217  exp loss = 2.432  adjusted loss = 2.432  adv prob = 0.250000   acc = 0.586   grad norm = 14.295   grad norm uniform = 30.530   loss each uniform = 5.443   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.240  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.947   grad norm = 2.076   grad norm uniform = 35.628   loss each uniform = 10.769   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [267]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.360  
Average loss each uniform: 12.163  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2270]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.675   loss each uniform = 12.618   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 139]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 40.318   loss each uniform = 9.719   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 37.229   loss each uniform = 9.099   feat norm = 0.454  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2261]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.757   loss each uniform = 12.025   feat norm = 0.447  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.552  
Average acc: 0.887  
Average grad norm: 4.520  
Average grad norm uniform: 33.965  
Average loss each uniform: 9.104  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.236   grad norm uniform = 35.206   loss each uniform = 12.384   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.736  exp loss = 0.821  adjusted loss = 0.821  adv prob = 0.250000   acc = 0.841   grad norm = 6.597   grad norm uniform = 33.435   loss each uniform = 6.455   feat norm = 0.466  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.277  exp loss = 2.453  adjusted loss = 2.453  adv prob = 0.250000   acc = 0.602   grad norm = 14.550   grad norm uniform = 30.207   loss each uniform = 5.458   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.262  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.947   grad norm = 2.252   grad norm uniform = 35.224   loss each uniform = 10.515   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8865721821784973


Epoch [268]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.378  
Average loss each uniform: 12.253  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.658   loss each uniform = 12.725   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 40.539   loss each uniform = 9.953   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 127]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.706   loss each uniform = 9.526   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2266]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.865   loss each uniform = 12.053   feat norm = 0.449  

Validation:
Average incurred loss: 0.573  
Average sample loss: 0.552  
Average acc: 0.890  
Average grad norm: 4.396  
Average grad norm uniform: 34.721  
Average loss each uniform: 9.474  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.996   grad norm = 0.138   grad norm uniform = 35.908   loss each uniform = 13.050   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.595  exp loss = 0.662  adjusted loss = 0.662  adv prob = 0.250000   acc = 0.876   grad norm = 5.509   grad norm uniform = 34.897   loss each uniform = 7.015   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.706  exp loss = 2.894  adjusted loss = 2.894  adv prob = 0.250000   acc = 0.541   grad norm = 16.901   grad norm uniform = 29.809   loss each uniform = 5.280   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.354  exp loss = 0.325  adjusted loss = 0.325  adv prob = 0.250000   acc = 0.917   grad norm = 2.941   grad norm uniform = 34.845   loss each uniform = 9.729   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8899082541465759


Epoch [269]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.353  
Average loss each uniform: 12.199  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2233]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.842   loss each uniform = 12.908   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 40.533   loss each uniform = 10.318   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 120]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.315   loss each uniform = 9.124   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2326]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.637   loss each uniform = 11.770   feat norm = 0.447  

Validation:
Average incurred loss: 0.582  
Average sample loss: 0.562  
Average acc: 0.877  
Average grad norm: 4.716  
Average grad norm uniform: 33.846  
Average loss each uniform: 8.952  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.258   grad norm uniform = 35.265   loss each uniform = 12.263   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.776  exp loss = 0.856  adjusted loss = 0.856  adv prob = 0.250000   acc = 0.826   grad norm = 7.104   grad norm uniform = 33.128   loss each uniform = 6.246   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.239  exp loss = 2.460  adjusted loss = 2.460  adv prob = 0.250000   acc = 0.579   grad norm = 14.631   grad norm uniform = 29.896   loss each uniform = 5.332   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.241  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.947   grad norm = 2.085   grad norm uniform = 35.333   loss each uniform = 10.430   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8765638470649719


Epoch [270]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.369  
Average loss each uniform: 12.298  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2371]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 35.471   loss each uniform = 12.333   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 40.065   loss each uniform = 9.296   feat norm = 0.502  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.782   loss each uniform = 9.921   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2196]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 37.118   loss each uniform = 12.540   feat norm = 0.451  

Validation:
Average incurred loss: 0.656  
Average sample loss: 0.637  
Average acc: 0.857  
Average grad norm: 5.413  
Average grad norm uniform: 33.290  
Average loss each uniform: 8.548  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.989   grad norm = 0.427   grad norm uniform = 34.670   loss each uniform = 11.431   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.107  exp loss = 1.210  adjusted loss = 1.210  adv prob = 0.250000   acc = 0.755   grad norm = 9.682   grad norm uniform = 32.027   loss each uniform = 5.645   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.762  exp loss = 1.964  adjusted loss = 1.964  adv prob = 0.250000   acc = 0.647   grad norm = 11.964   grad norm uniform = 30.020   loss each uniform = 5.608   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.962   grad norm = 1.408   grad norm uniform = 36.142   loss each uniform = 11.540   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [271]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.387  
Average loss each uniform: 12.222  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2233]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.890   loss each uniform = 12.947   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 110]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 40.668   loss each uniform = 10.342   feat norm = 0.508  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 110]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.465   loss each uniform = 8.753   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2342]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.656   loss each uniform = 11.782   feat norm = 0.447  

Validation:
Average incurred loss: 0.636  
Average sample loss: 0.619  
Average acc: 0.863  
Average grad norm: 5.249  
Average grad norm uniform: 33.442  
Average loss each uniform: 8.561  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.455   grad norm uniform = 34.752   loss each uniform = 11.348   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.073  exp loss = 1.186  adjusted loss = 1.186  adv prob = 0.250000   acc = 0.766   grad norm = 9.303   grad norm uniform = 32.163   loss each uniform = 5.705   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.690  exp loss = 1.905  adjusted loss = 1.905  adv prob = 0.250000   acc = 0.662   grad norm = 11.615   grad norm uniform = 30.447   loss each uniform = 5.753   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.962   grad norm = 1.513   grad norm uniform = 36.321   loss each uniform = 11.588   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [272]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.382  
Average loss each uniform: 12.285  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.823   loss each uniform = 12.815   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 109]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.433   loss each uniform = 9.882   feat norm = 0.492  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.767   loss each uniform = 9.519   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2281]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.772   loss each uniform = 12.029   feat norm = 0.448  

Validation:
Average incurred loss: 0.607  
Average sample loss: 0.588  
Average acc: 0.871  
Average grad norm: 4.953  
Average grad norm uniform: 33.822  
Average loss each uniform: 8.869  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.309   grad norm uniform = 35.281   loss each uniform = 12.073   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.884  exp loss = 0.988  adjusted loss = 0.988  adv prob = 0.250000   acc = 0.803   grad norm = 7.950   grad norm uniform = 32.900   loss each uniform = 6.060   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.091  exp loss = 2.292  adjusted loss = 2.292  adv prob = 0.250000   acc = 0.609   grad norm = 13.825   grad norm uniform = 30.250   loss each uniform = 5.463   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.947   grad norm = 1.889   grad norm uniform = 35.503   loss each uniform = 10.869   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [273]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.355  
Average loss each uniform: 12.276  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2304]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.768   loss each uniform = 12.613   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.226   loss each uniform = 9.342   feat norm = 0.490  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 93]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 37.081   loss each uniform = 9.441   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2275]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.766   loss each uniform = 12.208   feat norm = 0.448  

Validation:
Average incurred loss: 0.638  
Average sample loss: 0.619  
Average acc: 0.867  
Average grad norm: 5.263  
Average grad norm uniform: 33.951  
Average loss each uniform: 8.760  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.408   grad norm uniform = 35.208   loss each uniform = 11.768   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.007  exp loss = 1.120  adjusted loss = 1.120  adv prob = 0.250000   acc = 0.783   grad norm = 8.979   grad norm uniform = 32.917   loss each uniform = 5.912   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.937  exp loss = 2.155  adjusted loss = 2.155  adv prob = 0.250000   acc = 0.632   grad norm = 12.907   grad norm uniform = 30.866   loss each uniform = 5.632   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.962   grad norm = 1.652   grad norm uniform = 36.243   loss each uniform = 11.307   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [274]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.329  
Average loss each uniform: 12.251  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2218]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.895   loss each uniform = 13.030   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 40.367   loss each uniform = 10.253   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 121]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.237   loss each uniform = 9.167   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2341]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.548   loss each uniform = 11.772   feat norm = 0.447  

Validation:
Average incurred loss: 0.612  
Average sample loss: 0.593  
Average acc: 0.867  
Average grad norm: 4.997  
Average grad norm uniform: 33.535  
Average loss each uniform: 8.801  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.324   grad norm uniform = 34.985   loss each uniform = 11.948   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.923  exp loss = 1.036  adjusted loss = 1.036  adv prob = 0.250000   acc = 0.792   grad norm = 8.201   grad norm uniform = 32.591   loss each uniform = 6.021   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.999  exp loss = 2.193  adjusted loss = 2.193  adv prob = 0.250000   acc = 0.602   grad norm = 13.370   grad norm uniform = 29.747   loss each uniform = 5.378   feat norm = 0.420  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.808   grad norm uniform = 35.541   loss each uniform = 10.913   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8665555119514465


Epoch [275]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.352  
Average loss each uniform: 12.280  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2327]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.630   loss each uniform = 12.477   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 40.369   loss each uniform = 9.502   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 122]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 37.101   loss each uniform = 10.109   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2222]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.841   loss each uniform = 12.348   feat norm = 0.448  

Validation:
Average incurred loss: 0.650  
Average sample loss: 0.631  
Average acc: 0.857  
Average grad norm: 5.375  
Average grad norm uniform: 33.359  
Average loss each uniform: 8.578  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.422   grad norm uniform = 34.766   loss each uniform = 11.451   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.100  exp loss = 1.222  adjusted loss = 1.222  adv prob = 0.250000   acc = 0.755   grad norm = 9.599   grad norm uniform = 32.120   loss each uniform = 5.697   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.740  exp loss = 1.940  adjusted loss = 1.940  adv prob = 0.250000   acc = 0.647   grad norm = 11.932   grad norm uniform = 30.018   loss each uniform = 5.632   feat norm = 0.421  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.962   grad norm = 1.405   grad norm uniform = 36.103   loss each uniform = 11.534   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [276]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.345  
Average loss each uniform: 12.318  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.746   loss each uniform = 12.666   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 40.042   loss each uniform = 9.874   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 121]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.455   loss each uniform = 9.433   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2258]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.764   loss each uniform = 12.241   feat norm = 0.448  

Validation:
Average incurred loss: 0.650  
Average sample loss: 0.632  
Average acc: 0.861  
Average grad norm: 5.341  
Average grad norm uniform: 33.364  
Average loss each uniform: 8.629  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.408   grad norm uniform = 34.842   loss each uniform = 11.548   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.072  exp loss = 1.183  adjusted loss = 1.183  adv prob = 0.250000   acc = 0.764   grad norm = 9.414   grad norm uniform = 31.990   loss each uniform = 5.724   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.819  exp loss = 2.026  adjusted loss = 2.026  adv prob = 0.250000   acc = 0.647   grad norm = 12.222   grad norm uniform = 30.293   loss each uniform = 5.663   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.962   grad norm = 1.507   grad norm uniform = 36.056   loss each uniform = 11.524   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [277]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.340  
Average loss each uniform: 12.243  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2243]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.849   loss each uniform = 12.889   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.143   loss each uniform = 10.205   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 141]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 36.758   loss each uniform = 9.195   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2297]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.555   loss each uniform = 11.901   feat norm = 0.446  

Validation:
Average incurred loss: 0.579  
Average sample loss: 0.558  
Average acc: 0.885  
Average grad norm: 4.586  
Average grad norm uniform: 34.015  
Average loss each uniform: 9.119  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.994   grad norm = 0.214   grad norm uniform = 35.252   loss each uniform = 12.469   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.724  exp loss = 0.787  adjusted loss = 0.787  adv prob = 0.250000   acc = 0.845   grad norm = 6.573   grad norm uniform = 33.627   loss each uniform = 6.500   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.369  exp loss = 2.558  adjusted loss = 2.558  adv prob = 0.250000   acc = 0.586   grad norm = 15.190   grad norm uniform = 29.877   loss each uniform = 5.315   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.275  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.940   grad norm = 2.370   grad norm uniform = 35.165   loss each uniform = 10.334   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.884904146194458


Epoch [278]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.339  
Average loss each uniform: 12.260  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2285]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.671   loss each uniform = 12.544   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 144]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 40.535   loss each uniform = 9.955   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 123]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 36.524   loss each uniform = 9.429   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2243]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.741   loss each uniform = 12.275   feat norm = 0.447  

Validation:
Average incurred loss: 0.605  
Average sample loss: 0.585  
Average acc: 0.873  
Average grad norm: 4.895  
Average grad norm uniform: 33.759  
Average loss each uniform: 8.906  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.274   grad norm uniform = 35.130   loss each uniform = 12.161   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.838  exp loss = 0.932  adjusted loss = 0.932  adv prob = 0.250000   acc = 0.813   grad norm = 7.590   grad norm uniform = 32.954   loss each uniform = 6.151   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.235  exp loss = 2.421  adjusted loss = 2.421  adv prob = 0.250000   acc = 0.594   grad norm = 14.583   grad norm uniform = 30.131   loss each uniform = 5.353   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.234  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.947   grad norm = 1.995   grad norm uniform = 35.389   loss each uniform = 10.680   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485


Epoch [279]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.358  
Average loss each uniform: 12.295  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2316]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.718   loss each uniform = 12.587   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 40.047   loss each uniform = 9.368   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 134]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.982   loss each uniform = 9.730   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2233]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.800   loss each uniform = 12.293   feat norm = 0.448  

Validation:
Average incurred loss: 0.682  
Average sample loss: 0.663  
Average acc: 0.850  
Average grad norm: 5.674  
Average grad norm uniform: 33.423  
Average loss each uniform: 8.455  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.989   grad norm = 0.484   grad norm uniform = 34.953   loss each uniform = 11.308   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.194  exp loss = 1.314  adjusted loss = 1.314  adv prob = 0.250000   acc = 0.730   grad norm = 10.374   grad norm uniform = 31.941   loss each uniform = 5.515   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.681  exp loss = 1.860  adjusted loss = 1.860  adv prob = 0.250000   acc = 0.662   grad norm = 11.779   grad norm uniform = 30.474   loss each uniform = 5.606   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.970   grad norm = 1.325   grad norm uniform = 36.189   loss each uniform = 11.589   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8498749732971191


Epoch [280]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.351  
Average loss each uniform: 12.331  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2243]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.912   loss each uniform = 12.902   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 40.019   loss each uniform = 10.164   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 141]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.670   loss each uniform = 9.285   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2282]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.555   loss each uniform = 12.080   feat norm = 0.445  

Validation:
Average incurred loss: 0.681  
Average sample loss: 0.661  
Average acc: 0.847  
Average grad norm: 5.623  
Average grad norm uniform: 33.363  
Average loss each uniform: 8.541  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.989   grad norm = 0.461   grad norm uniform = 34.874   loss each uniform = 11.436   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.172  exp loss = 1.293  adjusted loss = 1.293  adv prob = 0.250000   acc = 0.732   grad norm = 10.179   grad norm uniform = 31.941   loss each uniform = 5.594   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.754  exp loss = 1.959  adjusted loss = 1.959  adv prob = 0.250000   acc = 0.639   grad norm = 12.134   grad norm uniform = 30.267   loss each uniform = 5.605   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.962   grad norm = 1.271   grad norm uniform = 36.136   loss each uniform = 11.639   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.847372829914093


Epoch [281]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.352  
Average loss each uniform: 12.370  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.661   loss each uniform = 12.562   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.912   loss each uniform = 9.497   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 36.944   loss each uniform = 9.722   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2213]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 36.852   loss each uniform = 12.479   feat norm = 0.448  

Validation:
Average incurred loss: 0.629  
Average sample loss: 0.609  
Average acc: 0.862  
Average grad norm: 5.145  
Average grad norm uniform: 33.111  
Average loss each uniform: 8.633  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.356   grad norm uniform = 34.467   loss each uniform = 11.680   feat norm = 0.412  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.983  exp loss = 1.084  adjusted loss = 1.084  adv prob = 0.250000   acc = 0.779   grad norm = 8.715   grad norm uniform = 31.950   loss each uniform = 5.757   feat norm = 0.463  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.944  exp loss = 2.102  adjusted loss = 2.102  adv prob = 0.250000   acc = 0.617   grad norm = 12.909   grad norm uniform = 29.980   loss each uniform = 5.479   feat norm = 0.419  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.955   grad norm = 1.687   grad norm uniform = 35.546   loss each uniform = 11.166   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [282]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.379  
Average loss each uniform: 12.285  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2239]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.836   loss each uniform = 12.874   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 139]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.979   loss each uniform = 9.797   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 131]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.445   loss each uniform = 9.165   feat norm = 0.443  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2286]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.689   loss each uniform = 12.038   feat norm = 0.447  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.608  
Average acc: 0.870  
Average grad norm: 5.125  
Average grad norm uniform: 33.895  
Average loss each uniform: 8.801  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.989   grad norm = 0.384   grad norm uniform = 35.166   loss each uniform = 11.808   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.982  exp loss = 1.092  adjusted loss = 1.092  adv prob = 0.250000   acc = 0.790   grad norm = 8.656   grad norm uniform = 32.762   loss each uniform = 5.933   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.917  exp loss = 2.113  adjusted loss = 2.113  adv prob = 0.250000   acc = 0.639   grad norm = 12.811   grad norm uniform = 31.211   loss each uniform = 5.705   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.205  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.962   grad norm = 1.712   grad norm uniform = 36.090   loss each uniform = 11.384   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8698916435241699


Epoch [283]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.355  
Average loss each uniform: 12.306  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2268]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.764   loss each uniform = 12.785   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 40.299   loss each uniform = 9.833   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 99]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.450   loss each uniform = 9.203   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2302]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.716   loss each uniform = 12.103   feat norm = 0.447  

Validation:
Average incurred loss: 0.586  
Average sample loss: 0.565  
Average acc: 0.885  
Average grad norm: 4.577  
Average grad norm uniform: 34.248  
Average loss each uniform: 9.242  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.994   grad norm = 0.216   grad norm uniform = 35.547   loss each uniform = 12.658   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.736  exp loss = 0.824  adjusted loss = 0.824  adv prob = 0.250000   acc = 0.845   grad norm = 6.555   grad norm uniform = 33.783   loss each uniform = 6.554   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.387  exp loss = 2.567  adjusted loss = 2.567  adv prob = 0.250000   acc = 0.579   grad norm = 15.202   grad norm uniform = 30.318   loss each uniform = 5.441   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.274  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.947   grad norm = 2.333   grad norm uniform = 35.244   loss each uniform = 10.464   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.884904146194458


Epoch [284]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.361  
Average loss each uniform: 12.346  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2288]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.795   loss each uniform = 12.716   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.882   loss each uniform = 9.858   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.979   loss each uniform = 9.584   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2258]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.706   loss each uniform = 12.260   feat norm = 0.447  

Validation:
Average incurred loss: 0.604  
Average sample loss: 0.586  
Average acc: 0.872  
Average grad norm: 4.849  
Average grad norm uniform: 33.494  
Average loss each uniform: 8.911  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.991   grad norm = 0.331   grad norm uniform = 34.843   loss each uniform = 12.051   feat norm = 0.415  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.895  exp loss = 1.006  adjusted loss = 1.006  adv prob = 0.250000   acc = 0.805   grad norm = 7.849   grad norm uniform = 32.649   loss each uniform = 6.110   feat norm = 0.463  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.020  exp loss = 2.227  adjusted loss = 2.227  adv prob = 0.250000   acc = 0.609   grad norm = 13.220   grad norm uniform = 29.867   loss each uniform = 5.539   feat norm = 0.419  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.221  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.947   grad norm = 1.836   grad norm uniform = 35.340   loss each uniform = 11.075   feat norm = 0.448  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [285]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.333  
Average loss each uniform: 12.317  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2231]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.923   loss each uniform = 13.047   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 40.926   loss each uniform = 10.158   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.666   loss each uniform = 9.292   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2320]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.489   loss each uniform = 11.892   feat norm = 0.445  

Validation:
Average incurred loss: 0.647  
Average sample loss: 0.628  
Average acc: 0.864  
Average grad norm: 5.300  
Average grad norm uniform: 33.686  
Average loss each uniform: 8.760  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.385   grad norm uniform = 35.216   loss each uniform = 11.828   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.035  exp loss = 1.128  adjusted loss = 1.128  adv prob = 0.250000   acc = 0.777   grad norm = 9.152   grad norm uniform = 32.437   loss each uniform = 5.853   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.931  exp loss = 2.128  adjusted loss = 2.128  adv prob = 0.250000   acc = 0.632   grad norm = 12.835   grad norm uniform = 30.446   loss each uniform = 5.587   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.962   grad norm = 1.530   grad norm uniform = 35.934   loss each uniform = 11.343   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [286]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.356  
Average loss each uniform: 12.362  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2305]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.825   loss each uniform = 12.662   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 40.061   loss each uniform = 10.165   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 140]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.277   loss each uniform = 9.281   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2235]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.718   loss each uniform = 12.359   feat norm = 0.446  

Validation:
Average incurred loss: 0.641  
Average sample loss: 0.621  
Average acc: 0.864  
Average grad norm: 5.234  
Average grad norm uniform: 33.922  
Average loss each uniform: 8.827  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.991   grad norm = 0.366   grad norm uniform = 35.292   loss each uniform = 11.960   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.994  exp loss = 1.108  adjusted loss = 1.108  adv prob = 0.250000   acc = 0.781   grad norm = 8.792   grad norm uniform = 32.970   loss each uniform = 5.929   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.005  exp loss = 2.187  adjusted loss = 2.187  adv prob = 0.250000   acc = 0.617   grad norm = 13.326   grad norm uniform = 30.368   loss each uniform = 5.543   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.955   grad norm = 1.770   grad norm uniform = 35.995   loss each uniform = 11.265   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [287]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.362  
Average loss each uniform: 12.354  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2253]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.897   loss each uniform = 12.930   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 40.688   loss each uniform = 10.238   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 36.612   loss each uniform = 9.348   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2303]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.589   loss each uniform = 12.059   feat norm = 0.446  

Validation:
Average incurred loss: 0.594  
Average sample loss: 0.576  
Average acc: 0.878  
Average grad norm: 4.759  
Average grad norm uniform: 33.676  
Average loss each uniform: 8.987  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.291   grad norm uniform = 35.085   loss each uniform = 12.234   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.839  exp loss = 0.930  adjusted loss = 0.930  adv prob = 0.250000   acc = 0.820   grad norm = 7.453   grad norm uniform = 32.918   loss each uniform = 6.250   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.122  exp loss = 2.340  adjusted loss = 2.340  adv prob = 0.250000   acc = 0.609   grad norm = 13.818   grad norm uniform = 29.880   loss each uniform = 5.439   feat norm = 0.419  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.239  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.955   grad norm = 1.946   grad norm uniform = 35.175   loss each uniform = 10.727   feat norm = 0.447  
Current lr: 0.001000
Current validation accuracy: 0.8782318830490112


Epoch [288]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.344  
Average loss each uniform: 12.369  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2297]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.766   loss each uniform = 12.665   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.982   loss each uniform = 9.799   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.945   loss each uniform = 9.679   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2256]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.692   loss each uniform = 12.349   feat norm = 0.447  

Validation:
Average incurred loss: 0.644  
Average sample loss: 0.625  
Average acc: 0.867  
Average grad norm: 5.222  
Average grad norm uniform: 34.118  
Average loss each uniform: 8.938  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.398   grad norm uniform = 35.564   loss each uniform = 12.083   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.032  exp loss = 1.133  adjusted loss = 1.133  adv prob = 0.250000   acc = 0.785   grad norm = 8.980   grad norm uniform = 33.067   loss each uniform = 5.998   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.899  exp loss = 2.110  adjusted loss = 2.110  adv prob = 0.250000   acc = 0.632   grad norm = 12.583   grad norm uniform = 30.662   loss each uniform = 5.674   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.962   grad norm = 1.632   grad norm uniform = 36.175   loss each uniform = 11.465   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.867389440536499


Epoch [289]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.343  
Average loss each uniform: 12.350  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2309]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.602   loss each uniform = 12.593   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 40.035   loss each uniform = 9.775   feat norm = 0.501  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.734   loss each uniform = 9.370   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2247]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.880   loss each uniform = 12.394   feat norm = 0.449  

Validation:
Average incurred loss: 0.682  
Average sample loss: 0.662  
Average acc: 0.857  
Average grad norm: 5.565  
Average grad norm uniform: 33.923  
Average loss each uniform: 8.705  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.989   grad norm = 0.440   grad norm uniform = 35.240   loss each uniform = 11.634   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.166  exp loss = 1.276  adjusted loss = 1.276  adv prob = 0.250000   acc = 0.755   grad norm = 10.030   grad norm uniform = 32.744   loss each uniform = 5.741   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.785  exp loss = 1.979  adjusted loss = 1.979  adv prob = 0.250000   acc = 0.639   grad norm = 12.112   grad norm uniform = 30.778   loss each uniform = 5.732   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.962   grad norm = 1.364   grad norm uniform = 36.578   loss each uniform = 11.773   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [290]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.347  
Average loss each uniform: 12.365  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.861   loss each uniform = 12.872   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 40.047   loss each uniform = 9.913   feat norm = 0.500  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 101]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 36.643   loss each uniform = 9.562   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2309]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.616   loss each uniform = 12.120   feat norm = 0.446  

Validation:
Average incurred loss: 0.716  
Average sample loss: 0.697  
Average acc: 0.841  
Average grad norm: 5.871  
Average grad norm uniform: 33.216  
Average loss each uniform: 8.391  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.985   grad norm = 0.549   grad norm uniform = 34.619   loss each uniform = 11.099   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.314  exp loss = 1.450  adjusted loss = 1.450  adv prob = 0.250000   acc = 0.702   grad norm = 11.138   grad norm uniform = 31.732   loss each uniform = 5.380   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.557  exp loss = 1.740  adjusted loss = 1.740  adv prob = 0.250000   acc = 0.699   grad norm = 10.775   grad norm uniform = 30.524   loss each uniform = 5.811   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.159  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.962   grad norm = 1.200   grad norm uniform = 36.186   loss each uniform = 12.017   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8407005667686462


Epoch [291]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.352  
Average loss each uniform: 12.377  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2280]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.737   loss each uniform = 12.769   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 40.521   loss each uniform = 9.899   feat norm = 0.509  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 112]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.797   loss each uniform = 9.413   feat norm = 0.448  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2276]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.714   loss each uniform = 12.269   feat norm = 0.446  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.574  
Average acc: 0.876  
Average grad norm: 4.785  
Average grad norm uniform: 34.129  
Average loss each uniform: 9.105  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.289   grad norm uniform = 35.445   loss each uniform = 12.398   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.833  exp loss = 0.929  adjusted loss = 0.929  adv prob = 0.250000   acc = 0.818   grad norm = 7.484   grad norm uniform = 33.538   loss each uniform = 6.365   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.124  exp loss = 2.316  adjusted loss = 2.316  adv prob = 0.250000   acc = 0.602   grad norm = 13.896   grad norm uniform = 30.207   loss each uniform = 5.464   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.249  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947   grad norm = 2.005   grad norm uniform = 35.500   loss each uniform = 10.785   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [292]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.335  
Average loss each uniform: 12.357  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2267]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.778   loss each uniform = 12.834   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 40.460   loss each uniform = 9.853   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 109]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 36.890   loss each uniform = 9.539   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2295]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.636   loss each uniform = 12.156   feat norm = 0.446  

Validation:
Average incurred loss: 0.598  
Average sample loss: 0.579  
Average acc: 0.871  
Average grad norm: 4.836  
Average grad norm uniform: 34.130  
Average loss each uniform: 9.044  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.282   grad norm uniform = 35.464   loss each uniform = 12.318   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.848  exp loss = 0.938  adjusted loss = 0.938  adv prob = 0.250000   acc = 0.807   grad norm = 7.594   grad norm uniform = 33.500   loss each uniform = 6.281   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.136  exp loss = 2.317  adjusted loss = 2.317  adv prob = 0.250000   acc = 0.594   grad norm = 14.011   grad norm uniform = 30.230   loss each uniform = 5.461   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.237  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.947   grad norm = 1.988   grad norm uniform = 35.555   loss each uniform = 10.806   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [293]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.375  
Average loss each uniform: 12.412  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2281]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.901   loss each uniform = 12.880   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 108]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.570   loss each uniform = 9.821   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 114]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 36.877   loss each uniform = 9.345   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2292]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.672   loss each uniform = 12.221   feat norm = 0.447  

Validation:
Average incurred loss: 0.638  
Average sample loss: 0.619  
Average acc: 0.865  
Average grad norm: 5.151  
Average grad norm uniform: 33.582  
Average loss each uniform: 8.814  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.989   grad norm = 0.377   grad norm uniform = 35.050   loss each uniform = 11.870   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.015  exp loss = 1.117  adjusted loss = 1.117  adv prob = 0.250000   acc = 0.779   grad norm = 8.810   grad norm uniform = 32.392   loss each uniform = 5.929   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.913  exp loss = 2.110  adjusted loss = 2.110  adv prob = 0.250000   acc = 0.639   grad norm = 12.631   grad norm uniform = 30.381   loss each uniform = 5.621   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.197  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.955   grad norm = 1.610   grad norm uniform = 35.795   loss each uniform = 11.385   feat norm = 0.450  
Current lr: 0.001000
Current validation accuracy: 0.8648874759674072


Epoch [294]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.338  
Average loss each uniform: 12.392  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2208]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.934   loss each uniform = 13.113   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 134]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 40.154   loss each uniform = 10.333   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.753   loss each uniform = 9.373   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2327]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.478   loss each uniform = 11.990   feat norm = 0.445  

Validation:
Average incurred loss: 0.672  
Average sample loss: 0.654  
Average acc: 0.850  
Average grad norm: 5.564  
Average grad norm uniform: 33.260  
Average loss each uniform: 8.517  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.989   grad norm = 0.475   grad norm uniform = 34.709   loss each uniform = 11.405   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.166  exp loss = 1.293  adjusted loss = 1.293  adv prob = 0.250000   acc = 0.734   grad norm = 10.142   grad norm uniform = 32.008   loss each uniform = 5.585   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.700  exp loss = 1.898  adjusted loss = 1.898  adv prob = 0.250000   acc = 0.647   grad norm = 11.682   grad norm uniform = 29.926   loss each uniform = 5.629   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.970   grad norm = 1.279   grad norm uniform = 35.889   loss each uniform = 11.534   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8498749136924744


Epoch [295]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.376  
Average loss each uniform: 12.454  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.699   loss each uniform = 12.667   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 40.611   loss each uniform = 9.957   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 94]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 37.940   loss each uniform = 10.115   feat norm = 0.460  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2265]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.796   loss each uniform = 12.456   feat norm = 0.447  

Validation:
Average incurred loss: 0.612  
Average sample loss: 0.592  
Average acc: 0.874  
Average grad norm: 4.916  
Average grad norm uniform: 34.023  
Average loss each uniform: 9.024  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.317   grad norm uniform = 35.408   loss each uniform = 12.294   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.882  exp loss = 0.969  adjusted loss = 0.969  adv prob = 0.250000   acc = 0.809   grad norm = 7.821   grad norm uniform = 33.227   loss each uniform = 6.230   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.136  exp loss = 2.303  adjusted loss = 2.303  adv prob = 0.250000   acc = 0.609   grad norm = 13.848   grad norm uniform = 30.377   loss each uniform = 5.459   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.234  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 1.950   grad norm uniform = 35.594   loss each uniform = 10.894   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8740617036819458


Epoch [296]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.299  
Average loss each uniform: 12.354  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2348]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.513   loss each uniform = 12.387   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.005  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000   grad norm = 0.176   grad norm uniform = 39.942   loss each uniform = 9.533   feat norm = 0.506  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 126]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 36.535   loss each uniform = 10.052   feat norm = 0.444  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2190]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 36.910   loss each uniform = 12.621   feat norm = 0.449  

Validation:
Average incurred loss: 0.731  
Average sample loss: 0.711  
Average acc: 0.843  
Average grad norm: 5.928  
Average grad norm uniform: 33.278  
Average loss each uniform: 8.447  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.037  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.987   grad norm = 0.522   grad norm uniform = 34.495   loss each uniform = 11.160   feat norm = 0.414  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.331  exp loss = 1.451  adjusted loss = 1.451  adv prob = 0.250000   acc = 0.708   grad norm = 11.189   grad norm uniform = 31.912   loss each uniform = 5.421   feat norm = 0.468  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.643  exp loss = 1.854  adjusted loss = 1.854  adv prob = 0.250000   acc = 0.684   grad norm = 11.229   grad norm uniform = 30.477   loss each uniform = 5.839   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.157  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.970   grad norm = 1.178   grad norm uniform = 36.593   loss each uniform = 12.134   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8432027101516724


Epoch [297]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.332  
Average loss each uniform: 12.307  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2264]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.500   loss each uniform = 12.776   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 153]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 40.203   loss each uniform = 9.925   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 124]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 37.028   loss each uniform = 9.349   feat norm = 0.450  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2254]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.867   loss each uniform = 12.161   feat norm = 0.449  

Validation:
Average incurred loss: 0.596  
Average sample loss: 0.577  
Average acc: 0.880  
Average grad norm: 4.737  
Average grad norm uniform: 34.359  
Average loss each uniform: 9.118  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.994   grad norm = 0.242   grad norm uniform = 35.564   loss each uniform = 12.414   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.805  exp loss = 0.912  adjusted loss = 0.912  adv prob = 0.250000   acc = 0.828   grad norm = 7.187   grad norm uniform = 33.774   loss each uniform = 6.399   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.238  exp loss = 2.407  adjusted loss = 2.407  adv prob = 0.250000   acc = 0.602   grad norm = 14.381   grad norm uniform = 30.527   loss each uniform = 5.451   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.273  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.940   grad norm = 2.286   grad norm uniform = 36.010   loss each uniform = 10.740   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8798999786376953


Epoch [298]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.310  
Average loss each uniform: 12.313  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2290]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 35.477   loss each uniform = 12.757   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 40.174   loss each uniform = 10.302   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 109]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 36.717   loss each uniform = 9.532   feat norm = 0.446  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2271]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 36.917   loss each uniform = 12.109   feat norm = 0.450  

Validation:
Average incurred loss: 0.673  
Average sample loss: 0.656  
Average acc: 0.857  
Average grad norm: 5.463  
Average grad norm uniform: 33.458  
Average loss each uniform: 8.621  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.991   grad norm = 0.465   grad norm uniform = 34.588   loss each uniform = 11.411   feat norm = 0.417  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.164  exp loss = 1.294  adjusted loss = 1.294  adv prob = 0.250000   acc = 0.745   grad norm = 9.955   grad norm uniform = 32.265   loss each uniform = 5.673   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.694  exp loss = 1.895  adjusted loss = 1.895  adv prob = 0.250000   acc = 0.669   grad norm = 11.316   grad norm uniform = 30.548   loss each uniform = 5.836   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.185  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.962   grad norm = 1.418   grad norm uniform = 36.585   loss each uniform = 11.935   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [299]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.303  
Average loss each uniform: 12.307  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2266]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 35.583   loss each uniform = 12.953   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 110]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.918   loss each uniform = 10.265   feat norm = 0.498  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 95]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 37.495   loss each uniform = 9.343   feat norm = 0.458  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 2324]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 36.785   loss each uniform = 11.896   feat norm = 0.449  

Validation:
Average incurred loss: 0.631  
Average sample loss: 0.612  
Average acc: 0.864  
Average grad norm: 5.130  
Average grad norm uniform: 33.451  
Average loss each uniform: 8.711  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.329   grad norm uniform = 34.751   loss each uniform = 11.751   feat norm = 0.416  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.970  exp loss = 1.083  adjusted loss = 1.083  adv prob = 0.250000   acc = 0.783   grad norm = 8.611   grad norm uniform = 32.376   loss each uniform = 5.864   feat norm = 0.467  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.004  exp loss = 2.209  adjusted loss = 2.209  adv prob = 0.250000   acc = 0.609   grad norm = 13.142   grad norm uniform = 30.304   loss each uniform = 5.514   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.220  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.955   grad norm = 1.784   grad norm uniform = 35.801   loss each uniform = 11.214   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204

