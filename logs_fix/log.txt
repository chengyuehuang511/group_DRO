Dataset: CUB
Shift type: confounder
Target name: waterbird_complete95
Confounder names: ['forest2water2']
Resume: False
Inference: False
Minority fraction: None
Imbalance ratio: None
Fraction: 1.0
Root dir: ./
Reweight groups: False
Augment data: False
Val fraction: 0.1
Robust: False
Alpha: 0.2
Generalization adjustment: 0.0
Automatic adjustment: False
Robust step size: 0.01
Use normalized loss: False
Btl: False
Hinge: False
Print grad loss: True
Print feat: True
Uniform loss: True
Model: resnet50
Train from scratch: False
N epochs: 300
Batch size: 128
Lr: 0.001
Scheduler: False
Weight decay: 0.0001
Gamma: 0.1
Minimum variational weight: 0
Seed: 0
Show progress: True
Log dir: ./logs_fix
Checkpoint dir: ./logs_a40
Log every: 50
Save step: 1000
Save best: True
Save last: True

Training Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 3498
    waterbird_complete95 = 0, forest2water2 = 1: n = 184
    waterbird_complete95 = 1, forest2water2 = 0: n = 56
    waterbird_complete95 = 1, forest2water2 = 1: n = 1057
Validation Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 467
    waterbird_complete95 = 0, forest2water2 = 1: n = 466
    waterbird_complete95 = 1, forest2water2 = 0: n = 133
    waterbird_complete95 = 1, forest2water2 = 1: n = 133
Test Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 2255
    waterbird_complete95 = 0, forest2water2 = 1: n = 2255
    waterbird_complete95 = 1, forest2water2 = 0: n = 642
    waterbird_complete95 = 1, forest2water2 = 1: n = 642

Epoch [0]:
Training:
Average incurred loss: 0.323  
Average sample loss: 0.321  
Average acc: 0.870  
Average grad norm: 8.241  
Average grad norm uniform: 23.191  
Average loss each uniform: 2.320  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.165  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.990   grad norm = 5.051   grad norm uniform = 25.830   loss each uniform = 2.532   feat norm = 0.440  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.521  exp loss = 0.614  adjusted loss = 0.614  adv prob = 0.250000   acc = 0.701   grad norm = 13.732   grad norm uniform = 14.804   loss each uniform = 1.659   feat norm = 0.460  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.503  exp loss = 1.545  adjusted loss = 1.545  adv prob = 0.250000   acc = 0.107   grad norm = 26.397   grad norm uniform = 18.274   loss each uniform = 1.839   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.749  exp loss = 0.457  adjusted loss = 0.457  adv prob = 0.250000   acc = 0.545   grad norm = 16.882   grad norm uniform = 16.177   loss each uniform = 1.759   feat norm = 0.446  

Validation:
Average incurred loss: 0.602  
Average sample loss: 0.590  
Average acc: 0.686  
Average grad norm: 11.873  
Average grad norm uniform: 24.018  
Average loss each uniform: 2.538  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.076  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.985   grad norm = 2.319   grad norm uniform = 31.806   loss each uniform = 3.424   feat norm = 0.442  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.985  exp loss = 1.000  adjusted loss = 1.000  adv prob = 0.250000   acc = 0.429   grad norm = 19.705   grad norm uniform = 17.432   loss each uniform = 1.839   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.499  exp loss = 1.643  adjusted loss = 1.643  adv prob = 0.250000   acc = 0.263   grad norm = 23.997   grad norm uniform = 18.659   loss each uniform = 2.004   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.955   grad norm = 5.851   grad norm uniform = 25.101   loss each uniform = 2.406   feat norm = 0.431  
Current lr: 0.001000
Current validation accuracy: 0.6855713129043579
Best model saved at epoch 0


Epoch [1]:
Training:
Average incurred loss: 0.124  
Average sample loss: 0.124  
Average acc: 0.956  
Average grad norm: 3.101  
Average grad norm uniform: 31.318  
Average loss each uniform: 3.771  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.041  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.998   grad norm = 1.336   grad norm uniform = 33.498   loss each uniform = 4.206   feat norm = 0.442  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.771  exp loss = 0.698  adjusted loss = 0.698  adv prob = 0.250000   acc = 0.565   grad norm = 16.343   grad norm uniform = 18.088   loss each uniform = 1.892   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.506  exp loss = 1.337  adjusted loss = 1.337  adv prob = 0.250000   acc = 0.286   grad norm = 23.853   grad norm uniform = 18.257   loss each uniform = 2.011   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.214  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.922   grad norm = 5.536   grad norm uniform = 27.099   loss each uniform = 2.752   feat norm = 0.436  

Validation:
Average incurred loss: 0.487  
Average sample loss: 0.472  
Average acc: 0.771  
Average grad norm: 9.221  
Average grad norm uniform: 26.710  
Average loss each uniform: 3.191  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.994   grad norm = 1.198   grad norm uniform = 33.765   loss each uniform = 4.555   feat norm = 0.440  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.731  exp loss = 0.755  adjusted loss = 0.755  adv prob = 0.250000   acc = 0.618   grad norm = 15.049   grad norm uniform = 20.316   loss each uniform = 2.108   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.522  exp loss = 1.739  adjusted loss = 1.739  adv prob = 0.250000   acc = 0.338   grad norm = 22.096   grad norm uniform = 20.896   loss each uniform = 2.243   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.962   grad norm = 4.099   grad norm uniform = 30.153   loss each uniform = 3.145   feat norm = 0.443  
Current lr: 0.001000
Current validation accuracy: 0.7714762687683105
Best model saved at epoch 1


Epoch [2]:
Training:
Average incurred loss: 0.085  
Average sample loss: 0.085  
Average acc: 0.970  
Average grad norm: 2.149  
Average grad norm uniform: 32.711  
Average loss each uniform: 4.407  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.026  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.998   grad norm = 0.867   grad norm uniform = 34.062   loss each uniform = 4.855   feat norm = 0.437  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.493  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.734   grad norm = 11.522   grad norm uniform = 21.076   loss each uniform = 2.131   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.043  exp loss = 1.217  adjusted loss = 1.217  adv prob = 0.250000   acc = 0.536   grad norm = 17.479   grad norm uniform = 18.693   loss each uniform = 2.034   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.159  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.940   grad norm = 3.947   grad norm uniform = 31.007   loss each uniform = 3.445   feat norm = 0.444  

Validation:
Average incurred loss: 0.422  
Average sample loss: 0.408  
Average acc: 0.822  
Average grad norm: 7.787  
Average grad norm uniform: 28.378  
Average loss each uniform: 3.604  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.998   grad norm = 0.836   grad norm uniform = 34.410   loss each uniform = 5.128   feat norm = 0.439  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.581  exp loss = 0.609  adjusted loss = 0.609  adv prob = 0.250000   acc = 0.717   grad norm = 12.216   grad norm uniform = 22.828   loss each uniform = 2.389   feat norm = 0.458  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.505  exp loss = 1.733  adjusted loss = 1.733  adv prob = 0.250000   acc = 0.429   grad norm = 20.739   grad norm uniform = 22.636   loss each uniform = 2.441   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.962   grad norm = 3.724   grad norm uniform = 32.384   loss each uniform = 3.671   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8215179443359375
Best model saved at epoch 2


Epoch [3]:
Training:
Average incurred loss: 0.060  
Average sample loss: 0.060  
Average acc: 0.981  
Average grad norm: 1.587  
Average grad norm uniform: 33.434  
Average loss each uniform: 4.876  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.020  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998   grad norm = 0.648   grad norm uniform = 34.275   loss each uniform = 5.283   feat norm = 0.435  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.369  exp loss = 0.402  adjusted loss = 0.402  adv prob = 0.250000   acc = 0.848   grad norm = 9.182   grad norm uniform = 23.154   loss each uniform = 2.362   feat norm = 0.463  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.775  exp loss = 0.678  adjusted loss = 0.678  adv prob = 0.250000   acc = 0.679   grad norm = 13.673   grad norm uniform = 20.327   loss each uniform = 2.138   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.103  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.963   grad norm = 2.731   grad norm uniform = 33.135   loss each uniform = 4.114   feat norm = 0.449  

Validation:
Average incurred loss: 0.418  
Average sample loss: 0.404  
Average acc: 0.832  
Average grad norm: 7.499  
Average grad norm uniform: 29.005  
Average loss each uniform: 3.808  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.998   grad norm = 0.784   grad norm uniform = 34.078   loss each uniform = 5.330   feat norm = 0.434  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.639  adjusted loss = 0.639  adv prob = 0.250000   acc = 0.727   grad norm = 12.169   grad norm uniform = 23.698   loss each uniform = 2.493   feat norm = 0.461  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.413  exp loss = 1.613  adjusted loss = 1.613  adv prob = 0.250000   acc = 0.481   grad norm = 19.203   grad norm uniform = 23.977   loss each uniform = 2.577   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.145  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.962   grad norm = 3.008   grad norm uniform = 34.815   loss each uniform = 4.299   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8315262794494629
Best model saved at epoch 3


Epoch [4]:
Training:
Average incurred loss: 0.047  
Average sample loss: 0.047  
Average acc: 0.985  
Average grad norm: 1.272  
Average grad norm uniform: 33.876  
Average loss each uniform: 5.250  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.015  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.998   grad norm = 0.494   grad norm uniform = 34.394   loss each uniform = 5.662   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.254  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.908   grad norm = 6.770   grad norm uniform = 26.889   loss each uniform = 2.689   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.542  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.732   grad norm = 9.882   grad norm uniform = 23.551   loss each uniform = 2.445   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.090  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 0.970   grad norm = 2.432   grad norm uniform = 33.927   loss each uniform = 4.483   feat norm = 0.454  

Validation:
Average incurred loss: 0.442  
Average sample loss: 0.429  
Average acc: 0.819  
Average grad norm: 7.547  
Average grad norm uniform: 29.283  
Average loss each uniform: 3.970  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.994   grad norm = 0.842   grad norm uniform = 33.726   loss each uniform = 5.421   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.720  exp loss = 0.775  adjusted loss = 0.775  adv prob = 0.250000   acc = 0.678   grad norm = 13.178   grad norm uniform = 24.002   loss each uniform = 2.555   feat norm = 0.459  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.237  exp loss = 1.424  adjusted loss = 1.424  adv prob = 0.250000   acc = 0.556   grad norm = 16.641   grad norm uniform = 25.288   loss each uniform = 2.747   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.122  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.962   grad norm = 2.261   grad norm uniform = 36.180   loss each uniform = 5.053   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8190158605575562


Epoch [5]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.992  
Average grad norm: 0.929  
Average grad norm uniform: 34.370  
Average loss each uniform: 5.624  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.999   grad norm = 0.350   grad norm uniform = 34.548   loss each uniform = 6.024   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.165  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.946   grad norm = 5.027   grad norm uniform = 29.144   loss each uniform = 3.019   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.411  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.839   grad norm = 8.063   grad norm uniform = 24.780   loss each uniform = 2.601   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.061  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.985   grad norm = 1.754   grad norm uniform = 35.202   loss each uniform = 4.916   feat norm = 0.457  

Validation:
Average incurred loss: 0.385  
Average sample loss: 0.369  
Average acc: 0.859  
Average grad norm: 6.241  
Average grad norm uniform: 30.858  
Average loss each uniform: 4.481  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.998   grad norm = 0.398   grad norm uniform = 34.687   loss each uniform = 6.301   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.460  exp loss = 0.502  adjusted loss = 0.502  adv prob = 0.250000   acc = 0.813   grad norm = 9.081   grad norm uniform = 27.597   loss each uniform = 3.065   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.629  exp loss = 1.833  adjusted loss = 1.833  adv prob = 0.250000   acc = 0.451   grad norm = 19.703   grad norm uniform = 24.857   loss each uniform = 2.828   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.940   grad norm = 3.342   grad norm uniform = 34.841   loss each uniform = 4.707   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577
Best model saved at epoch 5


Epoch [6]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.024  
Average acc: 0.996  
Average grad norm: 0.686  
Average grad norm uniform: 34.802  
Average loss each uniform: 5.947  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.293   grad norm uniform = 34.609   loss each uniform = 6.285   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.115  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.973   grad norm = 3.696   grad norm uniform = 31.545   loss each uniform = 3.203   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.291  exp loss = 0.375  adjusted loss = 0.375  adv prob = 0.250000   acc = 0.893   grad norm = 5.478   grad norm uniform = 28.710   loss each uniform = 2.982   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.041  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.992   grad norm = 1.208   grad norm uniform = 36.332   loss each uniform = 5.462   feat norm = 0.458  

Validation:
Average incurred loss: 0.488  
Average sample loss: 0.474  
Average acc: 0.811  
Average grad norm: 7.553  
Average grad norm uniform: 30.467  
Average loss each uniform: 4.471  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.762   grad norm uniform = 34.014   loss each uniform = 5.973   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.846  exp loss = 0.900  adjusted loss = 0.900  adv prob = 0.250000   acc = 0.655   grad norm = 13.809   grad norm uniform = 25.715   loss each uniform = 2.824   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.228  exp loss = 1.406  adjusted loss = 1.406  adv prob = 0.250000   acc = 0.586   grad norm = 15.275   grad norm uniform = 27.033   loss each uniform = 3.159   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.108  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.962   grad norm = 1.759   grad norm uniform = 38.097   loss each uniform = 6.278   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.8106756210327148


Epoch [7]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 0.997  
Average grad norm: 0.544  
Average grad norm uniform: 35.049  
Average loss each uniform: 6.245  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.230   grad norm uniform = 34.668   loss each uniform = 6.585   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.076  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.989   grad norm = 2.652   grad norm uniform = 33.349   loss each uniform = 3.555   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.210  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.893   grad norm = 4.563   grad norm uniform = 29.146   loss each uniform = 3.157   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.995   grad norm = 1.002   grad norm uniform = 36.921   loss each uniform = 5.752   feat norm = 0.460  

Validation:
Average incurred loss: 0.453  
Average sample loss: 0.439  
Average acc: 0.837  
Average grad norm: 6.871  
Average grad norm uniform: 30.858  
Average loss each uniform: 4.691  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.994   grad norm = 0.585   grad norm uniform = 33.985   loss each uniform = 6.325   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.731  exp loss = 0.794  adjusted loss = 0.794  adv prob = 0.250000   acc = 0.723   grad norm = 12.029   grad norm uniform = 26.757   loss each uniform = 3.027   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.326  exp loss = 1.499  adjusted loss = 1.499  adv prob = 0.250000   acc = 0.564   grad norm = 15.756   grad norm uniform = 27.312   loss each uniform = 3.202   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.962   grad norm = 1.988   grad norm uniform = 37.794   loss each uniform = 6.274   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.8373644351959229


Epoch [8]:
Training:
Average incurred loss: 0.014  
Average sample loss: 0.014  
Average acc: 0.998  
Average grad norm: 0.444  
Average grad norm uniform: 35.245  
Average loss each uniform: 6.482  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.202   grad norm uniform = 34.704   loss each uniform = 6.782   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.066  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.995   grad norm = 2.358   grad norm uniform = 34.410   loss each uniform = 3.701   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.171  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 0.911   grad norm = 3.459   grad norm uniform = 31.373   loss each uniform = 3.432   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.024  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.997   grad norm = 0.755   grad norm uniform = 37.384   loss each uniform = 6.133   feat norm = 0.459  

Validation:
Average incurred loss: 0.460  
Average sample loss: 0.445  
Average acc: 0.841  
Average grad norm: 6.782  
Average grad norm uniform: 31.305  
Average loss each uniform: 4.874  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994   grad norm = 0.539   grad norm uniform = 34.324   loss each uniform = 6.580   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.741  exp loss = 0.800  adjusted loss = 0.800  adv prob = 0.250000   acc = 0.730   grad norm = 11.864   grad norm uniform = 27.631   loss each uniform = 3.175   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.353  exp loss = 1.506  adjusted loss = 1.506  adv prob = 0.250000   acc = 0.579   grad norm = 15.704   grad norm uniform = 27.043   loss each uniform = 3.255   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.955   grad norm = 1.975   grad norm uniform = 37.836   loss each uniform = 6.458   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.840700626373291


Epoch [9]:
Training:
Average incurred loss: 0.011  
Average sample loss: 0.011  
Average acc: 0.999  
Average grad norm: 0.359  
Average grad norm uniform: 35.397  
Average loss each uniform: 6.751  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.160   grad norm uniform = 34.738   loss each uniform = 7.047   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.042  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 1.000   grad norm = 1.566   grad norm uniform = 36.120   loss each uniform = 4.043   feat norm = 0.491  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.151  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.946   grad norm = 3.487   grad norm uniform = 30.219   loss each uniform = 3.455   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.020  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.999   grad norm = 0.640   grad norm uniform = 37.729   loss each uniform = 6.417   feat norm = 0.460  

Validation:
Average incurred loss: 0.468  
Average sample loss: 0.454  
Average acc: 0.839  
Average grad norm: 6.701  
Average grad norm uniform: 31.333  
Average loss each uniform: 5.012  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994   grad norm = 0.527   grad norm uniform = 34.127   loss each uniform = 6.742   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.756  exp loss = 0.820  adjusted loss = 0.820  adv prob = 0.250000   acc = 0.725   grad norm = 11.724   grad norm uniform = 27.789   loss each uniform = 3.254   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.377  exp loss = 1.531  adjusted loss = 1.531  adv prob = 0.250000   acc = 0.579   grad norm = 15.556   grad norm uniform = 27.401   loss each uniform = 3.373   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.126  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.955   grad norm = 1.927   grad norm uniform = 37.877   loss each uniform = 6.731   feat norm = 0.471  
Current lr: 0.001000
Current validation accuracy: 0.8390325307846069


Epoch [10]:
Training:
Average incurred loss: 0.010  
Average sample loss: 0.011  
Average acc: 0.999  
Average grad norm: 0.327  
Average grad norm uniform: 35.466  
Average loss each uniform: 6.927  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.005  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.168   grad norm uniform = 34.757   loss each uniform = 7.171   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.041  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000   grad norm = 1.573   grad norm uniform = 36.310   loss each uniform = 4.100   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.104  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 0.964   grad norm = 2.531   grad norm uniform = 31.293   loss each uniform = 3.844   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.017  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.999   grad norm = 0.520   grad norm uniform = 37.888   loss each uniform = 6.778   feat norm = 0.458  

Validation:
Average incurred loss: 0.588  
Average sample loss: 0.574  
Average acc: 0.797  
Average grad norm: 7.928  
Average grad norm uniform: 31.173  
Average loss each uniform: 4.947  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.985   grad norm = 0.977   grad norm uniform = 33.095   loss each uniform = 6.216   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.154  exp loss = 1.220  adjusted loss = 1.220  adv prob = 0.250000   acc = 0.592   grad norm = 15.694   grad norm uniform = 27.529   loss each uniform = 3.150   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.022  exp loss = 1.173  adjusted loss = 1.173  adv prob = 0.250000   acc = 0.677   grad norm = 11.836   grad norm uniform = 28.748   loss each uniform = 3.756   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.090  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 0.977   grad norm = 1.217   grad norm uniform = 39.619   loss each uniform = 7.974   feat norm = 0.476  
Current lr: 0.001000
Current validation accuracy: 0.7973310947418213


Epoch [11]:
Training:
Average incurred loss: 0.008  
Average sample loss: 0.008  
Average acc: 0.999  
Average grad norm: 0.251  
Average grad norm uniform: 35.611  
Average loss each uniform: 7.241  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.091   grad norm uniform = 34.794   loss each uniform = 7.602   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.021  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000   grad norm = 0.799   grad norm uniform = 38.119   loss each uniform = 4.674   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.093  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.964   grad norm = 2.321   grad norm uniform = 32.001   loss each uniform = 3.839   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.018  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.997   grad norm = 0.572   grad norm uniform = 38.068   loss each uniform = 6.672   feat norm = 0.462  

Validation:
Average incurred loss: 0.492  
Average sample loss: 0.477  
Average acc: 0.838  
Average grad norm: 6.761  
Average grad norm uniform: 31.480  
Average loss each uniform: 5.228  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.998   grad norm = 0.453   grad norm uniform = 34.133   loss each uniform = 7.070   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.808  exp loss = 0.875  adjusted loss = 0.875  adv prob = 0.250000   acc = 0.719   grad norm = 11.993   grad norm uniform = 28.230   loss each uniform = 3.377   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.424  exp loss = 1.556  adjusted loss = 1.556  adv prob = 0.250000   acc = 0.579   grad norm = 15.477   grad norm uniform = 27.364   loss each uniform = 3.430   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.126  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.955   grad norm = 1.861   grad norm uniform = 37.668   loss each uniform = 7.039   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8381984829902649


Epoch [12]:
Training:
Average incurred loss: 0.007  
Average sample loss: 0.007  
Average acc: 0.999  
Average grad norm: 0.217  
Average grad norm uniform: 35.710  
Average loss each uniform: 7.346  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.109   grad norm uniform = 34.881   loss each uniform = 7.582   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.039  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.995   grad norm = 1.345   grad norm uniform = 37.314   loss each uniform = 4.348   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.063  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.982   grad norm = 1.668   grad norm uniform = 32.807   loss each uniform = 4.003   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.999   grad norm = 0.300   grad norm uniform = 38.329   loss each uniform = 7.262   feat norm = 0.457  

Validation:
Average incurred loss: 0.516  
Average sample loss: 0.502  
Average acc: 0.829  
Average grad norm: 6.857  
Average grad norm uniform: 31.527  
Average loss each uniform: 5.328  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.987   grad norm = 0.570   grad norm uniform = 33.716   loss each uniform = 7.037   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.904  exp loss = 0.976  adjusted loss = 0.976  adv prob = 0.250000   acc = 0.700   grad norm = 12.657   grad norm uniform = 28.347   loss each uniform = 3.438   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.283  exp loss = 1.417  adjusted loss = 1.417  adv prob = 0.250000   acc = 0.602   grad norm = 13.846   grad norm uniform = 28.066   loss each uniform = 3.639   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.119  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.955   grad norm = 1.624   grad norm uniform = 38.448   loss each uniform = 7.638   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8290241956710815


Epoch [13]:
Training:
Average incurred loss: 0.006  
Average sample loss: 0.006  
Average acc: 1.000  
Average grad norm: 0.190  
Average grad norm uniform: 35.743  
Average loss each uniform: 7.569  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 34.840   loss each uniform = 7.902   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.017  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000   grad norm = 0.669   grad norm uniform = 38.723   loss each uniform = 4.919   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.082  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.982   grad norm = 2.158   grad norm uniform = 31.941   loss each uniform = 3.918   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.390   grad norm uniform = 38.413   loss each uniform = 7.122   feat norm = 0.461  

Validation:
Average incurred loss: 0.516  
Average sample loss: 0.500  
Average acc: 0.834  
Average grad norm: 6.798  
Average grad norm uniform: 31.634  
Average loss each uniform: 5.424  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.998   grad norm = 0.467   grad norm uniform = 33.967   loss each uniform = 7.285   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.869  exp loss = 0.953  adjusted loss = 0.953  adv prob = 0.250000   acc = 0.706   grad norm = 12.248   grad norm uniform = 28.583   loss each uniform = 3.508   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.424  exp loss = 1.567  adjusted loss = 1.567  adv prob = 0.250000   acc = 0.586   grad norm = 15.002   grad norm uniform = 27.792   loss each uniform = 3.561   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.123  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.955   grad norm = 1.731   grad norm uniform = 37.975   loss each uniform = 7.466   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8340283632278442


Epoch [14]:
Training:
Average incurred loss: 0.005  
Average sample loss: 0.005  
Average acc: 1.000  
Average grad norm: 0.155  
Average grad norm uniform: 35.823  
Average loss each uniform: 7.675  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.083   grad norm uniform = 34.880   loss each uniform = 7.907   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.013  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000   grad norm = 0.519   grad norm uniform = 39.100   loss each uniform = 5.115   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.053  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.982   grad norm = 1.385   grad norm uniform = 33.347   loss each uniform = 4.385   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.999   grad norm = 0.265   grad norm uniform = 38.507   loss each uniform = 7.527   feat norm = 0.458  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.522  
Average acc: 0.831  
Average grad norm: 6.878  
Average grad norm uniform: 31.887  
Average loss each uniform: 5.527  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.987   grad norm = 0.562   grad norm uniform = 34.022   loss each uniform = 7.277   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.964  exp loss = 1.042  adjusted loss = 1.042  adv prob = 0.250000   acc = 0.693   grad norm = 12.887   grad norm uniform = 28.834   loss each uniform = 3.555   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.266  exp loss = 1.410  adjusted loss = 1.410  adv prob = 0.250000   acc = 0.624   grad norm = 13.414   grad norm uniform = 28.441   loss each uniform = 3.759   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.111  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 0.970   grad norm = 1.468   grad norm uniform = 38.538   loss each uniform = 8.055   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8306922316551208


Epoch [15]:
Training:
Average incurred loss: 0.005  
Average sample loss: 0.005  
Average acc: 1.000  
Average grad norm: 0.154  
Average grad norm uniform: 35.824  
Average loss each uniform: 7.788  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.080   grad norm uniform = 34.877   loss each uniform = 8.031   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.015  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.607   grad norm uniform = 39.000   loss each uniform = 5.099   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.051  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.982   grad norm = 1.270   grad norm uniform = 33.641   loss each uniform = 4.572   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.008  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.260   grad norm uniform = 38.519   loss each uniform = 7.623   feat norm = 0.458  

Validation:
Average incurred loss: 0.468  
Average sample loss: 0.450  
Average acc: 0.862  
Average grad norm: 5.979  
Average grad norm uniform: 32.137  
Average loss each uniform: 5.794  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.260   grad norm uniform = 34.475   loss each uniform = 7.988   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.651  exp loss = 0.712  adjusted loss = 0.712  adv prob = 0.250000   acc = 0.790   grad norm = 9.552   grad norm uniform = 29.886   loss each uniform = 3.884   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.739  exp loss = 1.897  adjusted loss = 1.897  adv prob = 0.250000   acc = 0.541   grad norm = 17.240   grad norm uniform = 26.811   loss each uniform = 3.539   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.955   grad norm = 2.275   grad norm uniform = 37.144   loss each uniform = 7.037   feat norm = 0.465  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391
Best model saved at epoch 15


Epoch [16]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.116  
Average grad norm uniform: 35.902  
Average loss each uniform: 7.961  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.057   grad norm uniform = 34.874   loss each uniform = 8.232   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.011  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.444   grad norm uniform = 39.469   loss each uniform = 5.455   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.037  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000   grad norm = 0.999   grad norm uniform = 34.157   loss each uniform = 4.532   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.206   grad norm uniform = 38.772   loss each uniform = 7.682   feat norm = 0.459  

Validation:
Average incurred loss: 0.455  
Average sample loss: 0.437  
Average acc: 0.867  
Average grad norm: 5.635  
Average grad norm uniform: 32.534  
Average loss each uniform: 6.003  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.216   grad norm uniform = 34.518   loss each uniform = 8.262   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.569  exp loss = 0.635  adjusted loss = 0.635  adv prob = 0.250000   acc = 0.820   grad norm = 8.423   grad norm uniform = 30.892   loss each uniform = 4.144   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.887  exp loss = 2.061  adjusted loss = 2.061  adv prob = 0.250000   acc = 0.489   grad norm = 17.931   grad norm uniform = 27.048   loss each uniform = 3.629   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947   grad norm = 2.598   grad norm uniform = 36.802   loss each uniform = 6.956   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8665555119514465
Best model saved at epoch 16


Epoch [17]:
Training:
Average incurred loss: 0.004  
Average sample loss: 0.004  
Average acc: 1.000  
Average grad norm: 0.122  
Average grad norm uniform: 35.901  
Average loss each uniform: 8.027  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.059   grad norm uniform = 34.930   loss each uniform = 8.254   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.014  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000   grad norm = 0.571   grad norm uniform = 39.218   loss each uniform = 5.374   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.033  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000   grad norm = 0.974   grad norm uniform = 34.175   loss each uniform = 4.612   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.207   grad norm uniform = 38.626   loss each uniform = 7.920   feat norm = 0.457  

Validation:
Average incurred loss: 0.520  
Average sample loss: 0.505  
Average acc: 0.840  
Average grad norm: 6.490  
Average grad norm uniform: 32.390  
Average loss each uniform: 5.816  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.987   grad norm = 0.490   grad norm uniform = 34.218   loss each uniform = 7.688   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.900  exp loss = 0.974  adjusted loss = 0.974  adv prob = 0.250000   acc = 0.723   grad norm = 11.847   grad norm uniform = 29.785   loss each uniform = 3.809   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.344  exp loss = 1.488  adjusted loss = 1.488  adv prob = 0.250000   acc = 0.617   grad norm = 13.685   grad norm uniform = 28.730   loss each uniform = 3.876   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.122  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 0.955   grad norm = 1.590   grad norm uniform = 38.758   loss each uniform = 8.212   feat norm = 0.470  
Current lr: 0.001000
Current validation accuracy: 0.8398665189743042


Epoch [18]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.102  
Average grad norm uniform: 35.938  
Average loss each uniform: 8.175  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 34.918   loss each uniform = 8.421   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.010  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.389   grad norm uniform = 39.735   loss each uniform = 5.681   feat norm = 0.509  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.034  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000   grad norm = 1.032   grad norm uniform = 33.964   loss each uniform = 4.693   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.178   grad norm uniform = 38.756   loss each uniform = 7.980   feat norm = 0.457  

Validation:
Average incurred loss: 0.503  
Average sample loss: 0.487  
Average acc: 0.851  
Average grad norm: 6.178  
Average grad norm uniform: 32.458  
Average loss each uniform: 5.948  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.994   grad norm = 0.398   grad norm uniform = 34.177   loss each uniform = 7.937   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.817  exp loss = 0.885  adjusted loss = 0.885  adv prob = 0.250000   acc = 0.751   grad norm = 10.862   grad norm uniform = 30.137   loss each uniform = 3.920   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.478  exp loss = 1.640  adjusted loss = 1.640  adv prob = 0.250000   acc = 0.594   grad norm = 14.500   grad norm uniform = 28.479   loss each uniform = 3.889   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.134  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.955   grad norm = 1.745   grad norm uniform = 38.534   loss each uniform = 8.126   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8507089018821716


Epoch [19]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.102  
Average grad norm uniform: 35.935  
Average loss each uniform: 8.250  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 34.895   loss each uniform = 8.517   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.010  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.380   grad norm uniform = 39.778   loss each uniform = 5.704   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.022  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000   grad norm = 0.687   grad norm uniform = 34.834   loss each uniform = 4.930   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.169   grad norm uniform = 38.767   loss each uniform = 7.989   feat norm = 0.458  

Validation:
Average incurred loss: 0.496  
Average sample loss: 0.480  
Average acc: 0.857  
Average grad norm: 6.025  
Average grad norm uniform: 32.601  
Average loss each uniform: 6.068  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.998   grad norm = 0.320   grad norm uniform = 34.342   loss each uniform = 8.199   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.762  exp loss = 0.821  adjusted loss = 0.821  adv prob = 0.250000   acc = 0.768   grad norm = 10.212   grad norm uniform = 30.619   loss each uniform = 4.061   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.611  exp loss = 1.770  adjusted loss = 1.770  adv prob = 0.250000   acc = 0.571   grad norm = 15.444   grad norm uniform = 28.110   loss each uniform = 3.808   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.148  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 0.955   grad norm = 1.969   grad norm uniform = 37.927   loss each uniform = 7.872   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [20]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.086  
Average grad norm uniform: 35.979  
Average loss each uniform: 8.399  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 34.910   loss each uniform = 8.652   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.007  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.298   grad norm uniform = 40.023   loss each uniform = 5.915   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.034  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 1.000   grad norm = 0.974   grad norm uniform = 34.215   loss each uniform = 4.854   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.141   grad norm uniform = 38.905   loss each uniform = 8.182   feat norm = 0.458  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.576  
Average acc: 0.818  
Average grad norm: 7.022  
Average grad norm uniform: 32.054  
Average loss each uniform: 5.874  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.987   grad norm = 0.563   grad norm uniform = 33.684   loss each uniform = 7.627   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.097  exp loss = 1.175  adjusted loss = 1.175  adv prob = 0.250000   acc = 0.659   grad norm = 13.485   grad norm uniform = 29.349   loss each uniform = 3.768   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.285  exp loss = 1.432  adjusted loss = 1.432  adv prob = 0.250000   acc = 0.632   grad norm = 12.731   grad norm uniform = 28.878   loss each uniform = 4.079   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.110  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.970   grad norm = 1.349   grad norm uniform = 38.984   loss each uniform = 8.889   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8181818723678589


Epoch [21]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.077  
Average grad norm uniform: 35.998  
Average loss each uniform: 8.483  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 34.897   loss each uniform = 8.751   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.204   grad norm uniform = 40.232   loss each uniform = 6.037   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.033  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 1.000   grad norm = 0.861   grad norm uniform = 34.466   loss each uniform = 4.865   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.140   grad norm uniform = 38.986   loss each uniform = 8.212   feat norm = 0.459  

Validation:
Average incurred loss: 0.459  
Average sample loss: 0.440  
Average acc: 0.872  
Average grad norm: 5.174  
Average grad norm uniform: 33.042  
Average loss each uniform: 6.512  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.126   grad norm uniform = 34.500   loss each uniform = 9.039   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.463  exp loss = 0.518  adjusted loss = 0.518  adv prob = 0.250000   acc = 0.850   grad norm = 6.676   grad norm uniform = 32.265   loss each uniform = 4.680   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.258  exp loss = 2.413  adjusted loss = 2.413  adv prob = 0.250000   acc = 0.436   grad norm = 19.733   grad norm uniform = 27.491   loss each uniform = 3.767   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.244  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.932   grad norm = 3.077   grad norm uniform = 36.196   loss each uniform = 6.800   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645
Best model saved at epoch 21


Epoch [22]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.089  
Average grad norm uniform: 35.985  
Average loss each uniform: 8.497  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.047   grad norm uniform = 34.968   loss each uniform = 8.696   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.008  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000   grad norm = 0.324   grad norm uniform = 39.928   loss each uniform = 5.826   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.023  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000   grad norm = 0.660   grad norm uniform = 34.897   loss each uniform = 5.327   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.005  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.156   grad norm uniform = 38.722   loss each uniform = 8.470   feat norm = 0.455  

Validation:
Average incurred loss: 0.604  
Average sample loss: 0.589  
Average acc: 0.822  
Average grad norm: 7.140  
Average grad norm uniform: 32.357  
Average loss each uniform: 5.945  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.987   grad norm = 0.598   grad norm uniform = 34.010   loss each uniform = 7.721   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.137  exp loss = 1.227  adjusted loss = 1.227  adv prob = 0.250000   acc = 0.670   grad norm = 13.775   grad norm uniform = 29.632   loss each uniform = 3.799   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.259  exp loss = 1.380  adjusted loss = 1.380  adv prob = 0.250000   acc = 0.639   grad norm = 12.676   grad norm uniform = 29.323   loss each uniform = 4.126   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.110  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 0.962   grad norm = 1.329   grad norm uniform = 39.135   loss each uniform = 9.045   feat norm = 0.471  
Current lr: 0.001000
Current validation accuracy: 0.8223519325256348


Epoch [23]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.063  
Average grad norm uniform: 36.041  
Average loss each uniform: 8.640  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 34.957   loss each uniform = 8.863   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.203   grad norm uniform = 40.238   loss each uniform = 6.058   feat norm = 0.512  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.022  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000   grad norm = 0.663   grad norm uniform = 34.893   loss each uniform = 5.136   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.103   grad norm uniform = 38.958   loss each uniform = 8.535   feat norm = 0.457  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.520  
Average acc: 0.847  
Average grad norm: 6.328  
Average grad norm uniform: 31.953  
Average loss each uniform: 6.064  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.998   grad norm = 0.355   grad norm uniform = 33.686   loss each uniform = 8.145   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.886  exp loss = 0.957  adjusted loss = 0.957  adv prob = 0.250000   acc = 0.734   grad norm = 11.272   grad norm uniform = 29.682   loss each uniform = 3.984   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.544  exp loss = 1.688  adjusted loss = 1.688  adv prob = 0.250000   acc = 0.602   grad norm = 14.592   grad norm uniform = 28.066   loss each uniform = 3.867   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.139  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.955   grad norm = 1.711   grad norm uniform = 37.713   loss each uniform = 8.246   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [24]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.067  
Average grad norm uniform: 36.030  
Average loss each uniform: 8.692  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 34.945   loss each uniform = 8.938   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.249   grad norm uniform = 40.222   loss each uniform = 6.104   feat norm = 0.513  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.021  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000   grad norm = 0.609   grad norm uniform = 35.143   loss each uniform = 5.400   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.115   grad norm uniform = 38.937   loss each uniform = 8.502   feat norm = 0.457  

Validation:
Average incurred loss: 0.486  
Average sample loss: 0.468  
Average acc: 0.872  
Average grad norm: 5.558  
Average grad norm uniform: 33.319  
Average loss each uniform: 6.562  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.240   grad norm uniform = 34.678   loss each uniform = 8.877   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.680  exp loss = 0.738  adjusted loss = 0.738  adv prob = 0.250000   acc = 0.811   grad norm = 8.848   grad norm uniform = 32.043   loss each uniform = 4.541   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.788  exp loss = 1.926  adjusted loss = 1.926  adv prob = 0.250000   acc = 0.564   grad norm = 16.084   grad norm uniform = 28.213   loss each uniform = 3.970   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.955   grad norm = 2.180   grad norm uniform = 38.123   loss each uniform = 8.101   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8723936080932617
Best model saved at epoch 24


Epoch [25]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.053  
Average grad norm uniform: 36.066  
Average loss each uniform: 8.788  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 34.957   loss each uniform = 9.011   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.181   grad norm uniform = 40.427   loss each uniform = 6.189   feat norm = 0.513  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.019  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000   grad norm = 0.545   grad norm uniform = 35.016   loss each uniform = 5.278   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.089   grad norm uniform = 39.033   loss each uniform = 8.688   feat norm = 0.457  

Validation:
Average incurred loss: 0.504  
Average sample loss: 0.485  
Average acc: 0.862  
Average grad norm: 5.814  
Average grad norm uniform: 33.049  
Average loss each uniform: 6.440  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.238   grad norm uniform = 34.757   loss each uniform = 8.803   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.709  exp loss = 0.786  adjusted loss = 0.786  adv prob = 0.250000   acc = 0.790   grad norm = 9.313   grad norm uniform = 31.367   loss each uniform = 4.357   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.853  exp loss = 1.980  adjusted loss = 1.980  adv prob = 0.250000   acc = 0.549   grad norm = 16.799   grad norm uniform = 27.982   loss each uniform = 3.914   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.955   grad norm = 2.150   grad norm uniform = 38.017   loss each uniform = 7.969   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8623853325843811


Epoch [26]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.054  
Average grad norm uniform: 36.073  
Average loss each uniform: 8.831  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 34.990   loss each uniform = 9.024   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.226   grad norm uniform = 40.273   loss each uniform = 6.131   feat norm = 0.513  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.012  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000   grad norm = 0.379   grad norm uniform = 35.504   loss each uniform = 5.573   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.088   grad norm uniform = 38.956   loss each uniform = 8.835   feat norm = 0.456  

Validation:
Average incurred loss: 0.505  
Average sample loss: 0.488  
Average acc: 0.860  
Average grad norm: 5.802  
Average grad norm uniform: 32.533  
Average loss each uniform: 6.401  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.264   grad norm uniform = 34.122   loss each uniform = 8.673   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.750  exp loss = 0.810  adjusted loss = 0.810  adv prob = 0.250000   acc = 0.779   grad norm = 9.634   grad norm uniform = 30.919   loss each uniform = 4.341   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.725  exp loss = 1.867  adjusted loss = 1.867  adv prob = 0.250000   acc = 0.564   grad norm = 15.613   grad norm uniform = 27.710   loss each uniform = 3.908   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.955   grad norm = 2.010   grad norm uniform = 37.427   loss each uniform = 8.131   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8598833084106445


Epoch [27]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.051  
Average grad norm uniform: 36.070  
Average loss each uniform: 8.907  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 34.952   loss each uniform = 9.124   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.153   grad norm uniform = 40.548   loss each uniform = 6.372   feat norm = 0.515  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.019  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000   grad norm = 0.560   grad norm uniform = 35.310   loss each uniform = 5.538   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 39.032   loss each uniform = 8.811   feat norm = 0.456  

Validation:
Average incurred loss: 0.532  
Average sample loss: 0.516  
Average acc: 0.850  
Average grad norm: 6.092  
Average grad norm uniform: 33.138  
Average loss each uniform: 6.501  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.335   grad norm uniform = 34.642   loss each uniform = 8.727   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.851  exp loss = 0.936  adjusted loss = 0.936  adv prob = 0.250000   acc = 0.745   grad norm = 10.570   grad norm uniform = 31.042   loss each uniform = 4.322   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.618  exp loss = 1.740  adjusted loss = 1.740  adv prob = 0.250000   acc = 0.602   grad norm = 14.875   grad norm uniform = 29.545   loss each uniform = 4.110   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.955   grad norm = 1.837   grad norm uniform = 38.793   loss each uniform = 8.714   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8498748540878296


Epoch [28]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.054  
Average grad norm uniform: 36.069  
Average loss each uniform: 8.955  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 34.968   loss each uniform = 9.173   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.196   grad norm uniform = 40.447   loss each uniform = 6.374   feat norm = 0.515  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.016  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000   grad norm = 0.493   grad norm uniform = 35.245   loss each uniform = 5.486   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.093   grad norm uniform = 38.997   loss each uniform = 8.866   feat norm = 0.456  

Validation:
Average incurred loss: 0.479  
Average sample loss: 0.458  
Average acc: 0.872  
Average grad norm: 5.149  
Average grad norm uniform: 33.286  
Average loss each uniform: 6.838  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.115   grad norm uniform = 34.518   loss each uniform = 9.474   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.492  exp loss = 0.545  adjusted loss = 0.545  adv prob = 0.250000   acc = 0.852   grad norm = 6.698   grad norm uniform = 32.702   loss each uniform = 4.909   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.332  exp loss = 2.489  adjusted loss = 2.489  adv prob = 0.250000   acc = 0.444   grad norm = 19.518   grad norm uniform = 27.771   loss each uniform = 3.950   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.250  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 0.925   grad norm = 3.025   grad norm uniform = 36.526   loss each uniform = 7.228   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8723937273025513
Best model saved at epoch 28


Epoch [29]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.046  
Average grad norm uniform: 36.093  
Average loss each uniform: 9.035  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 34.977   loss each uniform = 9.232   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.211   grad norm uniform = 40.493   loss each uniform = 6.444   feat norm = 0.516  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.011  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.339   grad norm uniform = 35.451   loss each uniform = 5.541   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.063   grad norm uniform = 39.054   loss each uniform = 9.018   feat norm = 0.456  

Validation:
Average incurred loss: 0.529  
Average sample loss: 0.512  
Average acc: 0.855  
Average grad norm: 5.966  
Average grad norm uniform: 32.922  
Average loss each uniform: 6.528  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.998   grad norm = 0.292   grad norm uniform = 34.342   loss each uniform = 8.805   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.823  exp loss = 0.891  adjusted loss = 0.891  adv prob = 0.250000   acc = 0.760   grad norm = 10.218   grad norm uniform = 31.073   loss each uniform = 4.329   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.691  exp loss = 1.821  adjusted loss = 1.821  adv prob = 0.250000   acc = 0.586   grad norm = 15.148   grad norm uniform = 28.863   loss each uniform = 4.082   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.955   grad norm = 1.812   grad norm uniform = 38.475   loss each uniform = 8.680   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8548790216445923


Epoch [30]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.047  
Average grad norm uniform: 36.084  
Average loss each uniform: 9.073  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 34.970   loss each uniform = 9.289   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.185   grad norm uniform = 40.585   loss each uniform = 6.390   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.016  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000   grad norm = 0.460   grad norm uniform = 35.203   loss each uniform = 5.442   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 39.032   loss each uniform = 9.017   feat norm = 0.456  

Validation:
Average incurred loss: 0.492  
Average sample loss: 0.473  
Average acc: 0.868  
Average grad norm: 5.334  
Average grad norm uniform: 33.083  
Average loss each uniform: 6.769  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.149   grad norm uniform = 34.452   loss each uniform = 9.308   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.601  exp loss = 0.662  adjusted loss = 0.662  adv prob = 0.250000   acc = 0.824   grad norm = 7.792   grad norm uniform = 32.237   loss each uniform = 4.747   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.111  exp loss = 2.244  adjusted loss = 2.244  adv prob = 0.250000   acc = 0.489   grad norm = 17.816   grad norm uniform = 27.282   loss each uniform = 3.975   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.204  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.947   grad norm = 2.446   grad norm uniform = 37.043   loss each uniform = 7.734   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [31]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.045  
Average grad norm uniform: 36.087  
Average loss each uniform: 9.119  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 34.971   loss each uniform = 9.327   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.182   grad norm uniform = 40.651   loss each uniform = 6.594   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.371   grad norm uniform = 35.584   loss each uniform = 5.723   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 39.012   loss each uniform = 9.050   feat norm = 0.455  

Validation:
Average incurred loss: 0.583  
Average sample loss: 0.567  
Average acc: 0.840  
Average grad norm: 6.514  
Average grad norm uniform: 32.853  
Average loss each uniform: 6.465  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.987   grad norm = 0.412   grad norm uniform = 34.310   loss each uniform = 8.586   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.014  exp loss = 1.112  adjusted loss = 1.112  adv prob = 0.250000   acc = 0.721   grad norm = 11.975   grad norm uniform = 30.592   loss each uniform = 4.180   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.514  exp loss = 1.648  adjusted loss = 1.648  adv prob = 0.250000   acc = 0.617   grad norm = 13.816   grad norm uniform = 29.638   loss each uniform = 4.266   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.130  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.962   grad norm = 1.500   grad norm uniform = 38.876   loss each uniform = 9.220   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8398665189743042


Epoch [32]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.044  
Average grad norm uniform: 36.094  
Average loss each uniform: 9.188  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 34.961   loss each uniform = 9.411   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.138   grad norm uniform = 40.538   loss each uniform = 6.660   feat norm = 0.515  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.011  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000   grad norm = 0.340   grad norm uniform = 35.675   loss each uniform = 5.809   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 39.090   loss each uniform = 9.068   feat norm = 0.456  

Validation:
Average incurred loss: 0.507  
Average sample loss: 0.489  
Average acc: 0.863  
Average grad norm: 5.565  
Average grad norm uniform: 32.545  
Average loss each uniform: 6.658  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.207   grad norm uniform = 34.120   loss each uniform = 9.084   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.712  exp loss = 0.781  adjusted loss = 0.781  adv prob = 0.250000   acc = 0.796   grad norm = 8.873   grad norm uniform = 31.082   loss each uniform = 4.533   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.870  exp loss = 2.011  adjusted loss = 2.011  adv prob = 0.250000   acc = 0.541   grad norm = 16.206   grad norm uniform = 27.521   loss each uniform = 4.009   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.947   grad norm = 2.146   grad norm uniform = 37.164   loss each uniform = 8.233   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [33]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.037  
Average grad norm uniform: 36.120  
Average loss each uniform: 9.242  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 34.984   loss each uniform = 9.442   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.139   grad norm uniform = 40.787   loss each uniform = 6.598   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.291   grad norm uniform = 35.732   loss each uniform = 5.893   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 39.087   loss each uniform = 9.217   feat norm = 0.455  

Validation:
Average incurred loss: 0.542  
Average sample loss: 0.523  
Average acc: 0.855  
Average grad norm: 5.994  
Average grad norm uniform: 33.238  
Average loss each uniform: 6.647  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.344   grad norm uniform = 34.431   loss each uniform = 8.864   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.873  exp loss = 0.949  adjusted loss = 0.949  adv prob = 0.250000   acc = 0.760   grad norm = 10.473   grad norm uniform = 31.484   loss each uniform = 4.435   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.625  exp loss = 1.757  adjusted loss = 1.757  adv prob = 0.250000   acc = 0.609   grad norm = 14.424   grad norm uniform = 29.581   loss each uniform = 4.248   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.151  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.955   grad norm = 1.709   grad norm uniform = 38.850   loss each uniform = 9.009   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8548790216445923


Epoch [34]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.037  
Average grad norm uniform: 36.118  
Average loss each uniform: 9.295  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 34.983   loss each uniform = 9.489   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.163   grad norm uniform = 40.702   loss each uniform = 6.676   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.302   grad norm uniform = 35.584   loss each uniform = 5.783   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.059   grad norm uniform = 39.106   loss each uniform = 9.292   feat norm = 0.455  

Validation:
Average incurred loss: 0.563  
Average sample loss: 0.547  
Average acc: 0.847  
Average grad norm: 6.163  
Average grad norm uniform: 32.854  
Average loss each uniform: 6.642  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.998   grad norm = 0.325   grad norm uniform = 34.190   loss each uniform = 8.903   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.934  exp loss = 1.008  adjusted loss = 1.008  adv prob = 0.250000   acc = 0.734   grad norm = 10.974   grad norm uniform = 30.985   loss each uniform = 4.368   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.613  exp loss = 1.751  adjusted loss = 1.751  adv prob = 0.250000   acc = 0.609   grad norm = 14.292   grad norm uniform = 29.046   loss each uniform = 4.219   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.147  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.955   grad norm = 1.681   grad norm uniform = 38.520   loss each uniform = 9.095   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [35]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.041  
Average grad norm uniform: 36.098  
Average loss each uniform: 9.338  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 34.941   loss each uniform = 9.566   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.119   grad norm uniform = 40.886   loss each uniform = 6.964   feat norm = 0.519  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.015  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000   grad norm = 0.465   grad norm uniform = 35.251   loss each uniform = 5.724   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 39.139   loss each uniform = 9.191   feat norm = 0.456  

Validation:
Average incurred loss: 0.496  
Average sample loss: 0.476  
Average acc: 0.871  
Average grad norm: 5.242  
Average grad norm uniform: 33.286  
Average loss each uniform: 6.971  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.124   grad norm uniform = 34.584   loss each uniform = 9.626   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.575  exp loss = 0.638  adjusted loss = 0.638  adv prob = 0.250000   acc = 0.843   grad norm = 7.377   grad norm uniform = 32.547   loss each uniform = 4.911   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.220  exp loss = 2.375  adjusted loss = 2.375  adv prob = 0.250000   acc = 0.459   grad norm = 18.349   grad norm uniform = 27.801   loss each uniform = 4.055   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.224  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.932   grad norm = 2.630   grad norm uniform = 36.805   loss each uniform = 7.784   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [36]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.040  
Average grad norm uniform: 36.109  
Average loss each uniform: 9.360  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 34.975   loss each uniform = 9.565   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.131   grad norm uniform = 40.781   loss each uniform = 6.902   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.012  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000   grad norm = 0.340   grad norm uniform = 35.596   loss each uniform = 5.915   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.072   grad norm uniform = 39.074   loss each uniform = 9.293   feat norm = 0.455  

Validation:
Average incurred loss: 0.505  
Average sample loss: 0.486  
Average acc: 0.873  
Average grad norm: 5.348  
Average grad norm uniform: 33.258  
Average loss each uniform: 6.994  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.171   grad norm uniform = 34.598   loss each uniform = 9.578   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.653  exp loss = 0.725  adjusted loss = 0.725  adv prob = 0.250000   acc = 0.824   grad norm = 8.060   grad norm uniform = 32.245   loss each uniform = 4.873   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.051  exp loss = 2.209  adjusted loss = 2.209  adv prob = 0.250000   acc = 0.534   grad norm = 17.084   grad norm uniform = 27.951   loss each uniform = 4.116   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.194  adjusted loss = 0.194  adv prob = 0.250000   acc = 0.947   grad norm = 2.290   grad norm uniform = 37.413   loss each uniform = 8.236   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485
Best model saved at epoch 36


Epoch [37]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.030  
Average grad norm uniform: 36.133  
Average loss each uniform: 9.429  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 35.000   loss each uniform = 9.615   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.106   grad norm uniform = 40.836   loss each uniform = 6.856   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.252   grad norm uniform = 35.794   loss each uniform = 6.164   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.047   grad norm uniform = 39.084   loss each uniform = 9.438   feat norm = 0.455  

Validation:
Average incurred loss: 0.497  
Average sample loss: 0.478  
Average acc: 0.872  
Average grad norm: 5.345  
Average grad norm uniform: 33.110  
Average loss each uniform: 6.924  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.168   grad norm uniform = 34.443   loss each uniform = 9.455   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.648  exp loss = 0.715  adjusted loss = 0.715  adv prob = 0.250000   acc = 0.820   grad norm = 8.107   grad norm uniform = 32.106   loss each uniform = 4.820   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.992  exp loss = 2.157  adjusted loss = 2.157  adv prob = 0.250000   acc = 0.534   grad norm = 16.897   grad norm uniform = 27.700   loss each uniform = 4.086   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.947   grad norm = 2.298   grad norm uniform = 37.355   loss each uniform = 8.243   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8715596795082092


Epoch [38]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.028  
Average grad norm uniform: 36.145  
Average loss each uniform: 9.476  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 34.997   loss each uniform = 9.664   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.101   grad norm uniform = 40.839   loss each uniform = 6.837   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.007  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.227   grad norm uniform = 35.952   loss each uniform = 6.176   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 39.139   loss each uniform = 9.487   feat norm = 0.455  

Validation:
Average incurred loss: 0.546  
Average sample loss: 0.529  
Average acc: 0.857  
Average grad norm: 5.879  
Average grad norm uniform: 33.304  
Average loss each uniform: 6.849  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.316   grad norm uniform = 34.578   loss each uniform = 9.209   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.861  exp loss = 0.945  adjusted loss = 0.945  adv prob = 0.250000   acc = 0.760   grad norm = 10.090   grad norm uniform = 31.734   loss each uniform = 4.580   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.699  exp loss = 1.827  adjusted loss = 1.827  adv prob = 0.250000   acc = 0.609   grad norm = 14.690   grad norm uniform = 29.221   loss each uniform = 4.293   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.955   grad norm = 1.845   grad norm uniform = 38.408   loss each uniform = 9.068   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [39]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.039  
Average grad norm uniform: 36.120  
Average loss each uniform: 9.506  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 34.995   loss each uniform = 9.704   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.101   grad norm uniform = 40.783   loss each uniform = 6.819   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.016  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 1.000   grad norm = 0.483   grad norm uniform = 35.336   loss each uniform = 5.968   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.085   grad norm uniform = 39.073   loss each uniform = 9.506   feat norm = 0.455  

Validation:
Average incurred loss: 0.513  
Average sample loss: 0.493  
Average acc: 0.872  
Average grad norm: 5.276  
Average grad norm uniform: 33.568  
Average loss each uniform: 7.205  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.114   grad norm uniform = 34.829   loss each uniform = 9.951   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.664  adjusted loss = 0.664  adv prob = 0.250000   acc = 0.841   grad norm = 7.494   grad norm uniform = 33.031   loss each uniform = 5.089   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.254  exp loss = 2.400  adjusted loss = 2.400  adv prob = 0.250000   acc = 0.459   grad norm = 18.294   grad norm uniform = 27.603   loss each uniform = 4.126   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.947   grad norm = 2.614   grad norm uniform = 36.989   loss each uniform = 8.057   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8715596795082092


Epoch [40]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.028  
Average grad norm uniform: 36.155  
Average loss each uniform: 9.500  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.098   loss each uniform = 9.589   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.128   grad norm uniform = 40.717   loss each uniform = 6.671   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.162   grad norm uniform = 35.679   loss each uniform = 6.270   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 38.884   loss each uniform = 9.869   feat norm = 0.451  

Validation:
Average incurred loss: 0.671  
Average sample loss: 0.656  
Average acc: 0.817  
Average grad norm: 7.044  
Average grad norm uniform: 32.630  
Average loss each uniform: 6.610  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.987   grad norm = 0.564   grad norm uniform = 34.080   loss each uniform = 8.629   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.276  exp loss = 1.380  adjusted loss = 1.380  adv prob = 0.250000   acc = 0.646   grad norm = 13.779   grad norm uniform = 30.270   loss each uniform = 4.178   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.364  exp loss = 1.495  adjusted loss = 1.495  adv prob = 0.250000   acc = 0.662   grad norm = 12.089   grad norm uniform = 29.723   loss each uniform = 4.572   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.114  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.977   grad norm = 1.152   grad norm uniform = 38.721   loss each uniform = 10.080   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8173477649688721


Epoch [41]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.029  
Average grad norm uniform: 36.153  
Average loss each uniform: 9.538  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.088   loss each uniform = 9.640   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.132   grad norm uniform = 40.786   loss each uniform = 6.801   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.201   grad norm uniform = 35.688   loss each uniform = 6.325   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 38.893   loss each uniform = 9.849   feat norm = 0.451  

Validation:
Average incurred loss: 0.525  
Average sample loss: 0.507  
Average acc: 0.867  
Average grad norm: 5.568  
Average grad norm uniform: 33.118  
Average loss each uniform: 7.011  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.242   grad norm uniform = 34.580   loss each uniform = 9.528   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.759  exp loss = 0.827  adjusted loss = 0.827  adv prob = 0.250000   acc = 0.796   grad norm = 9.093   grad norm uniform = 31.710   loss each uniform = 4.753   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.866  exp loss = 1.973  adjusted loss = 1.973  adv prob = 0.250000   acc = 0.564   grad norm = 15.571   grad norm uniform = 28.502   loss each uniform = 4.268   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.172  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955   grad norm = 1.916   grad norm uniform = 37.536   loss each uniform = 8.829   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [42]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.028  
Average grad norm uniform: 36.137  
Average loss each uniform: 9.583  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 35.035   loss each uniform = 9.730   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.117   grad norm uniform = 40.894   loss each uniform = 6.992   feat norm = 0.519  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.174   grad norm uniform = 35.970   loss each uniform = 6.400   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 38.964   loss each uniform = 9.714   feat norm = 0.452  

Validation:
Average incurred loss: 0.528  
Average sample loss: 0.511  
Average acc: 0.863  
Average grad norm: 5.652  
Average grad norm uniform: 32.677  
Average loss each uniform: 6.817  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.267   grad norm uniform = 33.953   loss each uniform = 9.193   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.811  exp loss = 0.893  adjusted loss = 0.893  adv prob = 0.250000   acc = 0.777   grad norm = 9.589   grad norm uniform = 31.241   loss each uniform = 4.573   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.726  exp loss = 1.841  adjusted loss = 1.841  adv prob = 0.250000   acc = 0.602   grad norm = 14.652   grad norm uniform = 28.417   loss each uniform = 4.239   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.955   grad norm = 1.768   grad norm uniform = 37.487   loss each uniform = 8.914   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [43]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.027  
Average grad norm uniform: 36.143  
Average loss each uniform: 9.630  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 35.022   loss each uniform = 9.792   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.097   grad norm uniform = 41.051   loss each uniform = 7.042   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.163   grad norm uniform = 36.027   loss each uniform = 6.500   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 39.004   loss each uniform = 9.711   feat norm = 0.453  

Validation:
Average incurred loss: 0.534  
Average sample loss: 0.515  
Average acc: 0.863  
Average grad norm: 5.602  
Average grad norm uniform: 33.211  
Average loss each uniform: 7.096  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.197   grad norm uniform = 34.619   loss each uniform = 9.753   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.732  exp loss = 0.806  adjusted loss = 0.806  adv prob = 0.250000   acc = 0.796   grad norm = 8.816   grad norm uniform = 32.185   loss each uniform = 4.853   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.035  exp loss = 2.145  adjusted loss = 2.145  adv prob = 0.250000   acc = 0.541   grad norm = 16.717   grad norm uniform = 27.788   loss each uniform = 4.178   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947   grad norm = 2.208   grad norm uniform = 37.282   loss each uniform = 8.544   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [44]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.031  
Average grad norm uniform: 36.129  
Average loss each uniform: 9.657  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.007   loss each uniform = 9.839   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.110   grad norm uniform = 40.968   loss each uniform = 7.052   feat norm = 0.520  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.008  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.244   grad norm uniform = 35.722   loss each uniform = 6.116   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 39.021   loss each uniform = 9.696   feat norm = 0.453  

Validation:
Average incurred loss: 0.530  
Average sample loss: 0.513  
Average acc: 0.864  
Average grad norm: 5.572  
Average grad norm uniform: 32.731  
Average loss each uniform: 6.942  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.228   grad norm uniform = 33.989   loss each uniform = 9.421   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.792  exp loss = 0.867  adjusted loss = 0.867  adv prob = 0.250000   acc = 0.783   grad norm = 9.269   grad norm uniform = 31.392   loss each uniform = 4.687   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.808  exp loss = 1.930  adjusted loss = 1.930  adv prob = 0.250000   acc = 0.586   grad norm = 15.031   grad norm uniform = 28.308   loss each uniform = 4.217   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.955   grad norm = 1.920   grad norm uniform = 37.430   loss each uniform = 8.858   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [45]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.025  
Average grad norm uniform: 36.141  
Average loss each uniform: 9.725  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 35.004   loss each uniform = 9.902   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.083   grad norm uniform = 40.923   loss each uniform = 7.196   feat norm = 0.519  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.228   grad norm uniform = 35.944   loss each uniform = 6.294   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 39.084   loss each uniform = 9.760   feat norm = 0.453  

Validation:
Average incurred loss: 0.507  
Average sample loss: 0.488  
Average acc: 0.877  
Average grad norm: 5.182  
Average grad norm uniform: 33.519  
Average loss each uniform: 7.275  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.175   grad norm uniform = 34.747   loss each uniform = 9.932   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.642  exp loss = 0.708  adjusted loss = 0.708  adv prob = 0.250000   acc = 0.833   grad norm = 7.648   grad norm uniform = 32.725   loss each uniform = 5.129   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.094  exp loss = 2.244  adjusted loss = 2.244  adv prob = 0.250000   acc = 0.534   grad norm = 16.966   grad norm uniform = 28.274   loss each uniform = 4.261   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.947   grad norm = 2.338   grad norm uniform = 37.233   loss each uniform = 8.478   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8765637874603271
Best model saved at epoch 45


Epoch [46]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.023  
Average grad norm uniform: 36.153  
Average loss each uniform: 9.759  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 35.011   loss each uniform = 9.930   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.082   grad norm uniform = 41.078   loss each uniform = 7.163   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.163   grad norm uniform = 36.113   loss each uniform = 6.473   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 39.079   loss each uniform = 9.819   feat norm = 0.453  

Validation:
Average incurred loss: 0.549  
Average sample loss: 0.532  
Average acc: 0.862  
Average grad norm: 5.676  
Average grad norm uniform: 33.454  
Average loss each uniform: 7.196  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.264   grad norm uniform = 34.616   loss each uniform = 9.714   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.829  exp loss = 0.910  adjusted loss = 0.910  adv prob = 0.250000   acc = 0.777   grad norm = 9.505   grad norm uniform = 32.292   loss each uniform = 4.881   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.841  exp loss = 1.992  adjusted loss = 1.992  adv prob = 0.250000   acc = 0.586   grad norm = 15.077   grad norm uniform = 28.793   loss each uniform = 4.406   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.171  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.955   grad norm = 1.865   grad norm uniform = 38.103   loss each uniform = 9.256   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [47]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.024  
Average grad norm uniform: 36.153  
Average loss each uniform: 9.809  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 34.997   loss each uniform = 9.987   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 41.019   loss each uniform = 7.251   feat norm = 0.520  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.182   grad norm uniform = 35.984   loss each uniform = 6.360   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 39.140   loss each uniform = 9.847   feat norm = 0.454  

Validation:
Average incurred loss: 0.561  
Average sample loss: 0.542  
Average acc: 0.857  
Average grad norm: 5.895  
Average grad norm uniform: 33.179  
Average loss each uniform: 7.045  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.288   grad norm uniform = 34.342   loss each uniform = 9.506   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.872  exp loss = 0.947  adjusted loss = 0.947  adv prob = 0.250000   acc = 0.768   grad norm = 10.077   grad norm uniform = 31.760   loss each uniform = 4.717   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.797  exp loss = 1.916  adjusted loss = 1.916  adv prob = 0.250000   acc = 0.571   grad norm = 15.062   grad norm uniform = 28.864   loss each uniform = 4.335   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.955   grad norm = 1.766   grad norm uniform = 38.382   loss each uniform = 9.272   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8565471768379211


Epoch [48]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.164  
Average loss each uniform: 9.838  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.022   loss each uniform = 9.994   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 40.932   loss each uniform = 7.370   feat norm = 0.519  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.156   grad norm uniform = 35.937   loss each uniform = 6.388   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 39.127   loss each uniform = 9.937   feat norm = 0.453  

Validation:
Average incurred loss: 0.660  
Average sample loss: 0.643  
Average acc: 0.827  
Average grad norm: 6.784  
Average grad norm uniform: 33.111  
Average loss each uniform: 6.861  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.987   grad norm = 0.519   grad norm uniform = 34.048   loss each uniform = 8.904   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.231  exp loss = 1.330  adjusted loss = 1.330  adv prob = 0.250000   acc = 0.676   grad norm = 13.079   grad norm uniform = 31.157   loss each uniform = 4.402   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.424  exp loss = 1.565  adjusted loss = 1.565  adv prob = 0.250000   acc = 0.647   grad norm = 12.225   grad norm uniform = 30.155   loss each uniform = 4.743   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.970   grad norm = 1.289   grad norm uniform = 39.624   loss each uniform = 10.419   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8265221118927002


Epoch [49]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.020  
Average grad norm uniform: 36.168  
Average loss each uniform: 9.871  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.020   loss each uniform = 10.033   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.055   grad norm uniform = 41.105   loss each uniform = 7.501   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.168   grad norm uniform = 35.981   loss each uniform = 6.494   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 39.118   loss each uniform = 9.928   feat norm = 0.453  

Validation:
Average incurred loss: 0.507  
Average sample loss: 0.486  
Average acc: 0.875  
Average grad norm: 5.032  
Average grad norm uniform: 33.757  
Average loss each uniform: 7.519  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.108   grad norm uniform = 34.872   loss each uniform = 10.362   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.571  exp loss = 0.625  adjusted loss = 0.625  adv prob = 0.250000   acc = 0.848   grad norm = 6.917   grad norm uniform = 33.447   loss each uniform = 5.391   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.309  exp loss = 2.448  adjusted loss = 2.448  adv prob = 0.250000   acc = 0.474   grad norm = 18.115   grad norm uniform = 27.739   loss each uniform = 4.269   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.246  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.932   grad norm = 2.632   grad norm uniform = 36.943   loss each uniform = 8.244   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8748957514762878


Epoch [50]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.021  
Average grad norm uniform: 36.161  
Average loss each uniform: 9.898  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.006   loss each uniform = 10.076   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 40.988   loss each uniform = 7.397   feat norm = 0.520  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.136   grad norm uniform = 35.999   loss each uniform = 6.427   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 39.150   loss each uniform = 9.928   feat norm = 0.453  

Validation:
Average incurred loss: 0.585  
Average sample loss: 0.568  
Average acc: 0.849  
Average grad norm: 6.054  
Average grad norm uniform: 33.206  
Average loss each uniform: 7.075  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.998   grad norm = 0.308   grad norm uniform = 34.348   loss each uniform = 9.534   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.949  exp loss = 1.030  adjusted loss = 1.030  adv prob = 0.250000   acc = 0.742   grad norm = 10.657   grad norm uniform = 31.720   loss each uniform = 4.680   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.749  exp loss = 1.875  adjusted loss = 1.875  adv prob = 0.250000   acc = 0.594   grad norm = 14.485   grad norm uniform = 29.218   loss each uniform = 4.397   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.955   grad norm = 1.669   grad norm uniform = 38.389   loss each uniform = 9.507   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8490408658981323


Epoch [51]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.163  
Average loss each uniform: 9.920  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.023   loss each uniform = 10.093   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.099   grad norm uniform = 40.991   loss each uniform = 7.382   feat norm = 0.520  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.197   grad norm uniform = 35.838   loss each uniform = 6.280   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.116   loss each uniform = 9.981   feat norm = 0.453  

Validation:
Average incurred loss: 0.684  
Average sample loss: 0.667  
Average acc: 0.820  
Average grad norm: 6.972  
Average grad norm uniform: 32.632  
Average loss each uniform: 6.805  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.987   grad norm = 0.536   grad norm uniform = 33.671   loss each uniform = 8.839   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.296  exp loss = 1.398  adjusted loss = 1.398  adv prob = 0.250000   acc = 0.657   grad norm = 13.580   grad norm uniform = 30.461   loss each uniform = 4.312   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.408  exp loss = 1.534  adjusted loss = 1.534  adv prob = 0.250000   acc = 0.654   grad norm = 12.155   grad norm uniform = 29.850   loss each uniform = 4.708   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.122  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.970   grad norm = 1.230   grad norm uniform = 39.369   loss each uniform = 10.495   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8198498487472534


Epoch [52]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.146  
Average loss each uniform: 9.934  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 34.978   loss each uniform = 10.134   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.072   grad norm uniform = 41.061   loss each uniform = 7.381   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.181   grad norm uniform = 36.073   loss each uniform = 6.493   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 39.159   loss each uniform = 9.897   feat norm = 0.454  

Validation:
Average incurred loss: 0.598  
Average sample loss: 0.580  
Average acc: 0.845  
Average grad norm: 6.137  
Average grad norm uniform: 33.378  
Average loss each uniform: 7.151  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.350   grad norm uniform = 34.272   loss each uniform = 9.494   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.999  exp loss = 1.083  adjusted loss = 1.083  adv prob = 0.250000   acc = 0.725   grad norm = 11.056   grad norm uniform = 31.865   loss each uniform = 4.707   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.686  exp loss = 1.824  adjusted loss = 1.824  adv prob = 0.250000   acc = 0.624   grad norm = 13.794   grad norm uniform = 29.887   loss each uniform = 4.648   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.955   grad norm = 1.566   grad norm uniform = 39.032   loss each uniform = 9.988   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8448706865310669


Epoch [53]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.155  
Average loss each uniform: 9.977  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 34.964   loss each uniform = 10.179   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 41.189   loss each uniform = 7.587   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.177   grad norm uniform = 36.373   loss each uniform = 6.576   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 39.206   loss each uniform = 9.904   feat norm = 0.454  

Validation:
Average incurred loss: 0.598  
Average sample loss: 0.580  
Average acc: 0.850  
Average grad norm: 6.110  
Average grad norm uniform: 33.296  
Average loss each uniform: 7.121  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.321   grad norm uniform = 34.297   loss each uniform = 9.509   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.981  exp loss = 1.065  adjusted loss = 1.065  adv prob = 0.250000   acc = 0.745   grad norm = 10.894   grad norm uniform = 31.772   loss each uniform = 4.695   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.747  exp loss = 1.883  adjusted loss = 1.883  adv prob = 0.250000   acc = 0.602   grad norm = 14.205   grad norm uniform = 29.654   loss each uniform = 4.554   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.158  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.955   grad norm = 1.579   grad norm uniform = 38.762   loss each uniform = 9.804   feat norm = 0.465  
Current lr: 0.001000
Current validation accuracy: 0.8498748540878296


Epoch [54]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.020  
Average grad norm uniform: 36.162  
Average loss each uniform: 10.020  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 34.987   loss each uniform = 10.218   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.056   grad norm uniform = 41.162   loss each uniform = 7.541   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.156   grad norm uniform = 36.286   loss each uniform = 6.785   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 39.175   loss each uniform = 9.967   feat norm = 0.454  

Validation:
Average incurred loss: 0.578  
Average sample loss: 0.561  
Average acc: 0.847  
Average grad norm: 5.996  
Average grad norm uniform: 33.247  
Average loss each uniform: 7.076  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.333   grad norm uniform = 34.335   loss each uniform = 9.453   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.954  exp loss = 1.044  adjusted loss = 1.044  adv prob = 0.250000   acc = 0.738   grad norm = 10.650   grad norm uniform = 31.663   loss each uniform = 4.679   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.665  exp loss = 1.796  adjusted loss = 1.796  adv prob = 0.250000   acc = 0.617   grad norm = 13.948   grad norm uniform = 29.711   loss each uniform = 4.513   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.955   grad norm = 1.619   grad norm uniform = 38.516   loss each uniform = 9.691   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8473728895187378


Epoch [55]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.017  
Average grad norm uniform: 36.174  
Average loss each uniform: 10.058  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 34.984   loss each uniform = 10.246   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 41.156   loss each uniform = 7.518   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.147   grad norm uniform = 36.229   loss each uniform = 6.565   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 39.241   loss each uniform = 10.062   feat norm = 0.454  

Validation:
Average incurred loss: 0.530  
Average sample loss: 0.510  
Average acc: 0.872  
Average grad norm: 5.244  
Average grad norm uniform: 34.031  
Average loss each uniform: 7.638  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.159   grad norm uniform = 35.197   loss each uniform = 10.484   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.669  exp loss = 0.726  adjusted loss = 0.726  adv prob = 0.250000   acc = 0.822   grad norm = 7.714   grad norm uniform = 33.563   loss each uniform = 5.390   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.195  exp loss = 2.360  adjusted loss = 2.360  adv prob = 0.250000   acc = 0.526   grad norm = 17.284   grad norm uniform = 28.239   loss each uniform = 4.370   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.216  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947   grad norm = 2.409   grad norm uniform = 37.370   loss each uniform = 8.788   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [56]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.169  
Average loss each uniform: 10.068  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 34.992   loss each uniform = 10.255   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 41.167   loss each uniform = 7.591   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.115   grad norm uniform = 36.260   loss each uniform = 6.679   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.186   loss each uniform = 10.062   feat norm = 0.453  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.532  
Average acc: 0.862  
Average grad norm: 5.601  
Average grad norm uniform: 33.367  
Average loss each uniform: 7.280  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.230   grad norm uniform = 34.441   loss each uniform = 9.839   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.814  exp loss = 0.888  adjusted loss = 0.888  adv prob = 0.250000   acc = 0.779   grad norm = 9.263   grad norm uniform = 32.195   loss each uniform = 4.953   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.894  exp loss = 2.041  adjusted loss = 2.041  adv prob = 0.250000   acc = 0.579   grad norm = 15.298   grad norm uniform = 29.090   loss each uniform = 4.425   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.955   grad norm = 1.935   grad norm uniform = 37.979   loss each uniform = 9.305   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [57]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.165  
Average loss each uniform: 10.072  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.004   loss each uniform = 10.275   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.059   grad norm uniform = 41.135   loss each uniform = 7.436   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.007  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.236   grad norm uniform = 35.906   loss each uniform = 6.391   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 39.156   loss each uniform = 10.053   feat norm = 0.453  

Validation:
Average incurred loss: 0.549  
Average sample loss: 0.530  
Average acc: 0.861  
Average grad norm: 5.575  
Average grad norm uniform: 32.904  
Average loss each uniform: 7.228  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.193   grad norm uniform = 34.268   loss each uniform = 9.909   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.772  exp loss = 0.841  adjusted loss = 0.841  adv prob = 0.250000   acc = 0.788   grad norm = 8.973   grad norm uniform = 31.727   loss each uniform = 4.897   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.035  exp loss = 2.199  adjusted loss = 2.199  adv prob = 0.250000   acc = 0.549   grad norm = 16.137   grad norm uniform = 27.989   loss each uniform = 4.304   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.947   grad norm = 2.002   grad norm uniform = 37.152   loss each uniform = 8.908   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [58]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.173  
Average loss each uniform: 10.111  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 34.998   loss each uniform = 10.291   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.054   grad norm uniform = 41.217   loss each uniform = 7.647   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.201   grad norm uniform = 35.811   loss each uniform = 6.475   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.201   loss each uniform = 10.137   feat norm = 0.453  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.547  
Average acc: 0.859  
Average grad norm: 5.647  
Average grad norm uniform: 33.370  
Average loss each uniform: 7.399  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.237   grad norm uniform = 34.335   loss each uniform = 10.034   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.831  exp loss = 0.910  adjusted loss = 0.910  adv prob = 0.250000   acc = 0.777   grad norm = 9.351   grad norm uniform = 32.404   loss each uniform = 5.014   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.968  exp loss = 2.105  adjusted loss = 2.105  adv prob = 0.250000   acc = 0.564   grad norm = 15.424   grad norm uniform = 28.599   loss each uniform = 4.493   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.955   grad norm = 1.891   grad norm uniform = 38.140   loss each uniform = 9.411   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [59]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.018  
Average grad norm uniform: 36.180  
Average loss each uniform: 10.134  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.024   loss each uniform = 10.318   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.064   grad norm uniform = 41.082   loss each uniform = 7.453   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.122   grad norm uniform = 36.289   loss each uniform = 6.747   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 39.144   loss each uniform = 10.173   feat norm = 0.453  

Validation:
Average incurred loss: 0.517  
Average sample loss: 0.496  
Average acc: 0.877  
Average grad norm: 4.954  
Average grad norm uniform: 33.952  
Average loss each uniform: 7.735  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 35.026   loss each uniform = 10.724   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.527  exp loss = 0.581  adjusted loss = 0.581  adv prob = 0.250000   acc = 0.861   grad norm = 6.393   grad norm uniform = 33.704   loss each uniform = 5.602   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.537  exp loss = 2.691  adjusted loss = 2.691  adv prob = 0.250000   acc = 0.444   grad norm = 19.145   grad norm uniform = 28.344   loss each uniform = 4.348   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.269  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.932   grad norm = 2.846   grad norm uniform = 36.662   loss each uniform = 8.104   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8765637874603271


Epoch [60]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.188  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.042   loss each uniform = 10.332   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 41.134   loss each uniform = 7.627   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.133   grad norm uniform = 36.099   loss each uniform = 6.757   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 39.143   loss each uniform = 10.339   feat norm = 0.452  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.575  
Average acc: 0.848  
Average grad norm: 5.938  
Average grad norm uniform: 33.548  
Average loss each uniform: 7.328  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.339   grad norm uniform = 34.546   loss each uniform = 9.773   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.985  exp loss = 1.065  adjusted loss = 1.065  adv prob = 0.250000   acc = 0.740   grad norm = 10.628   grad norm uniform = 32.093   loss each uniform = 4.877   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.682  exp loss = 1.820  adjusted loss = 1.820  adv prob = 0.250000   acc = 0.617   grad norm = 13.580   grad norm uniform = 30.055   loss each uniform = 4.678   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.153  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.955   grad norm = 1.519   grad norm uniform = 38.637   loss each uniform = 9.981   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [61]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.172  
Average loss each uniform: 10.166  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.033   loss each uniform = 10.341   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 41.170   loss each uniform = 7.484   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.127   grad norm uniform = 36.081   loss each uniform = 6.747   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 39.076   loss each uniform = 10.234   feat norm = 0.452  

Validation:
Average incurred loss: 0.509  
Average sample loss: 0.489  
Average acc: 0.879  
Average grad norm: 4.843  
Average grad norm uniform: 33.861  
Average loss each uniform: 7.812  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 34.728   loss each uniform = 10.741   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.553  exp loss = 0.614  adjusted loss = 0.614  adv prob = 0.250000   acc = 0.856   grad norm = 6.453   grad norm uniform = 33.803   loss each uniform = 5.653   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.386  exp loss = 2.536  adjusted loss = 2.536  adv prob = 0.250000   acc = 0.489   grad norm = 17.978   grad norm uniform = 28.204   loss each uniform = 4.420   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.261  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.925   grad norm = 2.768   grad norm uniform = 36.680   loss each uniform = 8.482   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8790659308433533
Best model saved at epoch 61


Epoch [62]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.180  
Average loss each uniform: 10.195  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.056   loss each uniform = 10.338   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.063   grad norm uniform = 41.126   loss each uniform = 7.585   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.149   grad norm uniform = 36.208   loss each uniform = 6.978   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.038   loss each uniform = 10.345   feat norm = 0.451  

Validation:
Average incurred loss: 0.530  
Average sample loss: 0.509  
Average acc: 0.875  
Average grad norm: 5.124  
Average grad norm uniform: 34.288  
Average loss each uniform: 7.836  
Average feat norm: 0.458  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.097   grad norm uniform = 35.388   loss each uniform = 10.811   feat norm = 0.435  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.606  exp loss = 0.667  adjusted loss = 0.667  adv prob = 0.250000   acc = 0.843   grad norm = 7.181   grad norm uniform = 33.939   loss each uniform = 5.591   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.407  exp loss = 2.597  adjusted loss = 2.597  adv prob = 0.250000   acc = 0.481   grad norm = 18.144   grad norm uniform = 28.602   loss each uniform = 4.461   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.239  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.940   grad norm = 2.551   grad norm uniform = 37.333   loss each uniform = 8.633   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8748958110809326


Epoch [63]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.017  
Average grad norm uniform: 36.191  
Average loss each uniform: 10.229  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.082   loss each uniform = 10.370   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.079   grad norm uniform = 41.132   loss each uniform = 7.437   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.153   grad norm uniform = 35.952   loss each uniform = 6.745   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.014   loss each uniform = 10.433   feat norm = 0.450  

Validation:
Average incurred loss: 0.610  
Average sample loss: 0.592  
Average acc: 0.845  
Average grad norm: 6.054  
Average grad norm uniform: 33.326  
Average loss each uniform: 7.299  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.346   grad norm uniform = 34.528   loss each uniform = 9.782   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.024  exp loss = 1.108  adjusted loss = 1.108  adv prob = 0.250000   acc = 0.730   grad norm = 10.881   grad norm uniform = 31.755   loss each uniform = 4.813   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.705  exp loss = 1.859  adjusted loss = 1.859  adv prob = 0.250000   acc = 0.617   grad norm = 13.731   grad norm uniform = 29.820   loss each uniform = 4.642   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.970   grad norm = 1.508   grad norm uniform = 38.114   loss each uniform = 9.950   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8448707461357117


Epoch [64]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.263  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.050   loss each uniform = 10.410   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.061   grad norm uniform = 41.269   loss each uniform = 7.731   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.119   grad norm uniform = 36.313   loss each uniform = 7.031   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.080   loss each uniform = 10.390   feat norm = 0.451  

Validation:
Average incurred loss: 0.542  
Average sample loss: 0.523  
Average acc: 0.870  
Average grad norm: 5.325  
Average grad norm uniform: 33.692  
Average loss each uniform: 7.612  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.171   grad norm uniform = 34.733   loss each uniform = 10.344   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.743  exp loss = 0.817  adjusted loss = 0.817  adv prob = 0.250000   acc = 0.807   grad norm = 8.361   grad norm uniform = 32.818   loss each uniform = 5.253   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.064  exp loss = 2.231  adjusted loss = 2.231  adv prob = 0.250000   acc = 0.556   grad norm = 16.007   grad norm uniform = 28.857   loss each uniform = 4.524   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.199  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.955   grad norm = 2.103   grad norm uniform = 37.936   loss each uniform = 9.373   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8698915839195251


Epoch [65]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.018  
Average grad norm uniform: 36.174  
Average loss each uniform: 10.251  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.028   loss each uniform = 10.420   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.072   grad norm uniform = 41.079   loss each uniform = 7.764   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.135   grad norm uniform = 36.092   loss each uniform = 6.770   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 39.116   loss each uniform = 10.309   feat norm = 0.452  

Validation:
Average incurred loss: 0.554  
Average sample loss: 0.536  
Average acc: 0.862  
Average grad norm: 5.531  
Average grad norm uniform: 33.345  
Average loss each uniform: 7.412  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.194   grad norm uniform = 34.509   loss each uniform = 10.068   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.807  exp loss = 0.879  adjusted loss = 0.879  adv prob = 0.250000   acc = 0.785   grad norm = 9.047   grad norm uniform = 32.266   loss each uniform = 5.043   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.954  exp loss = 2.105  adjusted loss = 2.105  adv prob = 0.250000   acc = 0.564   grad norm = 15.462   grad norm uniform = 28.673   loss each uniform = 4.451   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.955   grad norm = 2.014   grad norm uniform = 37.710   loss each uniform = 9.352   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8623853325843811


Epoch [66]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.016  
Average grad norm uniform: 36.185  
Average loss each uniform: 10.304  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.031   loss each uniform = 10.453   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 41.277   loss each uniform = 7.908   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.114   grad norm uniform = 36.299   loss each uniform = 6.918   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 39.114   loss each uniform = 10.405   feat norm = 0.451  

Validation:
Average incurred loss: 0.620  
Average sample loss: 0.603  
Average acc: 0.842  
Average grad norm: 6.207  
Average grad norm uniform: 32.991  
Average loss each uniform: 7.207  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.371   grad norm uniform = 33.971   loss each uniform = 9.591   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.060  exp loss = 1.150  adjusted loss = 1.150  adv prob = 0.250000   acc = 0.721   grad norm = 11.319   grad norm uniform = 31.303   loss each uniform = 4.679   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.665  exp loss = 1.795  adjusted loss = 1.795  adv prob = 0.250000   acc = 0.617   grad norm = 13.497   grad norm uniform = 29.677   loss each uniform = 4.681   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.147  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.962   grad norm = 1.496   grad norm uniform = 38.772   loss each uniform = 10.217   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8415346741676331


Epoch [67]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.173  
Average loss each uniform: 10.305  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 35.028   loss each uniform = 10.475   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 41.195   loss each uniform = 7.775   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.172   grad norm uniform = 36.010   loss each uniform = 6.710   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 39.098   loss each uniform = 10.374   feat norm = 0.452  

Validation:
Average incurred loss: 0.587  
Average sample loss: 0.569  
Average acc: 0.858  
Average grad norm: 5.847  
Average grad norm uniform: 33.500  
Average loss each uniform: 7.389  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.998   grad norm = 0.285   grad norm uniform = 34.539   loss each uniform = 9.916   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.934  exp loss = 1.009  adjusted loss = 1.009  adv prob = 0.250000   acc = 0.760   grad norm = 10.134   grad norm uniform = 32.082   loss each uniform = 4.930   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.815  exp loss = 1.961  adjusted loss = 1.961  adv prob = 0.250000   acc = 0.617   grad norm = 14.516   grad norm uniform = 29.612   loss each uniform = 4.616   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.955   grad norm = 1.683   grad norm uniform = 38.711   loss each uniform = 9.902   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8582152128219604


Epoch [68]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.363  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.035   loss each uniform = 10.528   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 41.147   loss each uniform = 7.623   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.128   grad norm uniform = 36.157   loss each uniform = 6.975   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 39.164   loss each uniform = 10.475   feat norm = 0.452  

Validation:
Average incurred loss: 0.535  
Average sample loss: 0.514  
Average acc: 0.875  
Average grad norm: 5.169  
Average grad norm uniform: 34.032  
Average loss each uniform: 7.752  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.140   grad norm uniform = 34.946   loss each uniform = 10.569   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.677  exp loss = 0.736  adjusted loss = 0.736  adv prob = 0.250000   acc = 0.826   grad norm = 7.670   grad norm uniform = 33.484   loss each uniform = 5.434   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.216  exp loss = 2.388  adjusted loss = 2.388  adv prob = 0.250000   acc = 0.541   grad norm = 16.936   grad norm uniform = 28.853   loss each uniform = 4.555   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.216  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.947   grad norm = 2.298   grad norm uniform = 37.927   loss each uniform = 9.178   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8748957514762878


Epoch [69]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.188  
Average loss each uniform: 10.386  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.025   loss each uniform = 10.553   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 41.258   loss each uniform = 7.699   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.094   grad norm uniform = 36.303   loss each uniform = 7.103   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 39.150   loss each uniform = 10.474   feat norm = 0.451  

Validation:
Average incurred loss: 0.536  
Average sample loss: 0.515  
Average acc: 0.874  
Average grad norm: 5.075  
Average grad norm uniform: 34.301  
Average loss each uniform: 7.902  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.081   grad norm uniform = 35.192   loss each uniform = 10.908   feat norm = 0.434  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.597  exp loss = 0.655  adjusted loss = 0.655  adv prob = 0.250000   acc = 0.843   grad norm = 6.923   grad norm uniform = 34.047   loss each uniform = 5.638   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.481  exp loss = 2.650  adjusted loss = 2.650  adv prob = 0.250000   acc = 0.474   grad norm = 18.510   grad norm uniform = 28.743   loss each uniform = 4.508   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.253  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.940   grad norm = 2.700   grad norm uniform = 37.621   loss each uniform = 8.674   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8740618228912354


Epoch [70]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.016  
Average grad norm uniform: 36.182  
Average loss each uniform: 10.386  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.013   loss each uniform = 10.563   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.077   grad norm uniform = 41.213   loss each uniform = 7.781   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.127   grad norm uniform = 36.048   loss each uniform = 6.551   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 39.180   loss each uniform = 10.457   feat norm = 0.452  

Validation:
Average incurred loss: 0.586  
Average sample loss: 0.567  
Average acc: 0.857  
Average grad norm: 5.792  
Average grad norm uniform: 33.483  
Average loss each uniform: 7.467  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.267   grad norm uniform = 34.498   loss each uniform = 10.049   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.914  exp loss = 0.990  adjusted loss = 0.990  adv prob = 0.250000   acc = 0.762   grad norm = 9.941   grad norm uniform = 32.038   loss each uniform = 4.958   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.871  exp loss = 2.002  adjusted loss = 2.002  adv prob = 0.250000   acc = 0.602   grad norm = 14.697   grad norm uniform = 29.694   loss each uniform = 4.686   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.168  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955   grad norm = 1.750   grad norm uniform = 38.766   loss each uniform = 9.972   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [71]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.194  
Average loss each uniform: 10.457  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.015   loss each uniform = 10.608   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 41.261   loss each uniform = 7.944   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.149   grad norm uniform = 36.206   loss each uniform = 6.808   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.214   loss each uniform = 10.586   feat norm = 0.452  

Validation:
Average incurred loss: 0.595  
Average sample loss: 0.577  
Average acc: 0.855  
Average grad norm: 5.795  
Average grad norm uniform: 33.541  
Average loss each uniform: 7.523  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.307   grad norm uniform = 34.375   loss each uniform = 10.023   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.972  exp loss = 1.060  adjusted loss = 1.060  adv prob = 0.250000   acc = 0.755   grad norm = 10.237   grad norm uniform = 32.096   loss each uniform = 5.023   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.747  exp loss = 1.886  adjusted loss = 1.886  adv prob = 0.250000   acc = 0.617   grad norm = 13.736   grad norm uniform = 30.340   loss each uniform = 4.794   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.955   grad norm = 1.560   grad norm uniform = 38.877   loss each uniform = 10.231   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8548791408538818


Epoch [72]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.191  
Average loss each uniform: 10.449  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.012   loss each uniform = 10.604   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 41.340   loss each uniform = 8.001   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.111   grad norm uniform = 36.181   loss each uniform = 6.952   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.197   loss each uniform = 10.547   feat norm = 0.452  

Validation:
Average incurred loss: 0.587  
Average sample loss: 0.569  
Average acc: 0.857  
Average grad norm: 5.780  
Average grad norm uniform: 33.627  
Average loss each uniform: 7.490  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.311   grad norm uniform = 34.409   loss each uniform = 10.017   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.937  exp loss = 1.011  adjusted loss = 1.011  adv prob = 0.250000   acc = 0.764   grad norm = 10.056   grad norm uniform = 32.534   loss each uniform = 5.035   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.793  exp loss = 1.936  adjusted loss = 1.936  adv prob = 0.250000   acc = 0.609   grad norm = 14.099   grad norm uniform = 29.599   loss each uniform = 4.692   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955   grad norm = 1.677   grad norm uniform = 38.736   loss each uniform = 10.017   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [73]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.189  
Average loss each uniform: 10.464  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.009   loss each uniform = 10.636   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.054   grad norm uniform = 41.334   loss each uniform = 7.845   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.114   grad norm uniform = 36.296   loss each uniform = 6.983   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.195   loss each uniform = 10.534   feat norm = 0.452  

Validation:
Average incurred loss: 0.552  
Average sample loss: 0.533  
Average acc: 0.868  
Average grad norm: 5.362  
Average grad norm uniform: 33.476  
Average loss each uniform: 7.653  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.155   grad norm uniform = 34.458   loss each uniform = 10.439   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.760  exp loss = 0.824  adjusted loss = 0.824  adv prob = 0.250000   acc = 0.805   grad norm = 8.474   grad norm uniform = 32.632   loss each uniform = 5.252   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.088  exp loss = 2.232  adjusted loss = 2.232  adv prob = 0.250000   acc = 0.556   grad norm = 15.946   grad norm uniform = 28.663   loss each uniform = 4.521   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.947   grad norm = 2.157   grad norm uniform = 37.798   loss each uniform = 9.418   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [74]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.195  
Average loss each uniform: 10.513  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.001   loss each uniform = 10.681   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 41.214   loss each uniform = 7.886   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 36.455   loss each uniform = 7.075   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.260   loss each uniform = 10.596   feat norm = 0.452  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.608  
Average acc: 0.847  
Average grad norm: 6.155  
Average grad norm uniform: 33.469  
Average loss each uniform: 7.391  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.342   grad norm uniform = 34.095   loss each uniform = 9.771   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.067  exp loss = 1.138  adjusted loss = 1.138  adv prob = 0.250000   acc = 0.734   grad norm = 11.213   grad norm uniform = 32.063   loss each uniform = 4.849   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.694  exp loss = 1.837  adjusted loss = 1.837  adv prob = 0.250000   acc = 0.617   grad norm = 13.520   grad norm uniform = 30.168   loss each uniform = 4.783   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.970   grad norm = 1.482   grad norm uniform = 39.497   loss each uniform = 10.552   feat norm = 0.470  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [75]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.193  
Average loss each uniform: 10.511  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.997   loss each uniform = 10.674   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 41.392   loss each uniform = 8.066   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.142   grad norm uniform = 36.282   loss each uniform = 6.795   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.243   loss each uniform = 10.594   feat norm = 0.452  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.525  
Average acc: 0.871  
Average grad norm: 5.219  
Average grad norm uniform: 33.461  
Average loss each uniform: 7.688  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.150   grad norm uniform = 34.407   loss each uniform = 10.488   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.704  exp loss = 0.770  adjusted loss = 0.770  adv prob = 0.250000   acc = 0.818   grad norm = 7.889   grad norm uniform = 32.804   loss each uniform = 5.362   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.215  exp loss = 2.374  adjusted loss = 2.374  adv prob = 0.250000   acc = 0.534   grad norm = 16.631   grad norm uniform = 28.417   loss each uniform = 4.539   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.214  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.947   grad norm = 2.257   grad norm uniform = 37.485   loss each uniform = 9.157   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [76]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.181  
Average loss each uniform: 10.503  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.002   loss each uniform = 10.684   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.065   grad norm uniform = 41.276   loss each uniform = 7.938   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.121   grad norm uniform = 36.063   loss each uniform = 6.755   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 39.203   loss each uniform = 10.550   feat norm = 0.452  

Validation:
Average incurred loss: 0.583  
Average sample loss: 0.565  
Average acc: 0.859  
Average grad norm: 5.648  
Average grad norm uniform: 33.506  
Average loss each uniform: 7.607  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.248   grad norm uniform = 34.358   loss each uniform = 10.222   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.898  exp loss = 0.986  adjusted loss = 0.986  adv prob = 0.250000   acc = 0.768   grad norm = 9.584   grad norm uniform = 32.380   loss each uniform = 5.139   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.896  exp loss = 2.036  adjusted loss = 2.036  adv prob = 0.250000   acc = 0.594   grad norm = 14.651   grad norm uniform = 29.583   loss each uniform = 4.702   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.955   grad norm = 1.818   grad norm uniform = 38.382   loss each uniform = 9.981   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [77]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.198  
Average loss each uniform: 10.562  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.001   loss each uniform = 10.727   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 41.366   loss each uniform = 7.995   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 36.512   loss each uniform = 7.170   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 39.242   loss each uniform = 10.641   feat norm = 0.452  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.554  
Average acc: 0.867  
Average grad norm: 5.611  
Average grad norm uniform: 33.713  
Average loss each uniform: 7.581  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.247   grad norm uniform = 34.570   loss each uniform = 10.209   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.870  exp loss = 0.961  adjusted loss = 0.961  adv prob = 0.250000   acc = 0.790   grad norm = 9.430   grad norm uniform = 32.609   loss each uniform = 5.119   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.896  exp loss = 2.051  adjusted loss = 2.051  adv prob = 0.250000   acc = 0.594   grad norm = 14.856   grad norm uniform = 29.658   loss each uniform = 4.656   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.955   grad norm = 1.820   grad norm uniform = 38.631   loss each uniform = 9.904   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8673895001411438


Epoch [78]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.196  
Average loss each uniform: 10.588  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.988   loss each uniform = 10.755   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.070   grad norm uniform = 41.366   loss each uniform = 7.978   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.079   grad norm uniform = 36.375   loss each uniform = 7.084   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.282   loss each uniform = 10.675   feat norm = 0.452  

Validation:
Average incurred loss: 0.599  
Average sample loss: 0.582  
Average acc: 0.856  
Average grad norm: 5.861  
Average grad norm uniform: 33.613  
Average loss each uniform: 7.482  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.302   grad norm uniform = 34.351   loss each uniform = 9.958   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.970  exp loss = 1.070  adjusted loss = 1.070  adv prob = 0.250000   acc = 0.755   grad norm = 10.267   grad norm uniform = 32.356   loss each uniform = 4.993   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.795  exp loss = 1.941  adjusted loss = 1.941  adv prob = 0.250000   acc = 0.624   grad norm = 14.098   grad norm uniform = 30.010   loss each uniform = 4.773   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.955   grad norm = 1.707   grad norm uniform = 39.026   loss each uniform = 10.221   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [79]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.586  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.979   loss each uniform = 10.761   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 41.379   loss each uniform = 8.215   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.089   grad norm uniform = 36.334   loss each uniform = 7.143   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 39.295   loss each uniform = 10.602   feat norm = 0.453  

Validation:
Average incurred loss: 0.636  
Average sample loss: 0.617  
Average acc: 0.848  
Average grad norm: 6.128  
Average grad norm uniform: 33.577  
Average loss each uniform: 7.576  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.332   grad norm uniform = 34.511   loss each uniform = 10.167   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.052  exp loss = 1.125  adjusted loss = 1.125  adv prob = 0.250000   acc = 0.740   grad norm = 11.028   grad norm uniform = 32.271   loss each uniform = 5.008   feat norm = 0.490  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.828  exp loss = 1.965  adjusted loss = 1.965  adv prob = 0.250000   acc = 0.609   grad norm = 13.935   grad norm uniform = 29.752   loss each uniform = 4.768   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.162  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.962   grad norm = 1.504   grad norm uniform = 38.695   loss each uniform = 10.286   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [80]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.180  
Average loss each uniform: 10.602  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.968   loss each uniform = 10.776   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 41.441   loss each uniform = 8.238   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 36.165   loss each uniform = 6.972   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.276   loss each uniform = 10.630   feat norm = 0.452  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.554  
Average acc: 0.867  
Average grad norm: 5.486  
Average grad norm uniform: 33.793  
Average loss each uniform: 7.767  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.218   grad norm uniform = 34.726   loss each uniform = 10.515   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.836  exp loss = 0.919  adjusted loss = 0.919  adv prob = 0.250000   acc = 0.794   grad norm = 8.988   grad norm uniform = 32.680   loss each uniform = 5.284   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.003  exp loss = 2.129  adjusted loss = 2.129  adv prob = 0.250000   acc = 0.571   grad norm = 15.222   grad norm uniform = 29.642   loss each uniform = 4.693   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.982   grad norm uniform = 38.574   loss each uniform = 9.890   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [81]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.189  
Average loss each uniform: 10.612  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.977   loss each uniform = 10.796   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 41.456   loss each uniform = 8.182   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.068   grad norm uniform = 36.808   loss each uniform = 7.354   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.250   loss each uniform = 10.600   feat norm = 0.452  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.574  
Average acc: 0.854  
Average grad norm: 5.712  
Average grad norm uniform: 33.588  
Average loss each uniform: 7.601  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.305   grad norm uniform = 34.247   loss each uniform = 10.124   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.956  exp loss = 1.054  adjusted loss = 1.054  adv prob = 0.250000   acc = 0.755   grad norm = 9.987   grad norm uniform = 32.438   loss each uniform = 5.075   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.768  exp loss = 1.903  adjusted loss = 1.903  adv prob = 0.250000   acc = 0.617   grad norm = 13.705   grad norm uniform = 29.958   loss each uniform = 4.833   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.955   grad norm = 1.726   grad norm uniform = 38.935   loss each uniform = 10.365   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [82]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.191  
Average loss each uniform: 10.637  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.976   loss each uniform = 10.817   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 41.481   loss each uniform = 8.199   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.093   grad norm uniform = 36.338   loss each uniform = 6.997   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.281   loss each uniform = 10.662   feat norm = 0.452  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.523  
Average acc: 0.876  
Average grad norm: 5.032  
Average grad norm uniform: 34.498  
Average loss each uniform: 8.122  
Average feat norm: 0.459  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.077   grad norm uniform = 35.228   loss each uniform = 11.171   feat norm = 0.434  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.591  exp loss = 0.655  adjusted loss = 0.655  adv prob = 0.250000   acc = 0.852   grad norm = 6.741   grad norm uniform = 34.475   loss each uniform = 5.863   feat norm = 0.489  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.571  exp loss = 2.700  adjusted loss = 2.700  adv prob = 0.250000   acc = 0.466   grad norm = 18.760   grad norm uniform = 28.794   loss each uniform = 4.600   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.268  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.932   grad norm = 2.716   grad norm uniform = 37.718   loss each uniform = 8.851   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [83]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.183  
Average loss each uniform: 10.642  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.981   loss each uniform = 10.819   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 41.361   loss each uniform = 8.179   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 36.475   loss each uniform = 7.132   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.243   loss each uniform = 10.669   feat norm = 0.452  

Validation:
Average incurred loss: 0.603  
Average sample loss: 0.584  
Average acc: 0.854  
Average grad norm: 5.770  
Average grad norm uniform: 33.634  
Average loss each uniform: 7.603  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.314   grad norm uniform = 34.344   loss each uniform = 10.116   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.981  exp loss = 1.071  adjusted loss = 1.071  adv prob = 0.250000   acc = 0.753   grad norm = 10.128   grad norm uniform = 32.340   loss each uniform = 5.056   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.786  exp loss = 1.911  adjusted loss = 1.911  adv prob = 0.250000   acc = 0.617   grad norm = 13.816   grad norm uniform = 30.395   loss each uniform = 4.884   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.160  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.955   grad norm = 1.611   grad norm uniform = 38.915   loss each uniform = 10.424   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [84]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.016  
Average grad norm uniform: 36.167  
Average loss each uniform: 10.624  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.974   loss each uniform = 10.815   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 41.379   loss each uniform = 8.195   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.096   grad norm uniform = 36.485   loss each uniform = 7.115   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 39.191   loss each uniform = 10.599   feat norm = 0.452  

Validation:
Average incurred loss: 0.681  
Average sample loss: 0.662  
Average acc: 0.837  
Average grad norm: 6.490  
Average grad norm uniform: 33.408  
Average loss each uniform: 7.435  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.432   grad norm uniform = 34.040   loss each uniform = 9.704   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.241  exp loss = 1.349  adjusted loss = 1.349  adv prob = 0.250000   acc = 0.704   grad norm = 12.348   grad norm uniform = 31.949   loss each uniform = 4.828   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.582  exp loss = 1.760  adjusted loss = 1.760  adv prob = 0.250000   acc = 0.639   grad norm = 12.495   grad norm uniform = 30.401   loss each uniform = 5.026   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.132  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.970   grad norm = 1.228   grad norm uniform = 39.307   loss each uniform = 11.010   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8373644948005676


Epoch [85]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.198  
Average loss each uniform: 10.691  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.004   loss each uniform = 10.857   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 41.465   loss each uniform = 8.155   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.101   grad norm uniform = 36.364   loss each uniform = 7.146   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.225   loss each uniform = 10.771   feat norm = 0.451  

Validation:
Average incurred loss: 0.675  
Average sample loss: 0.658  
Average acc: 0.837  
Average grad norm: 6.507  
Average grad norm uniform: 33.419  
Average loss each uniform: 7.447  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.987   grad norm = 0.411   grad norm uniform = 34.108   loss each uniform = 9.774   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.211  exp loss = 1.309  adjusted loss = 1.309  adv prob = 0.250000   acc = 0.708   grad norm = 12.267   grad norm uniform = 31.755   loss each uniform = 4.805   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.634  exp loss = 1.774  adjusted loss = 1.774  adv prob = 0.250000   acc = 0.632   grad norm = 12.879   grad norm uniform = 30.583   loss each uniform = 4.979   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.143  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.970   grad norm = 1.354   grad norm uniform = 39.666   loss each uniform = 11.002   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8373644351959229


Epoch [86]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.185  
Average loss each uniform: 10.701  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.001   loss each uniform = 10.864   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 41.317   loss each uniform = 8.234   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 36.569   loss each uniform = 7.460   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.190   loss each uniform = 10.764   feat norm = 0.451  

Validation:
Average incurred loss: 0.593  
Average sample loss: 0.574  
Average acc: 0.862  
Average grad norm: 5.613  
Average grad norm uniform: 33.870  
Average loss each uniform: 7.780  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.224   grad norm uniform = 34.762   loss each uniform = 10.522   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.884  exp loss = 0.961  adjusted loss = 0.961  adv prob = 0.250000   acc = 0.783   grad norm = 9.304   grad norm uniform = 32.822   loss each uniform = 5.245   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.031  exp loss = 2.178  adjusted loss = 2.178  adv prob = 0.250000   acc = 0.564   grad norm = 15.345   grad norm uniform = 29.691   loss each uniform = 4.755   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.955   grad norm = 1.874   grad norm uniform = 38.582   loss each uniform = 10.064   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [87]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.187  
Average loss each uniform: 10.725  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.975   loss each uniform = 10.906   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 41.449   loss each uniform = 8.341   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.118   grad norm uniform = 36.396   loss each uniform = 7.154   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.271   loss each uniform = 10.729   feat norm = 0.452  

Validation:
Average incurred loss: 0.567  
Average sample loss: 0.547  
Average acc: 0.871  
Average grad norm: 5.251  
Average grad norm uniform: 33.770  
Average loss each uniform: 7.989  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.127   grad norm uniform = 34.636   loss each uniform = 10.931   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.716  exp loss = 0.793  adjusted loss = 0.793  adv prob = 0.250000   acc = 0.824   grad norm = 7.826   grad norm uniform = 33.108   loss each uniform = 5.550   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.364  exp loss = 2.542  adjusted loss = 2.542  adv prob = 0.250000   acc = 0.519   grad norm = 17.116   grad norm uniform = 28.890   loss each uniform = 4.708   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.228  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.940   grad norm = 2.354   grad norm uniform = 37.930   loss each uniform = 9.492   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [88]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.776  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.964   loss each uniform = 10.951   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 41.397   loss each uniform = 8.298   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.080   grad norm uniform = 36.755   loss each uniform = 7.469   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.318   loss each uniform = 10.800   feat norm = 0.452  

Validation:
Average incurred loss: 0.640  
Average sample loss: 0.622  
Average acc: 0.847  
Average grad norm: 6.139  
Average grad norm uniform: 33.734  
Average loss each uniform: 7.638  
Average feat norm: 0.457  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.369   grad norm uniform = 34.517   loss each uniform = 10.142   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.090  exp loss = 1.183  adjusted loss = 1.183  adv prob = 0.250000   acc = 0.730   grad norm = 11.205   grad norm uniform = 32.328   loss each uniform = 5.024   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.728  exp loss = 1.861  adjusted loss = 1.861  adv prob = 0.250000   acc = 0.632   grad norm = 13.317   grad norm uniform = 30.344   loss each uniform = 4.938   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.162  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.970   grad norm = 1.468   grad norm uniform = 39.301   loss each uniform = 10.704   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [89]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.178  
Average loss each uniform: 10.750  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.970   loss each uniform = 10.931   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 41.317   loss each uniform = 8.401   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.084   grad norm uniform = 36.550   loss each uniform = 7.235   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 39.263   loss each uniform = 10.745   feat norm = 0.452  

Validation:
Average incurred loss: 0.607  
Average sample loss: 0.588  
Average acc: 0.856  
Average grad norm: 5.754  
Average grad norm uniform: 33.963  
Average loss each uniform: 7.802  
Average feat norm: 0.457  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.288   grad norm uniform = 34.654   loss each uniform = 10.457   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.966  exp loss = 1.040  adjusted loss = 1.040  adv prob = 0.250000   acc = 0.758   grad norm = 10.012   grad norm uniform = 32.975   loss each uniform = 5.261   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.870  exp loss = 2.025  adjusted loss = 2.025  adv prob = 0.250000   acc = 0.617   grad norm = 14.132   grad norm uniform = 30.073   loss each uniform = 4.846   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.955   grad norm = 1.646   grad norm uniform = 38.891   loss each uniform = 10.342   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [90]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.186  
Average loss each uniform: 10.791  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.965   loss each uniform = 10.966   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 41.480   loss each uniform = 8.379   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.069   grad norm uniform = 36.366   loss each uniform = 7.234   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 39.296   loss each uniform = 10.819   feat norm = 0.452  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.515  
Average acc: 0.876  
Average grad norm: 4.863  
Average grad norm uniform: 34.099  
Average loss each uniform: 8.128  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.074   grad norm uniform = 34.732   loss each uniform = 11.166   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.561  exp loss = 0.626  adjusted loss = 0.626  adv prob = 0.250000   acc = 0.856   grad norm = 6.319   grad norm uniform = 34.189   loss each uniform = 5.934   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.592  exp loss = 2.772  adjusted loss = 2.772  adv prob = 0.250000   acc = 0.459   grad norm = 18.607   grad norm uniform = 28.594   loss each uniform = 4.582   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.278  exp loss = 0.286  adjusted loss = 0.286  adv prob = 0.250000   acc = 0.925   grad norm = 2.833   grad norm uniform = 37.066   loss each uniform = 8.697   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [91]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.197  
Average loss each uniform: 10.810  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.998   loss each uniform = 10.969   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 41.348   loss each uniform = 8.308   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.099   grad norm uniform = 36.609   loss each uniform = 7.315   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.246   loss each uniform = 10.903   feat norm = 0.451  

Validation:
Average incurred loss: 0.585  
Average sample loss: 0.564  
Average acc: 0.865  
Average grad norm: 5.432  
Average grad norm uniform: 33.748  
Average loss each uniform: 7.929  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.152   grad norm uniform = 34.736   loss each uniform = 10.841   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.815  exp loss = 0.885  adjusted loss = 0.885  adv prob = 0.250000   acc = 0.798   grad norm = 8.643   grad norm uniform = 32.927   loss each uniform = 5.408   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.193  exp loss = 2.342  adjusted loss = 2.342  adv prob = 0.250000   acc = 0.549   grad norm = 16.122   grad norm uniform = 28.970   loss each uniform = 4.706   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.947   grad norm = 2.036   grad norm uniform = 37.936   loss each uniform = 9.757   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8648874759674072


Epoch [92]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.200  
Average loss each uniform: 10.812  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.017   loss each uniform = 10.964   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 41.323   loss each uniform = 8.307   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.080   grad norm uniform = 36.516   loss each uniform = 7.327   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.207   loss each uniform = 10.930   feat norm = 0.450  

Validation:
Average incurred loss: 0.674  
Average sample loss: 0.658  
Average acc: 0.836  
Average grad norm: 6.344  
Average grad norm uniform: 33.271  
Average loss each uniform: 7.635  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.987   grad norm = 0.399   grad norm uniform = 34.000   loss each uniform = 10.039   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.211  exp loss = 1.295  adjusted loss = 1.295  adv prob = 0.250000   acc = 0.706   grad norm = 11.935   grad norm uniform = 31.660   loss each uniform = 4.938   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.618  exp loss = 1.771  adjusted loss = 1.771  adv prob = 0.250000   acc = 0.624   grad norm = 12.617   grad norm uniform = 30.296   loss each uniform = 5.069   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.970   grad norm = 1.357   grad norm uniform = 39.330   loss each uniform = 11.208   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8356963992118835


Epoch [93]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.198  
Average loss each uniform: 10.843  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.997   loss each uniform = 11.003   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 41.356   loss each uniform = 8.184   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.067   grad norm uniform = 36.480   loss each uniform = 7.197   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.262   loss each uniform = 10.970   feat norm = 0.451  

Validation:
Average incurred loss: 0.611  
Average sample loss: 0.593  
Average acc: 0.857  
Average grad norm: 5.782  
Average grad norm uniform: 33.722  
Average loss each uniform: 7.830  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.255   grad norm uniform = 34.649   loss each uniform = 10.604   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.948  exp loss = 1.033  adjusted loss = 1.033  adv prob = 0.250000   acc = 0.766   grad norm = 9.851   grad norm uniform = 32.508   loss each uniform = 5.200   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.968  exp loss = 2.101  adjusted loss = 2.101  adv prob = 0.250000   acc = 0.594   grad norm = 14.867   grad norm uniform = 29.754   loss each uniform = 4.811   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.947   grad norm = 1.844   grad norm uniform = 38.686   loss each uniform = 10.318   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8573811054229736


Epoch [94]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.207  
Average loss each uniform: 10.862  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.005   loss each uniform = 11.020   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 41.445   loss each uniform = 8.268   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 36.442   loss each uniform = 7.218   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.264   loss each uniform = 10.985   feat norm = 0.451  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.529  
Average acc: 0.879  
Average grad norm: 4.959  
Average grad norm uniform: 33.955  
Average loss each uniform: 8.194  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.104   grad norm uniform = 34.731   loss each uniform = 11.241   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.663  exp loss = 0.725  adjusted loss = 0.725  adv prob = 0.250000   acc = 0.843   grad norm = 7.079   grad norm uniform = 33.605   loss each uniform = 5.778   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.377  exp loss = 2.496  adjusted loss = 2.496  adv prob = 0.250000   acc = 0.526   grad norm = 17.116   grad norm uniform = 28.670   loss each uniform = 4.711   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.247  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.932   grad norm = 2.419   grad norm uniform = 37.739   loss each uniform = 9.440   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8790659308433533


Epoch [95]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.203  
Average loss each uniform: 10.862  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.000   loss each uniform = 11.026   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 41.375   loss each uniform = 8.294   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.064   grad norm uniform = 36.560   loss each uniform = 7.445   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.267   loss each uniform = 10.948   feat norm = 0.451  

Validation:
Average incurred loss: 0.559  
Average sample loss: 0.538  
Average acc: 0.874  
Average grad norm: 5.116  
Average grad norm uniform: 34.187  
Average loss each uniform: 8.186  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.116   grad norm uniform = 35.216   loss each uniform = 11.269   feat norm = 0.435  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.682  exp loss = 0.754  adjusted loss = 0.754  adv prob = 0.250000   acc = 0.830   grad norm = 7.411   grad norm uniform = 33.713   loss each uniform = 5.771   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.401  exp loss = 2.553  adjusted loss = 2.553  adv prob = 0.250000   acc = 0.519   grad norm = 17.341   grad norm uniform = 28.883   loss each uniform = 4.689   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.240  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.940   grad norm = 2.406   grad norm uniform = 37.536   loss each uniform = 9.325   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8740617036819458


Epoch [96]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.194  
Average loss each uniform: 10.857  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.019   loss each uniform = 11.021   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 41.327   loss each uniform = 8.048   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.081   grad norm uniform = 36.348   loss each uniform = 7.237   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 39.182   loss each uniform = 10.996   feat norm = 0.450  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.574  
Average acc: 0.859  
Average grad norm: 5.521  
Average grad norm uniform: 33.456  
Average loss each uniform: 7.861  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.235   grad norm uniform = 34.433   loss each uniform = 10.630   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.889  exp loss = 0.977  adjusted loss = 0.977  adv prob = 0.250000   acc = 0.777   grad norm = 9.190   grad norm uniform = 32.303   loss each uniform = 5.311   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.999  exp loss = 2.141  adjusted loss = 2.141  adv prob = 0.250000   acc = 0.571   grad norm = 14.905   grad norm uniform = 29.446   loss each uniform = 4.775   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.947   grad norm = 1.845   grad norm uniform = 38.072   loss each uniform = 10.158   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [97]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.205  
Average loss each uniform: 10.894  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.027   loss each uniform = 11.039   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.387   loss each uniform = 8.304   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 36.657   loss each uniform = 7.593   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.179   loss each uniform = 11.039   feat norm = 0.450  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.607  
Average acc: 0.852  
Average grad norm: 5.872  
Average grad norm uniform: 33.687  
Average loss each uniform: 7.871  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.276   grad norm uniform = 34.575   loss each uniform = 10.626   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.001  exp loss = 1.080  adjusted loss = 1.080  adv prob = 0.250000   acc = 0.751   grad norm = 10.239   grad norm uniform = 32.390   loss each uniform = 5.203   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.924  exp loss = 2.064  adjusted loss = 2.064  adv prob = 0.250000   acc = 0.602   grad norm = 14.438   grad norm uniform = 30.007   loss each uniform = 4.884   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.955   grad norm = 1.654   grad norm uniform = 38.797   loss each uniform = 10.534   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8523769378662109


Epoch [98]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.206  
Average loss each uniform: 10.912  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.029   loss each uniform = 11.064   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 41.387   loss each uniform = 8.202   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 36.122   loss each uniform = 7.269   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.203   loss each uniform = 11.076   feat norm = 0.450  

Validation:
Average incurred loss: 0.673  
Average sample loss: 0.654  
Average acc: 0.843  
Average grad norm: 6.329  
Average grad norm uniform: 33.498  
Average loss each uniform: 7.602  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.378   grad norm uniform = 34.279   loss each uniform = 10.060   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.185  exp loss = 1.275  adjusted loss = 1.275  adv prob = 0.250000   acc = 0.719   grad norm = 11.778   grad norm uniform = 32.010   loss each uniform = 4.952   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.692  exp loss = 1.827  adjusted loss = 1.827  adv prob = 0.250000   acc = 0.639   grad norm = 13.072   grad norm uniform = 30.204   loss each uniform = 4.962   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.158  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.970   grad norm = 1.392   grad norm uniform = 39.262   loss each uniform = 10.901   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8432027101516724


Epoch [99]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.203  
Average loss each uniform: 10.925  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.000   loss each uniform = 11.078   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 41.546   loss each uniform = 8.298   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 36.462   loss each uniform = 7.399   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.241   loss each uniform = 11.063   feat norm = 0.450  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.551  
Average acc: 0.869  
Average grad norm: 5.201  
Average grad norm uniform: 33.587  
Average loss each uniform: 8.065  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.130   grad norm uniform = 34.546   loss each uniform = 11.054   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.739  exp loss = 0.816  adjusted loss = 0.816  adv prob = 0.250000   acc = 0.813   grad norm = 7.858   grad norm uniform = 32.935   loss each uniform = 5.614   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.326  exp loss = 2.493  adjusted loss = 2.493  adv prob = 0.250000   acc = 0.534   grad norm = 16.737   grad norm uniform = 28.702   loss each uniform = 4.702   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.224  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947   grad norm = 2.168   grad norm uniform = 37.384   loss each uniform = 9.526   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8690575957298279


Epoch [100]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.200  
Average loss each uniform: 10.925  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.002   loss each uniform = 11.084   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 41.471   loss each uniform = 8.281   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.055   grad norm uniform = 36.519   loss each uniform = 7.468   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.231   loss each uniform = 11.042   feat norm = 0.450  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.607  
Average acc: 0.849  
Average grad norm: 5.891  
Average grad norm uniform: 33.467  
Average loss each uniform: 7.787  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.281   grad norm uniform = 34.398   loss each uniform = 10.519   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.003  exp loss = 1.091  adjusted loss = 1.091  adv prob = 0.250000   acc = 0.742   grad norm = 10.289   grad norm uniform = 32.147   loss each uniform = 5.138   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.918  exp loss = 2.067  adjusted loss = 2.067  adv prob = 0.250000   acc = 0.602   grad norm = 14.453   grad norm uniform = 29.643   loss each uniform = 4.828   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955   grad norm = 1.617   grad norm uniform = 38.647   loss each uniform = 10.433   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8490408658981323


Epoch [101]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.199  
Average loss each uniform: 10.932  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.014   loss each uniform = 11.097   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 41.444   loss each uniform = 8.273   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.048   grad norm uniform = 36.535   loss each uniform = 7.588   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.190   loss each uniform = 11.026   feat norm = 0.450  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.570  
Average acc: 0.862  
Average grad norm: 5.516  
Average grad norm uniform: 33.843  
Average loss each uniform: 7.943  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.159   grad norm uniform = 34.766   loss each uniform = 10.875   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.824  exp loss = 0.904  adjusted loss = 0.904  adv prob = 0.250000   acc = 0.794   grad norm = 8.828   grad norm uniform = 33.205   loss each uniform = 5.425   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.217  exp loss = 2.366  adjusted loss = 2.366  adv prob = 0.250000   acc = 0.541   grad norm = 16.222   grad norm uniform = 28.964   loss each uniform = 4.682   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.947   grad norm = 2.016   grad norm uniform = 37.716   loss each uniform = 9.734   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [102]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.207  
Average loss each uniform: 10.971  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.007   loss each uniform = 11.120   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.420   loss each uniform = 8.450   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 36.571   loss each uniform = 7.428   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.252   loss each uniform = 11.101   feat norm = 0.450  

Validation:
Average incurred loss: 0.672  
Average sample loss: 0.655  
Average acc: 0.842  
Average grad norm: 6.297  
Average grad norm uniform: 33.227  
Average loss each uniform: 7.558  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.366   grad norm uniform = 33.883   loss each uniform = 9.987   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.182  exp loss = 1.268  adjusted loss = 1.268  adv prob = 0.250000   acc = 0.719   grad norm = 11.715   grad norm uniform = 31.795   loss each uniform = 4.888   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.699  exp loss = 1.850  adjusted loss = 1.850  adv prob = 0.250000   acc = 0.617   grad norm = 13.008   grad norm uniform = 30.040   loss each uniform = 4.971   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.151  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.970   grad norm = 1.431   grad norm uniform = 39.125   loss each uniform = 10.972   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8415346145629883


Epoch [103]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.200  
Average loss each uniform: 10.973  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.993   loss each uniform = 11.136   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.472   loss each uniform = 8.362   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 36.722   loss each uniform = 7.685   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.248   loss each uniform = 11.065   feat norm = 0.450  

Validation:
Average incurred loss: 0.575  
Average sample loss: 0.555  
Average acc: 0.868  
Average grad norm: 5.253  
Average grad norm uniform: 33.905  
Average loss each uniform: 8.129  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.169   grad norm uniform = 34.830   loss each uniform = 11.122   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.779  exp loss = 0.858  adjusted loss = 0.858  adv prob = 0.250000   acc = 0.807   grad norm = 8.131   grad norm uniform = 33.181   loss each uniform = 5.607   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.220  exp loss = 2.351  adjusted loss = 2.351  adv prob = 0.250000   acc = 0.549   grad norm = 16.144   grad norm uniform = 29.268   loss each uniform = 4.757   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.215  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.947   grad norm = 2.125   grad norm uniform = 37.834   loss each uniform = 9.823   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [104]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.205  
Average loss each uniform: 10.997  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.997   loss each uniform = 11.148   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 41.515   loss each uniform = 8.497   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 36.415   loss each uniform = 7.332   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.267   loss each uniform = 11.128   feat norm = 0.450  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.545  
Average acc: 0.870  
Average grad norm: 5.147  
Average grad norm uniform: 33.580  
Average loss each uniform: 8.034  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.136   grad norm uniform = 34.555   loss each uniform = 10.992   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.737  exp loss = 0.811  adjusted loss = 0.811  adv prob = 0.250000   acc = 0.815   grad norm = 7.782   grad norm uniform = 32.953   loss each uniform = 5.603   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.272  exp loss = 2.404  adjusted loss = 2.404  adv prob = 0.250000   acc = 0.534   grad norm = 16.407   grad norm uniform = 28.640   loss each uniform = 4.700   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.222  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.947   grad norm = 2.252   grad norm uniform = 37.291   loss each uniform = 9.503   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8698915839195251


Epoch [105]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.206  
Average loss each uniform: 11.009  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.002   loss each uniform = 11.169   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.306   loss each uniform = 8.371   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.048   grad norm uniform = 36.752   loss each uniform = 7.576   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.273   loss each uniform = 11.122   feat norm = 0.450  

Validation:
Average incurred loss: 0.634  
Average sample loss: 0.615  
Average acc: 0.848  
Average grad norm: 5.960  
Average grad norm uniform: 33.220  
Average loss each uniform: 7.716  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.285   grad norm uniform = 34.119   loss each uniform = 10.387   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.037  exp loss = 1.121  adjusted loss = 1.121  adv prob = 0.250000   acc = 0.734   grad norm = 10.567   grad norm uniform = 31.739   loss each uniform = 5.054   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.875  exp loss = 1.999  adjusted loss = 1.999  adv prob = 0.250000   acc = 0.617   grad norm = 14.139   grad norm uniform = 29.808   loss each uniform = 4.850   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.955   grad norm = 1.565   grad norm uniform = 38.662   loss each uniform = 10.534   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [106]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.203  
Average loss each uniform: 11.024  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.993   loss each uniform = 11.184   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.375   loss each uniform = 8.398   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.067   grad norm uniform = 36.416   loss each uniform = 7.297   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.295   loss each uniform = 11.149   feat norm = 0.450  

Validation:
Average incurred loss: 0.609  
Average sample loss: 0.590  
Average acc: 0.862  
Average grad norm: 5.641  
Average grad norm uniform: 33.972  
Average loss each uniform: 7.972  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.263   grad norm uniform = 34.662   loss each uniform = 10.700   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.939  exp loss = 1.014  adjusted loss = 1.014  adv prob = 0.250000   acc = 0.773   grad norm = 9.540   grad norm uniform = 33.035   loss each uniform = 5.394   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.965  exp loss = 2.124  adjusted loss = 2.124  adv prob = 0.250000   acc = 0.609   grad norm = 14.681   grad norm uniform = 29.885   loss each uniform = 4.907   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.193  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.820   grad norm uniform = 38.919   loss each uniform = 10.486   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [107]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.200  
Average loss each uniform: 11.044  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.979   loss each uniform = 11.192   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.488   loss each uniform = 8.594   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 36.420   loss each uniform = 7.498   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.307   loss each uniform = 11.169   feat norm = 0.451  

Validation:
Average incurred loss: 0.584  
Average sample loss: 0.564  
Average acc: 0.867  
Average grad norm: 5.354  
Average grad norm uniform: 33.777  
Average loss each uniform: 8.056  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.179   grad norm uniform = 34.720   loss each uniform = 10.984   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.810  exp loss = 0.876  adjusted loss = 0.876  adv prob = 0.250000   acc = 0.800   grad norm = 8.442   grad norm uniform = 32.873   loss each uniform = 5.512   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.198  exp loss = 2.344  adjusted loss = 2.344  adv prob = 0.250000   acc = 0.556   grad norm = 16.004   grad norm uniform = 29.388   loss each uniform = 4.808   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.947   grad norm = 2.054   grad norm uniform = 38.023   loss each uniform = 9.936   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8665555119514465


Epoch [108]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.186  
Average loss each uniform: 10.988  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.989   loss each uniform = 11.153   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 41.383   loss each uniform = 8.643   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.098   grad norm uniform = 36.128   loss each uniform = 7.095   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.247   loss each uniform = 11.057   feat norm = 0.450  

Validation:
Average incurred loss: 0.603  
Average sample loss: 0.582  
Average acc: 0.863  
Average grad norm: 5.520  
Average grad norm uniform: 33.837  
Average loss each uniform: 8.039  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.186   grad norm uniform = 34.600   loss each uniform = 10.942   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.852  exp loss = 0.930  adjusted loss = 0.930  adv prob = 0.250000   acc = 0.794   grad norm = 8.880   grad norm uniform = 33.139   loss each uniform = 5.470   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.217  exp loss = 2.357  adjusted loss = 2.357  adv prob = 0.250000   acc = 0.541   grad norm = 16.014   grad norm uniform = 29.131   loss each uniform = 4.812   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 1.980   grad norm uniform = 38.312   loss each uniform = 10.079   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [109]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.200  
Average loss each uniform: 11.051  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.002   loss each uniform = 11.209   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 41.354   loss each uniform = 8.418   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 36.518   loss each uniform = 7.390   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.251   loss each uniform = 11.183   feat norm = 0.450  

Validation:
Average incurred loss: 0.629  
Average sample loss: 0.609  
Average acc: 0.847  
Average grad norm: 5.903  
Average grad norm uniform: 33.472  
Average loss each uniform: 7.815  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.996   grad norm = 0.254   grad norm uniform = 34.490   loss each uniform = 10.593   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.987  exp loss = 1.074  adjusted loss = 1.074  adv prob = 0.250000   acc = 0.747   grad norm = 10.173   grad norm uniform = 32.107   loss each uniform = 5.169   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.995  exp loss = 2.122  adjusted loss = 2.122  adv prob = 0.250000   acc = 0.571   grad norm = 14.985   grad norm uniform = 29.630   loss each uniform = 4.806   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.955   grad norm = 1.696   grad norm uniform = 38.520   loss each uniform = 10.342   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [110]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.195  
Average loss each uniform: 11.047  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.992   loss each uniform = 11.205   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 41.420   loss each uniform = 8.512   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 36.528   loss each uniform = 7.562   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.250   loss each uniform = 11.149   feat norm = 0.450  

Validation:
Average incurred loss: 0.662  
Average sample loss: 0.644  
Average acc: 0.846  
Average grad norm: 6.165  
Average grad norm uniform: 33.641  
Average loss each uniform: 7.817  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.344   grad norm uniform = 34.305   loss each uniform = 10.418   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.135  exp loss = 1.221  adjusted loss = 1.221  adv prob = 0.250000   acc = 0.727   grad norm = 11.289   grad norm uniform = 32.378   loss each uniform = 5.111   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.778  exp loss = 1.912  adjusted loss = 1.912  adv prob = 0.250000   acc = 0.624   grad norm = 13.336   grad norm uniform = 30.092   loss each uniform = 5.015   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.158  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.970   grad norm = 1.475   grad norm uniform = 39.282   loss each uniform = 10.974   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8457047939300537


Epoch [111]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.188  
Average loss each uniform: 11.050  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.977   loss each uniform = 11.214   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.494   loss each uniform = 8.539   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.102   grad norm uniform = 36.621   loss each uniform = 7.488   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.252   loss each uniform = 11.136   feat norm = 0.450  

Validation:
Average incurred loss: 0.697  
Average sample loss: 0.679  
Average acc: 0.836  
Average grad norm: 6.479  
Average grad norm uniform: 33.441  
Average loss each uniform: 7.682  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.987   grad norm = 0.431   grad norm uniform = 34.108   loss each uniform = 10.136   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.248  exp loss = 1.356  adjusted loss = 1.356  adv prob = 0.250000   acc = 0.704   grad norm = 12.163   grad norm uniform = 31.957   loss each uniform = 4.949   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.689  exp loss = 1.836  adjusted loss = 1.836  adv prob = 0.250000   acc = 0.632   grad norm = 12.927   grad norm uniform = 30.360   loss each uniform = 5.091   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.970   grad norm = 1.353   grad norm uniform = 39.379   loss each uniform = 11.232   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8356964588165283


Epoch [112]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.193  
Average loss each uniform: 11.082  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.983   loss each uniform = 11.235   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 41.539   loss each uniform = 8.596   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 36.620   loss each uniform = 7.605   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.242   loss each uniform = 11.193   feat norm = 0.450  

Validation:
Average incurred loss: 0.615  
Average sample loss: 0.595  
Average acc: 0.860  
Average grad norm: 5.673  
Average grad norm uniform: 33.538  
Average loss each uniform: 7.871  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.253   grad norm uniform = 34.252   loss each uniform = 10.587   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.962  exp loss = 1.043  adjusted loss = 1.043  adv prob = 0.250000   acc = 0.766   grad norm = 9.754   grad norm uniform = 32.493   loss each uniform = 5.254   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.952  exp loss = 2.094  adjusted loss = 2.094  adv prob = 0.250000   acc = 0.609   grad norm = 14.416   grad norm uniform = 29.625   loss each uniform = 4.868   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.955   grad norm = 1.658   grad norm uniform = 38.602   loss each uniform = 10.500   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8598832488059998


Epoch [113]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.184  
Average loss each uniform: 11.059  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.983   loss each uniform = 11.246   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 41.293   loss each uniform = 8.347   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 36.423   loss each uniform = 7.497   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 39.255   loss each uniform = 11.102   feat norm = 0.450  

Validation:
Average incurred loss: 0.571  
Average sample loss: 0.550  
Average acc: 0.872  
Average grad norm: 5.129  
Average grad norm uniform: 33.932  
Average loss each uniform: 8.248  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.112   grad norm uniform = 34.738   loss each uniform = 11.308   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.723  exp loss = 0.787  adjusted loss = 0.787  adv prob = 0.250000   acc = 0.818   grad norm = 7.626   grad norm uniform = 33.558   loss each uniform = 5.795   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.360  exp loss = 2.504  adjusted loss = 2.504  adv prob = 0.250000   acc = 0.541   grad norm = 16.776   grad norm uniform = 28.638   loss each uniform = 4.712   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.245  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.947   grad norm = 2.347   grad norm uniform = 37.709   loss each uniform = 9.635   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8715596795082092


Epoch [114]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.200  
Average loss each uniform: 11.115  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.988   loss each uniform = 11.275   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.522   loss each uniform = 8.547   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 36.770   loss each uniform = 7.881   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.256   loss each uniform = 11.206   feat norm = 0.450  

Validation:
Average incurred loss: 0.573  
Average sample loss: 0.552  
Average acc: 0.877  
Average grad norm: 5.094  
Average grad norm uniform: 34.005  
Average loss each uniform: 8.288  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 34.984   loss each uniform = 11.442   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.704  exp loss = 0.768  adjusted loss = 0.768  adv prob = 0.250000   acc = 0.833   grad norm = 7.413   grad norm uniform = 33.751   loss each uniform = 5.848   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.450  exp loss = 2.600  adjusted loss = 2.600  adv prob = 0.250000   acc = 0.534   grad norm = 17.293   grad norm uniform = 28.255   loss each uniform = 4.673   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.238  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.947   grad norm = 2.329   grad norm uniform = 37.202   loss each uniform = 9.380   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.877397894859314


Epoch [115]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.180  
Average loss each uniform: 11.106  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.976   loss each uniform = 11.266   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.417   loss each uniform = 8.568   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.092   grad norm uniform = 36.537   loss each uniform = 7.726   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.234   loss each uniform = 11.197   feat norm = 0.450  

Validation:
Average incurred loss: 0.554  
Average sample loss: 0.532  
Average acc: 0.879  
Average grad norm: 4.787  
Average grad norm uniform: 33.924  
Average loss each uniform: 8.425  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.076   grad norm uniform = 34.742   loss each uniform = 11.624   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.593  exp loss = 0.652  adjusted loss = 0.652  adv prob = 0.250000   acc = 0.856   grad norm = 6.284   grad norm uniform = 33.984   loss each uniform = 6.104   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.619  exp loss = 2.790  adjusted loss = 2.790  adv prob = 0.250000   acc = 0.481   grad norm = 18.106   grad norm uniform = 28.197   loss each uniform = 4.708   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.290  exp loss = 0.293  adjusted loss = 0.293  adv prob = 0.250000   acc = 0.932   grad norm = 2.768   grad norm uniform = 36.573   loss each uniform = 9.039   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8790658712387085


Epoch [116]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.191  
Average loss each uniform: 11.081  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.028   loss each uniform = 11.212   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 41.500   loss each uniform = 8.446   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 36.728   loss each uniform = 7.966   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.087   loss each uniform = 11.274   feat norm = 0.448  

Validation:
Average incurred loss: 0.619  
Average sample loss: 0.601  
Average acc: 0.858  
Average grad norm: 5.674  
Average grad norm uniform: 33.535  
Average loss each uniform: 7.905  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.278   grad norm uniform = 34.218   loss each uniform = 10.621   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.989  exp loss = 1.075  adjusted loss = 1.075  adv prob = 0.250000   acc = 0.762   grad norm = 9.884   grad norm uniform = 32.622   loss each uniform = 5.296   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.897  exp loss = 2.039  adjusted loss = 2.039  adv prob = 0.250000   acc = 0.617   grad norm = 13.932   grad norm uniform = 29.546   loss each uniform = 4.891   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.955   grad norm = 1.612   grad norm uniform = 38.323   loss each uniform = 10.524   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8582152128219604


Epoch [117]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.184  
Average loss each uniform: 11.074  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.029   loss each uniform = 11.210   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 41.413   loss each uniform = 8.353   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.081   grad norm uniform = 36.579   loss each uniform = 7.808   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.077   loss each uniform = 11.268   feat norm = 0.448  

Validation:
Average incurred loss: 0.640  
Average sample loss: 0.622  
Average acc: 0.852  
Average grad norm: 5.895  
Average grad norm uniform: 33.258  
Average loss each uniform: 7.834  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.312   grad norm uniform = 33.974   loss each uniform = 10.489   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.051  exp loss = 1.141  adjusted loss = 1.141  adv prob = 0.250000   acc = 0.747   grad norm = 10.480   grad norm uniform = 31.873   loss each uniform = 5.142   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.868  exp loss = 2.003  adjusted loss = 2.003  adv prob = 0.250000   acc = 0.617   grad norm = 13.778   grad norm uniform = 30.261   loss each uniform = 4.986   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.171  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.962   grad norm = 1.552   grad norm uniform = 38.596   loss each uniform = 10.790   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8523770570755005


Epoch [118]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.192  
Average loss each uniform: 11.138  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.000   loss each uniform = 11.258   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.535   loss each uniform = 8.598   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 36.703   loss each uniform = 7.997   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.177   loss each uniform = 11.349   feat norm = 0.449  

Validation:
Average incurred loss: 0.593  
Average sample loss: 0.572  
Average acc: 0.871  
Average grad norm: 5.290  
Average grad norm uniform: 34.197  
Average loss each uniform: 8.347  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.136   grad norm uniform = 35.187   loss each uniform = 11.473   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.774  exp loss = 0.857  adjusted loss = 0.857  adv prob = 0.250000   acc = 0.815   grad norm = 7.996   grad norm uniform = 33.480   loss each uniform = 5.774   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.384  exp loss = 2.541  adjusted loss = 2.541  adv prob = 0.250000   acc = 0.541   grad norm = 16.972   grad norm uniform = 29.247   loss each uniform = 4.832   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.947   grad norm = 2.227   grad norm uniform = 38.180   loss each uniform = 9.904   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [119]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.196  
Average loss each uniform: 11.147  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.018   loss each uniform = 11.273   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.428   loss each uniform = 8.565   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 36.715   loss each uniform = 7.925   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.155   loss each uniform = 11.349   feat norm = 0.448  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.593  
Average acc: 0.858  
Average grad norm: 5.627  
Average grad norm uniform: 33.819  
Average loss each uniform: 8.033  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.228   grad norm uniform = 34.611   loss each uniform = 10.883   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.926  exp loss = 1.009  adjusted loss = 1.009  adv prob = 0.250000   acc = 0.775   grad norm = 9.438   grad norm uniform = 32.855   loss each uniform = 5.413   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.060  exp loss = 2.183  adjusted loss = 2.183  adv prob = 0.250000   acc = 0.564   grad norm = 15.107   grad norm uniform = 29.695   loss each uniform = 4.865   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.754   grad norm uniform = 38.538   loss each uniform = 10.375   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8582152724266052


Epoch [120]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.181  
Average loss each uniform: 11.137  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.991   loss each uniform = 11.275   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.584   loss each uniform = 8.667   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 36.584   loss each uniform = 7.666   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.158   loss each uniform = 11.295   feat norm = 0.449  

Validation:
Average incurred loss: 0.583  
Average sample loss: 0.563  
Average acc: 0.866  
Average grad norm: 5.279  
Average grad norm uniform: 33.710  
Average loss each uniform: 8.069  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.182   grad norm uniform = 34.415   loss each uniform = 10.919   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.838  exp loss = 0.913  adjusted loss = 0.913  adv prob = 0.250000   acc = 0.794   grad norm = 8.534   grad norm uniform = 32.933   loss each uniform = 5.515   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.093  exp loss = 2.228  adjusted loss = 2.228  adv prob = 0.250000   acc = 0.564   grad norm = 15.170   grad norm uniform = 29.427   loss each uniform = 4.864   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.877   grad norm uniform = 38.243   loss each uniform = 10.217   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [121]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.199  
Average loss each uniform: 11.199  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.999   loss each uniform = 11.327   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.478   loss each uniform = 8.611   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 36.688   loss each uniform = 7.931   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.228   loss each uniform = 11.398   feat norm = 0.449  

Validation:
Average incurred loss: 0.666  
Average sample loss: 0.648  
Average acc: 0.848  
Average grad norm: 6.095  
Average grad norm uniform: 33.699  
Average loss each uniform: 7.892  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.346   grad norm uniform = 34.311   loss each uniform = 10.561   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.127  exp loss = 1.234  adjusted loss = 1.234  adv prob = 0.250000   acc = 0.736   grad norm = 11.046   grad norm uniform = 32.605   loss each uniform = 5.186   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.842  exp loss = 1.984  adjusted loss = 1.984  adv prob = 0.250000   acc = 0.617   grad norm = 13.607   grad norm uniform = 30.182   loss each uniform = 4.981   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.160  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.970   grad norm = 1.427   grad norm uniform = 38.904   loss each uniform = 10.913   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [122]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.198  
Average loss each uniform: 11.189  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.998   loss each uniform = 11.326   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 41.515   loss each uniform = 8.609   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.046   grad norm uniform = 36.713   loss each uniform = 7.875   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.217   loss each uniform = 11.360   feat norm = 0.449  

Validation:
Average incurred loss: 0.573  
Average sample loss: 0.553  
Average acc: 0.871  
Average grad norm: 5.131  
Average grad norm uniform: 33.577  
Average loss each uniform: 8.168  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.137   grad norm uniform = 34.425   loss each uniform = 11.178   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.753  exp loss = 0.816  adjusted loss = 0.816  adv prob = 0.250000   acc = 0.813   grad norm = 7.814   grad norm uniform = 33.012   loss each uniform = 5.677   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.283  exp loss = 2.417  adjusted loss = 2.417  adv prob = 0.250000   acc = 0.549   grad norm = 16.230   grad norm uniform = 28.687   loss each uniform = 4.756   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.226  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.947   grad norm = 2.160   grad norm uniform = 37.465   loss each uniform = 9.737   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [123]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.182  
Average loss each uniform: 11.186  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.985   loss each uniform = 11.325   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.540   loss each uniform = 8.701   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.045   grad norm uniform = 36.767   loss each uniform = 7.959   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.181   loss each uniform = 11.332   feat norm = 0.449  

Validation:
Average incurred loss: 0.618  
Average sample loss: 0.598  
Average acc: 0.861  
Average grad norm: 5.605  
Average grad norm uniform: 33.688  
Average loss each uniform: 8.046  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.242   grad norm uniform = 34.476   loss each uniform = 10.882   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.944  exp loss = 1.032  adjusted loss = 1.032  adv prob = 0.250000   acc = 0.773   grad norm = 9.462   grad norm uniform = 32.725   loss each uniform = 5.405   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.039  exp loss = 2.184  adjusted loss = 2.184  adv prob = 0.250000   acc = 0.594   grad norm = 14.764   grad norm uniform = 29.664   loss each uniform = 4.927   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.955   grad norm = 1.760   grad norm uniform = 38.319   loss each uniform = 10.460   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [124]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.184  
Average loss each uniform: 11.185  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.990   loss each uniform = 11.327   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.444   loss each uniform = 8.813   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.082   grad norm uniform = 36.417   loss each uniform = 7.366   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.207   loss each uniform = 11.329   feat norm = 0.449  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.608  
Average acc: 0.857  
Average grad norm: 5.750  
Average grad norm uniform: 33.594  
Average loss each uniform: 7.959  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.258   grad norm uniform = 34.427   loss each uniform = 10.734   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.013  exp loss = 1.090  adjusted loss = 1.090  adv prob = 0.250000   acc = 0.751   grad norm = 10.093   grad norm uniform = 32.502   loss each uniform = 5.297   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.884  exp loss = 2.032  adjusted loss = 2.032  adv prob = 0.250000   acc = 0.624   grad norm = 13.955   grad norm uniform = 29.851   loss each uniform = 4.902   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.962   grad norm = 1.607   grad norm uniform = 38.236   loss each uniform = 10.595   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [125]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.189  
Average loss each uniform: 11.211  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.981   loss each uniform = 11.345   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.578   loss each uniform = 8.776   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 36.586   loss each uniform = 7.739   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.229   loss each uniform = 11.372   feat norm = 0.449  

Validation:
Average incurred loss: 0.625  
Average sample loss: 0.606  
Average acc: 0.857  
Average grad norm: 5.664  
Average grad norm uniform: 33.559  
Average loss each uniform: 8.014  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.229   grad norm uniform = 34.324   loss each uniform = 10.839   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.976  exp loss = 1.054  adjusted loss = 1.054  adv prob = 0.250000   acc = 0.760   grad norm = 9.723   grad norm uniform = 32.453   loss each uniform = 5.364   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.994  exp loss = 2.136  adjusted loss = 2.136  adv prob = 0.250000   acc = 0.602   grad norm = 14.479   grad norm uniform = 29.880   loss each uniform = 4.891   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.962   grad norm = 1.712   grad norm uniform = 38.426   loss each uniform = 10.507   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8573811650276184


Epoch [126]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.182  
Average loss each uniform: 11.226  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.983   loss each uniform = 11.370   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.441   loss each uniform = 8.607   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 36.628   loss each uniform = 7.677   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.212   loss each uniform = 11.391   feat norm = 0.449  

Validation:
Average incurred loss: 0.576  
Average sample loss: 0.555  
Average acc: 0.872  
Average grad norm: 5.160  
Average grad norm uniform: 34.017  
Average loss each uniform: 8.235  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.151   grad norm uniform = 34.834   loss each uniform = 11.256   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.772  exp loss = 0.848  adjusted loss = 0.848  adv prob = 0.250000   acc = 0.811   grad norm = 7.917   grad norm uniform = 33.479   loss each uniform = 5.708   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.253  exp loss = 2.397  adjusted loss = 2.397  adv prob = 0.250000   acc = 0.556   grad norm = 16.181   grad norm uniform = 29.195   loss each uniform = 4.818   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 2.071   grad norm uniform = 37.852   loss each uniform = 9.898   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [127]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.184  
Average loss each uniform: 11.221  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.988   loss each uniform = 11.359   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 41.468   loss each uniform = 8.764   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 36.515   loss each uniform = 7.744   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.208   loss each uniform = 11.377   feat norm = 0.449  

Validation:
Average incurred loss: 0.617  
Average sample loss: 0.597  
Average acc: 0.859  
Average grad norm: 5.585  
Average grad norm uniform: 33.397  
Average loss each uniform: 7.953  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.233   grad norm uniform = 34.146   loss each uniform = 10.725   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.958  exp loss = 1.034  adjusted loss = 1.034  adv prob = 0.250000   acc = 0.768   grad norm = 9.534   grad norm uniform = 32.302   loss each uniform = 5.314   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.986  exp loss = 2.129  adjusted loss = 2.129  adv prob = 0.250000   acc = 0.594   grad norm = 14.461   grad norm uniform = 29.638   loss each uniform = 4.902   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.955   grad norm = 1.664   grad norm uniform = 38.363   loss each uniform = 10.516   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [128]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.192  
Average loss each uniform: 11.238  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.993   loss each uniform = 11.385   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.465   loss each uniform = 8.585   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 36.501   loss each uniform = 7.696   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.224   loss each uniform = 11.400   feat norm = 0.449  

Validation:
Average incurred loss: 0.597  
Average sample loss: 0.577  
Average acc: 0.866  
Average grad norm: 5.389  
Average grad norm uniform: 34.151  
Average loss each uniform: 8.197  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.199   grad norm uniform = 34.719   loss each uniform = 11.077   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.867  exp loss = 0.929  adjusted loss = 0.929  adv prob = 0.250000   acc = 0.796   grad norm = 8.767   grad norm uniform = 33.704   loss each uniform = 5.671   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.108  exp loss = 2.263  adjusted loss = 2.263  adv prob = 0.250000   acc = 0.556   grad norm = 15.267   grad norm uniform = 29.442   loss each uniform = 4.859   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.212  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.955   grad norm = 1.898   grad norm uniform = 38.428   loss each uniform = 10.273   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [129]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.182  
Average loss each uniform: 11.250  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.979   loss each uniform = 11.397   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 41.444   loss each uniform = 8.733   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 36.566   loss each uniform = 7.789   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.227   loss each uniform = 11.384   feat norm = 0.449  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.593  
Average acc: 0.862  
Average grad norm: 5.526  
Average grad norm uniform: 34.098  
Average loss each uniform: 8.145  
Average feat norm: 0.457  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.186   grad norm uniform = 34.722   loss each uniform = 11.062   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.892  exp loss = 0.958  adjusted loss = 0.958  adv prob = 0.250000   acc = 0.788   grad norm = 9.064   grad norm uniform = 33.456   loss each uniform = 5.541   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.167  exp loss = 2.302  adjusted loss = 2.302  adv prob = 0.250000   acc = 0.564   grad norm = 15.499   grad norm uniform = 29.719   loss each uniform = 4.870   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.947   grad norm = 1.908   grad norm uniform = 38.539   loss each uniform = 10.306   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [130]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.180  
Average loss each uniform: 11.252  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.961   loss each uniform = 11.397   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.559   loss each uniform = 8.905   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.048   grad norm uniform = 36.966   loss each uniform = 8.020   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.235   loss each uniform = 11.349   feat norm = 0.449  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.544  
Average acc: 0.875  
Average grad norm: 4.987  
Average grad norm uniform: 33.981  
Average loss each uniform: 8.348  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.110   grad norm uniform = 34.675   loss each uniform = 11.372   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.691  exp loss = 0.765  adjusted loss = 0.765  adv prob = 0.250000   acc = 0.828   grad norm = 7.203   grad norm uniform = 33.647   loss each uniform = 5.939   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.412  exp loss = 2.570  adjusted loss = 2.570  adv prob = 0.250000   acc = 0.534   grad norm = 16.915   grad norm uniform = 29.058   loss each uniform = 4.820   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.251  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.947   grad norm = 2.417   grad norm uniform = 37.639   loss each uniform = 9.699   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8748958110809326


Epoch [131]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.176  
Average loss each uniform: 11.259  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.965   loss each uniform = 11.415   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 41.541   loss each uniform = 8.623   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.064   grad norm uniform = 36.631   loss each uniform = 7.998   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.225   loss each uniform = 11.372   feat norm = 0.449  

Validation:
Average incurred loss: 0.627  
Average sample loss: 0.610  
Average acc: 0.854  
Average grad norm: 5.730  
Average grad norm uniform: 33.964  
Average loss each uniform: 8.070  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.324   grad norm uniform = 34.471   loss each uniform = 10.735   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.030  exp loss = 1.136  adjusted loss = 1.136  adv prob = 0.250000   acc = 0.758   grad norm = 10.113   grad norm uniform = 32.913   loss each uniform = 5.407   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.825  exp loss = 1.979  adjusted loss = 1.979  adv prob = 0.250000   acc = 0.609   grad norm = 13.543   grad norm uniform = 30.675   loss each uniform = 5.097   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.172  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.955   grad norm = 1.540   grad norm uniform = 39.161   loss each uniform = 11.013   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [132]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.181  
Average loss each uniform: 11.269  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.971   loss each uniform = 11.430   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 41.464   loss each uniform = 8.605   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 36.457   loss each uniform = 7.719   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.253   loss each uniform = 11.387   feat norm = 0.449  

Validation:
Average incurred loss: 0.680  
Average sample loss: 0.662  
Average acc: 0.842  
Average grad norm: 6.159  
Average grad norm uniform: 33.376  
Average loss each uniform: 7.836  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.388   grad norm uniform = 33.886   loss each uniform = 10.339   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.196  exp loss = 1.280  adjusted loss = 1.280  adv prob = 0.250000   acc = 0.719   grad norm = 11.414   grad norm uniform = 32.004   loss each uniform = 5.105   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.717  exp loss = 1.865  adjusted loss = 1.865  adv prob = 0.250000   acc = 0.632   grad norm = 12.774   grad norm uniform = 30.633   loss each uniform = 5.159   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.161  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.970   grad norm = 1.398   grad norm uniform = 39.135   loss each uniform = 11.292   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8423686027526855


Epoch [133]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.179  
Average loss each uniform: 11.290  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.961   loss each uniform = 11.426   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.709   loss each uniform = 9.010   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 36.401   loss each uniform = 7.629   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.233   loss each uniform = 11.431   feat norm = 0.449  

Validation:
Average incurred loss: 0.599  
Average sample loss: 0.580  
Average acc: 0.867  
Average grad norm: 5.420  
Average grad norm uniform: 33.804  
Average loss each uniform: 8.115  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.996   grad norm = 0.228   grad norm uniform = 34.307   loss each uniform = 10.920   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.900  exp loss = 0.978  adjusted loss = 0.978  adv prob = 0.250000   acc = 0.790   grad norm = 9.025   grad norm uniform = 33.160   loss each uniform = 5.561   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.016  exp loss = 2.145  adjusted loss = 2.145  adv prob = 0.250000   acc = 0.602   grad norm = 14.591   grad norm uniform = 29.587   loss each uniform = 4.913   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.955   grad norm = 1.847   grad norm uniform = 38.511   loss each uniform = 10.416   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8673895597457886


Epoch [134]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.171  
Average loss each uniform: 11.280  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.961   loss each uniform = 11.435   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 41.664   loss each uniform = 8.813   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 36.759   loss each uniform = 7.943   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 39.189   loss each uniform = 11.373   feat norm = 0.449  

Validation:
Average incurred loss: 0.587  
Average sample loss: 0.566  
Average acc: 0.871  
Average grad norm: 5.100  
Average grad norm uniform: 33.707  
Average loss each uniform: 8.413  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.114   grad norm uniform = 34.613   loss each uniform = 11.556   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.742  exp loss = 0.808  adjusted loss = 0.808  adv prob = 0.250000   acc = 0.818   grad norm = 7.591   grad norm uniform = 33.187   loss each uniform = 5.859   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.439  exp loss = 2.599  adjusted loss = 2.599  adv prob = 0.250000   acc = 0.534   grad norm = 16.750   grad norm uniform = 28.749   loss each uniform = 4.879   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.947   grad norm = 2.228   grad norm uniform = 37.301   loss each uniform = 9.859   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [135]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.182  
Average loss each uniform: 11.321  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.963   loss each uniform = 11.450   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.566   loss each uniform = 8.828   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 36.413   loss each uniform = 7.766   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.267   loss each uniform = 11.514   feat norm = 0.449  

Validation:
Average incurred loss: 0.607  
Average sample loss: 0.587  
Average acc: 0.866  
Average grad norm: 5.394  
Average grad norm uniform: 34.085  
Average loss each uniform: 8.285  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.160   grad norm uniform = 34.915   loss each uniform = 11.343   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.848  exp loss = 0.919  adjusted loss = 0.919  adv prob = 0.250000   acc = 0.796   grad norm = 8.580   grad norm uniform = 33.420   loss each uniform = 5.658   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.261  exp loss = 2.385  adjusted loss = 2.385  adv prob = 0.250000   acc = 0.556   grad norm = 16.014   grad norm uniform = 29.443   loss each uniform = 4.883   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.219  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.955   grad norm = 1.991   grad norm uniform = 38.140   loss each uniform = 10.154   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [136]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.185  
Average loss each uniform: 11.344  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.974   loss each uniform = 11.459   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 41.563   loss each uniform = 8.878   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 36.662   loss each uniform = 7.931   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.232   loss each uniform = 11.571   feat norm = 0.448  

Validation:
Average incurred loss: 0.587  
Average sample loss: 0.567  
Average acc: 0.868  
Average grad norm: 5.244  
Average grad norm uniform: 33.813  
Average loss each uniform: 8.270  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.160   grad norm uniform = 34.679   loss each uniform = 11.256   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.811  exp loss = 0.892  adjusted loss = 0.892  adv prob = 0.250000   acc = 0.803   grad norm = 8.280   grad norm uniform = 33.036   loss each uniform = 5.712   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.216  exp loss = 2.354  adjusted loss = 2.354  adv prob = 0.250000   acc = 0.564   grad norm = 15.651   grad norm uniform = 29.409   loss each uniform = 4.891   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.947   grad norm = 2.050   grad norm uniform = 37.898   loss each uniform = 10.125   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8682234883308411


Epoch [137]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.188  
Average loss each uniform: 11.337  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.977   loss each uniform = 11.467   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.506   loss each uniform = 8.768   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 36.579   loss each uniform = 7.912   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.250   loss each uniform = 11.534   feat norm = 0.449  

Validation:
Average incurred loss: 0.606  
Average sample loss: 0.587  
Average acc: 0.865  
Average grad norm: 5.466  
Average grad norm uniform: 33.967  
Average loss each uniform: 8.182  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.216   grad norm uniform = 34.659   loss each uniform = 11.042   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.905  exp loss = 0.981  adjusted loss = 0.981  adv prob = 0.250000   acc = 0.783   grad norm = 9.059   grad norm uniform = 33.081   loss each uniform = 5.575   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.068  exp loss = 2.219  adjusted loss = 2.219  adv prob = 0.250000   acc = 0.594   grad norm = 14.967   grad norm uniform = 30.017   loss each uniform = 4.954   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.955   grad norm = 1.813   grad norm uniform = 38.592   loss each uniform = 10.500   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8648873567581177


Epoch [138]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.177  
Average loss each uniform: 11.326  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.978   loss each uniform = 11.455   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 41.499   loss each uniform = 8.827   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 36.509   loss each uniform = 7.888   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.200   loss each uniform = 11.513   feat norm = 0.448  

Validation:
Average incurred loss: 0.624  
Average sample loss: 0.606  
Average acc: 0.857  
Average grad norm: 5.711  
Average grad norm uniform: 33.235  
Average loss each uniform: 7.917  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.282   grad norm uniform = 33.952   loss each uniform = 10.588   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.008  exp loss = 1.095  adjusted loss = 1.095  adv prob = 0.250000   acc = 0.758   grad norm = 9.977   grad norm uniform = 31.936   loss each uniform = 5.278   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.877  exp loss = 1.999  adjusted loss = 1.999  adv prob = 0.250000   acc = 0.617   grad norm = 13.888   grad norm uniform = 30.113   loss each uniform = 4.971   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.955   grad norm = 1.655   grad norm uniform = 38.391   loss each uniform = 10.732   feat norm = 0.457  
