Dataset: CUB
Shift type: confounder
Target name: waterbird_complete95
Confounder names: ['forest2water2']
Resume: False
Inference: False
Minority fraction: None
Imbalance ratio: None
Fraction: 1.0
Root dir: ./
Reweight groups: False
Augment data: False
Val fraction: 0.1
Robust: False
Alpha: 0.2
Generalization adjustment: 0.0
Automatic adjustment: False
Robust step size: 0.01
Use normalized loss: False
Btl: False
Hinge: False
Print grad loss: True
Print feat: True
Uniform loss: True
Model: resnet50
Train from scratch: False
N epochs: 300
Batch size: 128
Lr: 0.001
Scheduler: False
Weight decay: 0.0001
Gamma: 0.1
Minimum variational weight: 0
Seed: 0
Show progress: True
Log dir: ./logs_fix
Checkpoint dir: ./logs_a40
Log every: 50
Save step: 1000
Save best: True
Save last: True

Training Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 3498
    waterbird_complete95 = 0, forest2water2 = 1: n = 184
    waterbird_complete95 = 1, forest2water2 = 0: n = 56
    waterbird_complete95 = 1, forest2water2 = 1: n = 1057
Validation Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 467
    waterbird_complete95 = 0, forest2water2 = 1: n = 466
    waterbird_complete95 = 1, forest2water2 = 0: n = 133
    waterbird_complete95 = 1, forest2water2 = 1: n = 133
Test Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 2255
    waterbird_complete95 = 0, forest2water2 = 1: n = 2255
    waterbird_complete95 = 1, forest2water2 = 0: n = 642
    waterbird_complete95 = 1, forest2water2 = 1: n = 642

Epoch [0]:
Training:
Average incurred loss: 0.323  
Average sample loss: 0.321  
Average acc: 0.870  
Average grad norm: 8.241  
Average grad norm uniform: 23.191  
Average loss each uniform: 2.320  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.165  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.990   grad norm = 5.051   grad norm uniform = 25.830   loss each uniform = 2.532   feat norm = 0.440  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.521  exp loss = 0.614  adjusted loss = 0.614  adv prob = 0.250000   acc = 0.701   grad norm = 13.732   grad norm uniform = 14.804   loss each uniform = 1.659   feat norm = 0.460  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.503  exp loss = 1.545  adjusted loss = 1.545  adv prob = 0.250000   acc = 0.107   grad norm = 26.397   grad norm uniform = 18.274   loss each uniform = 1.839   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.749  exp loss = 0.457  adjusted loss = 0.457  adv prob = 0.250000   acc = 0.545   grad norm = 16.882   grad norm uniform = 16.177   loss each uniform = 1.759   feat norm = 0.446  

Validation:
Average incurred loss: 0.602  
Average sample loss: 0.590  
Average acc: 0.686  
Average grad norm: 11.873  
Average grad norm uniform: 24.018  
Average loss each uniform: 2.538  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.076  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.985   grad norm = 2.319   grad norm uniform = 31.806   loss each uniform = 3.424   feat norm = 0.442  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.985  exp loss = 1.000  adjusted loss = 1.000  adv prob = 0.250000   acc = 0.429   grad norm = 19.705   grad norm uniform = 17.432   loss each uniform = 1.839   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.499  exp loss = 1.643  adjusted loss = 1.643  adv prob = 0.250000   acc = 0.263   grad norm = 23.997   grad norm uniform = 18.659   loss each uniform = 2.004   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.955   grad norm = 5.851   grad norm uniform = 25.101   loss each uniform = 2.406   feat norm = 0.431  
Current lr: 0.001000
Current validation accuracy: 0.6855713129043579
Best model saved at epoch 0


Epoch [1]:
Training:
Average incurred loss: 0.124  
Average sample loss: 0.124  
Average acc: 0.956  
Average grad norm: 3.101  
Average grad norm uniform: 31.318  
Average loss each uniform: 3.771  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.041  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.998   grad norm = 1.336   grad norm uniform = 33.498   loss each uniform = 4.206   feat norm = 0.442  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.771  exp loss = 0.698  adjusted loss = 0.698  adv prob = 0.250000   acc = 0.565   grad norm = 16.343   grad norm uniform = 18.088   loss each uniform = 1.892   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.506  exp loss = 1.337  adjusted loss = 1.337  adv prob = 0.250000   acc = 0.286   grad norm = 23.853   grad norm uniform = 18.257   loss each uniform = 2.011   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.214  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.922   grad norm = 5.536   grad norm uniform = 27.099   loss each uniform = 2.752   feat norm = 0.436  

Validation:
Average incurred loss: 0.487  
Average sample loss: 0.472  
Average acc: 0.771  
Average grad norm: 9.221  
Average grad norm uniform: 26.710  
Average loss each uniform: 3.191  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.994   grad norm = 1.198   grad norm uniform = 33.765   loss each uniform = 4.555   feat norm = 0.440  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.731  exp loss = 0.755  adjusted loss = 0.755  adv prob = 0.250000   acc = 0.618   grad norm = 15.049   grad norm uniform = 20.316   loss each uniform = 2.108   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.522  exp loss = 1.739  adjusted loss = 1.739  adv prob = 0.250000   acc = 0.338   grad norm = 22.096   grad norm uniform = 20.896   loss each uniform = 2.243   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.962   grad norm = 4.099   grad norm uniform = 30.153   loss each uniform = 3.145   feat norm = 0.443  
Current lr: 0.001000
Current validation accuracy: 0.7714762687683105
Best model saved at epoch 1


Epoch [2]:
Training:
Average incurred loss: 0.085  
Average sample loss: 0.085  
Average acc: 0.970  
Average grad norm: 2.149  
Average grad norm uniform: 32.711  
Average loss each uniform: 4.407  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.026  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.998   grad norm = 0.867   grad norm uniform = 34.062   loss each uniform = 4.855   feat norm = 0.437  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.493  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.734   grad norm = 11.522   grad norm uniform = 21.076   loss each uniform = 2.131   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.043  exp loss = 1.217  adjusted loss = 1.217  adv prob = 0.250000   acc = 0.536   grad norm = 17.479   grad norm uniform = 18.693   loss each uniform = 2.034   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.159  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.940   grad norm = 3.947   grad norm uniform = 31.007   loss each uniform = 3.445   feat norm = 0.444  

Validation:
Average incurred loss: 0.422  
Average sample loss: 0.408  
Average acc: 0.822  
Average grad norm: 7.787  
Average grad norm uniform: 28.378  
Average loss each uniform: 3.604  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.998   grad norm = 0.836   grad norm uniform = 34.410   loss each uniform = 5.128   feat norm = 0.439  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.581  exp loss = 0.609  adjusted loss = 0.609  adv prob = 0.250000   acc = 0.717   grad norm = 12.216   grad norm uniform = 22.828   loss each uniform = 2.389   feat norm = 0.458  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.505  exp loss = 1.733  adjusted loss = 1.733  adv prob = 0.250000   acc = 0.429   grad norm = 20.739   grad norm uniform = 22.636   loss each uniform = 2.441   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.962   grad norm = 3.724   grad norm uniform = 32.384   loss each uniform = 3.671   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8215179443359375
Best model saved at epoch 2


Epoch [3]:
Training:
Average incurred loss: 0.060  
Average sample loss: 0.060  
Average acc: 0.981  
Average grad norm: 1.587  
Average grad norm uniform: 33.434  
Average loss each uniform: 4.876  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.020  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998   grad norm = 0.648   grad norm uniform = 34.275   loss each uniform = 5.283   feat norm = 0.435  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.369  exp loss = 0.402  adjusted loss = 0.402  adv prob = 0.250000   acc = 0.848   grad norm = 9.182   grad norm uniform = 23.154   loss each uniform = 2.362   feat norm = 0.463  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.775  exp loss = 0.678  adjusted loss = 0.678  adv prob = 0.250000   acc = 0.679   grad norm = 13.673   grad norm uniform = 20.327   loss each uniform = 2.138   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.103  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.963   grad norm = 2.731   grad norm uniform = 33.135   loss each uniform = 4.114   feat norm = 0.449  

Validation:
Average incurred loss: 0.418  
Average sample loss: 0.404  
Average acc: 0.832  
Average grad norm: 7.499  
Average grad norm uniform: 29.005  
Average loss each uniform: 3.808  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.998   grad norm = 0.784   grad norm uniform = 34.078   loss each uniform = 5.330   feat norm = 0.434  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.639  adjusted loss = 0.639  adv prob = 0.250000   acc = 0.727   grad norm = 12.169   grad norm uniform = 23.698   loss each uniform = 2.493   feat norm = 0.461  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.413  exp loss = 1.613  adjusted loss = 1.613  adv prob = 0.250000   acc = 0.481   grad norm = 19.203   grad norm uniform = 23.977   loss each uniform = 2.577   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.145  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.962   grad norm = 3.008   grad norm uniform = 34.815   loss each uniform = 4.299   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8315262794494629
Best model saved at epoch 3


Epoch [4]:
Training:
Average incurred loss: 0.047  
Average sample loss: 0.047  
Average acc: 0.985  
Average grad norm: 1.272  
Average grad norm uniform: 33.876  
Average loss each uniform: 5.250  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.015  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.998   grad norm = 0.494   grad norm uniform = 34.394   loss each uniform = 5.662   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.254  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.908   grad norm = 6.770   grad norm uniform = 26.889   loss each uniform = 2.689   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.542  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.732   grad norm = 9.882   grad norm uniform = 23.551   loss each uniform = 2.445   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.090  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 0.970   grad norm = 2.432   grad norm uniform = 33.927   loss each uniform = 4.483   feat norm = 0.454  

Validation:
Average incurred loss: 0.442  
Average sample loss: 0.429  
Average acc: 0.819  
Average grad norm: 7.547  
Average grad norm uniform: 29.283  
Average loss each uniform: 3.970  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.994   grad norm = 0.842   grad norm uniform = 33.726   loss each uniform = 5.421   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.720  exp loss = 0.775  adjusted loss = 0.775  adv prob = 0.250000   acc = 0.678   grad norm = 13.178   grad norm uniform = 24.002   loss each uniform = 2.555   feat norm = 0.459  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.237  exp loss = 1.424  adjusted loss = 1.424  adv prob = 0.250000   acc = 0.556   grad norm = 16.641   grad norm uniform = 25.288   loss each uniform = 2.747   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.122  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.962   grad norm = 2.261   grad norm uniform = 36.180   loss each uniform = 5.053   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8190158605575562


Epoch [5]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.992  
Average grad norm: 0.929  
Average grad norm uniform: 34.370  
Average loss each uniform: 5.624  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.999   grad norm = 0.350   grad norm uniform = 34.548   loss each uniform = 6.024   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.165  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.946   grad norm = 5.027   grad norm uniform = 29.144   loss each uniform = 3.019   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.411  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.839   grad norm = 8.063   grad norm uniform = 24.780   loss each uniform = 2.601   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.061  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.985   grad norm = 1.754   grad norm uniform = 35.202   loss each uniform = 4.916   feat norm = 0.457  

Validation:
Average incurred loss: 0.385  
Average sample loss: 0.369  
Average acc: 0.859  
Average grad norm: 6.241  
Average grad norm uniform: 30.858  
Average loss each uniform: 4.481  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.998   grad norm = 0.398   grad norm uniform = 34.687   loss each uniform = 6.301   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.460  exp loss = 0.502  adjusted loss = 0.502  adv prob = 0.250000   acc = 0.813   grad norm = 9.081   grad norm uniform = 27.597   loss each uniform = 3.065   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.629  exp loss = 1.833  adjusted loss = 1.833  adv prob = 0.250000   acc = 0.451   grad norm = 19.703   grad norm uniform = 24.857   loss each uniform = 2.828   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.940   grad norm = 3.342   grad norm uniform = 34.841   loss each uniform = 4.707   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577
Best model saved at epoch 5


Epoch [6]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.024  
Average acc: 0.996  
Average grad norm: 0.686  
Average grad norm uniform: 34.802  
Average loss each uniform: 5.947  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.293   grad norm uniform = 34.609   loss each uniform = 6.285   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.115  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.973   grad norm = 3.696   grad norm uniform = 31.545   loss each uniform = 3.203   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.291  exp loss = 0.375  adjusted loss = 0.375  adv prob = 0.250000   acc = 0.893   grad norm = 5.478   grad norm uniform = 28.710   loss each uniform = 2.982   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.041  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.992   grad norm = 1.208   grad norm uniform = 36.332   loss each uniform = 5.462   feat norm = 0.458  

Validation:
Average incurred loss: 0.488  
Average sample loss: 0.474  
Average acc: 0.811  
Average grad norm: 7.553  
Average grad norm uniform: 30.467  
Average loss each uniform: 4.471  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.762   grad norm uniform = 34.014   loss each uniform = 5.973   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.846  exp loss = 0.900  adjusted loss = 0.900  adv prob = 0.250000   acc = 0.655   grad norm = 13.809   grad norm uniform = 25.715   loss each uniform = 2.824   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.228  exp loss = 1.406  adjusted loss = 1.406  adv prob = 0.250000   acc = 0.586   grad norm = 15.275   grad norm uniform = 27.033   loss each uniform = 3.159   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.108  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.962   grad norm = 1.759   grad norm uniform = 38.097   loss each uniform = 6.278   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.8106756210327148


Epoch [7]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 0.997  
Average grad norm: 0.544  
Average grad norm uniform: 35.049  
Average loss each uniform: 6.245  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.230   grad norm uniform = 34.668   loss each uniform = 6.585   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.076  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.989   grad norm = 2.652   grad norm uniform = 33.349   loss each uniform = 3.555   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.210  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.893   grad norm = 4.563   grad norm uniform = 29.146   loss each uniform = 3.157   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.995   grad norm = 1.002   grad norm uniform = 36.921   loss each uniform = 5.752   feat norm = 0.460  

Validation:
Average incurred loss: 0.453  
Average sample loss: 0.439  
Average acc: 0.837  
Average grad norm: 6.871  
Average grad norm uniform: 30.858  
Average loss each uniform: 4.691  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.994   grad norm = 0.585   grad norm uniform = 33.985   loss each uniform = 6.325   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.731  exp loss = 0.794  adjusted loss = 0.794  adv prob = 0.250000   acc = 0.723   grad norm = 12.029   grad norm uniform = 26.757   loss each uniform = 3.027   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.326  exp loss = 1.499  adjusted loss = 1.499  adv prob = 0.250000   acc = 0.564   grad norm = 15.756   grad norm uniform = 27.312   loss each uniform = 3.202   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.962   grad norm = 1.988   grad norm uniform = 37.794   loss each uniform = 6.274   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.8373644351959229


Epoch [8]:
Training:
Average incurred loss: 0.014  
Average sample loss: 0.014  
Average acc: 0.998  
Average grad norm: 0.444  
Average grad norm uniform: 35.245  
Average loss each uniform: 6.482  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.202   grad norm uniform = 34.704   loss each uniform = 6.782   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.066  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.995   grad norm = 2.358   grad norm uniform = 34.410   loss each uniform = 3.701   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.171  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 0.911   grad norm = 3.459   grad norm uniform = 31.373   loss each uniform = 3.432   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.024  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.997   grad norm = 0.755   grad norm uniform = 37.384   loss each uniform = 6.133   feat norm = 0.459  

Validation:
Average incurred loss: 0.460  
Average sample loss: 0.445  
Average acc: 0.841  
Average grad norm: 6.782  
Average grad norm uniform: 31.305  
Average loss each uniform: 4.874  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994   grad norm = 0.539   grad norm uniform = 34.324   loss each uniform = 6.580   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.741  exp loss = 0.800  adjusted loss = 0.800  adv prob = 0.250000   acc = 0.730   grad norm = 11.864   grad norm uniform = 27.631   loss each uniform = 3.175   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.353  exp loss = 1.506  adjusted loss = 1.506  adv prob = 0.250000   acc = 0.579   grad norm = 15.704   grad norm uniform = 27.043   loss each uniform = 3.255   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.955   grad norm = 1.975   grad norm uniform = 37.836   loss each uniform = 6.458   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.840700626373291


Epoch [9]:
Training:
Average incurred loss: 0.011  
Average sample loss: 0.011  
Average acc: 0.999  
Average grad norm: 0.359  
Average grad norm uniform: 35.397  
Average loss each uniform: 6.751  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.160   grad norm uniform = 34.738   loss each uniform = 7.047   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.042  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 1.000   grad norm = 1.566   grad norm uniform = 36.120   loss each uniform = 4.043   feat norm = 0.491  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.151  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.946   grad norm = 3.487   grad norm uniform = 30.219   loss each uniform = 3.455   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.020  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.999   grad norm = 0.640   grad norm uniform = 37.729   loss each uniform = 6.417   feat norm = 0.460  

Validation:
Average incurred loss: 0.468  
Average sample loss: 0.454  
Average acc: 0.839  
Average grad norm: 6.701  
Average grad norm uniform: 31.333  
Average loss each uniform: 5.012  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994   grad norm = 0.527   grad norm uniform = 34.127   loss each uniform = 6.742   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.756  exp loss = 0.820  adjusted loss = 0.820  adv prob = 0.250000   acc = 0.725   grad norm = 11.724   grad norm uniform = 27.789   loss each uniform = 3.254   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.377  exp loss = 1.531  adjusted loss = 1.531  adv prob = 0.250000   acc = 0.579   grad norm = 15.556   grad norm uniform = 27.401   loss each uniform = 3.373   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.126  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.955   grad norm = 1.927   grad norm uniform = 37.877   loss each uniform = 6.731   feat norm = 0.471  
Current lr: 0.001000
Current validation accuracy: 0.8390325307846069


Epoch [10]:
Training:
Average incurred loss: 0.010  
Average sample loss: 0.011  
Average acc: 0.999  
Average grad norm: 0.327  
Average grad norm uniform: 35.466  
Average loss each uniform: 6.927  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.005  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.168   grad norm uniform = 34.757   loss each uniform = 7.171   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.041  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000   grad norm = 1.573   grad norm uniform = 36.310   loss each uniform = 4.100   feat norm = 0.494  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.104  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 0.964   grad norm = 2.531   grad norm uniform = 31.293   loss each uniform = 3.844   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.017  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.999   grad norm = 0.520   grad norm uniform = 37.888   loss each uniform = 6.778   feat norm = 0.458  

Validation:
Average incurred loss: 0.588  
Average sample loss: 0.574  
Average acc: 0.797  
Average grad norm: 7.928  
Average grad norm uniform: 31.173  
Average loss each uniform: 4.947  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.985   grad norm = 0.977   grad norm uniform = 33.095   loss each uniform = 6.216   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.154  exp loss = 1.220  adjusted loss = 1.220  adv prob = 0.250000   acc = 0.592   grad norm = 15.694   grad norm uniform = 27.529   loss each uniform = 3.150   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.022  exp loss = 1.173  adjusted loss = 1.173  adv prob = 0.250000   acc = 0.677   grad norm = 11.836   grad norm uniform = 28.748   loss each uniform = 3.756   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.090  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 0.977   grad norm = 1.217   grad norm uniform = 39.619   loss each uniform = 7.974   feat norm = 0.476  
Current lr: 0.001000
Current validation accuracy: 0.7973310947418213


Epoch [11]:
Training:
Average incurred loss: 0.008  
Average sample loss: 0.008  
Average acc: 0.999  
Average grad norm: 0.251  
Average grad norm uniform: 35.611  
Average loss each uniform: 7.241  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.091   grad norm uniform = 34.794   loss each uniform = 7.602   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.021  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000   grad norm = 0.799   grad norm uniform = 38.119   loss each uniform = 4.674   feat norm = 0.497  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.093  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.964   grad norm = 2.321   grad norm uniform = 32.001   loss each uniform = 3.839   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.018  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.997   grad norm = 0.572   grad norm uniform = 38.068   loss each uniform = 6.672   feat norm = 0.462  

Validation:
Average incurred loss: 0.492  
Average sample loss: 0.477  
Average acc: 0.838  
Average grad norm: 6.761  
Average grad norm uniform: 31.480  
Average loss each uniform: 5.228  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.998   grad norm = 0.453   grad norm uniform = 34.133   loss each uniform = 7.070   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.808  exp loss = 0.875  adjusted loss = 0.875  adv prob = 0.250000   acc = 0.719   grad norm = 11.993   grad norm uniform = 28.230   loss each uniform = 3.377   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.424  exp loss = 1.556  adjusted loss = 1.556  adv prob = 0.250000   acc = 0.579   grad norm = 15.477   grad norm uniform = 27.364   loss each uniform = 3.430   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.126  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.955   grad norm = 1.861   grad norm uniform = 37.668   loss each uniform = 7.039   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8381984829902649


Epoch [12]:
Training:
Average incurred loss: 0.007  
Average sample loss: 0.007  
Average acc: 0.999  
Average grad norm: 0.217  
Average grad norm uniform: 35.710  
Average loss each uniform: 7.346  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.109   grad norm uniform = 34.881   loss each uniform = 7.582   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.039  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.995   grad norm = 1.345   grad norm uniform = 37.314   loss each uniform = 4.348   feat norm = 0.499  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.063  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.982   grad norm = 1.668   grad norm uniform = 32.807   loss each uniform = 4.003   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.999   grad norm = 0.300   grad norm uniform = 38.329   loss each uniform = 7.262   feat norm = 0.457  

Validation:
Average incurred loss: 0.516  
Average sample loss: 0.502  
Average acc: 0.829  
Average grad norm: 6.857  
Average grad norm uniform: 31.527  
Average loss each uniform: 5.328  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.987   grad norm = 0.570   grad norm uniform = 33.716   loss each uniform = 7.037   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.904  exp loss = 0.976  adjusted loss = 0.976  adv prob = 0.250000   acc = 0.700   grad norm = 12.657   grad norm uniform = 28.347   loss each uniform = 3.438   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.283  exp loss = 1.417  adjusted loss = 1.417  adv prob = 0.250000   acc = 0.602   grad norm = 13.846   grad norm uniform = 28.066   loss each uniform = 3.639   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.119  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.955   grad norm = 1.624   grad norm uniform = 38.448   loss each uniform = 7.638   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8290241956710815


Epoch [13]:
Training:
Average incurred loss: 0.006  
Average sample loss: 0.006  
Average acc: 1.000  
Average grad norm: 0.190  
Average grad norm uniform: 35.743  
Average loss each uniform: 7.569  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 34.840   loss each uniform = 7.902   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.017  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000   grad norm = 0.669   grad norm uniform = 38.723   loss each uniform = 4.919   feat norm = 0.503  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.082  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.982   grad norm = 2.158   grad norm uniform = 31.941   loss each uniform = 3.918   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.390   grad norm uniform = 38.413   loss each uniform = 7.122   feat norm = 0.461  

Validation:
Average incurred loss: 0.516  
Average sample loss: 0.500  
Average acc: 0.834  
Average grad norm: 6.798  
Average grad norm uniform: 31.634  
Average loss each uniform: 5.424  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.998   grad norm = 0.467   grad norm uniform = 33.967   loss each uniform = 7.285   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.869  exp loss = 0.953  adjusted loss = 0.953  adv prob = 0.250000   acc = 0.706   grad norm = 12.248   grad norm uniform = 28.583   loss each uniform = 3.508   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.424  exp loss = 1.567  adjusted loss = 1.567  adv prob = 0.250000   acc = 0.586   grad norm = 15.002   grad norm uniform = 27.792   loss each uniform = 3.561   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.123  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.955   grad norm = 1.731   grad norm uniform = 37.975   loss each uniform = 7.466   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8340283632278442


Epoch [14]:
Training:
Average incurred loss: 0.005  
Average sample loss: 0.005  
Average acc: 1.000  
Average grad norm: 0.155  
Average grad norm uniform: 35.823  
Average loss each uniform: 7.675  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.083   grad norm uniform = 34.880   loss each uniform = 7.907   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.013  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000   grad norm = 0.519   grad norm uniform = 39.100   loss each uniform = 5.115   feat norm = 0.504  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.053  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.982   grad norm = 1.385   grad norm uniform = 33.347   loss each uniform = 4.385   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.999   grad norm = 0.265   grad norm uniform = 38.507   loss each uniform = 7.527   feat norm = 0.458  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.522  
Average acc: 0.831  
Average grad norm: 6.878  
Average grad norm uniform: 31.887  
Average loss each uniform: 5.527  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.987   grad norm = 0.562   grad norm uniform = 34.022   loss each uniform = 7.277   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.964  exp loss = 1.042  adjusted loss = 1.042  adv prob = 0.250000   acc = 0.693   grad norm = 12.887   grad norm uniform = 28.834   loss each uniform = 3.555   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.266  exp loss = 1.410  adjusted loss = 1.410  adv prob = 0.250000   acc = 0.624   grad norm = 13.414   grad norm uniform = 28.441   loss each uniform = 3.759   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.111  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 0.970   grad norm = 1.468   grad norm uniform = 38.538   loss each uniform = 8.055   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8306922316551208


Epoch [15]:
Training:
Average incurred loss: 0.005  
Average sample loss: 0.005  
Average acc: 1.000  
Average grad norm: 0.154  
Average grad norm uniform: 35.824  
Average loss each uniform: 7.788  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.080   grad norm uniform = 34.877   loss each uniform = 8.031   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.015  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.607   grad norm uniform = 39.000   loss each uniform = 5.099   feat norm = 0.505  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.051  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.982   grad norm = 1.270   grad norm uniform = 33.641   loss each uniform = 4.572   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.008  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.260   grad norm uniform = 38.519   loss each uniform = 7.623   feat norm = 0.458  

Validation:
Average incurred loss: 0.468  
Average sample loss: 0.450  
Average acc: 0.862  
Average grad norm: 5.979  
Average grad norm uniform: 32.137  
Average loss each uniform: 5.794  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.260   grad norm uniform = 34.475   loss each uniform = 7.988   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.651  exp loss = 0.712  adjusted loss = 0.712  adv prob = 0.250000   acc = 0.790   grad norm = 9.552   grad norm uniform = 29.886   loss each uniform = 3.884   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.739  exp loss = 1.897  adjusted loss = 1.897  adv prob = 0.250000   acc = 0.541   grad norm = 17.240   grad norm uniform = 26.811   loss each uniform = 3.539   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.955   grad norm = 2.275   grad norm uniform = 37.144   loss each uniform = 7.037   feat norm = 0.465  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391
Best model saved at epoch 15


Epoch [16]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.116  
Average grad norm uniform: 35.902  
Average loss each uniform: 7.961  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.057   grad norm uniform = 34.874   loss each uniform = 8.232   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.011  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.444   grad norm uniform = 39.469   loss each uniform = 5.455   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.037  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000   grad norm = 0.999   grad norm uniform = 34.157   loss each uniform = 4.532   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.206   grad norm uniform = 38.772   loss each uniform = 7.682   feat norm = 0.459  

Validation:
Average incurred loss: 0.455  
Average sample loss: 0.437  
Average acc: 0.867  
Average grad norm: 5.635  
Average grad norm uniform: 32.534  
Average loss each uniform: 6.003  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.216   grad norm uniform = 34.518   loss each uniform = 8.262   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.569  exp loss = 0.635  adjusted loss = 0.635  adv prob = 0.250000   acc = 0.820   grad norm = 8.423   grad norm uniform = 30.892   loss each uniform = 4.144   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.887  exp loss = 2.061  adjusted loss = 2.061  adv prob = 0.250000   acc = 0.489   grad norm = 17.931   grad norm uniform = 27.048   loss each uniform = 3.629   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947   grad norm = 2.598   grad norm uniform = 36.802   loss each uniform = 6.956   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8665555119514465
Best model saved at epoch 16


Epoch [17]:
Training:
Average incurred loss: 0.004  
Average sample loss: 0.004  
Average acc: 1.000  
Average grad norm: 0.122  
Average grad norm uniform: 35.901  
Average loss each uniform: 8.027  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.059   grad norm uniform = 34.930   loss each uniform = 8.254   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.014  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000   grad norm = 0.571   grad norm uniform = 39.218   loss each uniform = 5.374   feat norm = 0.507  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.033  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000   grad norm = 0.974   grad norm uniform = 34.175   loss each uniform = 4.612   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.207   grad norm uniform = 38.626   loss each uniform = 7.920   feat norm = 0.457  

Validation:
Average incurred loss: 0.520  
Average sample loss: 0.505  
Average acc: 0.840  
Average grad norm: 6.490  
Average grad norm uniform: 32.390  
Average loss each uniform: 5.816  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.987   grad norm = 0.490   grad norm uniform = 34.218   loss each uniform = 7.688   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.900  exp loss = 0.974  adjusted loss = 0.974  adv prob = 0.250000   acc = 0.723   grad norm = 11.847   grad norm uniform = 29.785   loss each uniform = 3.809   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.344  exp loss = 1.488  adjusted loss = 1.488  adv prob = 0.250000   acc = 0.617   grad norm = 13.685   grad norm uniform = 28.730   loss each uniform = 3.876   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.122  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 0.955   grad norm = 1.590   grad norm uniform = 38.758   loss each uniform = 8.212   feat norm = 0.470  
Current lr: 0.001000
Current validation accuracy: 0.8398665189743042


Epoch [18]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.102  
Average grad norm uniform: 35.938  
Average loss each uniform: 8.175  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 34.918   loss each uniform = 8.421   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.010  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.389   grad norm uniform = 39.735   loss each uniform = 5.681   feat norm = 0.509  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.034  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000   grad norm = 1.032   grad norm uniform = 33.964   loss each uniform = 4.693   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.178   grad norm uniform = 38.756   loss each uniform = 7.980   feat norm = 0.457  

Validation:
Average incurred loss: 0.503  
Average sample loss: 0.487  
Average acc: 0.851  
Average grad norm: 6.178  
Average grad norm uniform: 32.458  
Average loss each uniform: 5.948  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.994   grad norm = 0.398   grad norm uniform = 34.177   loss each uniform = 7.937   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.817  exp loss = 0.885  adjusted loss = 0.885  adv prob = 0.250000   acc = 0.751   grad norm = 10.862   grad norm uniform = 30.137   loss each uniform = 3.920   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.478  exp loss = 1.640  adjusted loss = 1.640  adv prob = 0.250000   acc = 0.594   grad norm = 14.500   grad norm uniform = 28.479   loss each uniform = 3.889   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.134  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.955   grad norm = 1.745   grad norm uniform = 38.534   loss each uniform = 8.126   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8507089018821716


Epoch [19]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.102  
Average grad norm uniform: 35.935  
Average loss each uniform: 8.250  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 34.895   loss each uniform = 8.517   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.010  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.380   grad norm uniform = 39.778   loss each uniform = 5.704   feat norm = 0.510  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.022  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000   grad norm = 0.687   grad norm uniform = 34.834   loss each uniform = 4.930   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.169   grad norm uniform = 38.767   loss each uniform = 7.989   feat norm = 0.458  

Validation:
Average incurred loss: 0.496  
Average sample loss: 0.480  
Average acc: 0.857  
Average grad norm: 6.025  
Average grad norm uniform: 32.601  
Average loss each uniform: 6.068  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.998   grad norm = 0.320   grad norm uniform = 34.342   loss each uniform = 8.199   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.762  exp loss = 0.821  adjusted loss = 0.821  adv prob = 0.250000   acc = 0.768   grad norm = 10.212   grad norm uniform = 30.619   loss each uniform = 4.061   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.611  exp loss = 1.770  adjusted loss = 1.770  adv prob = 0.250000   acc = 0.571   grad norm = 15.444   grad norm uniform = 28.110   loss each uniform = 3.808   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.148  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 0.955   grad norm = 1.969   grad norm uniform = 37.927   loss each uniform = 7.872   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [20]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.086  
Average grad norm uniform: 35.979  
Average loss each uniform: 8.399  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 34.910   loss each uniform = 8.652   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.007  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.298   grad norm uniform = 40.023   loss each uniform = 5.915   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.034  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 1.000   grad norm = 0.974   grad norm uniform = 34.215   loss each uniform = 4.854   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.141   grad norm uniform = 38.905   loss each uniform = 8.182   feat norm = 0.458  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.576  
Average acc: 0.818  
Average grad norm: 7.022  
Average grad norm uniform: 32.054  
Average loss each uniform: 5.874  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.987   grad norm = 0.563   grad norm uniform = 33.684   loss each uniform = 7.627   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.097  exp loss = 1.175  adjusted loss = 1.175  adv prob = 0.250000   acc = 0.659   grad norm = 13.485   grad norm uniform = 29.349   loss each uniform = 3.768   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.285  exp loss = 1.432  adjusted loss = 1.432  adv prob = 0.250000   acc = 0.632   grad norm = 12.731   grad norm uniform = 28.878   loss each uniform = 4.079   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.110  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.970   grad norm = 1.349   grad norm uniform = 38.984   loss each uniform = 8.889   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8181818723678589


Epoch [21]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.077  
Average grad norm uniform: 35.998  
Average loss each uniform: 8.483  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 34.897   loss each uniform = 8.751   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.204   grad norm uniform = 40.232   loss each uniform = 6.037   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.033  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 1.000   grad norm = 0.861   grad norm uniform = 34.466   loss each uniform = 4.865   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.140   grad norm uniform = 38.986   loss each uniform = 8.212   feat norm = 0.459  

Validation:
Average incurred loss: 0.459  
Average sample loss: 0.440  
Average acc: 0.872  
Average grad norm: 5.174  
Average grad norm uniform: 33.042  
Average loss each uniform: 6.512  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.126   grad norm uniform = 34.500   loss each uniform = 9.039   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.463  exp loss = 0.518  adjusted loss = 0.518  adv prob = 0.250000   acc = 0.850   grad norm = 6.676   grad norm uniform = 32.265   loss each uniform = 4.680   feat norm = 0.470  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.258  exp loss = 2.413  adjusted loss = 2.413  adv prob = 0.250000   acc = 0.436   grad norm = 19.733   grad norm uniform = 27.491   loss each uniform = 3.767   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.244  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.932   grad norm = 3.077   grad norm uniform = 36.196   loss each uniform = 6.800   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645
Best model saved at epoch 21


Epoch [22]:
Training:
Average incurred loss: 0.003  
Average sample loss: 0.003  
Average acc: 1.000  
Average grad norm: 0.089  
Average grad norm uniform: 35.985  
Average loss each uniform: 8.497  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.047   grad norm uniform = 34.968   loss each uniform = 8.696   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.008  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000   grad norm = 0.324   grad norm uniform = 39.928   loss each uniform = 5.826   feat norm = 0.511  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.023  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000   grad norm = 0.660   grad norm uniform = 34.897   loss each uniform = 5.327   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.005  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.156   grad norm uniform = 38.722   loss each uniform = 8.470   feat norm = 0.455  

Validation:
Average incurred loss: 0.604  
Average sample loss: 0.589  
Average acc: 0.822  
Average grad norm: 7.140  
Average grad norm uniform: 32.357  
Average loss each uniform: 5.945  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.987   grad norm = 0.598   grad norm uniform = 34.010   loss each uniform = 7.721   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.137  exp loss = 1.227  adjusted loss = 1.227  adv prob = 0.250000   acc = 0.670   grad norm = 13.775   grad norm uniform = 29.632   loss each uniform = 3.799   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.259  exp loss = 1.380  adjusted loss = 1.380  adv prob = 0.250000   acc = 0.639   grad norm = 12.676   grad norm uniform = 29.323   loss each uniform = 4.126   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.110  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 0.962   grad norm = 1.329   grad norm uniform = 39.135   loss each uniform = 9.045   feat norm = 0.471  
Current lr: 0.001000
Current validation accuracy: 0.8223519325256348


Epoch [23]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.063  
Average grad norm uniform: 36.041  
Average loss each uniform: 8.640  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 34.957   loss each uniform = 8.863   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.203   grad norm uniform = 40.238   loss each uniform = 6.058   feat norm = 0.512  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.022  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000   grad norm = 0.663   grad norm uniform = 34.893   loss each uniform = 5.136   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.103   grad norm uniform = 38.958   loss each uniform = 8.535   feat norm = 0.457  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.520  
Average acc: 0.847  
Average grad norm: 6.328  
Average grad norm uniform: 31.953  
Average loss each uniform: 6.064  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.998   grad norm = 0.355   grad norm uniform = 33.686   loss each uniform = 8.145   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.886  exp loss = 0.957  adjusted loss = 0.957  adv prob = 0.250000   acc = 0.734   grad norm = 11.272   grad norm uniform = 29.682   loss each uniform = 3.984   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.544  exp loss = 1.688  adjusted loss = 1.688  adv prob = 0.250000   acc = 0.602   grad norm = 14.592   grad norm uniform = 28.066   loss each uniform = 3.867   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.139  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.955   grad norm = 1.711   grad norm uniform = 37.713   loss each uniform = 8.246   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [24]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.067  
Average grad norm uniform: 36.030  
Average loss each uniform: 8.692  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 34.945   loss each uniform = 8.938   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.249   grad norm uniform = 40.222   loss each uniform = 6.104   feat norm = 0.513  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.021  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000   grad norm = 0.609   grad norm uniform = 35.143   loss each uniform = 5.400   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.115   grad norm uniform = 38.937   loss each uniform = 8.502   feat norm = 0.457  

Validation:
Average incurred loss: 0.486  
Average sample loss: 0.468  
Average acc: 0.872  
Average grad norm: 5.558  
Average grad norm uniform: 33.319  
Average loss each uniform: 6.562  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.240   grad norm uniform = 34.678   loss each uniform = 8.877   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.680  exp loss = 0.738  adjusted loss = 0.738  adv prob = 0.250000   acc = 0.811   grad norm = 8.848   grad norm uniform = 32.043   loss each uniform = 4.541   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.788  exp loss = 1.926  adjusted loss = 1.926  adv prob = 0.250000   acc = 0.564   grad norm = 16.084   grad norm uniform = 28.213   loss each uniform = 3.970   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.955   grad norm = 2.180   grad norm uniform = 38.123   loss each uniform = 8.101   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8723936080932617
Best model saved at epoch 24


Epoch [25]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.053  
Average grad norm uniform: 36.066  
Average loss each uniform: 8.788  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 34.957   loss each uniform = 9.011   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.181   grad norm uniform = 40.427   loss each uniform = 6.189   feat norm = 0.513  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.019  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000   grad norm = 0.545   grad norm uniform = 35.016   loss each uniform = 5.278   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.089   grad norm uniform = 39.033   loss each uniform = 8.688   feat norm = 0.457  

Validation:
Average incurred loss: 0.504  
Average sample loss: 0.485  
Average acc: 0.862  
Average grad norm: 5.814  
Average grad norm uniform: 33.049  
Average loss each uniform: 6.440  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.238   grad norm uniform = 34.757   loss each uniform = 8.803   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.709  exp loss = 0.786  adjusted loss = 0.786  adv prob = 0.250000   acc = 0.790   grad norm = 9.313   grad norm uniform = 31.367   loss each uniform = 4.357   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.853  exp loss = 1.980  adjusted loss = 1.980  adv prob = 0.250000   acc = 0.549   grad norm = 16.799   grad norm uniform = 27.982   loss each uniform = 3.914   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.955   grad norm = 2.150   grad norm uniform = 38.017   loss each uniform = 7.969   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8623853325843811


Epoch [26]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.054  
Average grad norm uniform: 36.073  
Average loss each uniform: 8.831  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 34.990   loss each uniform = 9.024   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.226   grad norm uniform = 40.273   loss each uniform = 6.131   feat norm = 0.513  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.012  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000   grad norm = 0.379   grad norm uniform = 35.504   loss each uniform = 5.573   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.088   grad norm uniform = 38.956   loss each uniform = 8.835   feat norm = 0.456  

Validation:
Average incurred loss: 0.505  
Average sample loss: 0.488  
Average acc: 0.860  
Average grad norm: 5.802  
Average grad norm uniform: 32.533  
Average loss each uniform: 6.401  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.264   grad norm uniform = 34.122   loss each uniform = 8.673   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.750  exp loss = 0.810  adjusted loss = 0.810  adv prob = 0.250000   acc = 0.779   grad norm = 9.634   grad norm uniform = 30.919   loss each uniform = 4.341   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.725  exp loss = 1.867  adjusted loss = 1.867  adv prob = 0.250000   acc = 0.564   grad norm = 15.613   grad norm uniform = 27.710   loss each uniform = 3.908   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.955   grad norm = 2.010   grad norm uniform = 37.427   loss each uniform = 8.131   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8598833084106445


Epoch [27]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.051  
Average grad norm uniform: 36.070  
Average loss each uniform: 8.907  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 34.952   loss each uniform = 9.124   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.153   grad norm uniform = 40.548   loss each uniform = 6.372   feat norm = 0.515  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.019  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000   grad norm = 0.560   grad norm uniform = 35.310   loss each uniform = 5.538   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 39.032   loss each uniform = 8.811   feat norm = 0.456  

Validation:
Average incurred loss: 0.532  
Average sample loss: 0.516  
Average acc: 0.850  
Average grad norm: 6.092  
Average grad norm uniform: 33.138  
Average loss each uniform: 6.501  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.335   grad norm uniform = 34.642   loss each uniform = 8.727   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.851  exp loss = 0.936  adjusted loss = 0.936  adv prob = 0.250000   acc = 0.745   grad norm = 10.570   grad norm uniform = 31.042   loss each uniform = 4.322   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.618  exp loss = 1.740  adjusted loss = 1.740  adv prob = 0.250000   acc = 0.602   grad norm = 14.875   grad norm uniform = 29.545   loss each uniform = 4.110   feat norm = 0.439  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.955   grad norm = 1.837   grad norm uniform = 38.793   loss each uniform = 8.714   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8498748540878296


Epoch [28]:
Training:
Average incurred loss: 0.002  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.054  
Average grad norm uniform: 36.069  
Average loss each uniform: 8.955  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 34.968   loss each uniform = 9.173   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.196   grad norm uniform = 40.447   loss each uniform = 6.374   feat norm = 0.515  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.016  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000   grad norm = 0.493   grad norm uniform = 35.245   loss each uniform = 5.486   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.093   grad norm uniform = 38.997   loss each uniform = 8.866   feat norm = 0.456  

Validation:
Average incurred loss: 0.479  
Average sample loss: 0.458  
Average acc: 0.872  
Average grad norm: 5.149  
Average grad norm uniform: 33.286  
Average loss each uniform: 6.838  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.115   grad norm uniform = 34.518   loss each uniform = 9.474   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.492  exp loss = 0.545  adjusted loss = 0.545  adv prob = 0.250000   acc = 0.852   grad norm = 6.698   grad norm uniform = 32.702   loss each uniform = 4.909   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.332  exp loss = 2.489  adjusted loss = 2.489  adv prob = 0.250000   acc = 0.444   grad norm = 19.518   grad norm uniform = 27.771   loss each uniform = 3.950   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.250  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 0.925   grad norm = 3.025   grad norm uniform = 36.526   loss each uniform = 7.228   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8723937273025513
Best model saved at epoch 28


Epoch [29]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.046  
Average grad norm uniform: 36.093  
Average loss each uniform: 9.035  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 34.977   loss each uniform = 9.232   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.211   grad norm uniform = 40.493   loss each uniform = 6.444   feat norm = 0.516  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.011  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.339   grad norm uniform = 35.451   loss each uniform = 5.541   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.063   grad norm uniform = 39.054   loss each uniform = 9.018   feat norm = 0.456  

Validation:
Average incurred loss: 0.529  
Average sample loss: 0.512  
Average acc: 0.855  
Average grad norm: 5.966  
Average grad norm uniform: 32.922  
Average loss each uniform: 6.528  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.998   grad norm = 0.292   grad norm uniform = 34.342   loss each uniform = 8.805   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.823  exp loss = 0.891  adjusted loss = 0.891  adv prob = 0.250000   acc = 0.760   grad norm = 10.218   grad norm uniform = 31.073   loss each uniform = 4.329   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.691  exp loss = 1.821  adjusted loss = 1.821  adv prob = 0.250000   acc = 0.586   grad norm = 15.148   grad norm uniform = 28.863   loss each uniform = 4.082   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.955   grad norm = 1.812   grad norm uniform = 38.475   loss each uniform = 8.680   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8548790216445923


Epoch [30]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.047  
Average grad norm uniform: 36.084  
Average loss each uniform: 9.073  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 34.970   loss each uniform = 9.289   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.185   grad norm uniform = 40.585   loss each uniform = 6.390   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.016  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000   grad norm = 0.460   grad norm uniform = 35.203   loss each uniform = 5.442   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 39.032   loss each uniform = 9.017   feat norm = 0.456  

Validation:
Average incurred loss: 0.492  
Average sample loss: 0.473  
Average acc: 0.868  
Average grad norm: 5.334  
Average grad norm uniform: 33.083  
Average loss each uniform: 6.769  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.149   grad norm uniform = 34.452   loss each uniform = 9.308   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.601  exp loss = 0.662  adjusted loss = 0.662  adv prob = 0.250000   acc = 0.824   grad norm = 7.792   grad norm uniform = 32.237   loss each uniform = 4.747   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.111  exp loss = 2.244  adjusted loss = 2.244  adv prob = 0.250000   acc = 0.489   grad norm = 17.816   grad norm uniform = 27.282   loss each uniform = 3.975   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.204  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.947   grad norm = 2.446   grad norm uniform = 37.043   loss each uniform = 7.734   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [31]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.045  
Average grad norm uniform: 36.087  
Average loss each uniform: 9.119  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 34.971   loss each uniform = 9.327   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.182   grad norm uniform = 40.651   loss each uniform = 6.594   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.371   grad norm uniform = 35.584   loss each uniform = 5.723   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 39.012   loss each uniform = 9.050   feat norm = 0.455  

Validation:
Average incurred loss: 0.583  
Average sample loss: 0.567  
Average acc: 0.840  
Average grad norm: 6.514  
Average grad norm uniform: 32.853  
Average loss each uniform: 6.465  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.987   grad norm = 0.412   grad norm uniform = 34.310   loss each uniform = 8.586   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.014  exp loss = 1.112  adjusted loss = 1.112  adv prob = 0.250000   acc = 0.721   grad norm = 11.975   grad norm uniform = 30.592   loss each uniform = 4.180   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.514  exp loss = 1.648  adjusted loss = 1.648  adv prob = 0.250000   acc = 0.617   grad norm = 13.816   grad norm uniform = 29.638   loss each uniform = 4.266   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.130  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.962   grad norm = 1.500   grad norm uniform = 38.876   loss each uniform = 9.220   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8398665189743042


Epoch [32]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.044  
Average grad norm uniform: 36.094  
Average loss each uniform: 9.188  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 34.961   loss each uniform = 9.411   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.138   grad norm uniform = 40.538   loss each uniform = 6.660   feat norm = 0.515  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.011  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000   grad norm = 0.340   grad norm uniform = 35.675   loss each uniform = 5.809   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 39.090   loss each uniform = 9.068   feat norm = 0.456  

Validation:
Average incurred loss: 0.507  
Average sample loss: 0.489  
Average acc: 0.863  
Average grad norm: 5.565  
Average grad norm uniform: 32.545  
Average loss each uniform: 6.658  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.207   grad norm uniform = 34.120   loss each uniform = 9.084   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.712  exp loss = 0.781  adjusted loss = 0.781  adv prob = 0.250000   acc = 0.796   grad norm = 8.873   grad norm uniform = 31.082   loss each uniform = 4.533   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.870  exp loss = 2.011  adjusted loss = 2.011  adv prob = 0.250000   acc = 0.541   grad norm = 16.206   grad norm uniform = 27.521   loss each uniform = 4.009   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.947   grad norm = 2.146   grad norm uniform = 37.164   loss each uniform = 8.233   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [33]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.037  
Average grad norm uniform: 36.120  
Average loss each uniform: 9.242  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 34.984   loss each uniform = 9.442   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.139   grad norm uniform = 40.787   loss each uniform = 6.598   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.291   grad norm uniform = 35.732   loss each uniform = 5.893   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 39.087   loss each uniform = 9.217   feat norm = 0.455  

Validation:
Average incurred loss: 0.542  
Average sample loss: 0.523  
Average acc: 0.855  
Average grad norm: 5.994  
Average grad norm uniform: 33.238  
Average loss each uniform: 6.647  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.344   grad norm uniform = 34.431   loss each uniform = 8.864   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.873  exp loss = 0.949  adjusted loss = 0.949  adv prob = 0.250000   acc = 0.760   grad norm = 10.473   grad norm uniform = 31.484   loss each uniform = 4.435   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.625  exp loss = 1.757  adjusted loss = 1.757  adv prob = 0.250000   acc = 0.609   grad norm = 14.424   grad norm uniform = 29.581   loss each uniform = 4.248   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.151  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.955   grad norm = 1.709   grad norm uniform = 38.850   loss each uniform = 9.009   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8548790216445923


Epoch [34]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.037  
Average grad norm uniform: 36.118  
Average loss each uniform: 9.295  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 34.983   loss each uniform = 9.489   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.163   grad norm uniform = 40.702   loss each uniform = 6.676   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.302   grad norm uniform = 35.584   loss each uniform = 5.783   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.059   grad norm uniform = 39.106   loss each uniform = 9.292   feat norm = 0.455  

Validation:
Average incurred loss: 0.563  
Average sample loss: 0.547  
Average acc: 0.847  
Average grad norm: 6.163  
Average grad norm uniform: 32.854  
Average loss each uniform: 6.642  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.998   grad norm = 0.325   grad norm uniform = 34.190   loss each uniform = 8.903   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.934  exp loss = 1.008  adjusted loss = 1.008  adv prob = 0.250000   acc = 0.734   grad norm = 10.974   grad norm uniform = 30.985   loss each uniform = 4.368   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.613  exp loss = 1.751  adjusted loss = 1.751  adv prob = 0.250000   acc = 0.609   grad norm = 14.292   grad norm uniform = 29.046   loss each uniform = 4.219   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.147  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.955   grad norm = 1.681   grad norm uniform = 38.520   loss each uniform = 9.095   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [35]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.041  
Average grad norm uniform: 36.098  
Average loss each uniform: 9.338  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 34.941   loss each uniform = 9.566   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.119   grad norm uniform = 40.886   loss each uniform = 6.964   feat norm = 0.519  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.015  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000   grad norm = 0.465   grad norm uniform = 35.251   loss each uniform = 5.724   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 39.139   loss each uniform = 9.191   feat norm = 0.456  

Validation:
Average incurred loss: 0.496  
Average sample loss: 0.476  
Average acc: 0.871  
Average grad norm: 5.242  
Average grad norm uniform: 33.286  
Average loss each uniform: 6.971  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.124   grad norm uniform = 34.584   loss each uniform = 9.626   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.575  exp loss = 0.638  adjusted loss = 0.638  adv prob = 0.250000   acc = 0.843   grad norm = 7.377   grad norm uniform = 32.547   loss each uniform = 4.911   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.220  exp loss = 2.375  adjusted loss = 2.375  adv prob = 0.250000   acc = 0.459   grad norm = 18.349   grad norm uniform = 27.801   loss each uniform = 4.055   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.224  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.932   grad norm = 2.630   grad norm uniform = 36.805   loss each uniform = 7.784   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [36]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.040  
Average grad norm uniform: 36.109  
Average loss each uniform: 9.360  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 34.975   loss each uniform = 9.565   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.131   grad norm uniform = 40.781   loss each uniform = 6.902   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.012  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000   grad norm = 0.340   grad norm uniform = 35.596   loss each uniform = 5.915   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.072   grad norm uniform = 39.074   loss each uniform = 9.293   feat norm = 0.455  

Validation:
Average incurred loss: 0.505  
Average sample loss: 0.486  
Average acc: 0.873  
Average grad norm: 5.348  
Average grad norm uniform: 33.258  
Average loss each uniform: 6.994  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.171   grad norm uniform = 34.598   loss each uniform = 9.578   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.653  exp loss = 0.725  adjusted loss = 0.725  adv prob = 0.250000   acc = 0.824   grad norm = 8.060   grad norm uniform = 32.245   loss each uniform = 4.873   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.051  exp loss = 2.209  adjusted loss = 2.209  adv prob = 0.250000   acc = 0.534   grad norm = 17.084   grad norm uniform = 27.951   loss each uniform = 4.116   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.194  adjusted loss = 0.194  adv prob = 0.250000   acc = 0.947   grad norm = 2.290   grad norm uniform = 37.413   loss each uniform = 8.236   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485
Best model saved at epoch 36


Epoch [37]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.030  
Average grad norm uniform: 36.133  
Average loss each uniform: 9.429  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 35.000   loss each uniform = 9.615   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.106   grad norm uniform = 40.836   loss each uniform = 6.856   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.252   grad norm uniform = 35.794   loss each uniform = 6.164   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.047   grad norm uniform = 39.084   loss each uniform = 9.438   feat norm = 0.455  

Validation:
Average incurred loss: 0.497  
Average sample loss: 0.478  
Average acc: 0.872  
Average grad norm: 5.345  
Average grad norm uniform: 33.110  
Average loss each uniform: 6.924  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.168   grad norm uniform = 34.443   loss each uniform = 9.455   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.648  exp loss = 0.715  adjusted loss = 0.715  adv prob = 0.250000   acc = 0.820   grad norm = 8.107   grad norm uniform = 32.106   loss each uniform = 4.820   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.992  exp loss = 2.157  adjusted loss = 2.157  adv prob = 0.250000   acc = 0.534   grad norm = 16.897   grad norm uniform = 27.700   loss each uniform = 4.086   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.947   grad norm = 2.298   grad norm uniform = 37.355   loss each uniform = 8.243   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8715596795082092


Epoch [38]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.028  
Average grad norm uniform: 36.145  
Average loss each uniform: 9.476  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 34.997   loss each uniform = 9.664   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.101   grad norm uniform = 40.839   loss each uniform = 6.837   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.007  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000   grad norm = 0.227   grad norm uniform = 35.952   loss each uniform = 6.176   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 39.139   loss each uniform = 9.487   feat norm = 0.455  

Validation:
Average incurred loss: 0.546  
Average sample loss: 0.529  
Average acc: 0.857  
Average grad norm: 5.879  
Average grad norm uniform: 33.304  
Average loss each uniform: 6.849  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.316   grad norm uniform = 34.578   loss each uniform = 9.209   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.861  exp loss = 0.945  adjusted loss = 0.945  adv prob = 0.250000   acc = 0.760   grad norm = 10.090   grad norm uniform = 31.734   loss each uniform = 4.580   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.699  exp loss = 1.827  adjusted loss = 1.827  adv prob = 0.250000   acc = 0.609   grad norm = 14.690   grad norm uniform = 29.221   loss each uniform = 4.293   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.955   grad norm = 1.845   grad norm uniform = 38.408   loss each uniform = 9.068   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [39]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.002  
Average acc: 1.000  
Average grad norm: 0.039  
Average grad norm uniform: 36.120  
Average loss each uniform: 9.506  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 34.995   loss each uniform = 9.704   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.101   grad norm uniform = 40.783   loss each uniform = 6.819   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.016  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 1.000   grad norm = 0.483   grad norm uniform = 35.336   loss each uniform = 5.968   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.003  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.085   grad norm uniform = 39.073   loss each uniform = 9.506   feat norm = 0.455  

Validation:
Average incurred loss: 0.513  
Average sample loss: 0.493  
Average acc: 0.872  
Average grad norm: 5.276  
Average grad norm uniform: 33.568  
Average loss each uniform: 7.205  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.114   grad norm uniform = 34.829   loss each uniform = 9.951   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.664  adjusted loss = 0.664  adv prob = 0.250000   acc = 0.841   grad norm = 7.494   grad norm uniform = 33.031   loss each uniform = 5.089   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.254  exp loss = 2.400  adjusted loss = 2.400  adv prob = 0.250000   acc = 0.459   grad norm = 18.294   grad norm uniform = 27.603   loss each uniform = 4.126   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.947   grad norm = 2.614   grad norm uniform = 36.989   loss each uniform = 8.057   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8715596795082092


Epoch [40]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.028  
Average grad norm uniform: 36.155  
Average loss each uniform: 9.500  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.098   loss each uniform = 9.589   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.128   grad norm uniform = 40.717   loss each uniform = 6.671   feat norm = 0.517  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.162   grad norm uniform = 35.679   loss each uniform = 6.270   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 38.884   loss each uniform = 9.869   feat norm = 0.451  

Validation:
Average incurred loss: 0.671  
Average sample loss: 0.656  
Average acc: 0.817  
Average grad norm: 7.044  
Average grad norm uniform: 32.630  
Average loss each uniform: 6.610  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.987   grad norm = 0.564   grad norm uniform = 34.080   loss each uniform = 8.629   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.276  exp loss = 1.380  adjusted loss = 1.380  adv prob = 0.250000   acc = 0.646   grad norm = 13.779   grad norm uniform = 30.270   loss each uniform = 4.178   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.364  exp loss = 1.495  adjusted loss = 1.495  adv prob = 0.250000   acc = 0.662   grad norm = 12.089   grad norm uniform = 29.723   loss each uniform = 4.572   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.114  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.977   grad norm = 1.152   grad norm uniform = 38.721   loss each uniform = 10.080   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8173477649688721


Epoch [41]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.029  
Average grad norm uniform: 36.153  
Average loss each uniform: 9.538  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.088   loss each uniform = 9.640   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.132   grad norm uniform = 40.786   loss each uniform = 6.801   feat norm = 0.518  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.201   grad norm uniform = 35.688   loss each uniform = 6.325   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 38.893   loss each uniform = 9.849   feat norm = 0.451  

Validation:
Average incurred loss: 0.525  
Average sample loss: 0.507  
Average acc: 0.867  
Average grad norm: 5.568  
Average grad norm uniform: 33.118  
Average loss each uniform: 7.011  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.242   grad norm uniform = 34.580   loss each uniform = 9.528   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.759  exp loss = 0.827  adjusted loss = 0.827  adv prob = 0.250000   acc = 0.796   grad norm = 9.093   grad norm uniform = 31.710   loss each uniform = 4.753   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.866  exp loss = 1.973  adjusted loss = 1.973  adv prob = 0.250000   acc = 0.564   grad norm = 15.571   grad norm uniform = 28.502   loss each uniform = 4.268   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.172  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955   grad norm = 1.916   grad norm uniform = 37.536   loss each uniform = 8.829   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [42]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.028  
Average grad norm uniform: 36.137  
Average loss each uniform: 9.583  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 35.035   loss each uniform = 9.730   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.117   grad norm uniform = 40.894   loss each uniform = 6.992   feat norm = 0.519  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.174   grad norm uniform = 35.970   loss each uniform = 6.400   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 38.964   loss each uniform = 9.714   feat norm = 0.452  

Validation:
Average incurred loss: 0.528  
Average sample loss: 0.511  
Average acc: 0.863  
Average grad norm: 5.652  
Average grad norm uniform: 32.677  
Average loss each uniform: 6.817  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.267   grad norm uniform = 33.953   loss each uniform = 9.193   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.811  exp loss = 0.893  adjusted loss = 0.893  adv prob = 0.250000   acc = 0.777   grad norm = 9.589   grad norm uniform = 31.241   loss each uniform = 4.573   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.726  exp loss = 1.841  adjusted loss = 1.841  adv prob = 0.250000   acc = 0.602   grad norm = 14.652   grad norm uniform = 28.417   loss each uniform = 4.239   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.955   grad norm = 1.768   grad norm uniform = 37.487   loss each uniform = 8.914   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [43]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.027  
Average grad norm uniform: 36.143  
Average loss each uniform: 9.630  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 35.022   loss each uniform = 9.792   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.097   grad norm uniform = 41.051   loss each uniform = 7.042   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.163   grad norm uniform = 36.027   loss each uniform = 6.500   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 39.004   loss each uniform = 9.711   feat norm = 0.453  

Validation:
Average incurred loss: 0.534  
Average sample loss: 0.515  
Average acc: 0.863  
Average grad norm: 5.602  
Average grad norm uniform: 33.211  
Average loss each uniform: 7.096  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.197   grad norm uniform = 34.619   loss each uniform = 9.753   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.732  exp loss = 0.806  adjusted loss = 0.806  adv prob = 0.250000   acc = 0.796   grad norm = 8.816   grad norm uniform = 32.185   loss each uniform = 4.853   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.035  exp loss = 2.145  adjusted loss = 2.145  adv prob = 0.250000   acc = 0.541   grad norm = 16.717   grad norm uniform = 27.788   loss each uniform = 4.178   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947   grad norm = 2.208   grad norm uniform = 37.282   loss each uniform = 8.544   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [44]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.031  
Average grad norm uniform: 36.129  
Average loss each uniform: 9.657  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 35.007   loss each uniform = 9.839   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.110   grad norm uniform = 40.968   loss each uniform = 7.052   feat norm = 0.520  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.008  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.244   grad norm uniform = 35.722   loss each uniform = 6.116   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 39.021   loss each uniform = 9.696   feat norm = 0.453  

Validation:
Average incurred loss: 0.530  
Average sample loss: 0.513  
Average acc: 0.864  
Average grad norm: 5.572  
Average grad norm uniform: 32.731  
Average loss each uniform: 6.942  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.228   grad norm uniform = 33.989   loss each uniform = 9.421   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.792  exp loss = 0.867  adjusted loss = 0.867  adv prob = 0.250000   acc = 0.783   grad norm = 9.269   grad norm uniform = 31.392   loss each uniform = 4.687   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.808  exp loss = 1.930  adjusted loss = 1.930  adv prob = 0.250000   acc = 0.586   grad norm = 15.031   grad norm uniform = 28.308   loss each uniform = 4.217   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.955   grad norm = 1.920   grad norm uniform = 37.430   loss each uniform = 8.858   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [45]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.025  
Average grad norm uniform: 36.141  
Average loss each uniform: 9.725  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 35.004   loss each uniform = 9.902   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.083   grad norm uniform = 40.923   loss each uniform = 7.196   feat norm = 0.519  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.228   grad norm uniform = 35.944   loss each uniform = 6.294   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 39.084   loss each uniform = 9.760   feat norm = 0.453  

Validation:
Average incurred loss: 0.507  
Average sample loss: 0.488  
Average acc: 0.877  
Average grad norm: 5.182  
Average grad norm uniform: 33.519  
Average loss each uniform: 7.275  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.175   grad norm uniform = 34.747   loss each uniform = 9.932   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.642  exp loss = 0.708  adjusted loss = 0.708  adv prob = 0.250000   acc = 0.833   grad norm = 7.648   grad norm uniform = 32.725   loss each uniform = 5.129   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.094  exp loss = 2.244  adjusted loss = 2.244  adv prob = 0.250000   acc = 0.534   grad norm = 16.966   grad norm uniform = 28.274   loss each uniform = 4.261   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.947   grad norm = 2.338   grad norm uniform = 37.233   loss each uniform = 8.478   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8765637874603271
Best model saved at epoch 45


Epoch [46]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.023  
Average grad norm uniform: 36.153  
Average loss each uniform: 9.759  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 35.011   loss each uniform = 9.930   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.082   grad norm uniform = 41.078   loss each uniform = 7.163   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.163   grad norm uniform = 36.113   loss each uniform = 6.473   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 39.079   loss each uniform = 9.819   feat norm = 0.453  

Validation:
Average incurred loss: 0.549  
Average sample loss: 0.532  
Average acc: 0.862  
Average grad norm: 5.676  
Average grad norm uniform: 33.454  
Average loss each uniform: 7.196  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.264   grad norm uniform = 34.616   loss each uniform = 9.714   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.829  exp loss = 0.910  adjusted loss = 0.910  adv prob = 0.250000   acc = 0.777   grad norm = 9.505   grad norm uniform = 32.292   loss each uniform = 4.881   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.841  exp loss = 1.992  adjusted loss = 1.992  adv prob = 0.250000   acc = 0.586   grad norm = 15.077   grad norm uniform = 28.793   loss each uniform = 4.406   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.171  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.955   grad norm = 1.865   grad norm uniform = 38.103   loss each uniform = 9.256   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [47]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.024  
Average grad norm uniform: 36.153  
Average loss each uniform: 9.809  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 34.997   loss each uniform = 9.987   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 41.019   loss each uniform = 7.251   feat norm = 0.520  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.182   grad norm uniform = 35.984   loss each uniform = 6.360   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 39.140   loss each uniform = 9.847   feat norm = 0.454  

Validation:
Average incurred loss: 0.561  
Average sample loss: 0.542  
Average acc: 0.857  
Average grad norm: 5.895  
Average grad norm uniform: 33.179  
Average loss each uniform: 7.045  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.288   grad norm uniform = 34.342   loss each uniform = 9.506   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.872  exp loss = 0.947  adjusted loss = 0.947  adv prob = 0.250000   acc = 0.768   grad norm = 10.077   grad norm uniform = 31.760   loss each uniform = 4.717   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.797  exp loss = 1.916  adjusted loss = 1.916  adv prob = 0.250000   acc = 0.571   grad norm = 15.062   grad norm uniform = 28.864   loss each uniform = 4.335   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.955   grad norm = 1.766   grad norm uniform = 38.382   loss each uniform = 9.272   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8565471768379211


Epoch [48]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.164  
Average loss each uniform: 9.838  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.022   loss each uniform = 9.994   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 40.932   loss each uniform = 7.370   feat norm = 0.519  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.156   grad norm uniform = 35.937   loss each uniform = 6.388   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 39.127   loss each uniform = 9.937   feat norm = 0.453  

Validation:
Average incurred loss: 0.660  
Average sample loss: 0.643  
Average acc: 0.827  
Average grad norm: 6.784  
Average grad norm uniform: 33.111  
Average loss each uniform: 6.861  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.987   grad norm = 0.519   grad norm uniform = 34.048   loss each uniform = 8.904   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.231  exp loss = 1.330  adjusted loss = 1.330  adv prob = 0.250000   acc = 0.676   grad norm = 13.079   grad norm uniform = 31.157   loss each uniform = 4.402   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.424  exp loss = 1.565  adjusted loss = 1.565  adv prob = 0.250000   acc = 0.647   grad norm = 12.225   grad norm uniform = 30.155   loss each uniform = 4.743   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.970   grad norm = 1.289   grad norm uniform = 39.624   loss each uniform = 10.419   feat norm = 0.469  
Current lr: 0.001000
Current validation accuracy: 0.8265221118927002


Epoch [49]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.020  
Average grad norm uniform: 36.168  
Average loss each uniform: 9.871  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.020   loss each uniform = 10.033   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.055   grad norm uniform = 41.105   loss each uniform = 7.501   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.168   grad norm uniform = 35.981   loss each uniform = 6.494   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 39.118   loss each uniform = 9.928   feat norm = 0.453  

Validation:
Average incurred loss: 0.507  
Average sample loss: 0.486  
Average acc: 0.875  
Average grad norm: 5.032  
Average grad norm uniform: 33.757  
Average loss each uniform: 7.519  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.108   grad norm uniform = 34.872   loss each uniform = 10.362   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.571  exp loss = 0.625  adjusted loss = 0.625  adv prob = 0.250000   acc = 0.848   grad norm = 6.917   grad norm uniform = 33.447   loss each uniform = 5.391   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.309  exp loss = 2.448  adjusted loss = 2.448  adv prob = 0.250000   acc = 0.474   grad norm = 18.115   grad norm uniform = 27.739   loss each uniform = 4.269   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.246  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.932   grad norm = 2.632   grad norm uniform = 36.943   loss each uniform = 8.244   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8748957514762878


Epoch [50]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.021  
Average grad norm uniform: 36.161  
Average loss each uniform: 9.898  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.006   loss each uniform = 10.076   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 40.988   loss each uniform = 7.397   feat norm = 0.520  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.136   grad norm uniform = 35.999   loss each uniform = 6.427   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 39.150   loss each uniform = 9.928   feat norm = 0.453  

Validation:
Average incurred loss: 0.585  
Average sample loss: 0.568  
Average acc: 0.849  
Average grad norm: 6.054  
Average grad norm uniform: 33.206  
Average loss each uniform: 7.075  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.998   grad norm = 0.308   grad norm uniform = 34.348   loss each uniform = 9.534   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.949  exp loss = 1.030  adjusted loss = 1.030  adv prob = 0.250000   acc = 0.742   grad norm = 10.657   grad norm uniform = 31.720   loss each uniform = 4.680   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.749  exp loss = 1.875  adjusted loss = 1.875  adv prob = 0.250000   acc = 0.594   grad norm = 14.485   grad norm uniform = 29.218   loss each uniform = 4.397   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.955   grad norm = 1.669   grad norm uniform = 38.389   loss each uniform = 9.507   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8490408658981323


Epoch [51]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.163  
Average loss each uniform: 9.920  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 35.023   loss each uniform = 10.093   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.099   grad norm uniform = 40.991   loss each uniform = 7.382   feat norm = 0.520  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.197   grad norm uniform = 35.838   loss each uniform = 6.280   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.116   loss each uniform = 9.981   feat norm = 0.453  

Validation:
Average incurred loss: 0.684  
Average sample loss: 0.667  
Average acc: 0.820  
Average grad norm: 6.972  
Average grad norm uniform: 32.632  
Average loss each uniform: 6.805  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.987   grad norm = 0.536   grad norm uniform = 33.671   loss each uniform = 8.839   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.296  exp loss = 1.398  adjusted loss = 1.398  adv prob = 0.250000   acc = 0.657   grad norm = 13.580   grad norm uniform = 30.461   loss each uniform = 4.312   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.408  exp loss = 1.534  adjusted loss = 1.534  adv prob = 0.250000   acc = 0.654   grad norm = 12.155   grad norm uniform = 29.850   loss each uniform = 4.708   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.122  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.970   grad norm = 1.230   grad norm uniform = 39.369   loss each uniform = 10.495   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8198498487472534


Epoch [52]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.146  
Average loss each uniform: 9.934  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 34.978   loss each uniform = 10.134   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.072   grad norm uniform = 41.061   loss each uniform = 7.381   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.181   grad norm uniform = 36.073   loss each uniform = 6.493   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 39.159   loss each uniform = 9.897   feat norm = 0.454  

Validation:
Average incurred loss: 0.598  
Average sample loss: 0.580  
Average acc: 0.845  
Average grad norm: 6.137  
Average grad norm uniform: 33.378  
Average loss each uniform: 7.151  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.350   grad norm uniform = 34.272   loss each uniform = 9.494   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.999  exp loss = 1.083  adjusted loss = 1.083  adv prob = 0.250000   acc = 0.725   grad norm = 11.056   grad norm uniform = 31.865   loss each uniform = 4.707   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.686  exp loss = 1.824  adjusted loss = 1.824  adv prob = 0.250000   acc = 0.624   grad norm = 13.794   grad norm uniform = 29.887   loss each uniform = 4.648   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.955   grad norm = 1.566   grad norm uniform = 39.032   loss each uniform = 9.988   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8448706865310669


Epoch [53]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.155  
Average loss each uniform: 9.977  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 34.964   loss each uniform = 10.179   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 41.189   loss each uniform = 7.587   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.177   grad norm uniform = 36.373   loss each uniform = 6.576   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 39.206   loss each uniform = 9.904   feat norm = 0.454  

Validation:
Average incurred loss: 0.598  
Average sample loss: 0.580  
Average acc: 0.850  
Average grad norm: 6.110  
Average grad norm uniform: 33.296  
Average loss each uniform: 7.121  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.321   grad norm uniform = 34.297   loss each uniform = 9.509   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.981  exp loss = 1.065  adjusted loss = 1.065  adv prob = 0.250000   acc = 0.745   grad norm = 10.894   grad norm uniform = 31.772   loss each uniform = 4.695   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.747  exp loss = 1.883  adjusted loss = 1.883  adv prob = 0.250000   acc = 0.602   grad norm = 14.205   grad norm uniform = 29.654   loss each uniform = 4.554   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.158  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.955   grad norm = 1.579   grad norm uniform = 38.762   loss each uniform = 9.804   feat norm = 0.465  
Current lr: 0.001000
Current validation accuracy: 0.8498748540878296


Epoch [54]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.020  
Average grad norm uniform: 36.162  
Average loss each uniform: 10.020  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 34.987   loss each uniform = 10.218   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.056   grad norm uniform = 41.162   loss each uniform = 7.541   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.156   grad norm uniform = 36.286   loss each uniform = 6.785   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 39.175   loss each uniform = 9.967   feat norm = 0.454  

Validation:
Average incurred loss: 0.578  
Average sample loss: 0.561  
Average acc: 0.847  
Average grad norm: 5.996  
Average grad norm uniform: 33.247  
Average loss each uniform: 7.076  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.333   grad norm uniform = 34.335   loss each uniform = 9.453   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.954  exp loss = 1.044  adjusted loss = 1.044  adv prob = 0.250000   acc = 0.738   grad norm = 10.650   grad norm uniform = 31.663   loss each uniform = 4.679   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.665  exp loss = 1.796  adjusted loss = 1.796  adv prob = 0.250000   acc = 0.617   grad norm = 13.948   grad norm uniform = 29.711   loss each uniform = 4.513   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.955   grad norm = 1.619   grad norm uniform = 38.516   loss each uniform = 9.691   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8473728895187378


Epoch [55]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.017  
Average grad norm uniform: 36.174  
Average loss each uniform: 10.058  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 34.984   loss each uniform = 10.246   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 41.156   loss each uniform = 7.518   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.147   grad norm uniform = 36.229   loss each uniform = 6.565   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 39.241   loss each uniform = 10.062   feat norm = 0.454  

Validation:
Average incurred loss: 0.530  
Average sample loss: 0.510  
Average acc: 0.872  
Average grad norm: 5.244  
Average grad norm uniform: 34.031  
Average loss each uniform: 7.638  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.159   grad norm uniform = 35.197   loss each uniform = 10.484   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.669  exp loss = 0.726  adjusted loss = 0.726  adv prob = 0.250000   acc = 0.822   grad norm = 7.714   grad norm uniform = 33.563   loss each uniform = 5.390   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.195  exp loss = 2.360  adjusted loss = 2.360  adv prob = 0.250000   acc = 0.526   grad norm = 17.284   grad norm uniform = 28.239   loss each uniform = 4.370   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.216  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947   grad norm = 2.409   grad norm uniform = 37.370   loss each uniform = 8.788   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [56]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.169  
Average loss each uniform: 10.068  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 34.992   loss each uniform = 10.255   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 41.167   loss each uniform = 7.591   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.115   grad norm uniform = 36.260   loss each uniform = 6.679   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.186   loss each uniform = 10.062   feat norm = 0.453  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.532  
Average acc: 0.862  
Average grad norm: 5.601  
Average grad norm uniform: 33.367  
Average loss each uniform: 7.280  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.230   grad norm uniform = 34.441   loss each uniform = 9.839   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.814  exp loss = 0.888  adjusted loss = 0.888  adv prob = 0.250000   acc = 0.779   grad norm = 9.263   grad norm uniform = 32.195   loss each uniform = 4.953   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.894  exp loss = 2.041  adjusted loss = 2.041  adv prob = 0.250000   acc = 0.579   grad norm = 15.298   grad norm uniform = 29.090   loss each uniform = 4.425   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.955   grad norm = 1.935   grad norm uniform = 37.979   loss each uniform = 9.305   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [57]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.165  
Average loss each uniform: 10.072  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.004   loss each uniform = 10.275   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.059   grad norm uniform = 41.135   loss each uniform = 7.436   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.007  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.236   grad norm uniform = 35.906   loss each uniform = 6.391   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 39.156   loss each uniform = 10.053   feat norm = 0.453  

Validation:
Average incurred loss: 0.549  
Average sample loss: 0.530  
Average acc: 0.861  
Average grad norm: 5.575  
Average grad norm uniform: 32.904  
Average loss each uniform: 7.228  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.193   grad norm uniform = 34.268   loss each uniform = 9.909   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.772  exp loss = 0.841  adjusted loss = 0.841  adv prob = 0.250000   acc = 0.788   grad norm = 8.973   grad norm uniform = 31.727   loss each uniform = 4.897   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.035  exp loss = 2.199  adjusted loss = 2.199  adv prob = 0.250000   acc = 0.549   grad norm = 16.137   grad norm uniform = 27.989   loss each uniform = 4.304   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.947   grad norm = 2.002   grad norm uniform = 37.152   loss each uniform = 8.908   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [58]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.173  
Average loss each uniform: 10.111  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 34.998   loss each uniform = 10.291   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.054   grad norm uniform = 41.217   loss each uniform = 7.647   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.201   grad norm uniform = 35.811   loss each uniform = 6.475   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.201   loss each uniform = 10.137   feat norm = 0.453  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.547  
Average acc: 0.859  
Average grad norm: 5.647  
Average grad norm uniform: 33.370  
Average loss each uniform: 7.399  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.237   grad norm uniform = 34.335   loss each uniform = 10.034   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.831  exp loss = 0.910  adjusted loss = 0.910  adv prob = 0.250000   acc = 0.777   grad norm = 9.351   grad norm uniform = 32.404   loss each uniform = 5.014   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.968  exp loss = 2.105  adjusted loss = 2.105  adv prob = 0.250000   acc = 0.564   grad norm = 15.424   grad norm uniform = 28.599   loss each uniform = 4.493   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.955   grad norm = 1.891   grad norm uniform = 38.140   loss each uniform = 9.411   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [59]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.018  
Average grad norm uniform: 36.180  
Average loss each uniform: 10.134  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.024   loss each uniform = 10.318   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.064   grad norm uniform = 41.082   loss each uniform = 7.453   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.122   grad norm uniform = 36.289   loss each uniform = 6.747   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 39.144   loss each uniform = 10.173   feat norm = 0.453  

Validation:
Average incurred loss: 0.517  
Average sample loss: 0.496  
Average acc: 0.877  
Average grad norm: 4.954  
Average grad norm uniform: 33.952  
Average loss each uniform: 7.735  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 35.026   loss each uniform = 10.724   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.527  exp loss = 0.581  adjusted loss = 0.581  adv prob = 0.250000   acc = 0.861   grad norm = 6.393   grad norm uniform = 33.704   loss each uniform = 5.602   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.537  exp loss = 2.691  adjusted loss = 2.691  adv prob = 0.250000   acc = 0.444   grad norm = 19.145   grad norm uniform = 28.344   loss each uniform = 4.348   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.269  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.932   grad norm = 2.846   grad norm uniform = 36.662   loss each uniform = 8.104   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8765637874603271


Epoch [60]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.188  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.042   loss each uniform = 10.332   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 41.134   loss each uniform = 7.627   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.133   grad norm uniform = 36.099   loss each uniform = 6.757   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 39.143   loss each uniform = 10.339   feat norm = 0.452  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.575  
Average acc: 0.848  
Average grad norm: 5.938  
Average grad norm uniform: 33.548  
Average loss each uniform: 7.328  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.339   grad norm uniform = 34.546   loss each uniform = 9.773   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.985  exp loss = 1.065  adjusted loss = 1.065  adv prob = 0.250000   acc = 0.740   grad norm = 10.628   grad norm uniform = 32.093   loss each uniform = 4.877   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.682  exp loss = 1.820  adjusted loss = 1.820  adv prob = 0.250000   acc = 0.617   grad norm = 13.580   grad norm uniform = 30.055   loss each uniform = 4.678   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.153  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.955   grad norm = 1.519   grad norm uniform = 38.637   loss each uniform = 9.981   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [61]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.022  
Average grad norm uniform: 36.172  
Average loss each uniform: 10.166  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 35.033   loss each uniform = 10.341   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 41.170   loss each uniform = 7.484   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.127   grad norm uniform = 36.081   loss each uniform = 6.747   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 39.076   loss each uniform = 10.234   feat norm = 0.452  

Validation:
Average incurred loss: 0.509  
Average sample loss: 0.489  
Average acc: 0.879  
Average grad norm: 4.843  
Average grad norm uniform: 33.861  
Average loss each uniform: 7.812  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 34.728   loss each uniform = 10.741   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.553  exp loss = 0.614  adjusted loss = 0.614  adv prob = 0.250000   acc = 0.856   grad norm = 6.453   grad norm uniform = 33.803   loss each uniform = 5.653   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.386  exp loss = 2.536  adjusted loss = 2.536  adv prob = 0.250000   acc = 0.489   grad norm = 17.978   grad norm uniform = 28.204   loss each uniform = 4.420   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.261  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.925   grad norm = 2.768   grad norm uniform = 36.680   loss each uniform = 8.482   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8790659308433533
Best model saved at epoch 61


Epoch [62]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.180  
Average loss each uniform: 10.195  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.056   loss each uniform = 10.338   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.063   grad norm uniform = 41.126   loss each uniform = 7.585   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.149   grad norm uniform = 36.208   loss each uniform = 6.978   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.038   loss each uniform = 10.345   feat norm = 0.451  

Validation:
Average incurred loss: 0.530  
Average sample loss: 0.509  
Average acc: 0.875  
Average grad norm: 5.124  
Average grad norm uniform: 34.288  
Average loss each uniform: 7.836  
Average feat norm: 0.458  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.097   grad norm uniform = 35.388   loss each uniform = 10.811   feat norm = 0.435  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.606  exp loss = 0.667  adjusted loss = 0.667  adv prob = 0.250000   acc = 0.843   grad norm = 7.181   grad norm uniform = 33.939   loss each uniform = 5.591   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.407  exp loss = 2.597  adjusted loss = 2.597  adv prob = 0.250000   acc = 0.481   grad norm = 18.144   grad norm uniform = 28.602   loss each uniform = 4.461   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.239  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.940   grad norm = 2.551   grad norm uniform = 37.333   loss each uniform = 8.633   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8748958110809326


Epoch [63]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.017  
Average grad norm uniform: 36.191  
Average loss each uniform: 10.229  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.082   loss each uniform = 10.370   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.079   grad norm uniform = 41.132   loss each uniform = 7.437   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.153   grad norm uniform = 35.952   loss each uniform = 6.745   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.014   loss each uniform = 10.433   feat norm = 0.450  

Validation:
Average incurred loss: 0.610  
Average sample loss: 0.592  
Average acc: 0.845  
Average grad norm: 6.054  
Average grad norm uniform: 33.326  
Average loss each uniform: 7.299  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.346   grad norm uniform = 34.528   loss each uniform = 9.782   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.024  exp loss = 1.108  adjusted loss = 1.108  adv prob = 0.250000   acc = 0.730   grad norm = 10.881   grad norm uniform = 31.755   loss each uniform = 4.813   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.705  exp loss = 1.859  adjusted loss = 1.859  adv prob = 0.250000   acc = 0.617   grad norm = 13.731   grad norm uniform = 29.820   loss each uniform = 4.642   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.970   grad norm = 1.508   grad norm uniform = 38.114   loss each uniform = 9.950   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8448707461357117


Epoch [64]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.263  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.050   loss each uniform = 10.410   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.061   grad norm uniform = 41.269   loss each uniform = 7.731   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.119   grad norm uniform = 36.313   loss each uniform = 7.031   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.080   loss each uniform = 10.390   feat norm = 0.451  

Validation:
Average incurred loss: 0.542  
Average sample loss: 0.523  
Average acc: 0.870  
Average grad norm: 5.325  
Average grad norm uniform: 33.692  
Average loss each uniform: 7.612  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.171   grad norm uniform = 34.733   loss each uniform = 10.344   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.743  exp loss = 0.817  adjusted loss = 0.817  adv prob = 0.250000   acc = 0.807   grad norm = 8.361   grad norm uniform = 32.818   loss each uniform = 5.253   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.064  exp loss = 2.231  adjusted loss = 2.231  adv prob = 0.250000   acc = 0.556   grad norm = 16.007   grad norm uniform = 28.857   loss each uniform = 4.524   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.199  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.955   grad norm = 2.103   grad norm uniform = 37.936   loss each uniform = 9.373   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8698915839195251


Epoch [65]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.018  
Average grad norm uniform: 36.174  
Average loss each uniform: 10.251  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.028   loss each uniform = 10.420   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.072   grad norm uniform = 41.079   loss each uniform = 7.764   feat norm = 0.521  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.135   grad norm uniform = 36.092   loss each uniform = 6.770   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 39.116   loss each uniform = 10.309   feat norm = 0.452  

Validation:
Average incurred loss: 0.554  
Average sample loss: 0.536  
Average acc: 0.862  
Average grad norm: 5.531  
Average grad norm uniform: 33.345  
Average loss each uniform: 7.412  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.194   grad norm uniform = 34.509   loss each uniform = 10.068   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.807  exp loss = 0.879  adjusted loss = 0.879  adv prob = 0.250000   acc = 0.785   grad norm = 9.047   grad norm uniform = 32.266   loss each uniform = 5.043   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.954  exp loss = 2.105  adjusted loss = 2.105  adv prob = 0.250000   acc = 0.564   grad norm = 15.462   grad norm uniform = 28.673   loss each uniform = 4.451   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.955   grad norm = 2.014   grad norm uniform = 37.710   loss each uniform = 9.352   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8623853325843811


Epoch [66]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.016  
Average grad norm uniform: 36.185  
Average loss each uniform: 10.304  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.031   loss each uniform = 10.453   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 41.277   loss each uniform = 7.908   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.114   grad norm uniform = 36.299   loss each uniform = 6.918   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 39.114   loss each uniform = 10.405   feat norm = 0.451  

Validation:
Average incurred loss: 0.620  
Average sample loss: 0.603  
Average acc: 0.842  
Average grad norm: 6.207  
Average grad norm uniform: 32.991  
Average loss each uniform: 7.207  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.371   grad norm uniform = 33.971   loss each uniform = 9.591   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.060  exp loss = 1.150  adjusted loss = 1.150  adv prob = 0.250000   acc = 0.721   grad norm = 11.319   grad norm uniform = 31.303   loss each uniform = 4.679   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.665  exp loss = 1.795  adjusted loss = 1.795  adv prob = 0.250000   acc = 0.617   grad norm = 13.497   grad norm uniform = 29.677   loss each uniform = 4.681   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.147  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.962   grad norm = 1.496   grad norm uniform = 38.772   loss each uniform = 10.217   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8415346741676331


Epoch [67]:
Training:
Average incurred loss: 0.001  
Average sample loss: 0.001  
Average acc: 1.000  
Average grad norm: 0.019  
Average grad norm uniform: 36.173  
Average loss each uniform: 10.305  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 35.028   loss each uniform = 10.475   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 41.195   loss each uniform = 7.775   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.172   grad norm uniform = 36.010   loss each uniform = 6.710   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 39.098   loss each uniform = 10.374   feat norm = 0.452  

Validation:
Average incurred loss: 0.587  
Average sample loss: 0.569  
Average acc: 0.858  
Average grad norm: 5.847  
Average grad norm uniform: 33.500  
Average loss each uniform: 7.389  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.998   grad norm = 0.285   grad norm uniform = 34.539   loss each uniform = 9.916   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.934  exp loss = 1.009  adjusted loss = 1.009  adv prob = 0.250000   acc = 0.760   grad norm = 10.134   grad norm uniform = 32.082   loss each uniform = 4.930   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.815  exp loss = 1.961  adjusted loss = 1.961  adv prob = 0.250000   acc = 0.617   grad norm = 14.516   grad norm uniform = 29.612   loss each uniform = 4.616   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.955   grad norm = 1.683   grad norm uniform = 38.711   loss each uniform = 9.902   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8582152128219604


Epoch [68]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.363  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.035   loss each uniform = 10.528   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 41.147   loss each uniform = 7.623   feat norm = 0.522  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.128   grad norm uniform = 36.157   loss each uniform = 6.975   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 39.164   loss each uniform = 10.475   feat norm = 0.452  

Validation:
Average incurred loss: 0.535  
Average sample loss: 0.514  
Average acc: 0.875  
Average grad norm: 5.169  
Average grad norm uniform: 34.032  
Average loss each uniform: 7.752  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.140   grad norm uniform = 34.946   loss each uniform = 10.569   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.677  exp loss = 0.736  adjusted loss = 0.736  adv prob = 0.250000   acc = 0.826   grad norm = 7.670   grad norm uniform = 33.484   loss each uniform = 5.434   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.216  exp loss = 2.388  adjusted loss = 2.388  adv prob = 0.250000   acc = 0.541   grad norm = 16.936   grad norm uniform = 28.853   loss each uniform = 4.555   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.216  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.947   grad norm = 2.298   grad norm uniform = 37.927   loss each uniform = 9.178   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8748957514762878


Epoch [69]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.188  
Average loss each uniform: 10.386  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.025   loss each uniform = 10.553   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 41.258   loss each uniform = 7.699   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.094   grad norm uniform = 36.303   loss each uniform = 7.103   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 39.150   loss each uniform = 10.474   feat norm = 0.451  

Validation:
Average incurred loss: 0.536  
Average sample loss: 0.515  
Average acc: 0.874  
Average grad norm: 5.075  
Average grad norm uniform: 34.301  
Average loss each uniform: 7.902  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.081   grad norm uniform = 35.192   loss each uniform = 10.908   feat norm = 0.434  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.597  exp loss = 0.655  adjusted loss = 0.655  adv prob = 0.250000   acc = 0.843   grad norm = 6.923   grad norm uniform = 34.047   loss each uniform = 5.638   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.481  exp loss = 2.650  adjusted loss = 2.650  adv prob = 0.250000   acc = 0.474   grad norm = 18.510   grad norm uniform = 28.743   loss each uniform = 4.508   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.253  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.940   grad norm = 2.700   grad norm uniform = 37.621   loss each uniform = 8.674   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8740618228912354


Epoch [70]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.016  
Average grad norm uniform: 36.182  
Average loss each uniform: 10.386  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.013   loss each uniform = 10.563   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.077   grad norm uniform = 41.213   loss each uniform = 7.781   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.127   grad norm uniform = 36.048   loss each uniform = 6.551   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 39.180   loss each uniform = 10.457   feat norm = 0.452  

Validation:
Average incurred loss: 0.586  
Average sample loss: 0.567  
Average acc: 0.857  
Average grad norm: 5.792  
Average grad norm uniform: 33.483  
Average loss each uniform: 7.467  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.267   grad norm uniform = 34.498   loss each uniform = 10.049   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.914  exp loss = 0.990  adjusted loss = 0.990  adv prob = 0.250000   acc = 0.762   grad norm = 9.941   grad norm uniform = 32.038   loss each uniform = 4.958   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.871  exp loss = 2.002  adjusted loss = 2.002  adv prob = 0.250000   acc = 0.602   grad norm = 14.697   grad norm uniform = 29.694   loss each uniform = 4.686   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.168  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955   grad norm = 1.750   grad norm uniform = 38.766   loss each uniform = 9.972   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [71]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.194  
Average loss each uniform: 10.457  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 35.015   loss each uniform = 10.608   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 41.261   loss each uniform = 7.944   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.149   grad norm uniform = 36.206   loss each uniform = 6.808   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.214   loss each uniform = 10.586   feat norm = 0.452  

Validation:
Average incurred loss: 0.595  
Average sample loss: 0.577  
Average acc: 0.855  
Average grad norm: 5.795  
Average grad norm uniform: 33.541  
Average loss each uniform: 7.523  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.307   grad norm uniform = 34.375   loss each uniform = 10.023   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.972  exp loss = 1.060  adjusted loss = 1.060  adv prob = 0.250000   acc = 0.755   grad norm = 10.237   grad norm uniform = 32.096   loss each uniform = 5.023   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.747  exp loss = 1.886  adjusted loss = 1.886  adv prob = 0.250000   acc = 0.617   grad norm = 13.736   grad norm uniform = 30.340   loss each uniform = 4.794   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.955   grad norm = 1.560   grad norm uniform = 38.877   loss each uniform = 10.231   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8548791408538818


Epoch [72]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.191  
Average loss each uniform: 10.449  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.012   loss each uniform = 10.604   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 41.340   loss each uniform = 8.001   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.111   grad norm uniform = 36.181   loss each uniform = 6.952   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.197   loss each uniform = 10.547   feat norm = 0.452  

Validation:
Average incurred loss: 0.587  
Average sample loss: 0.569  
Average acc: 0.857  
Average grad norm: 5.780  
Average grad norm uniform: 33.627  
Average loss each uniform: 7.490  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.311   grad norm uniform = 34.409   loss each uniform = 10.017   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.937  exp loss = 1.011  adjusted loss = 1.011  adv prob = 0.250000   acc = 0.764   grad norm = 10.056   grad norm uniform = 32.534   loss each uniform = 5.035   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.793  exp loss = 1.936  adjusted loss = 1.936  adv prob = 0.250000   acc = 0.609   grad norm = 14.099   grad norm uniform = 29.599   loss each uniform = 4.692   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955   grad norm = 1.677   grad norm uniform = 38.736   loss each uniform = 10.017   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [73]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.189  
Average loss each uniform: 10.464  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.009   loss each uniform = 10.636   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.054   grad norm uniform = 41.334   loss each uniform = 7.845   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.114   grad norm uniform = 36.296   loss each uniform = 6.983   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.195   loss each uniform = 10.534   feat norm = 0.452  

Validation:
Average incurred loss: 0.552  
Average sample loss: 0.533  
Average acc: 0.868  
Average grad norm: 5.362  
Average grad norm uniform: 33.476  
Average loss each uniform: 7.653  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.155   grad norm uniform = 34.458   loss each uniform = 10.439   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.760  exp loss = 0.824  adjusted loss = 0.824  adv prob = 0.250000   acc = 0.805   grad norm = 8.474   grad norm uniform = 32.632   loss each uniform = 5.252   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.088  exp loss = 2.232  adjusted loss = 2.232  adv prob = 0.250000   acc = 0.556   grad norm = 15.946   grad norm uniform = 28.663   loss each uniform = 4.521   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.947   grad norm = 2.157   grad norm uniform = 37.798   loss each uniform = 9.418   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [74]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.195  
Average loss each uniform: 10.513  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.001   loss each uniform = 10.681   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 41.214   loss each uniform = 7.886   feat norm = 0.523  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 36.455   loss each uniform = 7.075   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.260   loss each uniform = 10.596   feat norm = 0.452  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.608  
Average acc: 0.847  
Average grad norm: 6.155  
Average grad norm uniform: 33.469  
Average loss each uniform: 7.391  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.342   grad norm uniform = 34.095   loss each uniform = 9.771   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.067  exp loss = 1.138  adjusted loss = 1.138  adv prob = 0.250000   acc = 0.734   grad norm = 11.213   grad norm uniform = 32.063   loss each uniform = 4.849   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.694  exp loss = 1.837  adjusted loss = 1.837  adv prob = 0.250000   acc = 0.617   grad norm = 13.520   grad norm uniform = 30.168   loss each uniform = 4.783   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.152  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.970   grad norm = 1.482   grad norm uniform = 39.497   loss each uniform = 10.552   feat norm = 0.470  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [75]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.193  
Average loss each uniform: 10.511  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.997   loss each uniform = 10.674   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 41.392   loss each uniform = 8.066   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.142   grad norm uniform = 36.282   loss each uniform = 6.795   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 39.243   loss each uniform = 10.594   feat norm = 0.452  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.525  
Average acc: 0.871  
Average grad norm: 5.219  
Average grad norm uniform: 33.461  
Average loss each uniform: 7.688  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.150   grad norm uniform = 34.407   loss each uniform = 10.488   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.704  exp loss = 0.770  adjusted loss = 0.770  adv prob = 0.250000   acc = 0.818   grad norm = 7.889   grad norm uniform = 32.804   loss each uniform = 5.362   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.215  exp loss = 2.374  adjusted loss = 2.374  adv prob = 0.250000   acc = 0.534   grad norm = 16.631   grad norm uniform = 28.417   loss each uniform = 4.539   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.214  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.947   grad norm = 2.257   grad norm uniform = 37.485   loss each uniform = 9.157   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [76]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.015  
Average grad norm uniform: 36.181  
Average loss each uniform: 10.503  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 35.002   loss each uniform = 10.684   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.065   grad norm uniform = 41.276   loss each uniform = 7.938   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.121   grad norm uniform = 36.063   loss each uniform = 6.755   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 39.203   loss each uniform = 10.550   feat norm = 0.452  

Validation:
Average incurred loss: 0.583  
Average sample loss: 0.565  
Average acc: 0.859  
Average grad norm: 5.648  
Average grad norm uniform: 33.506  
Average loss each uniform: 7.607  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.248   grad norm uniform = 34.358   loss each uniform = 10.222   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.898  exp loss = 0.986  adjusted loss = 0.986  adv prob = 0.250000   acc = 0.768   grad norm = 9.584   grad norm uniform = 32.380   loss each uniform = 5.139   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.896  exp loss = 2.036  adjusted loss = 2.036  adv prob = 0.250000   acc = 0.594   grad norm = 14.651   grad norm uniform = 29.583   loss each uniform = 4.702   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.955   grad norm = 1.818   grad norm uniform = 38.382   loss each uniform = 9.981   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [77]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.198  
Average loss each uniform: 10.562  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.001   loss each uniform = 10.727   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 41.366   loss each uniform = 7.995   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 36.512   loss each uniform = 7.170   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 39.242   loss each uniform = 10.641   feat norm = 0.452  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.554  
Average acc: 0.867  
Average grad norm: 5.611  
Average grad norm uniform: 33.713  
Average loss each uniform: 7.581  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.247   grad norm uniform = 34.570   loss each uniform = 10.209   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.870  exp loss = 0.961  adjusted loss = 0.961  adv prob = 0.250000   acc = 0.790   grad norm = 9.430   grad norm uniform = 32.609   loss each uniform = 5.119   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.896  exp loss = 2.051  adjusted loss = 2.051  adv prob = 0.250000   acc = 0.594   grad norm = 14.856   grad norm uniform = 29.658   loss each uniform = 4.656   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.955   grad norm = 1.820   grad norm uniform = 38.631   loss each uniform = 9.904   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8673895001411438


Epoch [78]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.196  
Average loss each uniform: 10.588  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.988   loss each uniform = 10.755   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.070   grad norm uniform = 41.366   loss each uniform = 7.978   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.079   grad norm uniform = 36.375   loss each uniform = 7.084   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.282   loss each uniform = 10.675   feat norm = 0.452  

Validation:
Average incurred loss: 0.599  
Average sample loss: 0.582  
Average acc: 0.856  
Average grad norm: 5.861  
Average grad norm uniform: 33.613  
Average loss each uniform: 7.482  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.302   grad norm uniform = 34.351   loss each uniform = 9.958   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.970  exp loss = 1.070  adjusted loss = 1.070  adv prob = 0.250000   acc = 0.755   grad norm = 10.267   grad norm uniform = 32.356   loss each uniform = 4.993   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.795  exp loss = 1.941  adjusted loss = 1.941  adv prob = 0.250000   acc = 0.624   grad norm = 14.098   grad norm uniform = 30.010   loss each uniform = 4.773   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.955   grad norm = 1.707   grad norm uniform = 39.026   loss each uniform = 10.221   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [79]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.586  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.979   loss each uniform = 10.761   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 41.379   loss each uniform = 8.215   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.089   grad norm uniform = 36.334   loss each uniform = 7.143   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 39.295   loss each uniform = 10.602   feat norm = 0.453  

Validation:
Average incurred loss: 0.636  
Average sample loss: 0.617  
Average acc: 0.848  
Average grad norm: 6.128  
Average grad norm uniform: 33.577  
Average loss each uniform: 7.576  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.332   grad norm uniform = 34.511   loss each uniform = 10.167   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.052  exp loss = 1.125  adjusted loss = 1.125  adv prob = 0.250000   acc = 0.740   grad norm = 11.028   grad norm uniform = 32.271   loss each uniform = 5.008   feat norm = 0.490  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.828  exp loss = 1.965  adjusted loss = 1.965  adv prob = 0.250000   acc = 0.609   grad norm = 13.935   grad norm uniform = 29.752   loss each uniform = 4.768   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.162  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.962   grad norm = 1.504   grad norm uniform = 38.695   loss each uniform = 10.286   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [80]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.180  
Average loss each uniform: 10.602  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.968   loss each uniform = 10.776   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 41.441   loss each uniform = 8.238   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 36.165   loss each uniform = 6.972   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.276   loss each uniform = 10.630   feat norm = 0.452  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.554  
Average acc: 0.867  
Average grad norm: 5.486  
Average grad norm uniform: 33.793  
Average loss each uniform: 7.767  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.218   grad norm uniform = 34.726   loss each uniform = 10.515   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.836  exp loss = 0.919  adjusted loss = 0.919  adv prob = 0.250000   acc = 0.794   grad norm = 8.988   grad norm uniform = 32.680   loss each uniform = 5.284   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.003  exp loss = 2.129  adjusted loss = 2.129  adv prob = 0.250000   acc = 0.571   grad norm = 15.222   grad norm uniform = 29.642   loss each uniform = 4.693   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.982   grad norm uniform = 38.574   loss each uniform = 9.890   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [81]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.189  
Average loss each uniform: 10.612  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.977   loss each uniform = 10.796   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 41.456   loss each uniform = 8.182   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.068   grad norm uniform = 36.808   loss each uniform = 7.354   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.250   loss each uniform = 10.600   feat norm = 0.452  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.574  
Average acc: 0.854  
Average grad norm: 5.712  
Average grad norm uniform: 33.588  
Average loss each uniform: 7.601  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.305   grad norm uniform = 34.247   loss each uniform = 10.124   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.956  exp loss = 1.054  adjusted loss = 1.054  adv prob = 0.250000   acc = 0.755   grad norm = 9.987   grad norm uniform = 32.438   loss each uniform = 5.075   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.768  exp loss = 1.903  adjusted loss = 1.903  adv prob = 0.250000   acc = 0.617   grad norm = 13.705   grad norm uniform = 29.958   loss each uniform = 4.833   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.955   grad norm = 1.726   grad norm uniform = 38.935   loss each uniform = 10.365   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [82]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.191  
Average loss each uniform: 10.637  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.976   loss each uniform = 10.817   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 41.481   loss each uniform = 8.199   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.093   grad norm uniform = 36.338   loss each uniform = 6.997   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 39.281   loss each uniform = 10.662   feat norm = 0.452  

Validation:
Average incurred loss: 0.545  
Average sample loss: 0.523  
Average acc: 0.876  
Average grad norm: 5.032  
Average grad norm uniform: 34.498  
Average loss each uniform: 8.122  
Average feat norm: 0.459  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.077   grad norm uniform = 35.228   loss each uniform = 11.171   feat norm = 0.434  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.591  exp loss = 0.655  adjusted loss = 0.655  adv prob = 0.250000   acc = 0.852   grad norm = 6.741   grad norm uniform = 34.475   loss each uniform = 5.863   feat norm = 0.489  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.571  exp loss = 2.700  adjusted loss = 2.700  adv prob = 0.250000   acc = 0.466   grad norm = 18.760   grad norm uniform = 28.794   loss each uniform = 4.600   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.268  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.932   grad norm = 2.716   grad norm uniform = 37.718   loss each uniform = 8.851   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [83]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.183  
Average loss each uniform: 10.642  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.981   loss each uniform = 10.819   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 41.361   loss each uniform = 8.179   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.086   grad norm uniform = 36.475   loss each uniform = 7.132   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.243   loss each uniform = 10.669   feat norm = 0.452  

Validation:
Average incurred loss: 0.603  
Average sample loss: 0.584  
Average acc: 0.854  
Average grad norm: 5.770  
Average grad norm uniform: 33.634  
Average loss each uniform: 7.603  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.314   grad norm uniform = 34.344   loss each uniform = 10.116   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.981  exp loss = 1.071  adjusted loss = 1.071  adv prob = 0.250000   acc = 0.753   grad norm = 10.128   grad norm uniform = 32.340   loss each uniform = 5.056   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.786  exp loss = 1.911  adjusted loss = 1.911  adv prob = 0.250000   acc = 0.617   grad norm = 13.816   grad norm uniform = 30.395   loss each uniform = 4.884   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.160  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.955   grad norm = 1.611   grad norm uniform = 38.915   loss each uniform = 10.424   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [84]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.016  
Average grad norm uniform: 36.167  
Average loss each uniform: 10.624  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 34.974   loss each uniform = 10.815   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 41.379   loss each uniform = 8.195   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.096   grad norm uniform = 36.485   loss each uniform = 7.115   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 39.191   loss each uniform = 10.599   feat norm = 0.452  

Validation:
Average incurred loss: 0.681  
Average sample loss: 0.662  
Average acc: 0.837  
Average grad norm: 6.490  
Average grad norm uniform: 33.408  
Average loss each uniform: 7.435  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.432   grad norm uniform = 34.040   loss each uniform = 9.704   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.241  exp loss = 1.349  adjusted loss = 1.349  adv prob = 0.250000   acc = 0.704   grad norm = 12.348   grad norm uniform = 31.949   loss each uniform = 4.828   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.582  exp loss = 1.760  adjusted loss = 1.760  adv prob = 0.250000   acc = 0.639   grad norm = 12.495   grad norm uniform = 30.401   loss each uniform = 5.026   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.132  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.970   grad norm = 1.228   grad norm uniform = 39.307   loss each uniform = 11.010   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8373644948005676


Epoch [85]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.198  
Average loss each uniform: 10.691  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.004   loss each uniform = 10.857   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 41.465   loss each uniform = 8.155   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.101   grad norm uniform = 36.364   loss each uniform = 7.146   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.225   loss each uniform = 10.771   feat norm = 0.451  

Validation:
Average incurred loss: 0.675  
Average sample loss: 0.658  
Average acc: 0.837  
Average grad norm: 6.507  
Average grad norm uniform: 33.419  
Average loss each uniform: 7.447  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.987   grad norm = 0.411   grad norm uniform = 34.108   loss each uniform = 9.774   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.211  exp loss = 1.309  adjusted loss = 1.309  adv prob = 0.250000   acc = 0.708   grad norm = 12.267   grad norm uniform = 31.755   loss each uniform = 4.805   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.634  exp loss = 1.774  adjusted loss = 1.774  adv prob = 0.250000   acc = 0.632   grad norm = 12.879   grad norm uniform = 30.583   loss each uniform = 4.979   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.143  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.970   grad norm = 1.354   grad norm uniform = 39.666   loss each uniform = 11.002   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8373644351959229


Epoch [86]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.014  
Average grad norm uniform: 36.185  
Average loss each uniform: 10.701  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 35.001   loss each uniform = 10.864   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 41.317   loss each uniform = 8.234   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.073   grad norm uniform = 36.569   loss each uniform = 7.460   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.190   loss each uniform = 10.764   feat norm = 0.451  

Validation:
Average incurred loss: 0.593  
Average sample loss: 0.574  
Average acc: 0.862  
Average grad norm: 5.613  
Average grad norm uniform: 33.870  
Average loss each uniform: 7.780  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.224   grad norm uniform = 34.762   loss each uniform = 10.522   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.884  exp loss = 0.961  adjusted loss = 0.961  adv prob = 0.250000   acc = 0.783   grad norm = 9.304   grad norm uniform = 32.822   loss each uniform = 5.245   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.031  exp loss = 2.178  adjusted loss = 2.178  adv prob = 0.250000   acc = 0.564   grad norm = 15.345   grad norm uniform = 29.691   loss each uniform = 4.755   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.955   grad norm = 1.874   grad norm uniform = 38.582   loss each uniform = 10.064   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [87]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.187  
Average loss each uniform: 10.725  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.975   loss each uniform = 10.906   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 41.449   loss each uniform = 8.341   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.004  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.118   grad norm uniform = 36.396   loss each uniform = 7.154   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 39.271   loss each uniform = 10.729   feat norm = 0.452  

Validation:
Average incurred loss: 0.567  
Average sample loss: 0.547  
Average acc: 0.871  
Average grad norm: 5.251  
Average grad norm uniform: 33.770  
Average loss each uniform: 7.989  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.127   grad norm uniform = 34.636   loss each uniform = 10.931   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.716  exp loss = 0.793  adjusted loss = 0.793  adv prob = 0.250000   acc = 0.824   grad norm = 7.826   grad norm uniform = 33.108   loss each uniform = 5.550   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.364  exp loss = 2.542  adjusted loss = 2.542  adv prob = 0.250000   acc = 0.519   grad norm = 17.116   grad norm uniform = 28.890   loss each uniform = 4.708   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.228  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.940   grad norm = 2.354   grad norm uniform = 37.930   loss each uniform = 9.492   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [88]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.192  
Average loss each uniform: 10.776  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.964   loss each uniform = 10.951   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 41.397   loss each uniform = 8.298   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.080   grad norm uniform = 36.755   loss each uniform = 7.469   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.318   loss each uniform = 10.800   feat norm = 0.452  

Validation:
Average incurred loss: 0.640  
Average sample loss: 0.622  
Average acc: 0.847  
Average grad norm: 6.139  
Average grad norm uniform: 33.734  
Average loss each uniform: 7.638  
Average feat norm: 0.457  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.369   grad norm uniform = 34.517   loss each uniform = 10.142   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.090  exp loss = 1.183  adjusted loss = 1.183  adv prob = 0.250000   acc = 0.730   grad norm = 11.205   grad norm uniform = 32.328   loss each uniform = 5.024   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.728  exp loss = 1.861  adjusted loss = 1.861  adv prob = 0.250000   acc = 0.632   grad norm = 13.317   grad norm uniform = 30.344   loss each uniform = 4.938   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.162  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.970   grad norm = 1.468   grad norm uniform = 39.301   loss each uniform = 10.704   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [89]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.011  
Average grad norm uniform: 36.178  
Average loss each uniform: 10.750  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.970   loss each uniform = 10.931   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 41.317   loss each uniform = 8.401   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.084   grad norm uniform = 36.550   loss each uniform = 7.235   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 39.263   loss each uniform = 10.745   feat norm = 0.452  

Validation:
Average incurred loss: 0.607  
Average sample loss: 0.588  
Average acc: 0.856  
Average grad norm: 5.754  
Average grad norm uniform: 33.963  
Average loss each uniform: 7.802  
Average feat norm: 0.457  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.288   grad norm uniform = 34.654   loss each uniform = 10.457   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.966  exp loss = 1.040  adjusted loss = 1.040  adv prob = 0.250000   acc = 0.758   grad norm = 10.012   grad norm uniform = 32.975   loss each uniform = 5.261   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.870  exp loss = 2.025  adjusted loss = 2.025  adv prob = 0.250000   acc = 0.617   grad norm = 14.132   grad norm uniform = 30.073   loss each uniform = 4.846   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.955   grad norm = 1.646   grad norm uniform = 38.891   loss each uniform = 10.342   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [90]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.186  
Average loss each uniform: 10.791  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.965   loss each uniform = 10.966   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 41.480   loss each uniform = 8.379   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.069   grad norm uniform = 36.366   loss each uniform = 7.234   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 39.296   loss each uniform = 10.819   feat norm = 0.452  

Validation:
Average incurred loss: 0.537  
Average sample loss: 0.515  
Average acc: 0.876  
Average grad norm: 4.863  
Average grad norm uniform: 34.099  
Average loss each uniform: 8.128  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.074   grad norm uniform = 34.732   loss each uniform = 11.166   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.561  exp loss = 0.626  adjusted loss = 0.626  adv prob = 0.250000   acc = 0.856   grad norm = 6.319   grad norm uniform = 34.189   loss each uniform = 5.934   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.592  exp loss = 2.772  adjusted loss = 2.772  adv prob = 0.250000   acc = 0.459   grad norm = 18.607   grad norm uniform = 28.594   loss each uniform = 4.582   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.278  exp loss = 0.286  adjusted loss = 0.286  adv prob = 0.250000   acc = 0.925   grad norm = 2.833   grad norm uniform = 37.066   loss each uniform = 8.697   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [91]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.197  
Average loss each uniform: 10.810  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.998   loss each uniform = 10.969   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 41.348   loss each uniform = 8.308   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.099   grad norm uniform = 36.609   loss each uniform = 7.315   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.246   loss each uniform = 10.903   feat norm = 0.451  

Validation:
Average incurred loss: 0.585  
Average sample loss: 0.564  
Average acc: 0.865  
Average grad norm: 5.432  
Average grad norm uniform: 33.748  
Average loss each uniform: 7.929  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.152   grad norm uniform = 34.736   loss each uniform = 10.841   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.815  exp loss = 0.885  adjusted loss = 0.885  adv prob = 0.250000   acc = 0.798   grad norm = 8.643   grad norm uniform = 32.927   loss each uniform = 5.408   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.193  exp loss = 2.342  adjusted loss = 2.342  adv prob = 0.250000   acc = 0.549   grad norm = 16.122   grad norm uniform = 28.970   loss each uniform = 4.706   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.947   grad norm = 2.036   grad norm uniform = 37.936   loss each uniform = 9.757   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8648874759674072


Epoch [92]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.200  
Average loss each uniform: 10.812  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.017   loss each uniform = 10.964   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 41.323   loss each uniform = 8.307   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.080   grad norm uniform = 36.516   loss each uniform = 7.327   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.207   loss each uniform = 10.930   feat norm = 0.450  

Validation:
Average incurred loss: 0.674  
Average sample loss: 0.658  
Average acc: 0.836  
Average grad norm: 6.344  
Average grad norm uniform: 33.271  
Average loss each uniform: 7.635  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.987   grad norm = 0.399   grad norm uniform = 34.000   loss each uniform = 10.039   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.211  exp loss = 1.295  adjusted loss = 1.295  adv prob = 0.250000   acc = 0.706   grad norm = 11.935   grad norm uniform = 31.660   loss each uniform = 4.938   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.618  exp loss = 1.771  adjusted loss = 1.771  adv prob = 0.250000   acc = 0.624   grad norm = 12.617   grad norm uniform = 30.296   loss each uniform = 5.069   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.970   grad norm = 1.357   grad norm uniform = 39.330   loss each uniform = 11.208   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8356963992118835


Epoch [93]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.198  
Average loss each uniform: 10.843  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.997   loss each uniform = 11.003   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 41.356   loss each uniform = 8.184   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.067   grad norm uniform = 36.480   loss each uniform = 7.197   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.262   loss each uniform = 10.970   feat norm = 0.451  

Validation:
Average incurred loss: 0.611  
Average sample loss: 0.593  
Average acc: 0.857  
Average grad norm: 5.782  
Average grad norm uniform: 33.722  
Average loss each uniform: 7.830  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.255   grad norm uniform = 34.649   loss each uniform = 10.604   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.948  exp loss = 1.033  adjusted loss = 1.033  adv prob = 0.250000   acc = 0.766   grad norm = 9.851   grad norm uniform = 32.508   loss each uniform = 5.200   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.968  exp loss = 2.101  adjusted loss = 2.101  adv prob = 0.250000   acc = 0.594   grad norm = 14.867   grad norm uniform = 29.754   loss each uniform = 4.811   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.947   grad norm = 1.844   grad norm uniform = 38.686   loss each uniform = 10.318   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8573811054229736


Epoch [94]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.207  
Average loss each uniform: 10.862  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.005   loss each uniform = 11.020   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 41.445   loss each uniform = 8.268   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 36.442   loss each uniform = 7.218   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.264   loss each uniform = 10.985   feat norm = 0.451  

Validation:
Average incurred loss: 0.550  
Average sample loss: 0.529  
Average acc: 0.879  
Average grad norm: 4.959  
Average grad norm uniform: 33.955  
Average loss each uniform: 8.194  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.104   grad norm uniform = 34.731   loss each uniform = 11.241   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.663  exp loss = 0.725  adjusted loss = 0.725  adv prob = 0.250000   acc = 0.843   grad norm = 7.079   grad norm uniform = 33.605   loss each uniform = 5.778   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.377  exp loss = 2.496  adjusted loss = 2.496  adv prob = 0.250000   acc = 0.526   grad norm = 17.116   grad norm uniform = 28.670   loss each uniform = 4.711   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.247  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.932   grad norm = 2.419   grad norm uniform = 37.739   loss each uniform = 9.440   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8790659308433533


Epoch [95]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.203  
Average loss each uniform: 10.862  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.000   loss each uniform = 11.026   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 41.375   loss each uniform = 8.294   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.064   grad norm uniform = 36.560   loss each uniform = 7.445   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.267   loss each uniform = 10.948   feat norm = 0.451  

Validation:
Average incurred loss: 0.559  
Average sample loss: 0.538  
Average acc: 0.874  
Average grad norm: 5.116  
Average grad norm uniform: 34.187  
Average loss each uniform: 8.186  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.116   grad norm uniform = 35.216   loss each uniform = 11.269   feat norm = 0.435  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.682  exp loss = 0.754  adjusted loss = 0.754  adv prob = 0.250000   acc = 0.830   grad norm = 7.411   grad norm uniform = 33.713   loss each uniform = 5.771   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.401  exp loss = 2.553  adjusted loss = 2.553  adv prob = 0.250000   acc = 0.519   grad norm = 17.341   grad norm uniform = 28.883   loss each uniform = 4.689   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.240  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.940   grad norm = 2.406   grad norm uniform = 37.536   loss each uniform = 9.325   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8740617036819458


Epoch [96]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.013  
Average grad norm uniform: 36.194  
Average loss each uniform: 10.857  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.019   loss each uniform = 11.021   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 41.327   loss each uniform = 8.048   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.081   grad norm uniform = 36.348   loss each uniform = 7.237   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 39.182   loss each uniform = 10.996   feat norm = 0.450  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.574  
Average acc: 0.859  
Average grad norm: 5.521  
Average grad norm uniform: 33.456  
Average loss each uniform: 7.861  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.235   grad norm uniform = 34.433   loss each uniform = 10.630   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.889  exp loss = 0.977  adjusted loss = 0.977  adv prob = 0.250000   acc = 0.777   grad norm = 9.190   grad norm uniform = 32.303   loss each uniform = 5.311   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.999  exp loss = 2.141  adjusted loss = 2.141  adv prob = 0.250000   acc = 0.571   grad norm = 14.905   grad norm uniform = 29.446   loss each uniform = 4.775   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.947   grad norm = 1.845   grad norm uniform = 38.072   loss each uniform = 10.158   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [97]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.205  
Average loss each uniform: 10.894  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.027   loss each uniform = 11.039   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.387   loss each uniform = 8.304   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 36.657   loss each uniform = 7.593   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.179   loss each uniform = 11.039   feat norm = 0.450  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.607  
Average acc: 0.852  
Average grad norm: 5.872  
Average grad norm uniform: 33.687  
Average loss each uniform: 7.871  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.276   grad norm uniform = 34.575   loss each uniform = 10.626   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.001  exp loss = 1.080  adjusted loss = 1.080  adv prob = 0.250000   acc = 0.751   grad norm = 10.239   grad norm uniform = 32.390   loss each uniform = 5.203   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.924  exp loss = 2.064  adjusted loss = 2.064  adv prob = 0.250000   acc = 0.602   grad norm = 14.438   grad norm uniform = 30.007   loss each uniform = 4.884   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.955   grad norm = 1.654   grad norm uniform = 38.797   loss each uniform = 10.534   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8523769378662109


Epoch [98]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.206  
Average loss each uniform: 10.912  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.029   loss each uniform = 11.064   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 41.387   loss each uniform = 8.202   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 36.122   loss each uniform = 7.269   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.203   loss each uniform = 11.076   feat norm = 0.450  

Validation:
Average incurred loss: 0.673  
Average sample loss: 0.654  
Average acc: 0.843  
Average grad norm: 6.329  
Average grad norm uniform: 33.498  
Average loss each uniform: 7.602  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.378   grad norm uniform = 34.279   loss each uniform = 10.060   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.185  exp loss = 1.275  adjusted loss = 1.275  adv prob = 0.250000   acc = 0.719   grad norm = 11.778   grad norm uniform = 32.010   loss each uniform = 4.952   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.692  exp loss = 1.827  adjusted loss = 1.827  adv prob = 0.250000   acc = 0.639   grad norm = 13.072   grad norm uniform = 30.204   loss each uniform = 4.962   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.158  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.970   grad norm = 1.392   grad norm uniform = 39.262   loss each uniform = 10.901   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8432027101516724


Epoch [99]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.203  
Average loss each uniform: 10.925  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.000   loss each uniform = 11.078   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 41.546   loss each uniform = 8.298   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.075   grad norm uniform = 36.462   loss each uniform = 7.399   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.241   loss each uniform = 11.063   feat norm = 0.450  

Validation:
Average incurred loss: 0.572  
Average sample loss: 0.551  
Average acc: 0.869  
Average grad norm: 5.201  
Average grad norm uniform: 33.587  
Average loss each uniform: 8.065  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.130   grad norm uniform = 34.546   loss each uniform = 11.054   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.739  exp loss = 0.816  adjusted loss = 0.816  adv prob = 0.250000   acc = 0.813   grad norm = 7.858   grad norm uniform = 32.935   loss each uniform = 5.614   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.326  exp loss = 2.493  adjusted loss = 2.493  adv prob = 0.250000   acc = 0.534   grad norm = 16.737   grad norm uniform = 28.702   loss each uniform = 4.702   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.224  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947   grad norm = 2.168   grad norm uniform = 37.384   loss each uniform = 9.526   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8690575957298279


Epoch [100]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.200  
Average loss each uniform: 10.925  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.002   loss each uniform = 11.084   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 41.471   loss each uniform = 8.281   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.055   grad norm uniform = 36.519   loss each uniform = 7.468   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.231   loss each uniform = 11.042   feat norm = 0.450  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.607  
Average acc: 0.849  
Average grad norm: 5.891  
Average grad norm uniform: 33.467  
Average loss each uniform: 7.787  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.281   grad norm uniform = 34.398   loss each uniform = 10.519   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.003  exp loss = 1.091  adjusted loss = 1.091  adv prob = 0.250000   acc = 0.742   grad norm = 10.289   grad norm uniform = 32.147   loss each uniform = 5.138   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.918  exp loss = 2.067  adjusted loss = 2.067  adv prob = 0.250000   acc = 0.602   grad norm = 14.453   grad norm uniform = 29.643   loss each uniform = 4.828   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955   grad norm = 1.617   grad norm uniform = 38.647   loss each uniform = 10.433   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8490408658981323


Epoch [101]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.199  
Average loss each uniform: 10.932  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.014   loss each uniform = 11.097   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 41.444   loss each uniform = 8.273   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.048   grad norm uniform = 36.535   loss each uniform = 7.588   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.190   loss each uniform = 11.026   feat norm = 0.450  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.570  
Average acc: 0.862  
Average grad norm: 5.516  
Average grad norm uniform: 33.843  
Average loss each uniform: 7.943  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.159   grad norm uniform = 34.766   loss each uniform = 10.875   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.824  exp loss = 0.904  adjusted loss = 0.904  adv prob = 0.250000   acc = 0.794   grad norm = 8.828   grad norm uniform = 33.205   loss each uniform = 5.425   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.217  exp loss = 2.366  adjusted loss = 2.366  adv prob = 0.250000   acc = 0.541   grad norm = 16.222   grad norm uniform = 28.964   loss each uniform = 4.682   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.947   grad norm = 2.016   grad norm uniform = 37.716   loss each uniform = 9.734   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [102]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.207  
Average loss each uniform: 10.971  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.007   loss each uniform = 11.120   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.420   loss each uniform = 8.450   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 36.571   loss each uniform = 7.428   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.252   loss each uniform = 11.101   feat norm = 0.450  

Validation:
Average incurred loss: 0.672  
Average sample loss: 0.655  
Average acc: 0.842  
Average grad norm: 6.297  
Average grad norm uniform: 33.227  
Average loss each uniform: 7.558  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.366   grad norm uniform = 33.883   loss each uniform = 9.987   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.182  exp loss = 1.268  adjusted loss = 1.268  adv prob = 0.250000   acc = 0.719   grad norm = 11.715   grad norm uniform = 31.795   loss each uniform = 4.888   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.699  exp loss = 1.850  adjusted loss = 1.850  adv prob = 0.250000   acc = 0.617   grad norm = 13.008   grad norm uniform = 30.040   loss each uniform = 4.971   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.151  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.970   grad norm = 1.431   grad norm uniform = 39.125   loss each uniform = 10.972   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8415346145629883


Epoch [103]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.200  
Average loss each uniform: 10.973  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.993   loss each uniform = 11.136   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.472   loss each uniform = 8.362   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 36.722   loss each uniform = 7.685   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.248   loss each uniform = 11.065   feat norm = 0.450  

Validation:
Average incurred loss: 0.575  
Average sample loss: 0.555  
Average acc: 0.868  
Average grad norm: 5.253  
Average grad norm uniform: 33.905  
Average loss each uniform: 8.129  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.169   grad norm uniform = 34.830   loss each uniform = 11.122   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.779  exp loss = 0.858  adjusted loss = 0.858  adv prob = 0.250000   acc = 0.807   grad norm = 8.131   grad norm uniform = 33.181   loss each uniform = 5.607   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.220  exp loss = 2.351  adjusted loss = 2.351  adv prob = 0.250000   acc = 0.549   grad norm = 16.144   grad norm uniform = 29.268   loss each uniform = 4.757   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.215  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.947   grad norm = 2.125   grad norm uniform = 37.834   loss each uniform = 9.823   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [104]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.205  
Average loss each uniform: 10.997  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.997   loss each uniform = 11.148   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 41.515   loss each uniform = 8.497   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 36.415   loss each uniform = 7.332   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.267   loss each uniform = 11.128   feat norm = 0.450  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.545  
Average acc: 0.870  
Average grad norm: 5.147  
Average grad norm uniform: 33.580  
Average loss each uniform: 8.034  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.136   grad norm uniform = 34.555   loss each uniform = 10.992   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.737  exp loss = 0.811  adjusted loss = 0.811  adv prob = 0.250000   acc = 0.815   grad norm = 7.782   grad norm uniform = 32.953   loss each uniform = 5.603   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.272  exp loss = 2.404  adjusted loss = 2.404  adv prob = 0.250000   acc = 0.534   grad norm = 16.407   grad norm uniform = 28.640   loss each uniform = 4.700   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.222  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.947   grad norm = 2.252   grad norm uniform = 37.291   loss each uniform = 9.503   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8698915839195251


Epoch [105]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.206  
Average loss each uniform: 11.009  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.002   loss each uniform = 11.169   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.306   loss each uniform = 8.371   feat norm = 0.524  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.048   grad norm uniform = 36.752   loss each uniform = 7.576   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.273   loss each uniform = 11.122   feat norm = 0.450  

Validation:
Average incurred loss: 0.634  
Average sample loss: 0.615  
Average acc: 0.848  
Average grad norm: 5.960  
Average grad norm uniform: 33.220  
Average loss each uniform: 7.716  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.285   grad norm uniform = 34.119   loss each uniform = 10.387   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.037  exp loss = 1.121  adjusted loss = 1.121  adv prob = 0.250000   acc = 0.734   grad norm = 10.567   grad norm uniform = 31.739   loss each uniform = 5.054   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.875  exp loss = 1.999  adjusted loss = 1.999  adv prob = 0.250000   acc = 0.617   grad norm = 14.139   grad norm uniform = 29.808   loss each uniform = 4.850   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.955   grad norm = 1.565   grad norm uniform = 38.662   loss each uniform = 10.534   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [106]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.203  
Average loss each uniform: 11.024  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.993   loss each uniform = 11.184   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.375   loss each uniform = 8.398   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.067   grad norm uniform = 36.416   loss each uniform = 7.297   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.295   loss each uniform = 11.149   feat norm = 0.450  

Validation:
Average incurred loss: 0.609  
Average sample loss: 0.590  
Average acc: 0.862  
Average grad norm: 5.641  
Average grad norm uniform: 33.972  
Average loss each uniform: 7.972  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.263   grad norm uniform = 34.662   loss each uniform = 10.700   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.939  exp loss = 1.014  adjusted loss = 1.014  adv prob = 0.250000   acc = 0.773   grad norm = 9.540   grad norm uniform = 33.035   loss each uniform = 5.394   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.965  exp loss = 2.124  adjusted loss = 2.124  adv prob = 0.250000   acc = 0.609   grad norm = 14.681   grad norm uniform = 29.885   loss each uniform = 4.907   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.193  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.820   grad norm uniform = 38.919   loss each uniform = 10.486   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [107]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.200  
Average loss each uniform: 11.044  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.979   loss each uniform = 11.192   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.488   loss each uniform = 8.594   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 36.420   loss each uniform = 7.498   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.307   loss each uniform = 11.169   feat norm = 0.451  

Validation:
Average incurred loss: 0.584  
Average sample loss: 0.564  
Average acc: 0.867  
Average grad norm: 5.354  
Average grad norm uniform: 33.777  
Average loss each uniform: 8.056  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.179   grad norm uniform = 34.720   loss each uniform = 10.984   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.810  exp loss = 0.876  adjusted loss = 0.876  adv prob = 0.250000   acc = 0.800   grad norm = 8.442   grad norm uniform = 32.873   loss each uniform = 5.512   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.198  exp loss = 2.344  adjusted loss = 2.344  adv prob = 0.250000   acc = 0.556   grad norm = 16.004   grad norm uniform = 29.388   loss each uniform = 4.808   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.947   grad norm = 2.054   grad norm uniform = 38.023   loss each uniform = 9.936   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8665555119514465


Epoch [108]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.186  
Average loss each uniform: 10.988  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.989   loss each uniform = 11.153   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 41.383   loss each uniform = 8.643   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.098   grad norm uniform = 36.128   loss each uniform = 7.095   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.247   loss each uniform = 11.057   feat norm = 0.450  

Validation:
Average incurred loss: 0.603  
Average sample loss: 0.582  
Average acc: 0.863  
Average grad norm: 5.520  
Average grad norm uniform: 33.837  
Average loss each uniform: 8.039  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.186   grad norm uniform = 34.600   loss each uniform = 10.942   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.852  exp loss = 0.930  adjusted loss = 0.930  adv prob = 0.250000   acc = 0.794   grad norm = 8.880   grad norm uniform = 33.139   loss each uniform = 5.470   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.217  exp loss = 2.357  adjusted loss = 2.357  adv prob = 0.250000   acc = 0.541   grad norm = 16.014   grad norm uniform = 29.131   loss each uniform = 4.812   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 1.980   grad norm uniform = 38.312   loss each uniform = 10.079   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [109]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.200  
Average loss each uniform: 11.051  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.002   loss each uniform = 11.209   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 41.354   loss each uniform = 8.418   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 36.518   loss each uniform = 7.390   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.251   loss each uniform = 11.183   feat norm = 0.450  

Validation:
Average incurred loss: 0.629  
Average sample loss: 0.609  
Average acc: 0.847  
Average grad norm: 5.903  
Average grad norm uniform: 33.472  
Average loss each uniform: 7.815  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.996   grad norm = 0.254   grad norm uniform = 34.490   loss each uniform = 10.593   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.987  exp loss = 1.074  adjusted loss = 1.074  adv prob = 0.250000   acc = 0.747   grad norm = 10.173   grad norm uniform = 32.107   loss each uniform = 5.169   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.995  exp loss = 2.122  adjusted loss = 2.122  adv prob = 0.250000   acc = 0.571   grad norm = 14.985   grad norm uniform = 29.630   loss each uniform = 4.806   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.955   grad norm = 1.696   grad norm uniform = 38.520   loss each uniform = 10.342   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [110]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.195  
Average loss each uniform: 11.047  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.992   loss each uniform = 11.205   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 41.420   loss each uniform = 8.512   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 36.528   loss each uniform = 7.562   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.250   loss each uniform = 11.149   feat norm = 0.450  

Validation:
Average incurred loss: 0.662  
Average sample loss: 0.644  
Average acc: 0.846  
Average grad norm: 6.165  
Average grad norm uniform: 33.641  
Average loss each uniform: 7.817  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.344   grad norm uniform = 34.305   loss each uniform = 10.418   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.135  exp loss = 1.221  adjusted loss = 1.221  adv prob = 0.250000   acc = 0.727   grad norm = 11.289   grad norm uniform = 32.378   loss each uniform = 5.111   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.778  exp loss = 1.912  adjusted loss = 1.912  adv prob = 0.250000   acc = 0.624   grad norm = 13.336   grad norm uniform = 30.092   loss each uniform = 5.015   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.158  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.970   grad norm = 1.475   grad norm uniform = 39.282   loss each uniform = 10.974   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8457047939300537


Epoch [111]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.188  
Average loss each uniform: 11.050  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.977   loss each uniform = 11.214   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.494   loss each uniform = 8.539   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.102   grad norm uniform = 36.621   loss each uniform = 7.488   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.252   loss each uniform = 11.136   feat norm = 0.450  

Validation:
Average incurred loss: 0.697  
Average sample loss: 0.679  
Average acc: 0.836  
Average grad norm: 6.479  
Average grad norm uniform: 33.441  
Average loss each uniform: 7.682  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.987   grad norm = 0.431   grad norm uniform = 34.108   loss each uniform = 10.136   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.248  exp loss = 1.356  adjusted loss = 1.356  adv prob = 0.250000   acc = 0.704   grad norm = 12.163   grad norm uniform = 31.957   loss each uniform = 4.949   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.689  exp loss = 1.836  adjusted loss = 1.836  adv prob = 0.250000   acc = 0.632   grad norm = 12.927   grad norm uniform = 30.360   loss each uniform = 5.091   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.970   grad norm = 1.353   grad norm uniform = 39.379   loss each uniform = 11.232   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8356964588165283


Epoch [112]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.193  
Average loss each uniform: 11.082  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.983   loss each uniform = 11.235   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 41.539   loss each uniform = 8.596   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 36.620   loss each uniform = 7.605   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.242   loss each uniform = 11.193   feat norm = 0.450  

Validation:
Average incurred loss: 0.615  
Average sample loss: 0.595  
Average acc: 0.860  
Average grad norm: 5.673  
Average grad norm uniform: 33.538  
Average loss each uniform: 7.871  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.253   grad norm uniform = 34.252   loss each uniform = 10.587   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.962  exp loss = 1.043  adjusted loss = 1.043  adv prob = 0.250000   acc = 0.766   grad norm = 9.754   grad norm uniform = 32.493   loss each uniform = 5.254   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.952  exp loss = 2.094  adjusted loss = 2.094  adv prob = 0.250000   acc = 0.609   grad norm = 14.416   grad norm uniform = 29.625   loss each uniform = 4.868   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.955   grad norm = 1.658   grad norm uniform = 38.602   loss each uniform = 10.500   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8598832488059998


Epoch [113]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.009  
Average grad norm uniform: 36.184  
Average loss each uniform: 11.059  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.983   loss each uniform = 11.246   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 41.293   loss each uniform = 8.347   feat norm = 0.525  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.078   grad norm uniform = 36.423   loss each uniform = 7.497   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 39.255   loss each uniform = 11.102   feat norm = 0.450  

Validation:
Average incurred loss: 0.571  
Average sample loss: 0.550  
Average acc: 0.872  
Average grad norm: 5.129  
Average grad norm uniform: 33.932  
Average loss each uniform: 8.248  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.112   grad norm uniform = 34.738   loss each uniform = 11.308   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.723  exp loss = 0.787  adjusted loss = 0.787  adv prob = 0.250000   acc = 0.818   grad norm = 7.626   grad norm uniform = 33.558   loss each uniform = 5.795   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.360  exp loss = 2.504  adjusted loss = 2.504  adv prob = 0.250000   acc = 0.541   grad norm = 16.776   grad norm uniform = 28.638   loss each uniform = 4.712   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.245  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.947   grad norm = 2.347   grad norm uniform = 37.709   loss each uniform = 9.635   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8715596795082092


Epoch [114]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.200  
Average loss each uniform: 11.115  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.988   loss each uniform = 11.275   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.522   loss each uniform = 8.547   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 36.770   loss each uniform = 7.881   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.256   loss each uniform = 11.206   feat norm = 0.450  

Validation:
Average incurred loss: 0.573  
Average sample loss: 0.552  
Average acc: 0.877  
Average grad norm: 5.094  
Average grad norm uniform: 34.005  
Average loss each uniform: 8.288  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 34.984   loss each uniform = 11.442   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.704  exp loss = 0.768  adjusted loss = 0.768  adv prob = 0.250000   acc = 0.833   grad norm = 7.413   grad norm uniform = 33.751   loss each uniform = 5.848   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.450  exp loss = 2.600  adjusted loss = 2.600  adv prob = 0.250000   acc = 0.534   grad norm = 17.293   grad norm uniform = 28.255   loss each uniform = 4.673   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.238  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.947   grad norm = 2.329   grad norm uniform = 37.202   loss each uniform = 9.380   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.877397894859314


Epoch [115]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.012  
Average grad norm uniform: 36.180  
Average loss each uniform: 11.106  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.976   loss each uniform = 11.266   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.417   loss each uniform = 8.568   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000   grad norm = 0.092   grad norm uniform = 36.537   loss each uniform = 7.726   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.001  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 39.234   loss each uniform = 11.197   feat norm = 0.450  

Validation:
Average incurred loss: 0.554  
Average sample loss: 0.532  
Average acc: 0.879  
Average grad norm: 4.787  
Average grad norm uniform: 33.924  
Average loss each uniform: 8.425  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.076   grad norm uniform = 34.742   loss each uniform = 11.624   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.593  exp loss = 0.652  adjusted loss = 0.652  adv prob = 0.250000   acc = 0.856   grad norm = 6.284   grad norm uniform = 33.984   loss each uniform = 6.104   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.619  exp loss = 2.790  adjusted loss = 2.790  adv prob = 0.250000   acc = 0.481   grad norm = 18.106   grad norm uniform = 28.197   loss each uniform = 4.708   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.290  exp loss = 0.293  adjusted loss = 0.293  adv prob = 0.250000   acc = 0.932   grad norm = 2.768   grad norm uniform = 36.573   loss each uniform = 9.039   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8790658712387085


Epoch [116]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.191  
Average loss each uniform: 11.081  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.028   loss each uniform = 11.212   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 41.500   loss each uniform = 8.446   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 36.728   loss each uniform = 7.966   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.087   loss each uniform = 11.274   feat norm = 0.448  

Validation:
Average incurred loss: 0.619  
Average sample loss: 0.601  
Average acc: 0.858  
Average grad norm: 5.674  
Average grad norm uniform: 33.535  
Average loss each uniform: 7.905  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.278   grad norm uniform = 34.218   loss each uniform = 10.621   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.989  exp loss = 1.075  adjusted loss = 1.075  adv prob = 0.250000   acc = 0.762   grad norm = 9.884   grad norm uniform = 32.622   loss each uniform = 5.296   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.897  exp loss = 2.039  adjusted loss = 2.039  adv prob = 0.250000   acc = 0.617   grad norm = 13.932   grad norm uniform = 29.546   loss each uniform = 4.891   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.955   grad norm = 1.612   grad norm uniform = 38.323   loss each uniform = 10.524   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8582152128219604


Epoch [117]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.010  
Average grad norm uniform: 36.184  
Average loss each uniform: 11.074  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 35.029   loss each uniform = 11.210   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 41.413   loss each uniform = 8.353   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.081   grad norm uniform = 36.579   loss each uniform = 7.808   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 39.077   loss each uniform = 11.268   feat norm = 0.448  

Validation:
Average incurred loss: 0.640  
Average sample loss: 0.622  
Average acc: 0.852  
Average grad norm: 5.895  
Average grad norm uniform: 33.258  
Average loss each uniform: 7.834  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.312   grad norm uniform = 33.974   loss each uniform = 10.489   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.051  exp loss = 1.141  adjusted loss = 1.141  adv prob = 0.250000   acc = 0.747   grad norm = 10.480   grad norm uniform = 31.873   loss each uniform = 5.142   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.868  exp loss = 2.003  adjusted loss = 2.003  adv prob = 0.250000   acc = 0.617   grad norm = 13.778   grad norm uniform = 30.261   loss each uniform = 4.986   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.171  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.962   grad norm = 1.552   grad norm uniform = 38.596   loss each uniform = 10.790   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8523770570755005


Epoch [118]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.192  
Average loss each uniform: 11.138  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 35.000   loss each uniform = 11.258   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.535   loss each uniform = 8.598   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 36.703   loss each uniform = 7.997   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.177   loss each uniform = 11.349   feat norm = 0.449  

Validation:
Average incurred loss: 0.593  
Average sample loss: 0.572  
Average acc: 0.871  
Average grad norm: 5.290  
Average grad norm uniform: 34.197  
Average loss each uniform: 8.347  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.136   grad norm uniform = 35.187   loss each uniform = 11.473   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.774  exp loss = 0.857  adjusted loss = 0.857  adv prob = 0.250000   acc = 0.815   grad norm = 7.996   grad norm uniform = 33.480   loss each uniform = 5.774   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.384  exp loss = 2.541  adjusted loss = 2.541  adv prob = 0.250000   acc = 0.541   grad norm = 16.972   grad norm uniform = 29.247   loss each uniform = 4.832   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.947   grad norm = 2.227   grad norm uniform = 38.180   loss each uniform = 9.904   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [119]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.196  
Average loss each uniform: 11.147  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 35.018   loss each uniform = 11.273   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.428   loss each uniform = 8.565   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 36.715   loss each uniform = 7.925   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.155   loss each uniform = 11.349   feat norm = 0.448  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.593  
Average acc: 0.858  
Average grad norm: 5.627  
Average grad norm uniform: 33.819  
Average loss each uniform: 8.033  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.228   grad norm uniform = 34.611   loss each uniform = 10.883   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.926  exp loss = 1.009  adjusted loss = 1.009  adv prob = 0.250000   acc = 0.775   grad norm = 9.438   grad norm uniform = 32.855   loss each uniform = 5.413   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.060  exp loss = 2.183  adjusted loss = 2.183  adv prob = 0.250000   acc = 0.564   grad norm = 15.107   grad norm uniform = 29.695   loss each uniform = 4.865   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.754   grad norm uniform = 38.538   loss each uniform = 10.375   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8582152724266052


Epoch [120]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.181  
Average loss each uniform: 11.137  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 34.991   loss each uniform = 11.275   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.584   loss each uniform = 8.667   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.060   grad norm uniform = 36.584   loss each uniform = 7.666   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.158   loss each uniform = 11.295   feat norm = 0.449  

Validation:
Average incurred loss: 0.583  
Average sample loss: 0.563  
Average acc: 0.866  
Average grad norm: 5.279  
Average grad norm uniform: 33.710  
Average loss each uniform: 8.069  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.182   grad norm uniform = 34.415   loss each uniform = 10.919   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.838  exp loss = 0.913  adjusted loss = 0.913  adv prob = 0.250000   acc = 0.794   grad norm = 8.534   grad norm uniform = 32.933   loss each uniform = 5.515   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.093  exp loss = 2.228  adjusted loss = 2.228  adv prob = 0.250000   acc = 0.564   grad norm = 15.170   grad norm uniform = 29.427   loss each uniform = 4.864   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.955   grad norm = 1.877   grad norm uniform = 38.243   loss each uniform = 10.217   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [121]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.199  
Average loss each uniform: 11.199  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.999   loss each uniform = 11.327   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.478   loss each uniform = 8.611   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.032   grad norm uniform = 36.688   loss each uniform = 7.931   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.228   loss each uniform = 11.398   feat norm = 0.449  

Validation:
Average incurred loss: 0.666  
Average sample loss: 0.648  
Average acc: 0.848  
Average grad norm: 6.095  
Average grad norm uniform: 33.699  
Average loss each uniform: 7.892  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.346   grad norm uniform = 34.311   loss each uniform = 10.561   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.127  exp loss = 1.234  adjusted loss = 1.234  adv prob = 0.250000   acc = 0.736   grad norm = 11.046   grad norm uniform = 32.605   loss each uniform = 5.186   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.842  exp loss = 1.984  adjusted loss = 1.984  adv prob = 0.250000   acc = 0.617   grad norm = 13.607   grad norm uniform = 30.182   loss each uniform = 4.981   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.160  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.970   grad norm = 1.427   grad norm uniform = 38.904   loss each uniform = 10.913   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [122]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.198  
Average loss each uniform: 11.189  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.998   loss each uniform = 11.326   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 41.515   loss each uniform = 8.609   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.046   grad norm uniform = 36.713   loss each uniform = 7.875   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.217   loss each uniform = 11.360   feat norm = 0.449  

Validation:
Average incurred loss: 0.573  
Average sample loss: 0.553  
Average acc: 0.871  
Average grad norm: 5.131  
Average grad norm uniform: 33.577  
Average loss each uniform: 8.168  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.137   grad norm uniform = 34.425   loss each uniform = 11.178   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.753  exp loss = 0.816  adjusted loss = 0.816  adv prob = 0.250000   acc = 0.813   grad norm = 7.814   grad norm uniform = 33.012   loss each uniform = 5.677   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.283  exp loss = 2.417  adjusted loss = 2.417  adv prob = 0.250000   acc = 0.549   grad norm = 16.230   grad norm uniform = 28.687   loss each uniform = 4.756   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.226  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.947   grad norm = 2.160   grad norm uniform = 37.465   loss each uniform = 9.737   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [123]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.182  
Average loss each uniform: 11.186  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.985   loss each uniform = 11.325   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.540   loss each uniform = 8.701   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.045   grad norm uniform = 36.767   loss each uniform = 7.959   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.181   loss each uniform = 11.332   feat norm = 0.449  

Validation:
Average incurred loss: 0.618  
Average sample loss: 0.598  
Average acc: 0.861  
Average grad norm: 5.605  
Average grad norm uniform: 33.688  
Average loss each uniform: 8.046  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.242   grad norm uniform = 34.476   loss each uniform = 10.882   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.944  exp loss = 1.032  adjusted loss = 1.032  adv prob = 0.250000   acc = 0.773   grad norm = 9.462   grad norm uniform = 32.725   loss each uniform = 5.405   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.039  exp loss = 2.184  adjusted loss = 2.184  adv prob = 0.250000   acc = 0.594   grad norm = 14.764   grad norm uniform = 29.664   loss each uniform = 4.927   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.955   grad norm = 1.760   grad norm uniform = 38.319   loss each uniform = 10.460   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [124]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.184  
Average loss each uniform: 11.185  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.990   loss each uniform = 11.327   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.444   loss each uniform = 8.813   feat norm = 0.526  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.082   grad norm uniform = 36.417   loss each uniform = 7.366   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 39.207   loss each uniform = 11.329   feat norm = 0.449  

Validation:
Average incurred loss: 0.626  
Average sample loss: 0.608  
Average acc: 0.857  
Average grad norm: 5.750  
Average grad norm uniform: 33.594  
Average loss each uniform: 7.959  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.258   grad norm uniform = 34.427   loss each uniform = 10.734   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.013  exp loss = 1.090  adjusted loss = 1.090  adv prob = 0.250000   acc = 0.751   grad norm = 10.093   grad norm uniform = 32.502   loss each uniform = 5.297   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.884  exp loss = 2.032  adjusted loss = 2.032  adv prob = 0.250000   acc = 0.624   grad norm = 13.955   grad norm uniform = 29.851   loss each uniform = 4.902   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.962   grad norm = 1.607   grad norm uniform = 38.236   loss each uniform = 10.595   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [125]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.189  
Average loss each uniform: 11.211  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.981   loss each uniform = 11.345   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.578   loss each uniform = 8.776   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 36.586   loss each uniform = 7.739   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.229   loss each uniform = 11.372   feat norm = 0.449  

Validation:
Average incurred loss: 0.625  
Average sample loss: 0.606  
Average acc: 0.857  
Average grad norm: 5.664  
Average grad norm uniform: 33.559  
Average loss each uniform: 8.014  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.229   grad norm uniform = 34.324   loss each uniform = 10.839   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.976  exp loss = 1.054  adjusted loss = 1.054  adv prob = 0.250000   acc = 0.760   grad norm = 9.723   grad norm uniform = 32.453   loss each uniform = 5.364   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.994  exp loss = 2.136  adjusted loss = 2.136  adv prob = 0.250000   acc = 0.602   grad norm = 14.479   grad norm uniform = 29.880   loss each uniform = 4.891   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.962   grad norm = 1.712   grad norm uniform = 38.426   loss each uniform = 10.507   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8573811650276184


Epoch [126]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.182  
Average loss each uniform: 11.226  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.983   loss each uniform = 11.370   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.441   loss each uniform = 8.607   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 36.628   loss each uniform = 7.677   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.212   loss each uniform = 11.391   feat norm = 0.449  

Validation:
Average incurred loss: 0.576  
Average sample loss: 0.555  
Average acc: 0.872  
Average grad norm: 5.160  
Average grad norm uniform: 34.017  
Average loss each uniform: 8.235  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.151   grad norm uniform = 34.834   loss each uniform = 11.256   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.772  exp loss = 0.848  adjusted loss = 0.848  adv prob = 0.250000   acc = 0.811   grad norm = 7.917   grad norm uniform = 33.479   loss each uniform = 5.708   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.253  exp loss = 2.397  adjusted loss = 2.397  adv prob = 0.250000   acc = 0.556   grad norm = 16.181   grad norm uniform = 29.195   loss each uniform = 4.818   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 2.071   grad norm uniform = 37.852   loss each uniform = 9.898   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [127]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.184  
Average loss each uniform: 11.221  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.988   loss each uniform = 11.359   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 41.468   loss each uniform = 8.764   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.049   grad norm uniform = 36.515   loss each uniform = 7.744   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.208   loss each uniform = 11.377   feat norm = 0.449  

Validation:
Average incurred loss: 0.617  
Average sample loss: 0.597  
Average acc: 0.859  
Average grad norm: 5.585  
Average grad norm uniform: 33.397  
Average loss each uniform: 7.953  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.233   grad norm uniform = 34.146   loss each uniform = 10.725   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.958  exp loss = 1.034  adjusted loss = 1.034  adv prob = 0.250000   acc = 0.768   grad norm = 9.534   grad norm uniform = 32.302   loss each uniform = 5.314   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.986  exp loss = 2.129  adjusted loss = 2.129  adv prob = 0.250000   acc = 0.594   grad norm = 14.461   grad norm uniform = 29.638   loss each uniform = 4.902   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.955   grad norm = 1.664   grad norm uniform = 38.363   loss each uniform = 10.516   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [128]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.192  
Average loss each uniform: 11.238  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.993   loss each uniform = 11.385   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.465   loss each uniform = 8.585   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.062   grad norm uniform = 36.501   loss each uniform = 7.696   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.224   loss each uniform = 11.400   feat norm = 0.449  

Validation:
Average incurred loss: 0.597  
Average sample loss: 0.577  
Average acc: 0.866  
Average grad norm: 5.389  
Average grad norm uniform: 34.151  
Average loss each uniform: 8.197  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.199   grad norm uniform = 34.719   loss each uniform = 11.077   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.867  exp loss = 0.929  adjusted loss = 0.929  adv prob = 0.250000   acc = 0.796   grad norm = 8.767   grad norm uniform = 33.704   loss each uniform = 5.671   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.108  exp loss = 2.263  adjusted loss = 2.263  adv prob = 0.250000   acc = 0.556   grad norm = 15.267   grad norm uniform = 29.442   loss each uniform = 4.859   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.212  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.955   grad norm = 1.898   grad norm uniform = 38.428   loss each uniform = 10.273   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [129]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.182  
Average loss each uniform: 11.250  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.979   loss each uniform = 11.397   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 41.444   loss each uniform = 8.733   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 36.566   loss each uniform = 7.789   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.227   loss each uniform = 11.384   feat norm = 0.449  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.593  
Average acc: 0.862  
Average grad norm: 5.526  
Average grad norm uniform: 34.098  
Average loss each uniform: 8.145  
Average feat norm: 0.457  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.186   grad norm uniform = 34.722   loss each uniform = 11.062   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.892  exp loss = 0.958  adjusted loss = 0.958  adv prob = 0.250000   acc = 0.788   grad norm = 9.064   grad norm uniform = 33.456   loss each uniform = 5.541   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.167  exp loss = 2.302  adjusted loss = 2.302  adv prob = 0.250000   acc = 0.564   grad norm = 15.499   grad norm uniform = 29.719   loss each uniform = 4.870   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.947   grad norm = 1.908   grad norm uniform = 38.539   loss each uniform = 10.306   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8623853921890259


Epoch [130]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.180  
Average loss each uniform: 11.252  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.961   loss each uniform = 11.397   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.559   loss each uniform = 8.905   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.048   grad norm uniform = 36.966   loss each uniform = 8.020   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.235   loss each uniform = 11.349   feat norm = 0.449  

Validation:
Average incurred loss: 0.565  
Average sample loss: 0.544  
Average acc: 0.875  
Average grad norm: 4.987  
Average grad norm uniform: 33.981  
Average loss each uniform: 8.348  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.110   grad norm uniform = 34.675   loss each uniform = 11.372   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.691  exp loss = 0.765  adjusted loss = 0.765  adv prob = 0.250000   acc = 0.828   grad norm = 7.203   grad norm uniform = 33.647   loss each uniform = 5.939   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.412  exp loss = 2.570  adjusted loss = 2.570  adv prob = 0.250000   acc = 0.534   grad norm = 16.915   grad norm uniform = 29.058   loss each uniform = 4.820   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.251  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.947   grad norm = 2.417   grad norm uniform = 37.639   loss each uniform = 9.699   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8748958110809326


Epoch [131]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.176  
Average loss each uniform: 11.259  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.965   loss each uniform = 11.415   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 41.541   loss each uniform = 8.623   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.064   grad norm uniform = 36.631   loss each uniform = 7.998   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.225   loss each uniform = 11.372   feat norm = 0.449  

Validation:
Average incurred loss: 0.627  
Average sample loss: 0.610  
Average acc: 0.854  
Average grad norm: 5.730  
Average grad norm uniform: 33.964  
Average loss each uniform: 8.070  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.324   grad norm uniform = 34.471   loss each uniform = 10.735   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.030  exp loss = 1.136  adjusted loss = 1.136  adv prob = 0.250000   acc = 0.758   grad norm = 10.113   grad norm uniform = 32.913   loss each uniform = 5.407   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.825  exp loss = 1.979  adjusted loss = 1.979  adv prob = 0.250000   acc = 0.609   grad norm = 13.543   grad norm uniform = 30.675   loss each uniform = 5.097   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.172  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.955   grad norm = 1.540   grad norm uniform = 39.161   loss each uniform = 11.013   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [132]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.181  
Average loss each uniform: 11.269  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.971   loss each uniform = 11.430   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 41.464   loss each uniform = 8.605   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 36.457   loss each uniform = 7.719   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.253   loss each uniform = 11.387   feat norm = 0.449  

Validation:
Average incurred loss: 0.680  
Average sample loss: 0.662  
Average acc: 0.842  
Average grad norm: 6.159  
Average grad norm uniform: 33.376  
Average loss each uniform: 7.836  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.388   grad norm uniform = 33.886   loss each uniform = 10.339   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.196  exp loss = 1.280  adjusted loss = 1.280  adv prob = 0.250000   acc = 0.719   grad norm = 11.414   grad norm uniform = 32.004   loss each uniform = 5.105   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.717  exp loss = 1.865  adjusted loss = 1.865  adv prob = 0.250000   acc = 0.632   grad norm = 12.774   grad norm uniform = 30.633   loss each uniform = 5.159   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.161  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.970   grad norm = 1.398   grad norm uniform = 39.135   loss each uniform = 11.292   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8423686027526855


Epoch [133]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.179  
Average loss each uniform: 11.290  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.961   loss each uniform = 11.426   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.709   loss each uniform = 9.010   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 36.401   loss each uniform = 7.629   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.233   loss each uniform = 11.431   feat norm = 0.449  

Validation:
Average incurred loss: 0.599  
Average sample loss: 0.580  
Average acc: 0.867  
Average grad norm: 5.420  
Average grad norm uniform: 33.804  
Average loss each uniform: 8.115  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.996   grad norm = 0.228   grad norm uniform = 34.307   loss each uniform = 10.920   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.900  exp loss = 0.978  adjusted loss = 0.978  adv prob = 0.250000   acc = 0.790   grad norm = 9.025   grad norm uniform = 33.160   loss each uniform = 5.561   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.016  exp loss = 2.145  adjusted loss = 2.145  adv prob = 0.250000   acc = 0.602   grad norm = 14.591   grad norm uniform = 29.587   loss each uniform = 4.913   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.955   grad norm = 1.847   grad norm uniform = 38.511   loss each uniform = 10.416   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8673895597457886


Epoch [134]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.171  
Average loss each uniform: 11.280  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.961   loss each uniform = 11.435   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 41.664   loss each uniform = 8.813   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.095   grad norm uniform = 36.759   loss each uniform = 7.943   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 39.189   loss each uniform = 11.373   feat norm = 0.449  

Validation:
Average incurred loss: 0.587  
Average sample loss: 0.566  
Average acc: 0.871  
Average grad norm: 5.100  
Average grad norm uniform: 33.707  
Average loss each uniform: 8.413  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.114   grad norm uniform = 34.613   loss each uniform = 11.556   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.742  exp loss = 0.808  adjusted loss = 0.808  adv prob = 0.250000   acc = 0.818   grad norm = 7.591   grad norm uniform = 33.187   loss each uniform = 5.859   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.439  exp loss = 2.599  adjusted loss = 2.599  adv prob = 0.250000   acc = 0.534   grad norm = 16.750   grad norm uniform = 28.749   loss each uniform = 4.879   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.947   grad norm = 2.228   grad norm uniform = 37.301   loss each uniform = 9.859   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [135]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.182  
Average loss each uniform: 11.321  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.963   loss each uniform = 11.450   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.566   loss each uniform = 8.828   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 36.413   loss each uniform = 7.766   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.267   loss each uniform = 11.514   feat norm = 0.449  

Validation:
Average incurred loss: 0.607  
Average sample loss: 0.587  
Average acc: 0.866  
Average grad norm: 5.394  
Average grad norm uniform: 34.085  
Average loss each uniform: 8.285  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.160   grad norm uniform = 34.915   loss each uniform = 11.343   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.848  exp loss = 0.919  adjusted loss = 0.919  adv prob = 0.250000   acc = 0.796   grad norm = 8.580   grad norm uniform = 33.420   loss each uniform = 5.658   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.261  exp loss = 2.385  adjusted loss = 2.385  adv prob = 0.250000   acc = 0.556   grad norm = 16.014   grad norm uniform = 29.443   loss each uniform = 4.883   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.219  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.955   grad norm = 1.991   grad norm uniform = 38.140   loss each uniform = 10.154   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [136]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.185  
Average loss each uniform: 11.344  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.974   loss each uniform = 11.459   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 41.563   loss each uniform = 8.878   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 36.662   loss each uniform = 7.931   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.232   loss each uniform = 11.571   feat norm = 0.448  

Validation:
Average incurred loss: 0.587  
Average sample loss: 0.567  
Average acc: 0.868  
Average grad norm: 5.244  
Average grad norm uniform: 33.813  
Average loss each uniform: 8.270  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.160   grad norm uniform = 34.679   loss each uniform = 11.256   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.811  exp loss = 0.892  adjusted loss = 0.892  adv prob = 0.250000   acc = 0.803   grad norm = 8.280   grad norm uniform = 33.036   loss each uniform = 5.712   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.216  exp loss = 2.354  adjusted loss = 2.354  adv prob = 0.250000   acc = 0.564   grad norm = 15.651   grad norm uniform = 29.409   loss each uniform = 4.891   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.947   grad norm = 2.050   grad norm uniform = 37.898   loss each uniform = 10.125   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8682234883308411


Epoch [137]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.188  
Average loss each uniform: 11.337  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.977   loss each uniform = 11.467   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.506   loss each uniform = 8.768   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 36.579   loss each uniform = 7.912   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.250   loss each uniform = 11.534   feat norm = 0.449  

Validation:
Average incurred loss: 0.606  
Average sample loss: 0.587  
Average acc: 0.865  
Average grad norm: 5.466  
Average grad norm uniform: 33.967  
Average loss each uniform: 8.182  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.216   grad norm uniform = 34.659   loss each uniform = 11.042   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.905  exp loss = 0.981  adjusted loss = 0.981  adv prob = 0.250000   acc = 0.783   grad norm = 9.059   grad norm uniform = 33.081   loss each uniform = 5.575   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.068  exp loss = 2.219  adjusted loss = 2.219  adv prob = 0.250000   acc = 0.594   grad norm = 14.967   grad norm uniform = 30.017   loss each uniform = 4.954   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.955   grad norm = 1.813   grad norm uniform = 38.592   loss each uniform = 10.500   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8648873567581177


Epoch [138]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.177  
Average loss each uniform: 11.326  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.978   loss each uniform = 11.455   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 41.499   loss each uniform = 8.827   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 36.509   loss each uniform = 7.888   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.200   loss each uniform = 11.513   feat norm = 0.448  

Validation:
Average incurred loss: 0.624  
Average sample loss: 0.606  
Average acc: 0.857  
Average grad norm: 5.711  
Average grad norm uniform: 33.235  
Average loss each uniform: 7.917  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.282   grad norm uniform = 33.952   loss each uniform = 10.588   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.008  exp loss = 1.095  adjusted loss = 1.095  adv prob = 0.250000   acc = 0.758   grad norm = 9.977   grad norm uniform = 31.936   loss each uniform = 5.278   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.877  exp loss = 1.999  adjusted loss = 1.999  adv prob = 0.250000   acc = 0.617   grad norm = 13.888   grad norm uniform = 30.113   loss each uniform = 4.971   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.955   grad norm = 1.655   grad norm uniform = 38.391   loss each uniform = 10.732   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [139]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.174  
Average loss each uniform: 11.342  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 34.955   loss each uniform = 11.470   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.048   grad norm uniform = 41.613   loss each uniform = 8.845   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 36.826   loss each uniform = 8.084   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.225   loss each uniform = 11.525   feat norm = 0.449  

Validation:
Average incurred loss: 0.641  
Average sample loss: 0.620  
Average acc: 0.856  
Average grad norm: 5.748  
Average grad norm uniform: 34.077  
Average loss each uniform: 8.201  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.996   grad norm = 0.255   grad norm uniform = 34.720   loss each uniform = 11.032   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.016  exp loss = 1.100  adjusted loss = 1.100  adv prob = 0.250000   acc = 0.758   grad norm = 9.969   grad norm uniform = 33.071   loss each uniform = 5.487   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.988  exp loss = 2.128  adjusted loss = 2.128  adv prob = 0.250000   acc = 0.609   grad norm = 14.322   grad norm uniform = 30.355   loss each uniform = 5.076   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.955   grad norm = 1.678   grad norm uniform = 39.067   loss each uniform = 10.897   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8557130694389343


Epoch [140]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.163  
Average loss each uniform: 11.309  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.961   loss each uniform = 11.469   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 41.505   loss each uniform = 8.667   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.093   grad norm uniform = 36.641   loss each uniform = 7.739   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 39.185   loss each uniform = 11.429   feat norm = 0.449  

Validation:
Average incurred loss: 0.683  
Average sample loss: 0.663  
Average acc: 0.846  
Average grad norm: 6.049  
Average grad norm uniform: 33.829  
Average loss each uniform: 8.095  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.987   grad norm = 0.356   grad norm uniform = 34.340   loss each uniform = 10.724   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.175  exp loss = 1.261  adjusted loss = 1.261  adv prob = 0.250000   acc = 0.730   grad norm = 11.056   grad norm uniform = 32.674   loss each uniform = 5.320   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.810  exp loss = 1.970  adjusted loss = 1.970  adv prob = 0.250000   acc = 0.632   grad norm = 13.077   grad norm uniform = 30.739   loss each uniform = 5.244   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.970   grad norm = 1.463   grad norm uniform = 39.169   loss each uniform = 11.439   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8457047343254089


Epoch [141]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.170  
Average loss each uniform: 11.337  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.968   loss each uniform = 11.492   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 41.523   loss each uniform = 8.630   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.065   grad norm uniform = 36.435   loss each uniform = 7.668   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.202   loss each uniform = 11.488   feat norm = 0.449  

Validation:
Average incurred loss: 0.646  
Average sample loss: 0.626  
Average acc: 0.854  
Average grad norm: 5.791  
Average grad norm uniform: 33.714  
Average loss each uniform: 8.075  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.309   grad norm uniform = 34.216   loss each uniform = 10.749   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.063  exp loss = 1.159  adjusted loss = 1.159  adv prob = 0.250000   acc = 0.749   grad norm = 10.277   grad norm uniform = 32.522   loss each uniform = 5.357   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.868  exp loss = 1.995  adjusted loss = 1.995  adv prob = 0.250000   acc = 0.632   grad norm = 13.540   grad norm uniform = 30.718   loss each uniform = 5.167   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.955   grad norm = 1.572   grad norm uniform = 39.129   loss each uniform = 11.116   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [142]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.007  
Average grad norm uniform: 36.163  
Average loss each uniform: 11.337  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.955   loss each uniform = 11.476   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.582   loss each uniform = 8.918   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.089   grad norm uniform = 36.600   loss each uniform = 7.822   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 39.195   loss each uniform = 11.485   feat norm = 0.449  

Validation:
Average incurred loss: 0.629  
Average sample loss: 0.609  
Average acc: 0.860  
Average grad norm: 5.619  
Average grad norm uniform: 33.785  
Average loss each uniform: 8.169  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.251   grad norm uniform = 34.529   loss each uniform = 11.044   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.980  exp loss = 1.079  adjusted loss = 1.079  adv prob = 0.250000   acc = 0.768   grad norm = 9.631   grad norm uniform = 32.913   loss each uniform = 5.495   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.009  exp loss = 2.153  adjusted loss = 2.153  adv prob = 0.250000   acc = 0.594   grad norm = 14.332   grad norm uniform = 29.706   loss each uniform = 4.998   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.187  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.962   grad norm = 1.696   grad norm uniform = 38.307   loss each uniform = 10.617   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8598833084106445


Epoch [143]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.177  
Average loss each uniform: 11.394  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.957   loss each uniform = 11.517   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.579   loss each uniform = 8.919   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.036   grad norm uniform = 36.506   loss each uniform = 8.044   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.254   loss each uniform = 11.592   feat norm = 0.449  

Validation:
Average incurred loss: 0.579  
Average sample loss: 0.559  
Average acc: 0.872  
Average grad norm: 5.068  
Average grad norm uniform: 33.990  
Average loss each uniform: 8.362  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.171   grad norm uniform = 34.611   loss each uniform = 11.322   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.802  exp loss = 0.868  adjusted loss = 0.868  adv prob = 0.250000   acc = 0.809   grad norm = 7.944   grad norm uniform = 33.546   loss each uniform = 5.850   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.165  exp loss = 2.302  adjusted loss = 2.302  adv prob = 0.250000   acc = 0.571   grad norm = 15.208   grad norm uniform = 29.502   loss each uniform = 4.937   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.225  exp loss = 0.217  adjusted loss = 0.217  adv prob = 0.250000   acc = 0.955   grad norm = 2.043   grad norm uniform = 37.856   loss each uniform = 10.198   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8723936676979065


Epoch [144]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.173  
Average loss each uniform: 11.399  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.958   loss each uniform = 11.533   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.548   loss each uniform = 8.852   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.785   loss each uniform = 8.263   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.227   loss each uniform = 11.564   feat norm = 0.449  

Validation:
Average incurred loss: 0.601  
Average sample loss: 0.581  
Average acc: 0.870  
Average grad norm: 5.292  
Average grad norm uniform: 34.078  
Average loss each uniform: 8.352  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.186   grad norm uniform = 34.923   loss each uniform = 11.389   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.849  exp loss = 0.921  adjusted loss = 0.921  adv prob = 0.250000   acc = 0.805   grad norm = 8.441   grad norm uniform = 33.565   loss each uniform = 5.764   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.202  exp loss = 2.336  adjusted loss = 2.336  adv prob = 0.250000   acc = 0.564   grad norm = 15.482   grad norm uniform = 29.095   loss each uniform = 4.897   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.219  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.955   grad norm = 1.999   grad norm uniform = 37.893   loss each uniform = 10.215   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8698915839195251


Epoch [145]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.179  
Average loss each uniform: 11.428  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.940   loss each uniform = 11.564   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.583   loss each uniform = 8.749   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 36.620   loss each uniform = 7.935   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.314   loss each uniform = 11.628   feat norm = 0.449  

Validation:
Average incurred loss: 0.651  
Average sample loss: 0.633  
Average acc: 0.850  
Average grad norm: 5.940  
Average grad norm uniform: 33.859  
Average loss each uniform: 7.940  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.327   grad norm uniform = 34.092   loss each uniform = 10.489   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.106  exp loss = 1.206  adjusted loss = 1.206  adv prob = 0.250000   acc = 0.738   grad norm = 10.790   grad norm uniform = 32.871   loss each uniform = 5.268   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.779  exp loss = 1.928  adjusted loss = 1.928  adv prob = 0.250000   acc = 0.624   grad norm = 13.126   grad norm uniform = 30.987   loss each uniform = 5.157   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.962   grad norm = 1.474   grad norm uniform = 39.378   loss each uniform = 11.138   feat norm = 0.465  
Current lr: 0.001000
Current validation accuracy: 0.8498749136924744


Epoch [146]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.175  
Average loss each uniform: 11.422  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.947   loss each uniform = 11.554   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 41.518   loss each uniform = 8.932   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 36.767   loss each uniform = 8.055   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.277   loss each uniform = 11.596   feat norm = 0.449  

Validation:
Average incurred loss: 0.630  
Average sample loss: 0.611  
Average acc: 0.856  
Average grad norm: 5.670  
Average grad norm uniform: 33.856  
Average loss each uniform: 8.121  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.265   grad norm uniform = 34.296   loss each uniform = 10.864   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.015  exp loss = 1.099  adjusted loss = 1.099  adv prob = 0.250000   acc = 0.753   grad norm = 9.948   grad norm uniform = 32.922   loss each uniform = 5.438   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.898  exp loss = 2.065  adjusted loss = 2.065  adv prob = 0.250000   acc = 0.624   grad norm = 13.739   grad norm uniform = 30.391   loss each uniform = 5.080   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.955   grad norm = 1.586   grad norm uniform = 39.047   loss each uniform = 10.937   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8557130694389343


Epoch [147]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.163  
Average loss each uniform: 11.415  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.921   loss each uniform = 11.559   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.610   loss each uniform = 8.880   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 36.645   loss each uniform = 7.990   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.299   loss each uniform = 11.561   feat norm = 0.449  

Validation:
Average incurred loss: 0.622  
Average sample loss: 0.603  
Average acc: 0.863  
Average grad norm: 5.529  
Average grad norm uniform: 33.973  
Average loss each uniform: 8.271  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.244   grad norm uniform = 34.631   loss each uniform = 11.199   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.946  exp loss = 1.027  adjusted loss = 1.027  adv prob = 0.250000   acc = 0.779   grad norm = 9.303   grad norm uniform = 33.231   loss each uniform = 5.592   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.060  exp loss = 2.202  adjusted loss = 2.202  adv prob = 0.250000   acc = 0.594   grad norm = 14.597   grad norm uniform = 29.667   loss each uniform = 5.015   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.955   grad norm = 1.794   grad norm uniform = 38.573   loss each uniform = 10.632   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [148]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.163  
Average loss each uniform: 11.435  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.927   loss each uniform = 11.575   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 41.607   loss each uniform = 8.891   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.907   loss each uniform = 8.260   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.265   loss each uniform = 11.579   feat norm = 0.449  

Validation:
Average incurred loss: 0.616  
Average sample loss: 0.598  
Average acc: 0.864  
Average grad norm: 5.504  
Average grad norm uniform: 33.757  
Average loss each uniform: 8.178  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.226   grad norm uniform = 34.357   loss each uniform = 11.014   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.943  exp loss = 1.012  adjusted loss = 1.012  adv prob = 0.250000   acc = 0.777   grad norm = 9.317   grad norm uniform = 32.962   loss each uniform = 5.558   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.019  exp loss = 2.167  adjusted loss = 2.167  adv prob = 0.250000   acc = 0.609   grad norm = 14.414   grad norm uniform = 29.748   loss each uniform = 4.969   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.199  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.955   grad norm = 1.769   grad norm uniform = 38.446   loss each uniform = 10.610   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [149]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.156  
Average loss each uniform: 11.435  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.931   loss each uniform = 11.574   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 41.614   loss each uniform = 8.962   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.822   loss each uniform = 8.113   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.223   loss each uniform = 11.580   feat norm = 0.448  

Validation:
Average incurred loss: 0.637  
Average sample loss: 0.618  
Average acc: 0.856  
Average grad norm: 5.702  
Average grad norm uniform: 33.523  
Average loss each uniform: 8.091  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.213   grad norm uniform = 34.345   loss each uniform = 10.959   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.987  exp loss = 1.062  adjusted loss = 1.062  adv prob = 0.250000   acc = 0.762   grad norm = 9.728   grad norm uniform = 32.387   loss each uniform = 5.381   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.073  exp loss = 2.211  adjusted loss = 2.211  adv prob = 0.250000   acc = 0.586   grad norm = 14.869   grad norm uniform = 29.703   loss each uniform = 4.962   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.955   grad norm = 1.705   grad norm uniform = 38.432   loss each uniform = 10.643   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [150]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.169  
Average loss each uniform: 11.456  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.939   loss each uniform = 11.590   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.600   loss each uniform = 9.015   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 36.832   loss each uniform = 8.081   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.255   loss each uniform = 11.617   feat norm = 0.449  

Validation:
Average incurred loss: 0.646  
Average sample loss: 0.628  
Average acc: 0.853  
Average grad norm: 5.770  
Average grad norm uniform: 33.507  
Average loss each uniform: 8.078  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.316   grad norm uniform = 33.930   loss each uniform = 10.728   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.089  exp loss = 1.189  adjusted loss = 1.189  adv prob = 0.250000   acc = 0.749   grad norm = 10.361   grad norm uniform = 32.296   loss each uniform = 5.347   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.791  exp loss = 1.937  adjusted loss = 1.937  adv prob = 0.250000   acc = 0.624   grad norm = 13.107   grad norm uniform = 30.720   loss each uniform = 5.158   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.955   grad norm = 1.495   grad norm uniform = 39.054   loss each uniform = 11.256   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8532110452651978


Epoch [151]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.156  
Average loss each uniform: 11.427  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.935   loss each uniform = 11.575   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.575   loss each uniform = 8.973   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.097   grad norm uniform = 36.373   loss each uniform = 7.684   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.243   loss each uniform = 11.564   feat norm = 0.449  

Validation:
Average incurred loss: 0.606  
Average sample loss: 0.587  
Average acc: 0.865  
Average grad norm: 5.387  
Average grad norm uniform: 33.964  
Average loss each uniform: 8.326  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.193   grad norm uniform = 34.640   loss each uniform = 11.303   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.889  exp loss = 0.961  adjusted loss = 0.961  adv prob = 0.250000   acc = 0.790   grad norm = 8.865   grad norm uniform = 33.283   loss each uniform = 5.670   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.120  exp loss = 2.250  adjusted loss = 2.250  adv prob = 0.250000   acc = 0.571   grad norm = 15.023   grad norm uniform = 29.572   loss each uniform = 4.968   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.955   grad norm = 1.806   grad norm uniform = 38.373   loss each uniform = 10.534   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8648874163627625


Epoch [152]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.163  
Average loss each uniform: 11.465  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.934   loss each uniform = 11.601   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.646   loss each uniform = 9.026   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.852   loss each uniform = 8.155   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.240   loss each uniform = 11.616   feat norm = 0.448  

Validation:
Average incurred loss: 0.617  
Average sample loss: 0.597  
Average acc: 0.864  
Average grad norm: 5.431  
Average grad norm uniform: 33.884  
Average loss each uniform: 8.299  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.195   grad norm uniform = 34.538   loss each uniform = 11.228   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.924  exp loss = 1.004  adjusted loss = 1.004  adv prob = 0.250000   acc = 0.783   grad norm = 9.052   grad norm uniform = 33.016   loss each uniform = 5.597   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.096  exp loss = 2.249  adjusted loss = 2.249  adv prob = 0.250000   acc = 0.586   grad norm = 14.749   grad norm uniform = 29.817   loss each uniform = 5.063   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.200  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.955   grad norm = 1.815   grad norm uniform = 38.693   loss each uniform = 10.716   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8640533685684204


Epoch [153]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.157  
Average loss each uniform: 11.467  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.920   loss each uniform = 11.612   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 41.627   loss each uniform = 9.004   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.047   grad norm uniform = 36.723   loss each uniform = 8.041   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.272   loss each uniform = 11.598   feat norm = 0.449  

Validation:
Average incurred loss: 0.606  
Average sample loss: 0.587  
Average acc: 0.869  
Average grad norm: 5.343  
Average grad norm uniform: 33.802  
Average loss each uniform: 8.323  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.235   grad norm uniform = 34.291   loss each uniform = 11.143   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.942  exp loss = 1.005  adjusted loss = 1.005  adv prob = 0.250000   acc = 0.785   grad norm = 9.123   grad norm uniform = 32.887   loss each uniform = 5.649   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.940  exp loss = 2.098  adjusted loss = 2.098  adv prob = 0.250000   acc = 0.624   grad norm = 13.695   grad norm uniform = 30.373   loss each uniform = 5.151   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.955   grad norm = 1.683   grad norm uniform = 38.717   loss each uniform = 10.958   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [154]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.160  
Average loss each uniform: 11.474  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.924   loss each uniform = 11.619   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.599   loss each uniform = 8.977   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.881   loss each uniform = 8.179   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.267   loss each uniform = 11.605   feat norm = 0.449  

Validation:
Average incurred loss: 0.676  
Average sample loss: 0.659  
Average acc: 0.847  
Average grad norm: 6.038  
Average grad norm uniform: 33.549  
Average loss each uniform: 7.998  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.347   grad norm uniform = 33.972   loss each uniform = 10.615   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.174  exp loss = 1.270  adjusted loss = 1.270  adv prob = 0.250000   acc = 0.732   grad norm = 11.115   grad norm uniform = 32.397   loss each uniform = 5.221   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.768  exp loss = 1.915  adjusted loss = 1.915  adv prob = 0.250000   acc = 0.624   grad norm = 12.925   grad norm uniform = 30.374   loss each uniform = 5.177   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.970   grad norm = 1.344   grad norm uniform = 39.275   loss each uniform = 11.358   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.847372829914093


Epoch [155]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.148  
Average loss each uniform: 11.457  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.916   loss each uniform = 11.605   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.614   loss each uniform = 9.113   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.040   grad norm uniform = 36.669   loss each uniform = 7.977   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.245   loss each uniform = 11.558   feat norm = 0.449  

Validation:
Average incurred loss: 0.592  
Average sample loss: 0.571  
Average acc: 0.866  
Average grad norm: 5.221  
Average grad norm uniform: 33.894  
Average loss each uniform: 8.331  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.157   grad norm uniform = 34.627   loss each uniform = 11.319   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.816  exp loss = 0.883  adjusted loss = 0.883  adv prob = 0.250000   acc = 0.800   grad norm = 8.189   grad norm uniform = 33.229   loss each uniform = 5.750   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.235  exp loss = 2.365  adjusted loss = 2.365  adv prob = 0.250000   acc = 0.549   grad norm = 15.804   grad norm uniform = 29.506   loss each uniform = 4.944   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.218  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.947   grad norm = 2.020   grad norm uniform = 38.041   loss each uniform = 10.266   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [156]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.156  
Average loss each uniform: 11.504  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.906   loss each uniform = 11.656   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 41.562   loss each uniform = 8.944   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.952   loss each uniform = 8.248   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.307   loss each uniform = 11.620   feat norm = 0.449  

Validation:
Average incurred loss: 0.625  
Average sample loss: 0.605  
Average acc: 0.865  
Average grad norm: 5.528  
Average grad norm uniform: 33.956  
Average loss each uniform: 8.289  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.231   grad norm uniform = 34.528   loss each uniform = 11.169   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.945  exp loss = 1.017  adjusted loss = 1.017  adv prob = 0.250000   acc = 0.783   grad norm = 9.267   grad norm uniform = 33.093   loss each uniform = 5.615   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.090  exp loss = 2.233  adjusted loss = 2.233  adv prob = 0.250000   acc = 0.594   grad norm = 14.769   grad norm uniform = 30.079   loss each uniform = 5.072   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.955   grad norm = 1.790   grad norm uniform = 38.850   loss each uniform = 10.759   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8648873567581177


Epoch [157]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.164  
Average loss each uniform: 11.535  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.907   loss each uniform = 11.678   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.677   loss each uniform = 9.058   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 37.195   loss each uniform = 8.333   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.308   loss each uniform = 11.665   feat norm = 0.449  

Validation:
Average incurred loss: 0.616  
Average sample loss: 0.597  
Average acc: 0.865  
Average grad norm: 5.525  
Average grad norm uniform: 33.502  
Average loss each uniform: 8.134  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.228   grad norm uniform = 34.376   loss each uniform = 11.011   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.955  exp loss = 1.038  adjusted loss = 1.038  adv prob = 0.250000   acc = 0.783   grad norm = 9.414   grad norm uniform = 32.370   loss each uniform = 5.442   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.986  exp loss = 2.108  adjusted loss = 2.108  adv prob = 0.250000   acc = 0.594   grad norm = 14.283   grad norm uniform = 29.789   loss each uniform = 4.988   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.187  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.955   grad norm = 1.737   grad norm uniform = 38.118   loss each uniform = 10.612   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8648873567581177


Epoch [158]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.159  
Average loss each uniform: 11.538  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.907   loss each uniform = 11.685   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.562   loss each uniform = 9.031   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.831   loss each uniform = 8.155   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.328   loss each uniform = 11.668   feat norm = 0.449  

Validation:
Average incurred loss: 0.711  
Average sample loss: 0.692  
Average acc: 0.841  
Average grad norm: 6.204  
Average grad norm uniform: 33.896  
Average loss each uniform: 8.150  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.987   grad norm = 0.420   grad norm uniform = 34.247   loss each uniform = 10.665   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.292  exp loss = 1.394  adjusted loss = 1.394  adv prob = 0.250000   acc = 0.712   grad norm = 11.767   grad norm uniform = 32.857   loss each uniform = 5.344   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.647  exp loss = 1.807  adjusted loss = 1.807  adv prob = 0.250000   acc = 0.647   grad norm = 11.974   grad norm uniform = 30.716   loss each uniform = 5.451   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.157  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.970   grad norm = 1.251   grad norm uniform = 39.482   loss each uniform = 11.849   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.840700626373291


Epoch [159]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.155  
Average loss each uniform: 11.533  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.898   loss each uniform = 11.671   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.645   loss each uniform = 9.289   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.047   grad norm uniform = 36.736   loss each uniform = 8.027   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.329   loss each uniform = 11.650   feat norm = 0.449  

Validation:
Average incurred loss: 0.590  
Average sample loss: 0.570  
Average acc: 0.866  
Average grad norm: 5.182  
Average grad norm uniform: 33.328  
Average loss each uniform: 8.298  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.137   grad norm uniform = 34.146   loss each uniform = 11.343   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.790  exp loss = 0.867  adjusted loss = 0.867  adv prob = 0.250000   acc = 0.800   grad norm = 8.025   grad norm uniform = 32.574   loss each uniform = 5.722   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.305  exp loss = 2.473  adjusted loss = 2.473  adv prob = 0.250000   acc = 0.549   grad norm = 16.002   grad norm uniform = 28.852   loss each uniform = 4.856   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.227  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947   grad norm = 2.114   grad norm uniform = 37.576   loss each uniform = 10.075   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8657214045524597


Epoch [160]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.155  
Average loss each uniform: 11.536  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.904   loss each uniform = 11.683   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.615   loss each uniform = 9.169   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.906   loss each uniform = 8.291   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.305   loss each uniform = 11.633   feat norm = 0.449  

Validation:
Average incurred loss: 0.641  
Average sample loss: 0.621  
Average acc: 0.855  
Average grad norm: 5.700  
Average grad norm uniform: 33.533  
Average loss each uniform: 8.157  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.259   grad norm uniform = 34.129   loss each uniform = 10.985   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.015  exp loss = 1.098  adjusted loss = 1.098  adv prob = 0.250000   acc = 0.755   grad norm = 9.880   grad norm uniform = 32.361   loss each uniform = 5.380   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.007  exp loss = 2.139  adjusted loss = 2.139  adv prob = 0.250000   acc = 0.602   grad norm = 14.245   grad norm uniform = 30.185   loss each uniform = 5.114   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.955   grad norm = 1.614   grad norm uniform = 38.898   loss each uniform = 11.005   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8548790812492371


Epoch [161]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.153  
Average loss each uniform: 11.542  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.915   loss each uniform = 11.691   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 41.537   loss each uniform = 9.085   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.051   grad norm uniform = 36.346   loss each uniform = 7.845   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.302   loss each uniform = 11.671   feat norm = 0.449  

Validation:
Average incurred loss: 0.717  
Average sample loss: 0.700  
Average acc: 0.832  
Average grad norm: 6.418  
Average grad norm uniform: 33.575  
Average loss each uniform: 7.966  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.987   grad norm = 0.454   grad norm uniform = 33.898   loss each uniform = 10.424   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.306  exp loss = 1.407  adjusted loss = 1.407  adv prob = 0.250000   acc = 0.691   grad norm = 12.192   grad norm uniform = 32.071   loss each uniform = 5.108   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.650  exp loss = 1.786  adjusted loss = 1.786  adv prob = 0.250000   acc = 0.647   grad norm = 12.196   grad norm uniform = 31.279   loss each uniform = 5.391   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 0.970   grad norm = 1.346   grad norm uniform = 40.007   loss each uniform = 11.924   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8323603272438049


Epoch [162]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.148  
Average loss each uniform: 11.547  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.901   loss each uniform = 11.701   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.601   loss each uniform = 9.025   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.038   grad norm uniform = 37.078   loss each uniform = 8.390   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.274   loss each uniform = 11.643   feat norm = 0.449  

Validation:
Average incurred loss: 0.636  
Average sample loss: 0.619  
Average acc: 0.855  
Average grad norm: 5.656  
Average grad norm uniform: 33.651  
Average loss each uniform: 8.232  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.253   grad norm uniform = 34.234   loss each uniform = 11.090   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.014  exp loss = 1.107  adjusted loss = 1.107  adv prob = 0.250000   acc = 0.753   grad norm = 9.805   grad norm uniform = 32.612   loss each uniform = 5.468   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.965  exp loss = 2.112  adjusted loss = 2.112  adv prob = 0.250000   acc = 0.609   grad norm = 14.106   grad norm uniform = 30.164   loss each uniform = 5.076   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.962   grad norm = 1.640   grad norm uniform = 38.732   loss each uniform = 11.036   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8548790216445923


Epoch [163]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.150  
Average loss each uniform: 11.549  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.906   loss each uniform = 11.685   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.573   loss each uniform = 9.193   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 1.000   grad norm = 0.070   grad norm uniform = 36.718   loss each uniform = 8.205   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.292   loss each uniform = 11.684   feat norm = 0.449  

Validation:
Average incurred loss: 0.650  
Average sample loss: 0.633  
Average acc: 0.853  
Average grad norm: 5.700  
Average grad norm uniform: 33.971  
Average loss each uniform: 8.285  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.304   grad norm uniform = 34.398   loss each uniform = 10.979   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.097  exp loss = 1.194  adjusted loss = 1.194  adv prob = 0.250000   acc = 0.751   grad norm = 10.237   grad norm uniform = 33.142   loss each uniform = 5.565   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.785  exp loss = 1.940  adjusted loss = 1.940  adv prob = 0.250000   acc = 0.624   grad norm = 12.923   grad norm uniform = 30.306   loss each uniform = 5.241   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.955   grad norm = 1.530   grad norm uniform = 39.043   loss each uniform = 11.396   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8532110452651978


Epoch [164]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.154  
Average loss each uniform: 11.566  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.914   loss each uniform = 11.695   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.675   loss each uniform = 9.205   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.637   loss each uniform = 8.027   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.273   loss each uniform = 11.738   feat norm = 0.448  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.568  
Average acc: 0.872  
Average grad norm: 5.021  
Average grad norm uniform: 34.314  
Average loss each uniform: 8.648  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.118   grad norm uniform = 35.017   loss each uniform = 11.885   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.739  exp loss = 0.801  adjusted loss = 0.801  adv prob = 0.250000   acc = 0.818   grad norm = 7.407   grad norm uniform = 34.108   loss each uniform = 6.071   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.480  exp loss = 2.632  adjusted loss = 2.632  adv prob = 0.250000   acc = 0.549   grad norm = 16.728   grad norm uniform = 29.152   loss each uniform = 4.972   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.243  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.940   grad norm = 2.168   grad norm uniform = 37.733   loss each uniform = 9.984   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [165]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.159  
Average loss each uniform: 11.588  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.916   loss each uniform = 11.717   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.574   loss each uniform = 9.129   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.829   loss each uniform = 8.236   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.294   loss each uniform = 11.767   feat norm = 0.448  

Validation:
Average incurred loss: 0.654  
Average sample loss: 0.634  
Average acc: 0.857  
Average grad norm: 5.747  
Average grad norm uniform: 33.812  
Average loss each uniform: 8.169  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.294   grad norm uniform = 34.369   loss each uniform = 10.959   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.058  exp loss = 1.142  adjusted loss = 1.142  adv prob = 0.250000   acc = 0.758   grad norm = 10.083   grad norm uniform = 32.750   loss each uniform = 5.440   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.968  exp loss = 2.111  adjusted loss = 2.111  adv prob = 0.250000   acc = 0.617   grad norm = 13.869   grad norm uniform = 30.586   loss each uniform = 5.129   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.955   grad norm = 1.580   grad norm uniform = 38.807   loss each uniform = 10.972   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [166]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.151  
Average loss each uniform: 11.561  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.915   loss each uniform = 11.707   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 41.529   loss each uniform = 9.065   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 36.933   loss each uniform = 8.315   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.263   loss each uniform = 11.683   feat norm = 0.448  

Validation:
Average incurred loss: 0.615  
Average sample loss: 0.594  
Average acc: 0.866  
Average grad norm: 5.350  
Average grad norm uniform: 34.021  
Average loss each uniform: 8.438  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.171   grad norm uniform = 34.746   loss each uniform = 11.512   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.865  exp loss = 0.940  adjusted loss = 0.940  adv prob = 0.250000   acc = 0.798   grad norm = 8.576   grad norm uniform = 33.433   loss each uniform = 5.788   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.274  exp loss = 2.426  adjusted loss = 2.426  adv prob = 0.250000   acc = 0.549   grad norm = 15.670   grad norm uniform = 29.439   loss each uniform = 4.983   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.212  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.955   grad norm = 1.918   grad norm uniform = 38.119   loss each uniform = 10.382   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [167]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.147  
Average loss each uniform: 11.584  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.910   loss each uniform = 11.718   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.489   loss each uniform = 9.169   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 36.960   loss each uniform = 8.300   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.268   loss each uniform = 11.735   feat norm = 0.448  

Validation:
Average incurred loss: 0.624  
Average sample loss: 0.603  
Average acc: 0.862  
Average grad norm: 5.467  
Average grad norm uniform: 33.894  
Average loss each uniform: 8.365  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.157   grad norm uniform = 34.770   loss each uniform = 11.474   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.878  exp loss = 0.952  adjusted loss = 0.952  adv prob = 0.250000   acc = 0.790   grad norm = 8.768   grad norm uniform = 33.233   loss each uniform = 5.694   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.312  exp loss = 2.436  adjusted loss = 2.436  adv prob = 0.250000   acc = 0.549   grad norm = 16.066   grad norm uniform = 29.090   loss each uniform = 4.902   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.216  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.947   grad norm = 1.944   grad norm uniform = 37.937   loss each uniform = 10.274   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [168]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.006  
Average grad norm uniform: 36.149  
Average loss each uniform: 11.592  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.912   loss each uniform = 11.727   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.649   loss each uniform = 9.094   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 36.902   loss each uniform = 8.324   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.242   loss each uniform = 11.751   feat norm = 0.448  

Validation:
Average incurred loss: 0.604  
Average sample loss: 0.585  
Average acc: 0.867  
Average grad norm: 5.319  
Average grad norm uniform: 33.635  
Average loss each uniform: 8.348  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.217   grad norm uniform = 34.266   loss each uniform = 11.255   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.896  exp loss = 0.981  adjusted loss = 0.981  adv prob = 0.250000   acc = 0.785   grad norm = 8.751   grad norm uniform = 32.818   loss each uniform = 5.705   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.073  exp loss = 2.221  adjusted loss = 2.221  adv prob = 0.250000   acc = 0.602   grad norm = 14.670   grad norm uniform = 29.608   loss each uniform = 5.028   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.200  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.955   grad norm = 1.861   grad norm uniform = 38.310   loss each uniform = 10.719   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [169]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.157  
Average loss each uniform: 11.587  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.941   loss each uniform = 11.712   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.572   loss each uniform = 9.141   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.042   grad norm uniform = 36.603   loss each uniform = 7.976   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.217   loss each uniform = 11.790   feat norm = 0.448  

Validation:
Average incurred loss: 0.712  
Average sample loss: 0.694  
Average acc: 0.839  
Average grad norm: 6.240  
Average grad norm uniform: 33.561  
Average loss each uniform: 8.139  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.987   grad norm = 0.384   grad norm uniform = 34.193   loss each uniform = 10.773   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.276  exp loss = 1.378  adjusted loss = 1.378  adv prob = 0.250000   acc = 0.710   grad norm = 11.722   grad norm uniform = 32.004   loss each uniform = 5.231   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.730  exp loss = 1.874  adjusted loss = 1.874  adv prob = 0.250000   acc = 0.639   grad norm = 12.524   grad norm uniform = 30.870   loss each uniform = 5.392   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.153  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.970   grad norm = 1.313   grad norm uniform = 39.494   loss each uniform = 11.831   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8390325307846069


Epoch [170]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.158  
Average loss each uniform: 11.611  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.932   loss each uniform = 11.741   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.492   loss each uniform = 8.966   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.039   grad norm uniform = 36.871   loss each uniform = 8.283   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.250   loss each uniform = 11.817   feat norm = 0.448  

Validation:
Average incurred loss: 0.660  
Average sample loss: 0.640  
Average acc: 0.852  
Average grad norm: 5.848  
Average grad norm uniform: 33.895  
Average loss each uniform: 8.238  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.287   grad norm uniform = 34.465   loss each uniform = 11.090   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.080  exp loss = 1.170  adjusted loss = 1.170  adv prob = 0.250000   acc = 0.747   grad norm = 10.372   grad norm uniform = 32.972   loss each uniform = 5.468   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.945  exp loss = 2.096  adjusted loss = 2.096  adv prob = 0.250000   acc = 0.609   grad norm = 13.831   grad norm uniform = 30.264   loss each uniform = 5.120   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.962   grad norm = 1.544   grad norm uniform = 38.757   loss each uniform = 11.047   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8515429496765137


Epoch [171]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.149  
Average loss each uniform: 11.592  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.929   loss each uniform = 11.730   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.557   loss each uniform = 8.995   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.671   loss each uniform = 8.103   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.215   loss each uniform = 11.771   feat norm = 0.448  

Validation:
Average incurred loss: 0.608  
Average sample loss: 0.588  
Average acc: 0.866  
Average grad norm: 5.302  
Average grad norm uniform: 33.793  
Average loss each uniform: 8.453  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.171   grad norm uniform = 34.526   loss each uniform = 11.494   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.872  exp loss = 0.950  adjusted loss = 0.950  adv prob = 0.250000   acc = 0.790   grad norm = 8.580   grad norm uniform = 33.067   loss each uniform = 5.784   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.192  exp loss = 2.306  adjusted loss = 2.306  adv prob = 0.250000   acc = 0.579   grad norm = 15.187   grad norm uniform = 29.446   loss each uniform = 5.018   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.208  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.955   grad norm = 1.951   grad norm uniform = 38.113   loss each uniform = 10.563   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [172]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.143  
Average loss each uniform: 11.599  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.920   loss each uniform = 11.740   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.540   loss each uniform = 9.040   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.727   loss each uniform = 8.153   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.222   loss each uniform = 11.760   feat norm = 0.448  

Validation:
Average incurred loss: 0.675  
Average sample loss: 0.656  
Average acc: 0.850  
Average grad norm: 5.944  
Average grad norm uniform: 33.540  
Average loss each uniform: 8.150  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.337   grad norm uniform = 33.892   loss each uniform = 10.808   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.150  exp loss = 1.243  adjusted loss = 1.243  adv prob = 0.250000   acc = 0.736   grad norm = 10.835   grad norm uniform = 32.493   loss each uniform = 5.370   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.833  exp loss = 1.972  adjusted loss = 1.972  adv prob = 0.250000   acc = 0.632   grad norm = 12.998   grad norm uniform = 30.504   loss each uniform = 5.254   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.170  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.970   grad norm = 1.442   grad norm uniform = 39.014   loss each uniform = 11.450   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8498749732971191


Epoch [173]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.153  
Average loss each uniform: 11.636  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.913   loss each uniform = 11.765   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.685   loss each uniform = 9.184   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.968   loss each uniform = 8.463   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.252   loss each uniform = 11.804   feat norm = 0.448  

Validation:
Average incurred loss: 0.589  
Average sample loss: 0.568  
Average acc: 0.876  
Average grad norm: 5.014  
Average grad norm uniform: 34.009  
Average loss each uniform: 8.592  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.129   grad norm uniform = 34.729   loss each uniform = 11.755   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.770  exp loss = 0.835  adjusted loss = 0.835  adv prob = 0.250000   acc = 0.826   grad norm = 7.540   grad norm uniform = 33.776   loss each uniform = 6.033   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.349  exp loss = 2.517  adjusted loss = 2.517  adv prob = 0.250000   acc = 0.541   grad norm = 16.155   grad norm uniform = 28.864   loss each uniform = 4.928   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.240  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.955   grad norm = 2.172   grad norm uniform = 37.446   loss each uniform = 10.119   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [174]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.147  
Average loss each uniform: 11.629  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.913   loss each uniform = 11.770   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.599   loss each uniform = 9.115   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.041   grad norm uniform = 36.541   loss each uniform = 8.135   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.262   loss each uniform = 11.785   feat norm = 0.448  

Validation:
Average incurred loss: 0.682  
Average sample loss: 0.662  
Average acc: 0.848  
Average grad norm: 5.978  
Average grad norm uniform: 34.112  
Average loss each uniform: 8.254  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.336   grad norm uniform = 34.510   loss each uniform = 10.943   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.173  exp loss = 1.265  adjusted loss = 1.265  adv prob = 0.250000   acc = 0.738   grad norm = 10.941   grad norm uniform = 32.999   loss each uniform = 5.430   feat norm = 0.487  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.810  exp loss = 1.987  adjusted loss = 1.987  adv prob = 0.250000   acc = 0.624   grad norm = 12.977   grad norm uniform = 31.301   loss each uniform = 5.345   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.168  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.962   grad norm = 1.401   grad norm uniform = 39.425   loss each uniform = 11.614   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8482068777084351


Epoch [175]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.146  
Average loss each uniform: 11.649  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.910   loss each uniform = 11.779   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.604   loss each uniform = 9.240   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 36.945   loss each uniform = 8.334   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.244   loss each uniform = 11.813   feat norm = 0.448  

Validation:
Average incurred loss: 0.593  
Average sample loss: 0.572  
Average acc: 0.869  
Average grad norm: 5.091  
Average grad norm uniform: 33.719  
Average loss each uniform: 8.478  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.133   grad norm uniform = 34.399   loss each uniform = 11.574   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.777  exp loss = 0.853  adjusted loss = 0.853  adv prob = 0.250000   acc = 0.811   grad norm = 7.737   grad norm uniform = 33.206   loss each uniform = 5.894   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.370  exp loss = 2.522  adjusted loss = 2.522  adv prob = 0.250000   acc = 0.541   grad norm = 16.188   grad norm uniform = 29.192   loss each uniform = 4.955   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.229  exp loss = 0.227  adjusted loss = 0.227  adv prob = 0.250000   acc = 0.947   grad norm = 2.133   grad norm uniform = 37.658   loss each uniform = 10.186   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [176]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.146  
Average loss each uniform: 11.664  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.900   loss each uniform = 11.798   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 41.593   loss each uniform = 9.128   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 37.078   loss each uniform = 8.542   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.273   loss each uniform = 11.828   feat norm = 0.448  

Validation:
Average incurred loss: 0.744  
Average sample loss: 0.727  
Average acc: 0.832  
Average grad norm: 6.544  
Average grad norm uniform: 33.937  
Average loss each uniform: 8.088  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.987   grad norm = 0.477   grad norm uniform = 34.295   loss each uniform = 10.557   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.381  exp loss = 1.493  adjusted loss = 1.493  adv prob = 0.250000   acc = 0.689   grad norm = 12.577   grad norm uniform = 32.555   loss each uniform = 5.187   feat norm = 0.486  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.637  exp loss = 1.781  adjusted loss = 1.781  adv prob = 0.250000   acc = 0.654   grad norm = 12.006   grad norm uniform = 31.251   loss each uniform = 5.549   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.970   grad norm = 1.244   grad norm uniform = 40.212   loss each uniform = 12.124   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8323602676391602


Epoch [177]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.146  
Average loss each uniform: 11.646  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.904   loss each uniform = 11.794   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.517   loss each uniform = 9.152   feat norm = 0.527  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.851   loss each uniform = 8.544   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.284   loss each uniform = 11.755   feat norm = 0.449  

Validation:
Average incurred loss: 0.713  
Average sample loss: 0.694  
Average acc: 0.841  
Average grad norm: 6.278  
Average grad norm uniform: 33.500  
Average loss each uniform: 8.044  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.369   grad norm uniform = 33.961   loss each uniform = 10.610   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.257  exp loss = 1.345  adjusted loss = 1.345  adv prob = 0.250000   acc = 0.715   grad norm = 11.677   grad norm uniform = 32.042   loss each uniform = 5.200   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.804  exp loss = 1.940  adjusted loss = 1.940  adv prob = 0.250000   acc = 0.632   grad norm = 13.029   grad norm uniform = 30.781   loss each uniform = 5.320   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.153  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.970   grad norm = 1.359   grad norm uniform = 39.711   loss each uniform = 11.720   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8407005667686462


Epoch [178]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.152  
Average loss each uniform: 11.701  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.909   loss each uniform = 11.832   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.591   loss each uniform = 9.206   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.877   loss each uniform = 8.369   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.279   loss each uniform = 11.877   feat norm = 0.448  

Validation:
Average incurred loss: 0.637  
Average sample loss: 0.619  
Average acc: 0.862  
Average grad norm: 5.525  
Average grad norm uniform: 33.722  
Average loss each uniform: 8.341  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.257   grad norm uniform = 34.180   loss each uniform = 11.195   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.998  exp loss = 1.070  adjusted loss = 1.070  adv prob = 0.250000   acc = 0.773   grad norm = 9.480   grad norm uniform = 32.949   loss each uniform = 5.628   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.014  exp loss = 2.159  adjusted loss = 2.159  adv prob = 0.250000   acc = 0.609   grad norm = 13.992   grad norm uniform = 29.990   loss each uniform = 5.163   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.955   grad norm = 1.700   grad norm uniform = 38.552   loss each uniform = 11.009   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8623852729797363


Epoch [179]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.149  
Average loss each uniform: 11.690  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.900   loss each uniform = 11.829   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.705   loss each uniform = 9.222   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.829   loss each uniform = 8.267   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.281   loss each uniform = 11.841   feat norm = 0.448  

Validation:
Average incurred loss: 0.639  
Average sample loss: 0.618  
Average acc: 0.862  
Average grad norm: 5.528  
Average grad norm uniform: 34.055  
Average loss each uniform: 8.452  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.220   grad norm uniform = 34.554   loss each uniform = 11.399   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.979  exp loss = 1.056  adjusted loss = 1.056  adv prob = 0.250000   acc = 0.775   grad norm = 9.351   grad norm uniform = 33.569   loss each uniform = 5.775   feat norm = 0.489  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.096  exp loss = 2.239  adjusted loss = 2.239  adv prob = 0.250000   acc = 0.594   grad norm = 14.581   grad norm uniform = 29.518   loss each uniform = 5.060   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.200  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.955   grad norm = 1.715   grad norm uniform = 38.542   loss each uniform = 10.877   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [180]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.139  
Average loss each uniform: 11.671  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.891   loss each uniform = 11.822   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 41.643   loss each uniform = 9.245   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.052   grad norm uniform = 36.785   loss each uniform = 8.091   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.277   loss each uniform = 11.787   feat norm = 0.448  

Validation:
Average incurred loss: 0.604  
Average sample loss: 0.584  
Average acc: 0.869  
Average grad norm: 5.209  
Average grad norm uniform: 34.081  
Average loss each uniform: 8.567  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.163   grad norm uniform = 34.752   loss each uniform = 11.669   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.843  exp loss = 0.911  adjusted loss = 0.911  adv prob = 0.250000   acc = 0.805   grad norm = 8.291   grad norm uniform = 33.554   loss each uniform = 5.903   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.250  exp loss = 2.389  adjusted loss = 2.389  adv prob = 0.250000   acc = 0.556   grad norm = 15.356   grad norm uniform = 29.552   loss each uniform = 5.064   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.218  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.955   grad norm = 1.986   grad norm uniform = 38.099   loss each uniform = 10.507   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [181]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.140  
Average loss each uniform: 11.698  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.884   loss each uniform = 11.847   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.647   loss each uniform = 9.172   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.915   loss each uniform = 8.309   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.298   loss each uniform = 11.826   feat norm = 0.448  

Validation:
Average incurred loss: 0.611  
Average sample loss: 0.591  
Average acc: 0.867  
Average grad norm: 5.263  
Average grad norm uniform: 33.756  
Average loss each uniform: 8.476  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.164   grad norm uniform = 34.390   loss each uniform = 11.534   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.861  exp loss = 0.922  adjusted loss = 0.922  adv prob = 0.250000   acc = 0.798   grad norm = 8.427   grad norm uniform = 33.309   loss each uniform = 5.826   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.248  exp loss = 2.405  adjusted loss = 2.405  adv prob = 0.250000   acc = 0.564   grad norm = 15.376   grad norm uniform = 29.009   loss each uniform = 5.004   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.955   grad norm = 1.971   grad norm uniform = 37.843   loss each uniform = 10.494   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8673895001411438


Epoch [182]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.142  
Average loss each uniform: 11.726  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.881   loss each uniform = 11.863   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.595   loss each uniform = 9.339   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.043   grad norm uniform = 36.860   loss each uniform = 8.270   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.330   loss each uniform = 11.871   feat norm = 0.449  

Validation:
Average incurred loss: 0.638  
Average sample loss: 0.619  
Average acc: 0.861  
Average grad norm: 5.500  
Average grad norm uniform: 33.658  
Average loss each uniform: 8.432  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.222   grad norm uniform = 34.292   loss each uniform = 11.362   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.992  exp loss = 1.066  adjusted loss = 1.066  adv prob = 0.250000   acc = 0.768   grad norm = 9.406   grad norm uniform = 32.727   loss each uniform = 5.662   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.053  exp loss = 2.204  adjusted loss = 2.204  adv prob = 0.250000   acc = 0.609   grad norm = 14.170   grad norm uniform = 29.979   loss each uniform = 5.197   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.955   grad norm = 1.674   grad norm uniform = 38.373   loss each uniform = 11.077   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [183]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.134  
Average loss each uniform: 11.693  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.877   loss each uniform = 11.843   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.772   loss each uniform = 9.244   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.865   loss each uniform = 8.318   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.273   loss each uniform = 11.802   feat norm = 0.448  

Validation:
Average incurred loss: 0.606  
Average sample loss: 0.585  
Average acc: 0.867  
Average grad norm: 5.147  
Average grad norm uniform: 34.030  
Average loss each uniform: 8.640  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.146   grad norm uniform = 34.685   loss each uniform = 11.770   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.839  exp loss = 0.911  adjusted loss = 0.911  adv prob = 0.250000   acc = 0.800   grad norm = 8.125   grad norm uniform = 33.611   loss each uniform = 5.992   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.278  exp loss = 2.429  adjusted loss = 2.429  adv prob = 0.250000   acc = 0.549   grad norm = 15.447   grad norm uniform = 29.367   loss each uniform = 5.058   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.221  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.955   grad norm = 1.971   grad norm uniform = 37.857   loss each uniform = 10.508   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [184]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.008  
Average grad norm uniform: 36.121  
Average loss each uniform: 11.653  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.880   loss each uniform = 11.818   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 41.735   loss each uniform = 9.268   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 1.000   grad norm = 0.066   grad norm uniform = 36.725   loss each uniform = 8.342   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 39.218   loss each uniform = 11.698   feat norm = 0.448  

Validation:
Average incurred loss: 0.593  
Average sample loss: 0.571  
Average acc: 0.872  
Average grad norm: 4.979  
Average grad norm uniform: 33.984  
Average loss each uniform: 8.700  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.118   grad norm uniform = 34.589   loss each uniform = 11.884   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.759  exp loss = 0.826  adjusted loss = 0.826  adv prob = 0.250000   acc = 0.818   grad norm = 7.455   grad norm uniform = 33.752   loss each uniform = 6.133   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.423  exp loss = 2.550  adjusted loss = 2.550  adv prob = 0.250000   acc = 0.549   grad norm = 16.151   grad norm uniform = 28.995   loss each uniform = 5.012   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.245  exp loss = 0.243  adjusted loss = 0.243  adv prob = 0.250000   acc = 0.947   grad norm = 2.205   grad norm uniform = 37.657   loss each uniform = 10.202   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8723937273025513


Epoch [185]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.131  
Average loss each uniform: 11.686  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.888   loss each uniform = 11.837   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.632   loss each uniform = 9.221   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.037   grad norm uniform = 36.642   loss each uniform = 8.246   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.259   loss each uniform = 11.798   feat norm = 0.448  

Validation:
Average incurred loss: 0.693  
Average sample loss: 0.677  
Average acc: 0.847  
Average grad norm: 5.999  
Average grad norm uniform: 33.404  
Average loss each uniform: 8.221  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.994   grad norm = 0.325   grad norm uniform = 33.852   loss each uniform = 10.923   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.199  exp loss = 1.297  adjusted loss = 1.297  adv prob = 0.250000   acc = 0.727   grad norm = 11.030   grad norm uniform = 32.331   loss each uniform = 5.370   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.827  exp loss = 1.975  adjusted loss = 1.975  adv prob = 0.250000   acc = 0.624   grad norm = 12.845   grad norm uniform = 30.090   loss each uniform = 5.297   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.970   grad norm = 1.449   grad norm uniform = 38.905   loss each uniform = 11.650   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.846538782119751


Epoch [186]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.140  
Average loss each uniform: 11.737  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.884   loss each uniform = 11.867   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.809   loss each uniform = 9.410   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.653   loss each uniform = 8.289   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.285   loss each uniform = 11.898   feat norm = 0.448  

Validation:
Average incurred loss: 0.596  
Average sample loss: 0.574  
Average acc: 0.875  
Average grad norm: 5.046  
Average grad norm uniform: 34.564  
Average loss each uniform: 8.846  
Average feat norm: 0.457  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.103   grad norm uniform = 35.229   loss each uniform = 12.156   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.737  exp loss = 0.796  adjusted loss = 0.796  adv prob = 0.250000   acc = 0.830   grad norm = 7.305   grad norm uniform = 34.606   loss each uniform = 6.293   feat norm = 0.489  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.529  exp loss = 2.676  adjusted loss = 2.676  adv prob = 0.250000   acc = 0.526   grad norm = 17.207   grad norm uniform = 28.887   loss each uniform = 4.974   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.251  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.947   grad norm = 2.328   grad norm uniform = 37.761   loss each uniform = 10.045   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8748958110809326


Epoch [187]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.122  
Average loss each uniform: 11.688  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.884   loss each uniform = 11.845   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 41.730   loss each uniform = 9.211   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.902   loss each uniform = 8.553   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.200   loss each uniform = 11.768   feat norm = 0.448  

Validation:
Average incurred loss: 0.676  
Average sample loss: 0.658  
Average acc: 0.851  
Average grad norm: 5.873  
Average grad norm uniform: 33.493  
Average loss each uniform: 8.227  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.345   grad norm uniform = 33.823   loss each uniform = 10.799   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.169  exp loss = 1.260  adjusted loss = 1.260  adv prob = 0.250000   acc = 0.740   grad norm = 10.751   grad norm uniform = 32.307   loss each uniform = 5.424   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.768  exp loss = 1.921  adjusted loss = 1.921  adv prob = 0.250000   acc = 0.632   grad norm = 12.583   grad norm uniform = 30.525   loss each uniform = 5.408   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.962   grad norm = 1.485   grad norm uniform = 39.457   loss each uniform = 11.838   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8507089614868164


Epoch [188]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.134  
Average loss each uniform: 11.746  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.876   loss each uniform = 11.879   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 41.680   loss each uniform = 9.412   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.035   grad norm uniform = 36.535   loss each uniform = 8.034   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.309   loss each uniform = 11.907   feat norm = 0.448  

Validation:
Average incurred loss: 0.792  
Average sample loss: 0.776  
Average acc: 0.820  
Average grad norm: 6.809  
Average grad norm uniform: 33.417  
Average loss each uniform: 7.984  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.987   grad norm = 0.573   grad norm uniform = 33.776   loss each uniform = 10.295   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.533  exp loss = 1.659  adjusted loss = 1.659  adv prob = 0.250000   acc = 0.650   grad norm = 13.423   grad norm uniform = 31.749   loss each uniform = 5.051   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.520  exp loss = 1.665  adjusted loss = 1.665  adv prob = 0.250000   acc = 0.677   grad norm = 11.228   grad norm uniform = 31.283   loss each uniform = 5.640   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.127  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.970   grad norm = 1.114   grad norm uniform = 40.140   loss each uniform = 12.490   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8198498487472534


Epoch [189]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.120  
Average loss each uniform: 11.721  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 34.862   loss each uniform = 11.879   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.674   loss each uniform = 9.390   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.768   loss each uniform = 8.357   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.285   loss each uniform = 11.782   feat norm = 0.448  

Validation:
Average incurred loss: 0.571  
Average sample loss: 0.551  
Average acc: 0.880  
Average grad norm: 4.858  
Average grad norm uniform: 34.136  
Average loss each uniform: 8.739  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.104   grad norm uniform = 34.728   loss each uniform = 11.891   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.709  exp loss = 0.771  adjusted loss = 0.771  adv prob = 0.250000   acc = 0.839   grad norm = 7.055   grad norm uniform = 33.959   loss each uniform = 6.253   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.399  exp loss = 2.564  adjusted loss = 2.564  adv prob = 0.250000   acc = 0.541   grad norm = 16.381   grad norm uniform = 29.141   loss each uniform = 4.988   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.252  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.947   grad norm = 2.332   grad norm uniform = 37.669   loss each uniform = 10.134   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8798999786376953
Best model saved at epoch 189


Epoch [190]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.122  
Average loss each uniform: 11.759  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.845   loss each uniform = 11.921   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 41.734   loss each uniform = 9.278   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.050   grad norm uniform = 36.966   loss each uniform = 8.425   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.326   loss each uniform = 11.831   feat norm = 0.449  

Validation:
Average incurred loss: 0.580  
Average sample loss: 0.557  
Average acc: 0.877  
Average grad norm: 4.859  
Average grad norm uniform: 34.165  
Average loss each uniform: 8.763  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.068   grad norm uniform = 34.583   loss each uniform = 12.016   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.654  exp loss = 0.711  adjusted loss = 0.711  adv prob = 0.250000   acc = 0.850   grad norm = 6.643   grad norm uniform = 34.294   loss each uniform = 6.291   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.656  exp loss = 2.805  adjusted loss = 2.805  adv prob = 0.250000   acc = 0.474   grad norm = 17.786   grad norm uniform = 28.697   loss each uniform = 4.942   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.271  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.940   grad norm = 2.503   grad norm uniform = 37.711   loss each uniform = 9.825   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8765637874603271


Epoch [191]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.123  
Average loss each uniform: 11.771  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.852   loss each uniform = 11.900   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.775   loss each uniform = 9.605   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.057   grad norm uniform = 36.602   loss each uniform = 7.983   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.321   loss each uniform = 11.919   feat norm = 0.448  

Validation:
Average incurred loss: 0.638  
Average sample loss: 0.619  
Average acc: 0.863  
Average grad norm: 5.508  
Average grad norm uniform: 33.651  
Average loss each uniform: 8.395  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.244   grad norm uniform = 34.034   loss each uniform = 11.252   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.997  exp loss = 1.065  adjusted loss = 1.065  adv prob = 0.250000   acc = 0.779   grad norm = 9.458   grad norm uniform = 32.825   loss each uniform = 5.644   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.021  exp loss = 2.154  adjusted loss = 2.154  adv prob = 0.250000   acc = 0.602   grad norm = 13.986   grad norm uniform = 29.969   loss each uniform = 5.191   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.200  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.955   grad norm = 1.668   grad norm uniform = 38.880   loss each uniform = 11.206   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8632193207740784


Epoch [192]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.127  
Average loss each uniform: 11.747  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.874   loss each uniform = 11.895   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.651   loss each uniform = 9.274   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.887   loss each uniform = 8.422   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.273   loss each uniform = 11.860   feat norm = 0.448  

Validation:
Average incurred loss: 0.730  
Average sample loss: 0.710  
Average acc: 0.841  
Average grad norm: 6.290  
Average grad norm uniform: 33.899  
Average loss each uniform: 8.289  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.987   grad norm = 0.421   grad norm uniform = 34.159   loss each uniform = 10.887   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.317  exp loss = 1.420  adjusted loss = 1.420  adv prob = 0.250000   acc = 0.712   grad norm = 11.881   grad norm uniform = 32.825   loss each uniform = 5.395   feat norm = 0.486  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.733  exp loss = 1.881  adjusted loss = 1.881  adv prob = 0.250000   acc = 0.647   grad norm = 12.259   grad norm uniform = 30.838   loss each uniform = 5.516   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.159  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 0.970   grad norm = 1.335   grad norm uniform = 39.810   loss each uniform = 12.078   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.840700626373291


Epoch [193]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.122  
Average loss each uniform: 11.780  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.861   loss each uniform = 11.915   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.742   loss each uniform = 9.354   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 36.689   loss each uniform = 8.208   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 39.286   loss each uniform = 11.945   feat norm = 0.448  

Validation:
Average incurred loss: 0.653  
Average sample loss: 0.632  
Average acc: 0.858  
Average grad norm: 5.660  
Average grad norm uniform: 33.669  
Average loss each uniform: 8.318  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.253   grad norm uniform = 33.993   loss each uniform = 11.116   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.043  exp loss = 1.128  adjusted loss = 1.128  adv prob = 0.250000   acc = 0.762   grad norm = 9.857   grad norm uniform = 32.799   loss each uniform = 5.568   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.010  exp loss = 2.157  adjusted loss = 2.157  adv prob = 0.250000   acc = 0.609   grad norm = 14.011   grad norm uniform = 30.265   loss each uniform = 5.211   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.955   grad norm = 1.585   grad norm uniform = 38.985   loss each uniform = 11.235   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8582152128219604


Epoch [194]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.118  
Average loss each uniform: 11.752  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.868   loss each uniform = 11.896   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.740   loss each uniform = 9.445   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.031   grad norm uniform = 36.648   loss each uniform = 8.137   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.247   loss each uniform = 11.867   feat norm = 0.448  

Validation:
Average incurred loss: 0.699  
Average sample loss: 0.680  
Average acc: 0.847  
Average grad norm: 6.068  
Average grad norm uniform: 33.764  
Average loss each uniform: 8.270  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.991   grad norm = 0.352   grad norm uniform = 34.071   loss each uniform = 10.927   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.225  exp loss = 1.308  adjusted loss = 1.308  adv prob = 0.250000   acc = 0.730   grad norm = 11.255   grad norm uniform = 32.780   loss each uniform = 5.461   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.780  exp loss = 1.933  adjusted loss = 1.933  adv prob = 0.250000   acc = 0.632   grad norm = 12.665   grad norm uniform = 30.552   loss each uniform = 5.338   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.168  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.970   grad norm = 1.371   grad norm uniform = 39.342   loss each uniform = 11.715   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [195]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.133  
Average loss each uniform: 11.815  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.860   loss each uniform = 11.951   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.717   loss each uniform = 9.394   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.849   loss each uniform = 8.460   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.335   loss each uniform = 11.966   feat norm = 0.448  

Validation:
Average incurred loss: 0.621  
Average sample loss: 0.599  
Average acc: 0.869  
Average grad norm: 5.287  
Average grad norm uniform: 33.784  
Average loss each uniform: 8.480  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.143   grad norm uniform = 34.389   loss each uniform = 11.583   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.869  exp loss = 0.930  adjusted loss = 0.930  adv prob = 0.250000   acc = 0.803   grad norm = 8.436   grad norm uniform = 33.344   loss each uniform = 5.820   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.313  exp loss = 2.440  adjusted loss = 2.440  adv prob = 0.250000   acc = 0.564   grad norm = 15.677   grad norm uniform = 29.124   loss each uniform = 4.968   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.955   grad norm = 1.928   grad norm uniform = 37.864   loss each uniform = 10.416   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [196]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.125  
Average loss each uniform: 11.814  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.855   loss each uniform = 11.950   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.650   loss each uniform = 9.413   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.937   loss each uniform = 8.481   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.323   loss each uniform = 11.958   feat norm = 0.448  

Validation:
Average incurred loss: 0.663  
Average sample loss: 0.645  
Average acc: 0.852  
Average grad norm: 5.832  
Average grad norm uniform: 34.172  
Average loss each uniform: 8.379  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.314   grad norm uniform = 34.448   loss each uniform = 11.192   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.100  exp loss = 1.182  adjusted loss = 1.182  adv prob = 0.250000   acc = 0.745   grad norm = 10.430   grad norm uniform = 33.405   loss each uniform = 5.585   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.894  exp loss = 2.032  adjusted loss = 2.032  adv prob = 0.250000   acc = 0.624   grad norm = 13.397   grad norm uniform = 30.692   loss each uniform = 5.244   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.970   grad norm = 1.537   grad norm uniform = 39.372   loss each uniform = 11.426   feat norm = 0.465  
Current lr: 0.001000
Current validation accuracy: 0.8523769378662109


Epoch [197]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.123  
Average loss each uniform: 11.794  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.856   loss each uniform = 11.937   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.635   loss each uniform = 9.454   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.068   grad norm uniform = 36.856   loss each uniform = 8.302   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.314   loss each uniform = 11.914   feat norm = 0.448  

Validation:
Average incurred loss: 0.618  
Average sample loss: 0.598  
Average acc: 0.865  
Average grad norm: 5.319  
Average grad norm uniform: 34.021  
Average loss each uniform: 8.513  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.187   grad norm uniform = 34.494   loss each uniform = 11.497   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.896  exp loss = 0.975  adjusted loss = 0.975  adv prob = 0.250000   acc = 0.788   grad norm = 8.647   grad norm uniform = 33.499   loss each uniform = 5.844   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.194  exp loss = 2.328  adjusted loss = 2.328  adv prob = 0.250000   acc = 0.579   grad norm = 15.120   grad norm uniform = 29.564   loss each uniform = 5.097   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.955   grad norm = 1.874   grad norm uniform = 38.648   loss each uniform = 10.798   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8648874759674072


Epoch [198]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.118  
Average loss each uniform: 11.793  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.858   loss each uniform = 11.935   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.725   loss each uniform = 9.387   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.807   loss each uniform = 8.308   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.278   loss each uniform = 11.928   feat norm = 0.448  

Validation:
Average incurred loss: 0.602  
Average sample loss: 0.582  
Average acc: 0.872  
Average grad norm: 5.210  
Average grad norm uniform: 33.888  
Average loss each uniform: 8.544  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.145   grad norm uniform = 34.505   loss each uniform = 11.623   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.839  exp loss = 0.913  adjusted loss = 0.913  adv prob = 0.250000   acc = 0.807   grad norm = 8.283   grad norm uniform = 33.208   loss each uniform = 5.852   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.258  exp loss = 2.398  adjusted loss = 2.398  adv prob = 0.250000   acc = 0.579   grad norm = 15.478   grad norm uniform = 29.596   loss each uniform = 5.063   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.212  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.955   grad norm = 1.957   grad norm uniform = 38.400   loss each uniform = 10.647   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8723936676979065


Epoch [199]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.106  
Average loss each uniform: 11.772  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.859   loss each uniform = 11.922   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 41.668   loss each uniform = 9.323   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.058   grad norm uniform = 36.952   loss each uniform = 8.600   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.219   loss each uniform = 11.868   feat norm = 0.447  

Validation:
Average incurred loss: 0.686  
Average sample loss: 0.667  
Average acc: 0.847  
Average grad norm: 5.981  
Average grad norm uniform: 33.581  
Average loss each uniform: 8.196  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.312   grad norm uniform = 33.933   loss each uniform = 10.881   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.166  exp loss = 1.251  adjusted loss = 1.251  adv prob = 0.250000   acc = 0.734   grad norm = 10.889   grad norm uniform = 32.654   loss each uniform = 5.427   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.882  exp loss = 2.056  adjusted loss = 2.056  adv prob = 0.250000   acc = 0.624   grad norm = 13.274   grad norm uniform = 30.223   loss each uniform = 5.231   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.962   grad norm = 1.393   grad norm uniform = 38.948   loss each uniform = 11.438   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.847372829914093


Epoch [200]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.123  
Average loss each uniform: 11.827  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.863   loss each uniform = 11.964   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.745   loss each uniform = 9.385   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.897   loss each uniform = 8.476   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.274   loss each uniform = 11.973   feat norm = 0.448  

Validation:
Average incurred loss: 0.657  
Average sample loss: 0.638  
Average acc: 0.855  
Average grad norm: 5.715  
Average grad norm uniform: 33.931  
Average loss each uniform: 8.363  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.269   grad norm uniform = 34.321   loss each uniform = 11.167   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.069  exp loss = 1.150  adjusted loss = 1.150  adv prob = 0.250000   acc = 0.751   grad norm = 10.067   grad norm uniform = 32.935   loss each uniform = 5.561   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.959  exp loss = 2.098  adjusted loss = 2.098  adv prob = 0.250000   acc = 0.617   grad norm = 13.746   grad norm uniform = 30.783   loss each uniform = 5.291   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.955   grad norm = 1.564   grad norm uniform = 39.196   loss each uniform = 11.409   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8548790216445923


Epoch [201]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.114  
Average loss each uniform: 11.822  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.857   loss each uniform = 11.957   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 41.628   loss each uniform = 9.512   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.954   loss each uniform = 8.537   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.273   loss each uniform = 11.953   feat norm = 0.448  

Validation:
Average incurred loss: 0.732  
Average sample loss: 0.714  
Average acc: 0.846  
Average grad norm: 6.271  
Average grad norm uniform: 34.284  
Average loss each uniform: 8.326  
Average feat norm: 0.458  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.989   grad norm = 0.460   grad norm uniform = 34.009   loss each uniform = 10.734   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.349  exp loss = 1.453  adjusted loss = 1.453  adv prob = 0.250000   acc = 0.717   grad norm = 11.983   grad norm uniform = 33.709   loss each uniform = 5.499   feat norm = 0.495  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.621  exp loss = 1.784  adjusted loss = 1.784  adv prob = 0.250000   acc = 0.669   grad norm = 11.557   grad norm uniform = 30.997   loss each uniform = 5.661   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.164  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.970   grad norm = 1.372   grad norm uniform = 40.556   loss each uniform = 12.443   feat norm = 0.470  
Current lr: 0.001000
Current validation accuracy: 0.8457046747207642


Epoch [202]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.120  
Average loss each uniform: 11.832  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.847   loss each uniform = 11.984   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.656   loss each uniform = 9.293   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.943   loss each uniform = 8.472   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.326   loss each uniform = 11.952   feat norm = 0.448  

Validation:
Average incurred loss: 0.632  
Average sample loss: 0.612  
Average acc: 0.868  
Average grad norm: 5.415  
Average grad norm uniform: 33.865  
Average loss each uniform: 8.513  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.206   grad norm uniform = 34.364   loss each uniform = 11.487   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.942  exp loss = 1.020  adjusted loss = 1.020  adv prob = 0.250000   acc = 0.790   grad norm = 8.990   grad norm uniform = 33.098   loss each uniform = 5.768   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.158  exp loss = 2.312  adjusted loss = 2.312  adv prob = 0.250000   acc = 0.602   grad norm = 14.766   grad norm uniform = 30.137   loss each uniform = 5.185   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.955   grad norm = 1.831   grad norm uniform = 38.528   loss each uniform = 11.019   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [203]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.119  
Average loss each uniform: 11.866  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.847   loss each uniform = 11.987   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.647   loss each uniform = 9.658   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.935   loss each uniform = 8.701   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.324   loss each uniform = 12.016   feat norm = 0.448  

Validation:
Average incurred loss: 0.603  
Average sample loss: 0.581  
Average acc: 0.870  
Average grad norm: 5.116  
Average grad norm uniform: 34.087  
Average loss each uniform: 8.692  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.111   grad norm uniform = 34.649   loss each uniform = 11.889   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.779  exp loss = 0.844  adjusted loss = 0.844  adv prob = 0.250000   acc = 0.815   grad norm = 7.710   grad norm uniform = 33.751   loss each uniform = 6.039   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.460  exp loss = 2.596  adjusted loss = 2.596  adv prob = 0.250000   acc = 0.534   grad norm = 16.534   grad norm uniform = 29.180   loss each uniform = 5.051   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.235  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.947   grad norm = 2.188   grad norm uniform = 38.201   loss each uniform = 10.403   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8698915839195251


Epoch [204]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.123  
Average loss each uniform: 11.857  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.851   loss each uniform = 11.995   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.678   loss each uniform = 9.484   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.033   grad norm uniform = 36.734   loss each uniform = 8.293   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.334   loss each uniform = 12.005   feat norm = 0.448  

Validation:
Average incurred loss: 0.685  
Average sample loss: 0.666  
Average acc: 0.856  
Average grad norm: 5.885  
Average grad norm uniform: 34.294  
Average loss each uniform: 8.526  
Average feat norm: 0.458  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.328   grad norm uniform = 34.600   loss each uniform = 11.357   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.141  exp loss = 1.244  adjusted loss = 1.244  adv prob = 0.250000   acc = 0.747   grad norm = 10.567   grad norm uniform = 33.535   loss each uniform = 5.699   feat norm = 0.490  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.946  exp loss = 2.081  adjusted loss = 2.081  adv prob = 0.250000   acc = 0.647   grad norm = 13.374   grad norm uniform = 30.702   loss each uniform = 5.373   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.970   grad norm = 1.503   grad norm uniform = 39.473   loss each uniform = 11.647   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [205]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.115  
Average loss each uniform: 11.874  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.847   loss each uniform = 12.003   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.664   loss each uniform = 9.497   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 36.828   loss each uniform = 8.401   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.307   loss each uniform = 12.043   feat norm = 0.448  

Validation:
Average incurred loss: 0.667  
Average sample loss: 0.646  
Average acc: 0.852  
Average grad norm: 5.718  
Average grad norm uniform: 33.607  
Average loss each uniform: 8.371  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.240   grad norm uniform = 34.080   loss each uniform = 11.280   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.065  exp loss = 1.144  adjusted loss = 1.144  adv prob = 0.250000   acc = 0.749   grad norm = 9.991   grad norm uniform = 32.779   loss each uniform = 5.562   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.059  exp loss = 2.196  adjusted loss = 2.196  adv prob = 0.250000   acc = 0.594   grad norm = 14.112   grad norm uniform = 29.864   loss each uniform = 5.189   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.962   grad norm = 1.585   grad norm uniform = 38.589   loss each uniform = 11.174   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8523769974708557


Epoch [206]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.113  
Average loss each uniform: 11.828  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.855   loss each uniform = 11.977   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.759   loss each uniform = 9.341   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 37.017   loss each uniform = 8.555   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.244   loss each uniform = 11.941   feat norm = 0.448  

Validation:
Average incurred loss: 0.667  
Average sample loss: 0.649  
Average acc: 0.852  
Average grad norm: 5.769  
Average grad norm uniform: 33.349  
Average loss each uniform: 8.264  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.996   grad norm = 0.297   grad norm uniform = 33.745   loss each uniform = 11.049   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.108  exp loss = 1.185  adjusted loss = 1.185  adv prob = 0.250000   acc = 0.749   grad norm = 10.342   grad norm uniform = 32.285   loss each uniform = 5.421   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.902  exp loss = 2.040  adjusted loss = 2.040  adv prob = 0.250000   acc = 0.609   grad norm = 13.243   grad norm uniform = 30.209   loss each uniform = 5.261   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.955   grad norm = 1.489   grad norm uniform = 38.829   loss each uniform = 11.448   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8523769378662109


Epoch [207]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.116  
Average loss each uniform: 11.887  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.838   loss each uniform = 12.008   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.752   loss each uniform = 9.593   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.791   loss each uniform = 8.477   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.330   loss each uniform = 12.066   feat norm = 0.448  

Validation:
Average incurred loss: 0.622  
Average sample loss: 0.601  
Average acc: 0.868  
Average grad norm: 5.351  
Average grad norm uniform: 33.889  
Average loss each uniform: 8.517  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.194   grad norm uniform = 34.351   loss each uniform = 11.520   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.927  exp loss = 0.991  adjusted loss = 0.991  adv prob = 0.250000   acc = 0.792   grad norm = 8.893   grad norm uniform = 33.259   loss each uniform = 5.783   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.128  exp loss = 2.273  adjusted loss = 2.273  adv prob = 0.250000   acc = 0.594   grad norm = 14.631   grad norm uniform = 29.772   loss each uniform = 5.139   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.203  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 1.766   grad norm uniform = 38.591   loss each uniform = 10.932   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [208]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.114  
Average loss each uniform: 11.861  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.849   loss each uniform = 12.000   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.772   loss each uniform = 9.504   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.814   loss each uniform = 8.525   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.278   loss each uniform = 11.986   feat norm = 0.448  

Validation:
Average incurred loss: 0.577  
Average sample loss: 0.554  
Average acc: 0.881  
Average grad norm: 4.634  
Average grad norm uniform: 34.244  
Average loss each uniform: 9.103  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.053   grad norm uniform = 34.854   loss each uniform = 12.539   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.661  adjusted loss = 0.661  adv prob = 0.250000   acc = 0.861   grad norm = 6.007   grad norm uniform = 34.495   loss each uniform = 6.642   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.780  exp loss = 2.935  adjusted loss = 2.935  adv prob = 0.250000   acc = 0.489   grad norm = 17.864   grad norm uniform = 28.552   loss each uniform = 5.054   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.299  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 0.925   grad norm = 2.679   grad norm uniform = 36.917   loss each uniform = 9.710   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8807339668273926
Best model saved at epoch 208


Epoch [209]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.120  
Average loss each uniform: 11.893  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.846   loss each uniform = 12.015   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.708   loss each uniform = 9.622   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.788   loss each uniform = 8.435   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.329   loss each uniform = 12.066   feat norm = 0.448  

Validation:
Average incurred loss: 0.618  
Average sample loss: 0.597  
Average acc: 0.869  
Average grad norm: 5.212  
Average grad norm uniform: 34.057  
Average loss each uniform: 8.653  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.132   grad norm uniform = 34.643   loss each uniform = 11.796   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.871  exp loss = 0.926  adjusted loss = 0.926  adv prob = 0.250000   acc = 0.800   grad norm = 8.344   grad norm uniform = 33.547   loss each uniform = 5.934   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.285  exp loss = 2.445  adjusted loss = 2.445  adv prob = 0.250000   acc = 0.571   grad norm = 15.419   grad norm uniform = 29.592   loss each uniform = 5.109   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.221  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.955   grad norm = 1.873   grad norm uniform = 38.251   loss each uniform = 10.688   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [210]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.113  
Average loss each uniform: 11.891  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.846   loss each uniform = 12.023   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.698   loss each uniform = 9.435   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.817   loss each uniform = 8.379   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.298   loss each uniform = 12.067   feat norm = 0.448  

Validation:
Average incurred loss: 0.607  
Average sample loss: 0.586  
Average acc: 0.869  
Average grad norm: 5.157  
Average grad norm uniform: 33.469  
Average loss each uniform: 8.515  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.178   grad norm uniform = 33.952   loss each uniform = 11.493   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.859  exp loss = 0.936  adjusted loss = 0.936  adv prob = 0.250000   acc = 0.803   grad norm = 8.239   grad norm uniform = 32.910   loss each uniform = 5.876   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.217  exp loss = 2.360  adjusted loss = 2.360  adv prob = 0.250000   acc = 0.564   grad norm = 15.051   grad norm uniform = 29.268   loss each uniform = 5.103   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.221  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.955   grad norm = 1.951   grad norm uniform = 37.934   loss each uniform = 10.719   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [211]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.114  
Average loss each uniform: 11.891  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.856   loss each uniform = 12.024   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 41.655   loss each uniform = 9.425   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.777   loss each uniform = 8.416   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.281   loss each uniform = 12.064   feat norm = 0.447  

Validation:
Average incurred loss: 0.679  
Average sample loss: 0.661  
Average acc: 0.852  
Average grad norm: 5.836  
Average grad norm uniform: 33.576  
Average loss each uniform: 8.286  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.326   grad norm uniform = 33.805   loss each uniform = 10.915   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.176  exp loss = 1.261  adjusted loss = 1.261  adv prob = 0.250000   acc = 0.740   grad norm = 10.752   grad norm uniform = 32.469   loss each uniform = 5.429   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.776  exp loss = 1.908  adjusted loss = 1.908  adv prob = 0.250000   acc = 0.647   grad norm = 12.370   grad norm uniform = 30.819   loss each uniform = 5.474   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.164  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.970   grad norm = 1.422   grad norm uniform = 39.408   loss each uniform = 11.875   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8523769378662109


Epoch [212]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.106  
Average loss each uniform: 11.867  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.852   loss each uniform = 12.022   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.519   loss each uniform = 9.280   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.553   loss each uniform = 8.187   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.292   loss each uniform = 12.001   feat norm = 0.448  

Validation:
Average incurred loss: 0.691  
Average sample loss: 0.673  
Average acc: 0.851  
Average grad norm: 5.927  
Average grad norm uniform: 33.660  
Average loss each uniform: 8.374  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.298   grad norm uniform = 34.166   loss each uniform = 11.213   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.168  exp loss = 1.271  adjusted loss = 1.271  adv prob = 0.250000   acc = 0.736   grad norm = 10.743   grad norm uniform = 32.546   loss each uniform = 5.461   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.912  exp loss = 2.037  adjusted loss = 2.037  adv prob = 0.250000   acc = 0.624   grad norm = 13.301   grad norm uniform = 30.382   loss each uniform = 5.332   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.970   grad norm = 1.444   grad norm uniform = 39.060   loss each uniform = 11.660   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8507089614868164


Epoch [213]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.104  
Average loss each uniform: 11.872  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.835   loss each uniform = 12.023   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.727   loss each uniform = 9.420   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.034   grad norm uniform = 36.828   loss each uniform = 8.430   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.287   loss each uniform = 11.982   feat norm = 0.448  

Validation:
Average incurred loss: 0.636  
Average sample loss: 0.617  
Average acc: 0.863  
Average grad norm: 5.399  
Average grad norm uniform: 33.894  
Average loss each uniform: 8.462  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.245   grad norm uniform = 34.030   loss each uniform = 11.261   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.009  exp loss = 1.078  adjusted loss = 1.078  adv prob = 0.250000   acc = 0.773   grad norm = 9.331   grad norm uniform = 33.256   loss each uniform = 5.748   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.970  exp loss = 2.122  adjusted loss = 2.122  adv prob = 0.250000   acc = 0.617   grad norm = 13.510   grad norm uniform = 30.595   loss each uniform = 5.289   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.955   grad norm = 1.609   grad norm uniform = 38.946   loss each uniform = 11.314   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [214]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.112  
Average loss each uniform: 11.928  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.822   loss each uniform = 12.058   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.819   loss each uniform = 9.537   feat norm = 0.532  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 37.066   loss each uniform = 8.722   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.335   loss each uniform = 12.085   feat norm = 0.448  

Validation:
Average incurred loss: 0.648  
Average sample loss: 0.628  
Average acc: 0.862  
Average grad norm: 5.522  
Average grad norm uniform: 33.995  
Average loss each uniform: 8.564  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.187   grad norm uniform = 34.526   loss each uniform = 11.611   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.972  exp loss = 1.057  adjusted loss = 1.057  adv prob = 0.250000   acc = 0.781   grad norm = 9.242   grad norm uniform = 33.203   loss each uniform = 5.756   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.207  exp loss = 2.348  adjusted loss = 2.348  adv prob = 0.250000   acc = 0.571   grad norm = 14.962   grad norm uniform = 29.959   loss each uniform = 5.189   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.201  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.955   grad norm = 1.786   grad norm uniform = 38.946   loss each uniform = 11.076   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [215]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.104  
Average loss each uniform: 11.891  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.841   loss each uniform = 12.039   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.690   loss each uniform = 9.496   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 37.038   loss each uniform = 8.628   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.264   loss each uniform = 11.992   feat norm = 0.447  

Validation:
Average incurred loss: 0.596  
Average sample loss: 0.575  
Average acc: 0.876  
Average grad norm: 5.011  
Average grad norm uniform: 33.752  
Average loss each uniform: 8.677  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.111   grad norm uniform = 34.364   loss each uniform = 11.854   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.769  exp loss = 0.844  adjusted loss = 0.844  adv prob = 0.250000   acc = 0.828   grad norm = 7.509   grad norm uniform = 33.589   loss each uniform = 6.114   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.425  exp loss = 2.594  adjusted loss = 2.594  adv prob = 0.250000   acc = 0.541   grad norm = 16.290   grad norm uniform = 28.548   loss each uniform = 4.971   feat norm = 0.421  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.244  exp loss = 0.252  adjusted loss = 0.252  adv prob = 0.250000   acc = 0.947   grad norm = 2.180   grad norm uniform = 37.380   loss each uniform = 10.203   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [216]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.098  
Average loss each uniform: 11.892  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.828   loss each uniform = 12.035   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.628   loss each uniform = 9.618   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.957   loss each uniform = 8.527   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.292   loss each uniform = 11.992   feat norm = 0.448  

Validation:
Average incurred loss: 0.646  
Average sample loss: 0.625  
Average acc: 0.859  
Average grad norm: 5.526  
Average grad norm uniform: 33.979  
Average loss each uniform: 8.506  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.279   grad norm uniform = 34.259   loss each uniform = 11.339   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.041  exp loss = 1.136  adjusted loss = 1.136  adv prob = 0.250000   acc = 0.762   grad norm = 9.669   grad norm uniform = 33.260   loss each uniform = 5.724   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.948  exp loss = 2.104  adjusted loss = 2.104  adv prob = 0.250000   acc = 0.617   grad norm = 13.453   grad norm uniform = 30.512   loss each uniform = 5.345   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.962   grad norm = 1.509   grad norm uniform = 38.981   loss each uniform = 11.463   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [217]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.107  
Average loss each uniform: 11.938  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.827   loss each uniform = 12.067   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.653   loss each uniform = 9.680   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.027   grad norm uniform = 36.819   loss each uniform = 8.418   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.339   loss each uniform = 12.090   feat norm = 0.448  

Validation:
Average incurred loss: 0.600  
Average sample loss: 0.578  
Average acc: 0.873  
Average grad norm: 4.987  
Average grad norm uniform: 33.821  
Average loss each uniform: 8.711  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.107   grad norm uniform = 34.389   loss each uniform = 11.864   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.775  exp loss = 0.846  adjusted loss = 0.846  adv prob = 0.250000   acc = 0.820   grad norm = 7.495   grad norm uniform = 33.366   loss each uniform = 6.092   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.433  exp loss = 2.580  adjusted loss = 2.580  adv prob = 0.250000   acc = 0.549   grad norm = 16.164   grad norm uniform = 29.389   loss each uniform = 5.082   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.244  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.947   grad norm = 2.157   grad norm uniform = 37.850   loss each uniform = 10.447   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8732277154922485


Epoch [218]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.109  
Average loss each uniform: 11.957  
Average feat norm: 0.438  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.823   loss each uniform = 12.082   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.715   loss each uniform = 9.619   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.716   loss each uniform = 8.363   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.357   loss each uniform = 12.140   feat norm = 0.448  

Validation:
Average incurred loss: 0.627  
Average sample loss: 0.607  
Average acc: 0.868  
Average grad norm: 5.311  
Average grad norm uniform: 33.713  
Average loss each uniform: 8.600  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.182   grad norm uniform = 34.332   loss each uniform = 11.699   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.911  exp loss = 0.994  adjusted loss = 0.994  adv prob = 0.250000   acc = 0.796   grad norm = 8.658   grad norm uniform = 33.163   loss each uniform = 5.883   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.219  exp loss = 2.375  adjusted loss = 2.375  adv prob = 0.250000   acc = 0.579   grad norm = 15.002   grad norm uniform = 29.305   loss each uniform = 5.075   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.214  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.955   grad norm = 1.898   grad norm uniform = 37.873   loss each uniform = 10.763   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [219]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.102  
Average loss each uniform: 11.924  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.825   loss each uniform = 12.063   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.709   loss each uniform = 9.573   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.894   loss each uniform = 8.475   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.312   loss each uniform = 12.057   feat norm = 0.448  

Validation:
Average incurred loss: 0.732  
Average sample loss: 0.714  
Average acc: 0.837  
Average grad norm: 6.248  
Average grad norm uniform: 33.497  
Average loss each uniform: 8.225  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.987   grad norm = 0.424   grad norm uniform = 33.710   loss each uniform = 10.729   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.352  exp loss = 1.457  adjusted loss = 1.457  adv prob = 0.250000   acc = 0.700   grad norm = 11.969   grad norm uniform = 32.165   loss each uniform = 5.283   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.639  exp loss = 1.757  adjusted loss = 1.757  adv prob = 0.250000   acc = 0.654   grad norm = 11.652   grad norm uniform = 30.994   loss each uniform = 5.603   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.149  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.970   grad norm = 1.247   grad norm uniform = 39.921   loss each uniform = 12.365   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8365304470062256


Epoch [220]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.104  
Average loss each uniform: 11.939  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.824   loss each uniform = 12.077   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.737   loss each uniform = 9.530   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.980   loss each uniform = 8.648   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.312   loss each uniform = 12.074   feat norm = 0.448  

Validation:
Average incurred loss: 0.618  
Average sample loss: 0.597  
Average acc: 0.867  
Average grad norm: 5.201  
Average grad norm uniform: 34.014  
Average loss each uniform: 8.643  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.177   grad norm uniform = 34.401   loss each uniform = 11.694   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.879  exp loss = 0.957  adjusted loss = 0.957  adv prob = 0.250000   acc = 0.794   grad norm = 8.371   grad norm uniform = 33.527   loss each uniform = 5.944   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.243  exp loss = 2.425  adjusted loss = 2.425  adv prob = 0.250000   acc = 0.571   grad norm = 15.021   grad norm uniform = 29.967   loss each uniform = 5.171   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.217  adjusted loss = 0.217  adv prob = 0.250000   acc = 0.955   grad norm = 1.914   grad norm uniform = 38.406   loss each uniform = 10.857   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [221]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.101  
Average loss each uniform: 11.924  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.828   loss each uniform = 12.068   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.697   loss each uniform = 9.516   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 37.004   loss each uniform = 8.655   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.293   loss each uniform = 12.037   feat norm = 0.448  

Validation:
Average incurred loss: 0.591  
Average sample loss: 0.570  
Average acc: 0.877  
Average grad norm: 4.877  
Average grad norm uniform: 34.038  
Average loss each uniform: 8.872  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.098   grad norm uniform = 34.592   loss each uniform = 12.096   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.731  exp loss = 0.802  adjusted loss = 0.802  adv prob = 0.250000   acc = 0.835   grad norm = 7.047   grad norm uniform = 33.915   loss each uniform = 6.344   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.506  exp loss = 2.690  adjusted loss = 2.690  adv prob = 0.250000   acc = 0.541   grad norm = 16.642   grad norm uniform = 29.113   loss each uniform = 5.053   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.254  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.940   grad norm = 2.294   grad norm uniform = 37.453   loss each uniform = 10.230   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.877397894859314


Epoch [222]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.094  
Average loss each uniform: 11.915  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.825   loss each uniform = 12.063   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.698   loss each uniform = 9.489   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.029   grad norm uniform = 36.699   loss each uniform = 8.336   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.286   loss each uniform = 12.036   feat norm = 0.448  

Validation:
Average incurred loss: 0.656  
Average sample loss: 0.638  
Average acc: 0.855  
Average grad norm: 5.650  
Average grad norm uniform: 33.326  
Average loss each uniform: 8.317  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.257   grad norm uniform = 33.845   loss each uniform = 11.141   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.070  exp loss = 1.165  adjusted loss = 1.165  adv prob = 0.250000   acc = 0.753   grad norm = 9.950   grad norm uniform = 32.291   loss each uniform = 5.529   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.941  exp loss = 2.070  adjusted loss = 2.070  adv prob = 0.250000   acc = 0.609   grad norm = 13.598   grad norm uniform = 29.918   loss each uniform = 5.188   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.185  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.955   grad norm = 1.575   grad norm uniform = 38.538   loss each uniform = 11.295   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8548790216445923


Epoch [223]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.094  
Average loss each uniform: 11.957  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.813   loss each uniform = 12.082   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.703   loss each uniform = 9.685   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.953   loss each uniform = 8.683   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.309   loss each uniform = 12.113   feat norm = 0.447  

Validation:
Average incurred loss: 0.625  
Average sample loss: 0.604  
Average acc: 0.867  
Average grad norm: 5.238  
Average grad norm uniform: 33.841  
Average loss each uniform: 8.632  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.179   grad norm uniform = 34.427   loss each uniform = 11.719   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.900  exp loss = 0.970  adjusted loss = 0.970  adv prob = 0.250000   acc = 0.796   grad norm = 8.483   grad norm uniform = 33.494   loss each uniform = 5.953   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.245  exp loss = 2.405  adjusted loss = 2.405  adv prob = 0.250000   acc = 0.564   grad norm = 15.018   grad norm uniform = 29.132   loss each uniform = 5.108   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.955   grad norm = 1.856   grad norm uniform = 37.704   loss each uniform = 10.703   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8665554523468018


Epoch [224]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.102  
Average loss each uniform: 11.957  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.829   loss each uniform = 12.093   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.561   loss each uniform = 9.529   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.858   loss each uniform = 8.622   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.324   loss each uniform = 12.106   feat norm = 0.448  

Validation:
Average incurred loss: 0.688  
Average sample loss: 0.669  
Average acc: 0.850  
Average grad norm: 5.892  
Average grad norm uniform: 33.798  
Average loss each uniform: 8.385  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.334   grad norm uniform = 33.980   loss each uniform = 11.079   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.184  exp loss = 1.274  adjusted loss = 1.274  adv prob = 0.250000   acc = 0.738   grad norm = 10.761   grad norm uniform = 32.880   loss each uniform = 5.557   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.824  exp loss = 1.987  adjusted loss = 1.987  adv prob = 0.250000   acc = 0.632   grad norm = 12.814   grad norm uniform = 30.782   loss each uniform = 5.394   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.970   grad norm = 1.428   grad norm uniform = 39.397   loss each uniform = 11.822   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8498748540878296


Epoch [225]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.105  
Average loss each uniform: 11.966  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.831   loss each uniform = 12.093   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.744   loss each uniform = 9.677   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.881   loss each uniform = 8.602   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.299   loss each uniform = 12.125   feat norm = 0.447  

Validation:
Average incurred loss: 0.782  
Average sample loss: 0.763  
Average acc: 0.834  
Average grad norm: 6.544  
Average grad norm uniform: 34.238  
Average loss each uniform: 8.431  
Average feat norm: 0.456  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.987   grad norm = 0.480   grad norm uniform = 34.150   loss each uniform = 10.925   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.472  exp loss = 1.600  adjusted loss = 1.600  adv prob = 0.250000   acc = 0.693   grad norm = 12.684   grad norm uniform = 33.437   loss each uniform = 5.489   feat norm = 0.491  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.644  exp loss = 1.801  adjusted loss = 1.801  adv prob = 0.250000   acc = 0.654   grad norm = 11.642   grad norm uniform = 31.161   loss each uniform = 5.754   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.970   grad norm = 1.223   grad norm uniform = 40.433   loss each uniform = 12.658   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8340283632278442


Epoch [226]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.096  
Average loss each uniform: 11.958  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.828   loss each uniform = 12.094   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.712   loss each uniform = 9.604   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.592   loss each uniform = 8.204   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.288   loss each uniform = 12.116   feat norm = 0.447  

Validation:
Average incurred loss: 0.657  
Average sample loss: 0.636  
Average acc: 0.859  
Average grad norm: 5.533  
Average grad norm uniform: 34.014  
Average loss each uniform: 8.639  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.255   grad norm uniform = 34.310   loss each uniform = 11.562   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.034  exp loss = 1.113  adjusted loss = 1.113  adv prob = 0.250000   acc = 0.766   grad norm = 9.578   grad norm uniform = 33.293   loss each uniform = 5.820   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.060  exp loss = 2.204  adjusted loss = 2.204  adv prob = 0.250000   acc = 0.609   grad norm = 13.825   grad norm uniform = 30.504   loss each uniform = 5.368   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.955   grad norm = 1.599   grad norm uniform = 39.012   loss each uniform = 11.519   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577


Epoch [227]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.099  
Average loss each uniform: 11.983  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.817   loss each uniform = 12.109   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.721   loss each uniform = 9.690   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.986   loss each uniform = 8.703   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.317   loss each uniform = 12.139   feat norm = 0.448  

Validation:
Average incurred loss: 0.688  
Average sample loss: 0.669  
Average acc: 0.852  
Average grad norm: 5.838  
Average grad norm uniform: 33.969  
Average loss each uniform: 8.525  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.328   grad norm uniform = 34.229   loss each uniform = 11.318   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.164  exp loss = 1.262  adjusted loss = 1.262  adv prob = 0.250000   acc = 0.745   grad norm = 10.544   grad norm uniform = 33.082   loss each uniform = 5.650   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.892  exp loss = 2.033  adjusted loss = 2.033  adv prob = 0.250000   acc = 0.624   grad norm = 13.059   grad norm uniform = 30.941   loss each uniform = 5.463   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.962   grad norm = 1.482   grad norm uniform = 39.195   loss each uniform = 11.853   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8515429496765137


Epoch [228]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.099  
Average loss each uniform: 11.971  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.828   loss each uniform = 12.108   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.737   loss each uniform = 9.559   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.655   loss each uniform = 8.361   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.292   loss each uniform = 12.128   feat norm = 0.447  

Validation:
Average incurred loss: 0.667  
Average sample loss: 0.649  
Average acc: 0.856  
Average grad norm: 5.590  
Average grad norm uniform: 34.039  
Average loss each uniform: 8.631  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.350   grad norm uniform = 34.304   loss each uniform = 11.437   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.121  exp loss = 1.228  adjusted loss = 1.228  adv prob = 0.250000   acc = 0.753   grad norm = 10.005   grad norm uniform = 33.146   loss each uniform = 5.763   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.844  exp loss = 2.022  adjusted loss = 2.022  adv prob = 0.250000   acc = 0.639   grad norm = 12.633   grad norm uniform = 31.091   loss each uniform = 5.534   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.962   grad norm = 1.476   grad norm uniform = 39.191   loss each uniform = 11.926   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8557130694389343


Epoch [229]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.100  
Average loss each uniform: 12.001  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.823   loss each uniform = 12.133   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.568   loss each uniform = 9.521   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.921   loss each uniform = 8.641   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.331   loss each uniform = 12.172   feat norm = 0.448  

Validation:
Average incurred loss: 0.613  
Average sample loss: 0.590  
Average acc: 0.872  
Average grad norm: 5.076  
Average grad norm uniform: 33.936  
Average loss each uniform: 8.819  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.102   grad norm uniform = 34.607   loss each uniform = 12.076   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.774  exp loss = 0.844  adjusted loss = 0.844  adv prob = 0.250000   acc = 0.822   grad norm = 7.533   grad norm uniform = 33.656   loss each uniform = 6.214   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.544  exp loss = 2.705  adjusted loss = 2.705  adv prob = 0.250000   acc = 0.541   grad norm = 16.750   grad norm uniform = 29.017   loss each uniform = 5.053   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.257  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.940   grad norm = 2.258   grad norm uniform = 37.479   loss each uniform = 10.281   feat norm = 0.451  
Current lr: 0.001000
Current validation accuracy: 0.8723937273025513


Epoch [230]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.005  
Average grad norm uniform: 36.086  
Average loss each uniform: 11.963  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.812   loss each uniform = 12.101   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 41.688   loss each uniform = 9.679   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.003  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000   grad norm = 0.083   grad norm uniform = 36.588   loss each uniform = 8.221   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 39.300   loss each uniform = 12.103   feat norm = 0.448  

Validation:
Average incurred loss: 0.602  
Average sample loss: 0.580  
Average acc: 0.876  
Average grad norm: 4.993  
Average grad norm uniform: 33.963  
Average loss each uniform: 8.858  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.089   grad norm uniform = 34.618   loss each uniform = 12.140   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.748  exp loss = 0.817  adjusted loss = 0.817  adv prob = 0.250000   acc = 0.830   grad norm = 7.334   grad norm uniform = 33.676   loss each uniform = 6.245   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.537  exp loss = 2.680  adjusted loss = 2.680  adv prob = 0.250000   acc = 0.534   grad norm = 16.735   grad norm uniform = 28.837   loss each uniform = 5.059   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.256  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 0.940   grad norm = 2.263   grad norm uniform = 37.792   loss each uniform = 10.286   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8757297992706299


Epoch [231]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.094  
Average loss each uniform: 11.986  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.834   loss each uniform = 12.103   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.705   loss each uniform = 9.630   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 36.731   loss each uniform = 8.475   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.254   loss each uniform = 12.197   feat norm = 0.447  

Validation:
Average incurred loss: 0.695  
Average sample loss: 0.677  
Average acc: 0.852  
Average grad norm: 5.845  
Average grad norm uniform: 34.031  
Average loss each uniform: 8.559  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.349   grad norm uniform = 34.369   loss each uniform = 11.358   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.183  exp loss = 1.283  adjusted loss = 1.283  adv prob = 0.250000   acc = 0.742   grad norm = 10.590   grad norm uniform = 33.110   loss each uniform = 5.664   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.883  exp loss = 2.034  adjusted loss = 2.034  adv prob = 0.250000   acc = 0.632   grad norm = 12.889   grad norm uniform = 30.862   loss each uniform = 5.508   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.970   grad norm = 1.475   grad norm uniform = 39.241   loss each uniform = 11.921   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8515429496765137


Epoch [232]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.086  
Average loss each uniform: 11.979  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.822   loss each uniform = 12.104   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.590   loss each uniform = 9.563   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.424   loss each uniform = 8.195   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.294   loss each uniform = 12.188   feat norm = 0.447  

Validation:
Average incurred loss: 0.676  
Average sample loss: 0.658  
Average acc: 0.852  
Average grad norm: 5.684  
Average grad norm uniform: 33.245  
Average loss each uniform: 8.461  
Average feat norm: 0.443  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.322   grad norm uniform = 33.709   loss each uniform = 11.292   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.135  exp loss = 1.227  adjusted loss = 1.227  adv prob = 0.250000   acc = 0.747   grad norm = 10.199   grad norm uniform = 32.302   loss each uniform = 5.598   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.885  exp loss = 2.028  adjusted loss = 2.028  adv prob = 0.250000   acc = 0.632   grad norm = 12.902   grad norm uniform = 29.841   loss each uniform = 5.358   feat norm = 0.418  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.962   grad norm = 1.477   grad norm uniform = 38.329   loss each uniform = 11.653   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8523769378662109


Epoch [233]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.093  
Average loss each uniform: 12.002  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.840   loss each uniform = 12.119   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.509   loss each uniform = 9.599   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.893   loss each uniform = 8.903   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.252   loss each uniform = 12.201   feat norm = 0.447  

Validation:
Average incurred loss: 0.675  
Average sample loss: 0.655  
Average acc: 0.856  
Average grad norm: 5.708  
Average grad norm uniform: 33.586  
Average loss each uniform: 8.425  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.290   grad norm uniform = 34.005   loss each uniform = 11.259   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.114  exp loss = 1.205  adjusted loss = 1.205  adv prob = 0.250000   acc = 0.749   grad norm = 10.186   grad norm uniform = 32.570   loss each uniform = 5.569   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.950  exp loss = 2.077  adjusted loss = 2.077  adv prob = 0.250000   acc = 0.632   grad norm = 13.285   grad norm uniform = 30.576   loss each uniform = 5.347   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.970   grad norm = 1.467   grad norm uniform = 38.686   loss each uniform = 11.553   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [234]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.095  
Average loss each uniform: 12.005  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.835   loss each uniform = 12.128   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.572   loss each uniform = 9.505   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.932   loss each uniform = 8.626   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.270   loss each uniform = 12.212   feat norm = 0.447  

Validation:
Average incurred loss: 0.631  
Average sample loss: 0.612  
Average acc: 0.869  
Average grad norm: 5.239  
Average grad norm uniform: 33.804  
Average loss each uniform: 8.693  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.224   grad norm uniform = 34.260   loss each uniform = 11.726   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.946  exp loss = 1.032  adjusted loss = 1.032  adv prob = 0.250000   acc = 0.790   grad norm = 8.668   grad norm uniform = 33.186   loss each uniform = 5.933   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.136  exp loss = 2.286  adjusted loss = 2.286  adv prob = 0.250000   acc = 0.609   grad norm = 14.307   grad norm uniform = 29.895   loss each uniform = 5.271   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.208  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.955   grad norm = 1.768   grad norm uniform = 38.273   loss each uniform = 11.133   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [235]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.090  
Average loss each uniform: 11.999  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.827   loss each uniform = 12.128   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 41.687   loss each uniform = 9.557   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 36.945   loss each uniform = 8.760   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.249   loss each uniform = 12.169   feat norm = 0.447  

Validation:
Average incurred loss: 0.696  
Average sample loss: 0.677  
Average acc: 0.854  
Average grad norm: 5.826  
Average grad norm uniform: 33.746  
Average loss each uniform: 8.571  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.994   grad norm = 0.312   grad norm uniform = 34.200   loss each uniform = 11.474   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.172  exp loss = 1.244  adjusted loss = 1.244  adv prob = 0.250000   acc = 0.745   grad norm = 10.533   grad norm uniform = 32.744   loss each uniform = 5.636   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.935  exp loss = 2.048  adjusted loss = 2.048  adv prob = 0.250000   acc = 0.632   grad norm = 13.080   grad norm uniform = 30.270   loss each uniform = 5.411   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.970   grad norm = 1.438   grad norm uniform = 39.138   loss each uniform = 11.820   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [236]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.093  
Average loss each uniform: 12.017  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.827   loss each uniform = 12.140   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.740   loss each uniform = 9.615   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 36.828   loss each uniform = 8.558   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.262   loss each uniform = 12.213   feat norm = 0.447  

Validation:
Average incurred loss: 0.628  
Average sample loss: 0.607  
Average acc: 0.869  
Average grad norm: 5.222  
Average grad norm uniform: 33.778  
Average loss each uniform: 8.703  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.186   grad norm uniform = 34.055   loss each uniform = 11.723   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.930  exp loss = 1.002  adjusted loss = 1.002  adv prob = 0.250000   acc = 0.792   grad norm = 8.634   grad norm uniform = 33.197   loss each uniform = 5.936   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.165  exp loss = 2.319  adjusted loss = 2.319  adv prob = 0.250000   acc = 0.602   grad norm = 14.399   grad norm uniform = 30.001   loss each uniform = 5.277   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.955   grad norm = 1.773   grad norm uniform = 38.621   loss each uniform = 11.217   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8690575957298279


Epoch [237]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.082  
Average loss each uniform: 12.002  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.814   loss each uniform = 12.122   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.731   loss each uniform = 9.808   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.950   loss each uniform = 8.631   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.251   loss each uniform = 12.166   feat norm = 0.447  

Validation:
Average incurred loss: 0.790  
Average sample loss: 0.772  
Average acc: 0.829  
Average grad norm: 6.619  
Average grad norm uniform: 33.828  
Average loss each uniform: 8.353  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.987   grad norm = 0.488   grad norm uniform = 34.066   loss each uniform = 10.855   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.497  exp loss = 1.606  adjusted loss = 1.606  adv prob = 0.250000   acc = 0.676   grad norm = 12.926   grad norm uniform = 32.455   loss each uniform = 5.330   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.628  exp loss = 1.765  adjusted loss = 1.765  adv prob = 0.250000   acc = 0.669   grad norm = 11.525   grad norm uniform = 31.403   loss each uniform = 5.749   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.147  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.970   grad norm = 1.145   grad norm uniform = 40.228   loss each uniform = 12.762   feat norm = 0.464  
Current lr: 0.001000
Current validation accuracy: 0.8290241956710815


Epoch [238]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.084  
Average loss each uniform: 12.030  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.815   loss each uniform = 12.154   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 41.757   loss each uniform = 9.612   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 37.069   loss each uniform = 8.841   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.244   loss each uniform = 12.209   feat norm = 0.446  

Validation:
Average incurred loss: 0.621  
Average sample loss: 0.601  
Average acc: 0.868  
Average grad norm: 5.192  
Average grad norm uniform: 33.686  
Average loss each uniform: 8.661  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.206   grad norm uniform = 34.073   loss each uniform = 11.637   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.919  exp loss = 0.991  adjusted loss = 0.991  adv prob = 0.250000   acc = 0.788   grad norm = 8.558   grad norm uniform = 33.225   loss each uniform = 5.973   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.134  exp loss = 2.281  adjusted loss = 2.281  adv prob = 0.250000   acc = 0.609   grad norm = 14.297   grad norm uniform = 29.488   loss each uniform = 5.228   feat norm = 0.421  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.214  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.955   grad norm = 1.805   grad norm uniform = 38.143   loss each uniform = 11.061   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [239]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.084  
Average loss each uniform: 12.055  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.804   loss each uniform = 12.178   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.618   loss each uniform = 9.676   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.885   loss each uniform = 8.639   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.314   loss each uniform = 12.243   feat norm = 0.447  

Validation:
Average incurred loss: 0.622  
Average sample loss: 0.600  
Average acc: 0.871  
Average grad norm: 5.071  
Average grad norm uniform: 34.080  
Average loss each uniform: 8.881  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.122   grad norm uniform = 34.454   loss each uniform = 12.082   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.822  exp loss = 0.896  adjusted loss = 0.896  adv prob = 0.250000   acc = 0.813   grad norm = 7.749   grad norm uniform = 33.895   loss each uniform = 6.214   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.461  exp loss = 2.599  adjusted loss = 2.599  adv prob = 0.250000   acc = 0.549   grad norm = 16.005   grad norm uniform = 29.346   loss each uniform = 5.189   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.252  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.947   grad norm = 2.137   grad norm uniform = 38.149   loss each uniform = 10.680   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [240]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.078  
Average loss each uniform: 12.020  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.807   loss each uniform = 12.163   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.608   loss each uniform = 9.587   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 37.088   loss each uniform = 8.601   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.266   loss each uniform = 12.154   feat norm = 0.447  

Validation:
Average incurred loss: 0.676  
Average sample loss: 0.656  
Average acc: 0.852  
Average grad norm: 5.804  
Average grad norm uniform: 33.739  
Average loss each uniform: 8.450  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.991   grad norm = 0.294   grad norm uniform = 34.177   loss each uniform = 11.260   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.123  exp loss = 1.230  adjusted loss = 1.230  adv prob = 0.250000   acc = 0.745   grad norm = 10.370   grad norm uniform = 32.535   loss each uniform = 5.559   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.931  exp loss = 2.090  adjusted loss = 2.090  adv prob = 0.250000   acc = 0.624   grad norm = 13.424   grad norm uniform = 30.929   loss each uniform = 5.414   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.962   grad norm = 1.528   grad norm uniform = 39.229   loss each uniform = 11.750   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8515429496765137


Epoch [241]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.079  
Average loss each uniform: 12.044  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.799   loss each uniform = 12.181   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.573   loss each uniform = 9.600   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 36.717   loss each uniform = 8.493   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.326   loss each uniform = 12.206   feat norm = 0.447  

Validation:
Average incurred loss: 0.659  
Average sample loss: 0.638  
Average acc: 0.860  
Average grad norm: 5.505  
Average grad norm uniform: 33.647  
Average loss each uniform: 8.616  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.217   grad norm uniform = 34.039   loss each uniform = 11.624   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.013  exp loss = 1.082  adjusted loss = 1.082  adv prob = 0.250000   acc = 0.770   grad norm = 9.384   grad norm uniform = 33.110   loss each uniform = 5.849   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.155  exp loss = 2.292  adjusted loss = 2.292  adv prob = 0.250000   acc = 0.594   grad norm = 14.341   grad norm uniform = 29.540   loss each uniform = 5.191   feat norm = 0.420  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.205  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.955   grad norm = 1.644   grad norm uniform = 38.262   loss each uniform = 11.171   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8598832488059998


Epoch [242]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.085  
Average loss each uniform: 12.053  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.814   loss each uniform = 12.190   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.528   loss each uniform = 9.590   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 36.986   loss each uniform = 8.825   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.296   loss each uniform = 12.199   feat norm = 0.447  

Validation:
Average incurred loss: 0.735  
Average sample loss: 0.716  
Average acc: 0.845  
Average grad norm: 6.210  
Average grad norm uniform: 33.562  
Average loss each uniform: 8.329  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.989   grad norm = 0.395   grad norm uniform = 33.777   loss each uniform = 10.927   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.333  exp loss = 1.428  adjusted loss = 1.428  adv prob = 0.250000   acc = 0.717   grad norm = 11.787   grad norm uniform = 32.339   loss each uniform = 5.382   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.725  exp loss = 1.860  adjusted loss = 1.860  adv prob = 0.250000   acc = 0.662   grad norm = 12.023   grad norm uniform = 30.807   loss each uniform = 5.582   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.159  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 0.970   grad norm = 1.272   grad norm uniform = 39.846   loss each uniform = 12.277   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8448706865310669


Epoch [243]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.090  
Average loss each uniform: 12.088  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.794   loss each uniform = 12.213   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.825   loss each uniform = 9.740   feat norm = 0.532  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.013   grad norm uniform = 36.891   loss each uniform = 8.617   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.341   loss each uniform = 12.269   feat norm = 0.447  

Validation:
Average incurred loss: 0.608  
Average sample loss: 0.588  
Average acc: 0.873  
Average grad norm: 5.063  
Average grad norm uniform: 33.513  
Average loss each uniform: 8.620  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.183   grad norm uniform = 33.965   loss each uniform = 11.631   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.875  exp loss = 0.950  adjusted loss = 0.950  adv prob = 0.250000   acc = 0.805   grad norm = 8.138   grad norm uniform = 32.833   loss each uniform = 5.892   feat norm = 0.471  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.169  exp loss = 2.295  adjusted loss = 2.295  adv prob = 0.250000   acc = 0.594   grad norm = 14.653   grad norm uniform = 29.707   loss each uniform = 5.214   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.955   grad norm = 1.839   grad norm uniform = 38.112   loss each uniform = 11.013   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8732276558876038


Epoch [244]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.077  
Average loss each uniform: 12.056  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.792   loss each uniform = 12.196   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.710   loss each uniform = 9.617   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.044   grad norm uniform = 36.715   loss each uniform = 8.450   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.313   loss each uniform = 12.207   feat norm = 0.447  

Validation:
Average incurred loss: 0.614  
Average sample loss: 0.593  
Average acc: 0.869  
Average grad norm: 5.089  
Average grad norm uniform: 33.867  
Average loss each uniform: 8.754  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.132   grad norm uniform = 34.230   loss each uniform = 11.831   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.835  exp loss = 0.901  adjusted loss = 0.901  adv prob = 0.250000   acc = 0.809   grad norm = 7.909   grad norm uniform = 33.530   loss each uniform = 6.110   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.348  exp loss = 2.467  adjusted loss = 2.467  adv prob = 0.250000   acc = 0.549   grad norm = 15.594   grad norm uniform = 29.464   loss each uniform = 5.179   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.246  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.947   grad norm = 2.109   grad norm uniform = 38.179   loss each uniform = 10.788   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [245]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.083  
Average loss each uniform: 12.066  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.799   loss each uniform = 12.206   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.677   loss each uniform = 9.536   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 36.771   loss each uniform = 8.635   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.322   loss each uniform = 12.228   feat norm = 0.447  

Validation:
Average incurred loss: 0.659  
Average sample loss: 0.639  
Average acc: 0.860  
Average grad norm: 5.590  
Average grad norm uniform: 33.955  
Average loss each uniform: 8.553  
Average feat norm: 0.453  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.280   grad norm uniform = 34.186   loss each uniform = 11.418   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.058  exp loss = 1.146  adjusted loss = 1.146  adv prob = 0.250000   acc = 0.762   grad norm = 9.757   grad norm uniform = 33.206   loss each uniform = 5.743   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.995  exp loss = 2.141  adjusted loss = 2.141  adv prob = 0.250000   acc = 0.624   grad norm = 13.653   grad norm uniform = 30.627   loss each uniform = 5.355   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.962   grad norm = 1.569   grad norm uniform = 39.091   loss each uniform = 11.537   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8598832488059998


Epoch [246]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.086  
Average loss each uniform: 12.106  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.791   loss each uniform = 12.222   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.761   loss each uniform = 9.755   feat norm = 0.532  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.856   loss each uniform = 8.714   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.344   loss each uniform = 12.312   feat norm = 0.447  

Validation:
Average incurred loss: 0.751  
Average sample loss: 0.731  
Average acc: 0.840  
Average grad norm: 6.297  
Average grad norm uniform: 33.857  
Average loss each uniform: 8.449  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.987   grad norm = 0.444   grad norm uniform = 34.087   loss each uniform = 11.049   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.361  exp loss = 1.483  adjusted loss = 1.483  adv prob = 0.250000   acc = 0.710   grad norm = 11.914   grad norm uniform = 32.672   loss each uniform = 5.476   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.759  exp loss = 1.908  adjusted loss = 1.908  adv prob = 0.250000   acc = 0.647   grad norm = 12.169   grad norm uniform = 31.185   loss each uniform = 5.713   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.156  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.970   grad norm = 1.300   grad norm uniform = 39.870   loss each uniform = 12.475   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8398665189743042


Epoch [247]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.074  
Average loss each uniform: 12.078  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.784   loss each uniform = 12.199   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.691   loss each uniform = 9.887   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.946   loss each uniform = 8.691   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.318   loss each uniform = 12.238   feat norm = 0.447  

Validation:
Average incurred loss: 0.722  
Average sample loss: 0.703  
Average acc: 0.847  
Average grad norm: 6.032  
Average grad norm uniform: 33.905  
Average loss each uniform: 8.533  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.989   grad norm = 0.406   grad norm uniform = 34.286   loss each uniform = 11.263   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.274  exp loss = 1.390  adjusted loss = 1.390  adv prob = 0.250000   acc = 0.732   grad norm = 11.183   grad norm uniform = 32.746   loss each uniform = 5.570   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.798  exp loss = 1.943  adjusted loss = 1.943  adv prob = 0.250000   acc = 0.632   grad norm = 12.417   grad norm uniform = 31.211   loss each uniform = 5.624   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.172  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.970   grad norm = 1.355   grad norm uniform = 39.317   loss each uniform = 12.236   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8473727703094482


Epoch [248]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.070  
Average loss each uniform: 12.043  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.801   loss each uniform = 12.182   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 41.719   loss each uniform = 9.722   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 37.095   loss each uniform = 8.728   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.235   loss each uniform = 12.162   feat norm = 0.447  

Validation:
Average incurred loss: 0.661  
Average sample loss: 0.643  
Average acc: 0.856  
Average grad norm: 5.584  
Average grad norm uniform: 33.733  
Average loss each uniform: 8.614  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.272   grad norm uniform = 34.085   loss each uniform = 11.543   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.064  exp loss = 1.144  adjusted loss = 1.144  adv prob = 0.250000   acc = 0.758   grad norm = 9.764   grad norm uniform = 32.813   loss each uniform = 5.724   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.004  exp loss = 2.138  adjusted loss = 2.138  adv prob = 0.250000   acc = 0.609   grad norm = 13.588   grad norm uniform = 30.519   loss each uniform = 5.398   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.192  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.955   grad norm = 1.584   grad norm uniform = 38.934   loss each uniform = 11.670   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8557130098342896


Epoch [249]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.079  
Average loss each uniform: 12.096  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.792   loss each uniform = 12.222   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.700   loss each uniform = 9.759   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.882   loss each uniform = 8.618   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.315   loss each uniform = 12.269   feat norm = 0.447  

Validation:
Average incurred loss: 0.651  
Average sample loss: 0.631  
Average acc: 0.862  
Average grad norm: 5.562  
Average grad norm uniform: 33.448  
Average loss each uniform: 8.441  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.227   grad norm uniform = 33.886   loss each uniform = 11.339   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.025  exp loss = 1.115  adjusted loss = 1.115  adv prob = 0.250000   acc = 0.768   grad norm = 9.581   grad norm uniform = 32.534   loss each uniform = 5.651   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.050  exp loss = 2.187  adjusted loss = 2.187  adv prob = 0.250000   acc = 0.617   grad norm = 14.118   grad norm uniform = 30.018   loss each uniform = 5.207   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.197  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.955   grad norm = 1.658   grad norm uniform = 38.548   loss each uniform = 11.277   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8615513443946838


Epoch [250]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.082  
Average loss each uniform: 12.100  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.793   loss each uniform = 12.232   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.674   loss each uniform = 9.683   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 37.109   loss each uniform = 8.884   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.321   loss each uniform = 12.254   feat norm = 0.447  

Validation:
Average incurred loss: 0.653  
Average sample loss: 0.633  
Average acc: 0.861  
Average grad norm: 5.484  
Average grad norm uniform: 33.721  
Average loss each uniform: 8.557  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.210   grad norm uniform = 34.015   loss each uniform = 11.515   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.010  exp loss = 1.077  adjusted loss = 1.077  adv prob = 0.250000   acc = 0.773   grad norm = 9.370   grad norm uniform = 33.153   loss each uniform = 5.768   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.114  exp loss = 2.262  adjusted loss = 2.262  adv prob = 0.250000   acc = 0.594   grad norm = 14.194   grad norm uniform = 29.888   loss each uniform = 5.230   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.204  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.955   grad norm = 1.676   grad norm uniform = 38.505   loss each uniform = 11.268   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8607172966003418


Epoch [251]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.075  
Average loss each uniform: 12.090  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.796   loss each uniform = 12.235   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.490   loss each uniform = 9.497   feat norm = 0.528  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 37.014   loss each uniform = 8.779   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.314   loss each uniform = 12.237   feat norm = 0.447  

Validation:
Average incurred loss: 0.662  
Average sample loss: 0.643  
Average acc: 0.857  
Average grad norm: 5.602  
Average grad norm uniform: 33.855  
Average loss each uniform: 8.547  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.284   grad norm uniform = 33.972   loss each uniform = 11.384   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.076  exp loss = 1.160  adjusted loss = 1.160  adv prob = 0.250000   acc = 0.760   grad norm = 9.860   grad norm uniform = 33.269   loss each uniform = 5.757   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.967  exp loss = 2.117  adjusted loss = 2.117  adv prob = 0.250000   acc = 0.617   grad norm = 13.412   grad norm uniform = 30.434   loss each uniform = 5.330   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.187  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.962   grad norm = 1.549   grad norm uniform = 38.921   loss each uniform = 11.578   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [252]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.076  
Average loss each uniform: 12.089  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.804   loss each uniform = 12.218   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.640   loss each uniform = 9.763   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.730   loss each uniform = 8.442   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.281   loss each uniform = 12.263   feat norm = 0.447  

Validation:
Average incurred loss: 0.750  
Average sample loss: 0.731  
Average acc: 0.840  
Average grad norm: 6.320  
Average grad norm uniform: 33.975  
Average loss each uniform: 8.456  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.987   grad norm = 0.426   grad norm uniform = 34.088   loss each uniform = 11.066   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.372  exp loss = 1.469  adjusted loss = 1.469  adv prob = 0.250000   acc = 0.708   grad norm = 12.054   grad norm uniform = 32.848   loss each uniform = 5.480   feat norm = 0.486  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.709  exp loss = 1.866  adjusted loss = 1.866  adv prob = 0.250000   acc = 0.654   grad norm = 11.953   grad norm uniform = 31.189   loss each uniform = 5.658   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.162  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.970   grad norm = 1.293   grad norm uniform = 40.311   loss each uniform = 12.521   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8398665189743042


Epoch [253]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.074  
Average loss each uniform: 12.107  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.785   loss each uniform = 12.233   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.687   loss each uniform = 9.795   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.750   loss each uniform = 8.488   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.324   loss each uniform = 12.284   feat norm = 0.447  

Validation:
Average incurred loss: 0.649  
Average sample loss: 0.630  
Average acc: 0.865  
Average grad norm: 5.473  
Average grad norm uniform: 34.032  
Average loss each uniform: 8.689  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.230   grad norm uniform = 34.328   loss each uniform = 11.629   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.015  exp loss = 1.103  adjusted loss = 1.103  adv prob = 0.250000   acc = 0.777   grad norm = 9.368   grad norm uniform = 33.353   loss each uniform = 5.879   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.057  exp loss = 2.189  adjusted loss = 2.189  adv prob = 0.250000   acc = 0.617   grad norm = 13.967   grad norm uniform = 30.248   loss each uniform = 5.345   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 1.741   grad norm uniform = 39.151   loss each uniform = 11.552   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8648874759674072


Epoch [254]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.068  
Average loss each uniform: 12.083  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.786   loss each uniform = 12.228   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 41.648   loss each uniform = 9.653   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.964   loss each uniform = 8.808   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.294   loss each uniform = 12.200   feat norm = 0.447  

Validation:
Average incurred loss: 0.782  
Average sample loss: 0.765  
Average acc: 0.837  
Average grad norm: 6.480  
Average grad norm uniform: 34.065  
Average loss each uniform: 8.465  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.987   grad norm = 0.479   grad norm uniform = 34.117   loss each uniform = 10.942   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.481  exp loss = 1.593  adjusted loss = 1.593  adv prob = 0.250000   acc = 0.695   grad norm = 12.627   grad norm uniform = 32.876   loss each uniform = 5.440   feat norm = 0.486  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.616  exp loss = 1.759  adjusted loss = 1.759  adv prob = 0.250000   acc = 0.669   grad norm = 11.297   grad norm uniform = 31.501   loss each uniform = 5.865   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.148  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.970   grad norm = 1.194   grad norm uniform = 40.614   loss each uniform = 12.964   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8365304470062256


Epoch [255]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.071  
Average loss each uniform: 12.116  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.774   loss each uniform = 12.263   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.655   loss each uniform = 9.556   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.996   loss each uniform = 8.755   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.339   loss each uniform = 12.253   feat norm = 0.447  

Validation:
Average incurred loss: 0.695  
Average sample loss: 0.674  
Average acc: 0.852  
Average grad norm: 5.864  
Average grad norm uniform: 33.897  
Average loss each uniform: 8.497  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 0.989   grad norm = 0.359   grad norm uniform = 33.864   loss each uniform = 11.160   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.201  exp loss = 1.296  adjusted loss = 1.296  adv prob = 0.250000   acc = 0.742   grad norm = 10.772   grad norm uniform = 32.842   loss each uniform = 5.579   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.820  exp loss = 1.970  adjusted loss = 1.970  adv prob = 0.250000   acc = 0.639   grad norm = 12.478   grad norm uniform = 31.495   loss each uniform = 5.592   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.171  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.970   grad norm = 1.387   grad norm uniform = 40.109   loss each uniform = 12.279   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8523769378662109


Epoch [256]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.064  
Average loss each uniform: 12.109  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.761   loss each uniform = 12.263   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.025   grad norm uniform = 41.611   loss each uniform = 9.711   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 37.079   loss each uniform = 8.610   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.357   loss each uniform = 12.205   feat norm = 0.448  

Validation:
Average incurred loss: 0.642  
Average sample loss: 0.622  
Average acc: 0.865  
Average grad norm: 5.424  
Average grad norm uniform: 33.709  
Average loss each uniform: 8.593  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.216   grad norm uniform = 34.162   loss each uniform = 11.576   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.972  exp loss = 1.057  adjusted loss = 1.057  adv prob = 0.250000   acc = 0.785   grad norm = 9.037   grad norm uniform = 32.894   loss each uniform = 5.798   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.147  exp loss = 2.293  adjusted loss = 2.293  adv prob = 0.250000   acc = 0.594   grad norm = 14.643   grad norm uniform = 30.103   loss each uniform = 5.243   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.947   grad norm = 1.833   grad norm uniform = 38.580   loss each uniform = 11.264   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8648873567581177


Epoch [257]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.062  
Average loss each uniform: 12.122  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.764   loss each uniform = 12.274   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.683   loss each uniform = 9.658   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 37.075   loss each uniform = 8.769   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.326   loss each uniform = 12.224   feat norm = 0.447  

Validation:
Average incurred loss: 0.671  
Average sample loss: 0.651  
Average acc: 0.854  
Average grad norm: 5.667  
Average grad norm uniform: 33.899  
Average loss each uniform: 8.570  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.279   grad norm uniform = 34.175   loss each uniform = 11.408   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.106  exp loss = 1.175  adjusted loss = 1.175  adv prob = 0.250000   acc = 0.751   grad norm = 10.078   grad norm uniform = 33.031   loss each uniform = 5.693   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.931  exp loss = 2.082  adjusted loss = 2.082  adv prob = 0.250000   acc = 0.617   grad norm = 13.235   grad norm uniform = 30.647   loss each uniform = 5.436   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.193  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.955   grad norm = 1.566   grad norm uniform = 39.221   loss each uniform = 11.815   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [258]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.066  
Average loss each uniform: 12.158  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.752   loss each uniform = 12.288   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.726   loss each uniform = 9.962   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.245   loss each uniform = 8.843   feat norm = 0.435  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.370   loss each uniform = 12.287   feat norm = 0.448  

Validation:
Average incurred loss: 0.678  
Average sample loss: 0.660  
Average acc: 0.852  
Average grad norm: 5.808  
Average grad norm uniform: 33.473  
Average loss each uniform: 8.382  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.289   grad norm uniform = 33.944   loss each uniform = 11.199   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.133  exp loss = 1.228  adjusted loss = 1.228  adv prob = 0.250000   acc = 0.740   grad norm = 10.436   grad norm uniform = 32.420   loss each uniform = 5.511   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.927  exp loss = 2.064  adjusted loss = 2.064  adv prob = 0.250000   acc = 0.617   grad norm = 13.345   grad norm uniform = 30.063   loss each uniform = 5.316   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.970   grad norm = 1.434   grad norm uniform = 38.921   loss each uniform = 11.614   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8515429496765137


Epoch [259]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.067  
Average loss each uniform: 12.168  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.761   loss each uniform = 12.298   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 41.715   loss each uniform = 9.932   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 36.939   loss each uniform = 8.885   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.363   loss each uniform = 12.301   feat norm = 0.447  

Validation:
Average incurred loss: 0.696  
Average sample loss: 0.677  
Average acc: 0.851  
Average grad norm: 5.778  
Average grad norm uniform: 33.738  
Average loss each uniform: 8.606  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.307   grad norm uniform = 33.928   loss each uniform = 11.451   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.172  exp loss = 1.259  adjusted loss = 1.259  adv prob = 0.250000   acc = 0.740   grad norm = 10.433   grad norm uniform = 32.804   loss each uniform = 5.665   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.930  exp loss = 2.086  adjusted loss = 2.086  adv prob = 0.250000   acc = 0.632   grad norm = 12.958   grad norm uniform = 30.895   loss each uniform = 5.549   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.185  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.962   grad norm = 1.502   grad norm uniform = 39.182   loss each uniform = 11.980   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8507089614868164


Epoch [260]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.060  
Average loss each uniform: 12.135  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.754   loss each uniform = 12.287   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.658   loss each uniform = 9.756   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.832   loss each uniform = 8.515   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.369   loss each uniform = 12.237   feat norm = 0.448  

Validation:
Average incurred loss: 0.696  
Average sample loss: 0.677  
Average acc: 0.854  
Average grad norm: 5.829  
Average grad norm uniform: 33.608  
Average loss each uniform: 8.519  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.279   grad norm uniform = 33.823   loss each uniform = 11.381   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.167  exp loss = 1.240  adjusted loss = 1.240  adv prob = 0.250000   acc = 0.747   grad norm = 10.533   grad norm uniform = 32.908   loss each uniform = 5.633   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.956  exp loss = 2.087  adjusted loss = 2.087  adv prob = 0.250000   acc = 0.617   grad norm = 13.214   grad norm uniform = 29.888   loss each uniform = 5.345   feat norm = 0.421  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.970   grad norm = 1.451   grad norm uniform = 39.023   loss each uniform = 11.758   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.854045033454895


Epoch [261]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.062  
Average loss each uniform: 12.168  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.743   loss each uniform = 12.306   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 41.785   loss each uniform = 9.898   feat norm = 0.532  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 36.838   loss each uniform = 8.720   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.388   loss each uniform = 12.292   feat norm = 0.448  

Validation:
Average incurred loss: 0.687  
Average sample loss: 0.668  
Average acc: 0.852  
Average grad norm: 5.773  
Average grad norm uniform: 33.870  
Average loss each uniform: 8.596  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.291   grad norm uniform = 34.138   loss each uniform = 11.487   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.141  exp loss = 1.227  adjusted loss = 1.227  adv prob = 0.250000   acc = 0.740   grad norm = 10.344   grad norm uniform = 33.004   loss each uniform = 5.669   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.972  exp loss = 2.121  adjusted loss = 2.121  adv prob = 0.250000   acc = 0.624   grad norm = 13.311   grad norm uniform = 30.685   loss each uniform = 5.449   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.970   grad norm = 1.472   grad norm uniform = 39.153   loss each uniform = 11.845   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8515429496765137


Epoch [262]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.067  
Average loss each uniform: 12.168  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.751   loss each uniform = 12.308   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.766   loss each uniform = 9.861   feat norm = 0.532  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 36.787   loss each uniform = 8.465   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.391   loss each uniform = 12.303   feat norm = 0.448  

Validation:
Average incurred loss: 0.798  
Average sample loss: 0.781  
Average acc: 0.826  
Average grad norm: 6.633  
Average grad norm uniform: 33.410  
Average loss each uniform: 8.249  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.987   grad norm = 0.527   grad norm uniform = 33.452   loss each uniform = 10.605   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.526  exp loss = 1.656  adjusted loss = 1.656  adv prob = 0.250000   acc = 0.672   grad norm = 13.000   grad norm uniform = 32.048   loss each uniform = 5.253   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.601  exp loss = 1.754  adjusted loss = 1.754  adv prob = 0.250000   acc = 0.654   grad norm = 11.267   grad norm uniform = 31.203   loss each uniform = 5.851   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.143  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.970   grad norm = 1.127   grad norm uniform = 40.246   loss each uniform = 12.871   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8256880640983582


Epoch [263]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.053  
Average loss each uniform: 12.134  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.748   loss each uniform = 12.285   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.753   loss each uniform = 9.942   feat norm = 0.532  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 37.274   loss each uniform = 9.023   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 39.316   loss each uniform = 12.180   feat norm = 0.447  

Validation:
Average incurred loss: 0.767  
Average sample loss: 0.746  
Average acc: 0.835  
Average grad norm: 6.473  
Average grad norm uniform: 33.726  
Average loss each uniform: 8.345  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.987   grad norm = 0.458   grad norm uniform = 33.886   loss each uniform = 10.896   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.409  exp loss = 1.524  adjusted loss = 1.524  adv prob = 0.250000   acc = 0.697   grad norm = 12.380   grad norm uniform = 32.606   loss each uniform = 5.387   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.736  exp loss = 1.880  adjusted loss = 1.880  adv prob = 0.250000   acc = 0.647   grad norm = 12.162   grad norm uniform = 30.904   loss each uniform = 5.640   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.154  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 0.970   grad norm = 1.206   grad norm uniform = 39.909   loss each uniform = 12.456   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8348624110221863


Epoch [264]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.055  
Average loss each uniform: 12.149  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.750   loss each uniform = 12.299   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.703   loss each uniform = 9.919   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 37.121   loss each uniform = 8.784   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.336   loss each uniform = 12.217   feat norm = 0.447  

Validation:
Average incurred loss: 0.663  
Average sample loss: 0.643  
Average acc: 0.862  
Average grad norm: 5.517  
Average grad norm uniform: 33.873  
Average loss each uniform: 8.698  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.273   grad norm uniform = 34.157   loss each uniform = 11.623   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.052  exp loss = 1.135  adjusted loss = 1.135  adv prob = 0.250000   acc = 0.773   grad norm = 9.571   grad norm uniform = 33.192   loss each uniform = 5.862   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.045  exp loss = 2.183  adjusted loss = 2.183  adv prob = 0.250000   acc = 0.617   grad norm = 13.630   grad norm uniform = 30.190   loss each uniform = 5.420   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.199  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.955   grad norm = 1.614   grad norm uniform = 38.945   loss each uniform = 11.641   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8615513443946838


Epoch [265]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.058  
Average loss each uniform: 12.188  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.742   loss each uniform = 12.328   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 41.758   loss each uniform = 9.856   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 37.166   loss each uniform = 8.983   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.362   loss each uniform = 12.300   feat norm = 0.447  

Validation:
Average incurred loss: 0.669  
Average sample loss: 0.649  
Average acc: 0.857  
Average grad norm: 5.553  
Average grad norm uniform: 33.953  
Average loss each uniform: 8.747  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.996   grad norm = 0.278   grad norm uniform = 34.244   loss each uniform = 11.624   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.102  exp loss = 1.203  adjusted loss = 1.203  adv prob = 0.250000   acc = 0.755   grad norm = 9.851   grad norm uniform = 33.106   loss each uniform = 5.861   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.934  exp loss = 2.074  adjusted loss = 2.074  adv prob = 0.250000   acc = 0.617   grad norm = 13.030   grad norm uniform = 30.742   loss each uniform = 5.557   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.962   grad norm = 1.542   grad norm uniform = 39.112   loss each uniform = 11.951   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [266]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.063  
Average loss each uniform: 12.186  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.754   loss each uniform = 12.325   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 41.721   loss each uniform = 9.925   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.818   loss each uniform = 8.516   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.368   loss each uniform = 12.315   feat norm = 0.447  

Validation:
Average incurred loss: 0.629  
Average sample loss: 0.607  
Average acc: 0.872  
Average grad norm: 5.214  
Average grad norm uniform: 34.029  
Average loss each uniform: 8.699  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.174   grad norm uniform = 34.298   loss each uniform = 11.729   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.911  exp loss = 0.980  adjusted loss = 0.980  adv prob = 0.250000   acc = 0.803   grad norm = 8.486   grad norm uniform = 33.632   loss each uniform = 5.985   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.229  exp loss = 2.364  adjusted loss = 2.364  adv prob = 0.250000   acc = 0.586   grad norm = 14.808   grad norm uniform = 29.883   loss each uniform = 5.234   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.225  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.955   grad norm = 1.854   grad norm uniform = 38.620   loss each uniform = 11.037   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8715596199035645


Epoch [267]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.053  
Average loss each uniform: 12.174  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.748   loss each uniform = 12.317   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.702   loss each uniform = 9.920   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 37.137   loss each uniform = 8.837   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.330   loss each uniform = 12.268   feat norm = 0.447  

Validation:
Average incurred loss: 0.661  
Average sample loss: 0.640  
Average acc: 0.863  
Average grad norm: 5.471  
Average grad norm uniform: 34.097  
Average loss each uniform: 8.782  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.199   grad norm uniform = 34.584   loss each uniform = 11.880   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.010  exp loss = 1.093  adjusted loss = 1.093  adv prob = 0.250000   acc = 0.781   grad norm = 9.236   grad norm uniform = 33.417   loss each uniform = 5.950   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.185  exp loss = 2.325  adjusted loss = 2.325  adv prob = 0.250000   acc = 0.579   grad norm = 14.550   grad norm uniform = 30.261   loss each uniform = 5.281   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.205  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.962   grad norm = 1.710   grad norm uniform = 38.602   loss each uniform = 11.327   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [268]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.058  
Average loss each uniform: 12.187  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.741   loss each uniform = 12.329   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.746   loss each uniform = 9.928   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 37.073   loss each uniform = 8.800   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.371   loss each uniform = 12.289   feat norm = 0.448  

Validation:
Average incurred loss: 0.599  
Average sample loss: 0.577  
Average acc: 0.878  
Average grad norm: 4.769  
Average grad norm uniform: 33.683  
Average loss each uniform: 8.994  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.002  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.069   grad norm uniform = 34.270   loss each uniform = 12.361   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.692  exp loss = 0.756  adjusted loss = 0.756  adv prob = 0.250000   acc = 0.843   grad norm = 6.629   grad norm uniform = 33.642   loss each uniform = 6.401   feat norm = 0.473  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.690  exp loss = 2.833  adjusted loss = 2.833  adv prob = 0.250000   acc = 0.511   grad norm = 17.101   grad norm uniform = 28.356   loss each uniform = 5.096   feat norm = 0.419  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.280  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.940   grad norm = 2.421   grad norm uniform = 37.090   loss each uniform = 10.152   feat norm = 0.446  
Current lr: 0.001000
Current validation accuracy: 0.8782318830490112


Epoch [269]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.061  
Average loss each uniform: 12.198  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.750   loss each uniform = 12.335   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 41.651   loss each uniform = 9.925   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 37.136   loss each uniform = 8.756   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.369   loss each uniform = 12.324   feat norm = 0.447  

Validation:
Average incurred loss: 0.661  
Average sample loss: 0.639  
Average acc: 0.862  
Average grad norm: 5.524  
Average grad norm uniform: 33.459  
Average loss each uniform: 8.539  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.230   grad norm uniform = 33.844   loss each uniform = 11.507   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.016  exp loss = 1.094  adjusted loss = 1.094  adv prob = 0.250000   acc = 0.777   grad norm = 9.384   grad norm uniform = 32.618   loss each uniform = 5.701   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.176  exp loss = 2.318  adjusted loss = 2.318  adv prob = 0.250000   acc = 0.586   grad norm = 14.498   grad norm uniform = 29.942   loss each uniform = 5.287   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.192  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.955   grad norm = 1.614   grad norm uniform = 38.569   loss each uniform = 11.311   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8615512847900391


Epoch [270]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.048  
Average loss each uniform: 12.156  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.743   loss each uniform = 12.308   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.726   loss each uniform = 9.892   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.930   loss each uniform = 8.604   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.331   loss each uniform = 12.234   feat norm = 0.447  

Validation:
Average incurred loss: 0.637  
Average sample loss: 0.616  
Average acc: 0.863  
Average grad norm: 5.301  
Average grad norm uniform: 33.608  
Average loss each uniform: 8.675  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.166   grad norm uniform = 34.103   loss each uniform = 11.752   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.920  exp loss = 1.005  adjusted loss = 1.005  adv prob = 0.250000   acc = 0.783   grad norm = 8.604   grad norm uniform = 32.988   loss each uniform = 5.911   feat norm = 0.476  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.275  exp loss = 2.413  adjusted loss = 2.413  adv prob = 0.250000   acc = 0.586   grad norm = 15.091   grad norm uniform = 29.566   loss each uniform = 5.212   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.225  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.947   grad norm = 1.968   grad norm uniform = 38.087   loss each uniform = 11.015   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [271]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.041  
Average loss each uniform: 12.137  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.744   loss each uniform = 12.302   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.713   loss each uniform = 9.710   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.030   grad norm uniform = 36.941   loss each uniform = 8.581   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 39.297   loss each uniform = 12.199   feat norm = 0.447  

Validation:
Average incurred loss: 0.630  
Average sample loss: 0.608  
Average acc: 0.870  
Average grad norm: 5.076  
Average grad norm uniform: 33.802  
Average loss each uniform: 8.892  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.005  exp loss = 0.003  adjusted loss = 0.003  adv prob = 0.250000   acc = 0.998   grad norm = 0.132   grad norm uniform = 34.187   loss each uniform = 12.090   feat norm = 0.422  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.856  exp loss = 0.916  adjusted loss = 0.916  adv prob = 0.250000   acc = 0.809   grad norm = 7.912   grad norm uniform = 33.536   loss each uniform = 6.162   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.425  exp loss = 2.567  adjusted loss = 2.567  adv prob = 0.250000   acc = 0.549   grad norm = 15.572   grad norm uniform = 29.264   loss each uniform = 5.234   feat norm = 0.421  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.240  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.955   grad norm = 2.006   grad norm uniform = 37.919   loss each uniform = 10.882   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8698915243148804


Epoch [272]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.058  
Average loss each uniform: 12.179  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.770   loss each uniform = 12.327   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.599   loss each uniform = 9.703   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.023   grad norm uniform = 36.912   loss each uniform = 8.824   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.309   loss each uniform = 12.300   feat norm = 0.447  

Validation:
Average incurred loss: 0.811  
Average sample loss: 0.794  
Average acc: 0.826  
Average grad norm: 6.639  
Average grad norm uniform: 33.327  
Average loss each uniform: 8.307  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.987   grad norm = 0.490   grad norm uniform = 33.513   loss each uniform = 10.736   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.554  exp loss = 1.673  adjusted loss = 1.673  adv prob = 0.250000   acc = 0.667   grad norm = 13.047   grad norm uniform = 31.919   loss each uniform = 5.263   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.621  exp loss = 1.761  adjusted loss = 1.761  adv prob = 0.250000   acc = 0.669   grad norm = 11.256   grad norm uniform = 31.016   loss each uniform = 5.848   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.141  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.970   grad norm = 1.161   grad norm uniform = 39.920   loss each uniform = 12.908   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8256881237030029


Epoch [273]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.048  
Average loss each uniform: 12.184  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.750   loss each uniform = 12.327   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.677   loss each uniform = 9.770   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.940   loss each uniform = 8.759   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.315   loss each uniform = 12.314   feat norm = 0.447  

Validation:
Average incurred loss: 0.656  
Average sample loss: 0.634  
Average acc: 0.865  
Average grad norm: 5.364  
Average grad norm uniform: 33.896  
Average loss each uniform: 8.818  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.147   grad norm uniform = 34.391   loss each uniform = 12.043   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.944  exp loss = 1.008  adjusted loss = 1.008  adv prob = 0.250000   acc = 0.792   grad norm = 8.765   grad norm uniform = 33.449   loss each uniform = 5.993   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.368  exp loss = 2.515  adjusted loss = 2.515  adv prob = 0.250000   acc = 0.564   grad norm = 15.307   grad norm uniform = 29.555   loss each uniform = 5.218   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.220  exp loss = 0.227  adjusted loss = 0.227  adv prob = 0.250000   acc = 0.955   grad norm = 1.827   grad norm uniform = 38.070   loss each uniform = 10.991   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8648874759674072


Epoch [274]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.051  
Average loss each uniform: 12.196  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.763   loss each uniform = 12.329   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.741   loss each uniform = 9.823   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.022   grad norm uniform = 36.915   loss each uniform = 8.866   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.276   loss each uniform = 12.346   feat norm = 0.446  

Validation:
Average incurred loss: 0.732  
Average sample loss: 0.713  
Average acc: 0.846  
Average grad norm: 6.097  
Average grad norm uniform: 33.940  
Average loss each uniform: 8.571  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 0.991   grad norm = 0.397   grad norm uniform = 34.029   loss each uniform = 11.312   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.288  exp loss = 1.396  adjusted loss = 1.396  adv prob = 0.250000   acc = 0.725   grad norm = 11.342   grad norm uniform = 33.170   loss each uniform = 5.643   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.835  exp loss = 1.983  adjusted loss = 1.983  adv prob = 0.250000   acc = 0.632   grad norm = 12.468   grad norm uniform = 30.706   loss each uniform = 5.571   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.970   grad norm = 1.365   grad norm uniform = 39.560   loss each uniform = 12.205   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8457047939300537


Epoch [275]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.055  
Average loss each uniform: 12.204  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.766   loss each uniform = 12.338   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.576   loss each uniform = 9.799   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 37.174   loss each uniform = 8.885   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.301   loss each uniform = 12.356   feat norm = 0.447  

Validation:
Average incurred loss: 0.644  
Average sample loss: 0.624  
Average acc: 0.862  
Average grad norm: 5.370  
Average grad norm uniform: 33.516  
Average loss each uniform: 8.758  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.151   grad norm uniform = 34.266   loss each uniform = 11.957   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.940  exp loss = 1.008  adjusted loss = 1.008  adv prob = 0.250000   acc = 0.781   grad norm = 8.849   grad norm uniform = 32.825   loss each uniform = 5.962   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.268  exp loss = 2.416  adjusted loss = 2.416  adv prob = 0.250000   acc = 0.586   grad norm = 14.995   grad norm uniform = 28.984   loss each uniform = 5.141   feat norm = 0.420  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.222  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.947   grad norm = 1.884   grad norm uniform = 37.831   loss each uniform = 10.940   feat norm = 0.449  
Current lr: 0.001000
Current validation accuracy: 0.8623853325843811


Epoch [276]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.052  
Average loss each uniform: 12.223  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.751   loss each uniform = 12.359   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.661   loss each uniform = 9.676   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.019   loss each uniform = 8.865   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.333   loss each uniform = 12.396   feat norm = 0.447  

Validation:
Average incurred loss: 0.630  
Average sample loss: 0.610  
Average acc: 0.871  
Average grad norm: 5.124  
Average grad norm uniform: 33.986  
Average loss each uniform: 8.920  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.208   grad norm uniform = 34.335   loss each uniform = 12.024   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.916  exp loss = 0.997  adjusted loss = 0.997  adv prob = 0.250000   acc = 0.796   grad norm = 8.319   grad norm uniform = 33.543   loss each uniform = 6.150   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.217  exp loss = 2.368  adjusted loss = 2.368  adv prob = 0.250000   acc = 0.609   grad norm = 14.405   grad norm uniform = 29.958   loss each uniform = 5.378   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.224  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947   grad norm = 1.915   grad norm uniform = 38.342   loss each uniform = 11.264   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [277]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.055  
Average loss each uniform: 12.223  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.769   loss each uniform = 12.355   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.588   loss each uniform = 9.779   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.059   loss each uniform = 8.958   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.293   loss each uniform = 12.382   feat norm = 0.446  

Validation:
Average incurred loss: 0.659  
Average sample loss: 0.638  
Average acc: 0.863  
Average grad norm: 5.411  
Average grad norm uniform: 33.774  
Average loss each uniform: 8.739  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.203   grad norm uniform = 34.234   loss each uniform = 11.806   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.002  exp loss = 1.085  adjusted loss = 1.085  adv prob = 0.250000   acc = 0.779   grad norm = 9.110   grad norm uniform = 33.194   loss each uniform = 5.934   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.189  exp loss = 2.357  adjusted loss = 2.357  adv prob = 0.250000   acc = 0.594   grad norm = 14.435   grad norm uniform = 29.739   loss each uniform = 5.278   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.955   grad norm = 1.718   grad norm uniform = 38.226   loss each uniform = 11.258   feat norm = 0.452  
Current lr: 0.001000
Current validation accuracy: 0.8632193803787231


Epoch [278]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.054  
Average loss each uniform: 12.230  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.756   loss each uniform = 12.359   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.669   loss each uniform = 9.816   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 36.893   loss each uniform = 8.646   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.325   loss each uniform = 12.411   feat norm = 0.447  

Validation:
Average incurred loss: 0.683  
Average sample loss: 0.662  
Average acc: 0.857  
Average grad norm: 5.602  
Average grad norm uniform: 33.994  
Average loss each uniform: 8.804  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.263   grad norm uniform = 34.442   loss each uniform = 11.816   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.090  exp loss = 1.182  adjusted loss = 1.182  adv prob = 0.250000   acc = 0.762   grad norm = 9.732   grad norm uniform = 33.087   loss each uniform = 5.890   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.099  exp loss = 2.226  adjusted loss = 2.226  adv prob = 0.250000   acc = 0.602   grad norm = 13.913   grad norm uniform = 30.605   loss each uniform = 5.480   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.955   grad norm = 1.564   grad norm uniform = 38.984   loss each uniform = 11.762   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8565471172332764


Epoch [279]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.004  
Average grad norm uniform: 36.044  
Average loss each uniform: 12.192  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.756   loss each uniform = 12.333   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.009   grad norm uniform = 41.659   loss each uniform = 9.846   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.024   grad norm uniform = 37.249   loss each uniform = 8.886   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.265   loss each uniform = 12.307   feat norm = 0.446  

Validation:
Average incurred loss: 0.770  
Average sample loss: 0.752  
Average acc: 0.832  
Average grad norm: 6.373  
Average grad norm uniform: 33.629  
Average loss each uniform: 8.438  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.987   grad norm = 0.408   grad norm uniform = 33.738   loss each uniform = 11.046   feat norm = 0.421  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.422  exp loss = 1.528  adjusted loss = 1.528  adv prob = 0.250000   acc = 0.689   grad norm = 12.275   grad norm uniform = 32.528   loss each uniform = 5.441   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.721  exp loss = 1.875  adjusted loss = 1.875  adv prob = 0.250000   acc = 0.647   grad norm = 11.811   grad norm uniform = 30.982   loss each uniform = 5.660   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.155  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.970   grad norm = 1.203   grad norm uniform = 39.752   loss each uniform = 12.562   feat norm = 0.459  
Current lr: 0.001000
Current validation accuracy: 0.8315262794494629


Epoch [280]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.051  
Average loss each uniform: 12.241  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.747   loss each uniform = 12.376   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.646   loss each uniform = 9.839   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 37.058   loss each uniform = 8.827   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.337   loss each uniform = 12.393   feat norm = 0.447  

Validation:
Average incurred loss: 0.680  
Average sample loss: 0.663  
Average acc: 0.852  
Average grad norm: 5.714  
Average grad norm uniform: 33.491  
Average loss each uniform: 8.502  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.314   grad norm uniform = 33.640   loss each uniform = 11.256   feat norm = 0.420  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.145  exp loss = 1.236  adjusted loss = 1.236  adv prob = 0.250000   acc = 0.745   grad norm = 10.292   grad norm uniform = 32.509   loss each uniform = 5.600   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.892  exp loss = 2.021  adjusted loss = 2.021  adv prob = 0.250000   acc = 0.632   grad norm = 12.878   grad norm uniform = 30.799   loss each uniform = 5.508   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.962   grad norm = 1.474   grad norm uniform = 39.098   loss each uniform = 11.990   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8523769378662109


Epoch [281]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.046  
Average loss each uniform: 12.243  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.739   loss each uniform = 12.375   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.682   loss each uniform = 9.917   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.003   loss each uniform = 8.868   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.341   loss each uniform = 12.391   feat norm = 0.447  

Validation:
Average incurred loss: 0.637  
Average sample loss: 0.616  
Average acc: 0.868  
Average grad norm: 5.233  
Average grad norm uniform: 34.048  
Average loss each uniform: 8.790  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.010  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.209   grad norm uniform = 34.233   loss each uniform = 11.810   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.947  exp loss = 1.022  adjusted loss = 1.022  adv prob = 0.250000   acc = 0.790   grad norm = 8.696   grad norm uniform = 33.499   loss each uniform = 5.985   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.171  exp loss = 2.321  adjusted loss = 2.321  adv prob = 0.250000   acc = 0.602   grad norm = 14.217   grad norm uniform = 30.558   loss each uniform = 5.390   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.214  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.955   grad norm = 1.756   grad norm uniform = 38.807   loss each uniform = 11.412   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [282]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.044  
Average loss each uniform: 12.244  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.734   loss each uniform = 12.379   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.605   loss each uniform = 9.895   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 37.122   loss each uniform = 8.961   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.357   loss each uniform = 12.382   feat norm = 0.447  

Validation:
Average incurred loss: 0.646  
Average sample loss: 0.624  
Average acc: 0.871  
Average grad norm: 5.184  
Average grad norm uniform: 34.695  
Average loss each uniform: 9.141  
Average feat norm: 0.457  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.191   grad norm uniform = 34.825   loss each uniform = 12.299   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.944  exp loss = 1.025  adjusted loss = 1.025  adv prob = 0.250000   acc = 0.798   grad norm = 8.440   grad norm uniform = 34.508   loss each uniform = 6.349   feat norm = 0.490  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.267  exp loss = 2.439  adjusted loss = 2.439  adv prob = 0.250000   acc = 0.594   grad norm = 14.636   grad norm uniform = 30.535   loss each uniform = 5.468   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.220  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.955   grad norm = 1.851   grad norm uniform = 39.049   loss each uniform = 11.510   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [283]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.046  
Average loss each uniform: 12.252  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.745   loss each uniform = 12.386   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.542   loss each uniform = 9.842   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 37.125   loss each uniform = 8.898   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.338   loss each uniform = 12.404   feat norm = 0.447  

Validation:
Average incurred loss: 0.657  
Average sample loss: 0.636  
Average acc: 0.866  
Average grad norm: 5.358  
Average grad norm uniform: 33.724  
Average loss each uniform: 8.803  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 0.998   grad norm = 0.208   grad norm uniform = 34.147   loss each uniform = 11.892   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.988  exp loss = 1.063  adjusted loss = 1.063  adv prob = 0.250000   acc = 0.785   grad norm = 8.980   grad norm uniform = 32.979   loss each uniform = 5.949   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.214  exp loss = 2.356  adjusted loss = 2.356  adv prob = 0.250000   acc = 0.594   grad norm = 14.411   grad norm uniform = 30.201   loss each uniform = 5.378   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.955   grad norm = 1.696   grad norm uniform = 38.378   loss each uniform = 11.384   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [284]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.046  
Average loss each uniform: 12.259  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.742   loss each uniform = 12.397   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.540   loss each uniform = 9.774   feat norm = 0.529  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.967   loss each uniform = 8.706   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.356   loss each uniform = 12.426   feat norm = 0.447  

Validation:
Average incurred loss: 0.679  
Average sample loss: 0.660  
Average acc: 0.857  
Average grad norm: 5.610  
Average grad norm uniform: 33.950  
Average loss each uniform: 8.738  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.991   grad norm = 0.313   grad norm uniform = 34.126   loss each uniform = 11.620   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.117  exp loss = 1.214  adjusted loss = 1.214  adv prob = 0.250000   acc = 0.760   grad norm = 9.925   grad norm uniform = 33.064   loss each uniform = 5.821   feat norm = 0.480  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.969  exp loss = 2.108  adjusted loss = 2.108  adv prob = 0.250000   acc = 0.624   grad norm = 13.206   grad norm uniform = 31.162   loss each uniform = 5.558   feat norm = 0.428  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.962   grad norm = 1.491   grad norm uniform = 39.231   loss each uniform = 12.017   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8573812246322632


Epoch [285]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.029  
Average loss each uniform: 12.210  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.729   loss each uniform = 12.359   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.730   loss each uniform = 9.847   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.920   loss each uniform = 8.771   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.292   loss each uniform = 12.312   feat norm = 0.447  

Validation:
Average incurred loss: 0.654  
Average sample loss: 0.634  
Average acc: 0.866  
Average grad norm: 5.310  
Average grad norm uniform: 33.915  
Average loss each uniform: 8.924  
Average feat norm: 0.449  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.009  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.193   grad norm uniform = 34.356   loss each uniform = 12.090   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.970  exp loss = 1.048  adjusted loss = 1.048  adv prob = 0.250000   acc = 0.785   grad norm = 8.789   grad norm uniform = 33.333   loss each uniform = 6.052   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.253  exp loss = 2.371  adjusted loss = 2.371  adv prob = 0.250000   acc = 0.594   grad norm = 14.564   grad norm uniform = 29.999   loss each uniform = 5.371   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.955   grad norm = 1.836   grad norm uniform = 38.324   loss each uniform = 11.427   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [286]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.038  
Average loss each uniform: 12.234  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.741   loss each uniform = 12.380   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.011   grad norm uniform = 41.599   loss each uniform = 9.800   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 36.860   loss each uniform = 8.536   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.318   loss each uniform = 12.371   feat norm = 0.447  

Validation:
Average incurred loss: 0.742  
Average sample loss: 0.724  
Average acc: 0.843  
Average grad norm: 6.155  
Average grad norm uniform: 33.403  
Average loss each uniform: 8.451  
Average feat norm: 0.445  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.987   grad norm = 0.405   grad norm uniform = 33.519   loss each uniform = 11.089   feat norm = 0.418  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.339  exp loss = 1.444  adjusted loss = 1.444  adv prob = 0.250000   acc = 0.719   grad norm = 11.616   grad norm uniform = 32.432   loss each uniform = 5.513   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.757  exp loss = 1.907  adjusted loss = 1.907  adv prob = 0.250000   acc = 0.647   grad norm = 12.031   grad norm uniform = 30.451   loss each uniform = 5.596   feat norm = 0.420  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.164  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.970   grad norm = 1.339   grad norm uniform = 39.349   loss each uniform = 12.335   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8432026505470276


Epoch [287]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.022  
Average loss each uniform: 12.207  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.738   loss each uniform = 12.355   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.010   grad norm uniform = 41.618   loss each uniform = 9.910   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.026   grad norm uniform = 36.751   loss each uniform = 8.630   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.259   loss each uniform = 12.306   feat norm = 0.446  

Validation:
Average incurred loss: 0.631  
Average sample loss: 0.610  
Average acc: 0.871  
Average grad norm: 5.108  
Average grad norm uniform: 34.048  
Average loss each uniform: 8.970  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 0.998   grad norm = 0.177   grad norm uniform = 34.424   loss each uniform = 12.142   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.905  exp loss = 0.974  adjusted loss = 0.974  adv prob = 0.250000   acc = 0.803   grad norm = 8.234   grad norm uniform = 33.639   loss each uniform = 6.184   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.266  exp loss = 2.416  adjusted loss = 2.416  adv prob = 0.250000   acc = 0.579   grad norm = 14.727   grad norm uniform = 29.850   loss each uniform = 5.325   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.224  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.955   grad norm = 1.848   grad norm uniform = 38.360   loss each uniform = 11.235   feat norm = 0.454  
Current lr: 0.001000
Current validation accuracy: 0.8707256317138672


Epoch [288]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.038  
Average loss each uniform: 12.259  
Average feat norm: 0.437  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.728   loss each uniform = 12.396   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.658   loss each uniform = 9.924   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.019   grad norm uniform = 37.053   loss each uniform = 8.940   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.339   loss each uniform = 12.390   feat norm = 0.447  

Validation:
Average incurred loss: 0.753  
Average sample loss: 0.735  
Average acc: 0.842  
Average grad norm: 6.219  
Average grad norm uniform: 33.995  
Average loss each uniform: 8.609  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.987   grad norm = 0.420   grad norm uniform = 34.015   loss each uniform = 11.218   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.366  exp loss = 1.478  adjusted loss = 1.478  adv prob = 0.250000   acc = 0.712   grad norm = 11.746   grad norm uniform = 32.880   loss each uniform = 5.596   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.765  exp loss = 1.930  adjusted loss = 1.930  adv prob = 0.250000   acc = 0.654   grad norm = 12.161   grad norm uniform = 31.405   loss each uniform = 5.804   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.163  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.970   grad norm = 1.271   grad norm uniform = 40.420   loss each uniform = 12.808   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8415346145629883


Epoch [289]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.029  
Average loss each uniform: 12.227  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.727   loss each uniform = 12.369   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.008   grad norm uniform = 41.721   loss each uniform = 9.966   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 36.956   loss each uniform = 8.816   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.298   loss each uniform = 12.332   feat norm = 0.447  

Validation:
Average incurred loss: 0.842  
Average sample loss: 0.823  
Average acc: 0.822  
Average grad norm: 6.873  
Average grad norm uniform: 33.754  
Average loss each uniform: 8.366  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.983   grad norm = 0.606   grad norm uniform = 33.693   loss each uniform = 10.633   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.669  exp loss = 1.795  adjusted loss = 1.795  adv prob = 0.250000   acc = 0.650   grad norm = 13.815   grad norm uniform = 32.432   loss each uniform = 5.332   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.476  exp loss = 1.648  adjusted loss = 1.648  adv prob = 0.250000   acc = 0.707   grad norm = 10.382   grad norm uniform = 31.662   loss each uniform = 6.050   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.139  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.977   grad norm = 1.046   grad norm uniform = 40.692   loss each uniform = 13.352   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8223519325256348


Epoch [290]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.041  
Average loss each uniform: 12.290  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.731   loss each uniform = 12.417   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 41.664   loss each uniform = 9.994   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.017   grad norm uniform = 37.009   loss each uniform = 8.810   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.346   loss each uniform = 12.457   feat norm = 0.447  

Validation:
Average incurred loss: 0.604  
Average sample loss: 0.582  
Average acc: 0.878  
Average grad norm: 4.865  
Average grad norm uniform: 34.117  
Average loss each uniform: 9.047  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.004  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 0.998   grad norm = 0.098   grad norm uniform = 34.676   loss each uniform = 12.361   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.765  exp loss = 0.820  adjusted loss = 0.820  adv prob = 0.250000   acc = 0.833   grad norm = 7.196   grad norm uniform = 33.858   loss each uniform = 6.384   feat norm = 0.479  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.498  exp loss = 2.666  adjusted loss = 2.666  adv prob = 0.250000   acc = 0.549   grad norm = 16.151   grad norm uniform = 29.423   loss each uniform = 5.199   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.252  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 0.947   grad norm = 2.147   grad norm uniform = 37.758   loss each uniform = 10.584   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8782318830490112


Epoch [291]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.028  
Average loss each uniform: 12.274  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.708   loss each uniform = 12.406   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.012   grad norm uniform = 41.688   loss each uniform = 9.997   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.020   grad norm uniform = 37.149   loss each uniform = 8.827   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.354   loss each uniform = 12.415   feat norm = 0.447  

Validation:
Average incurred loss: 0.683  
Average sample loss: 0.663  
Average acc: 0.852  
Average grad norm: 5.648  
Average grad norm uniform: 33.567  
Average loss each uniform: 8.596  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.991   grad norm = 0.305   grad norm uniform = 33.828   loss each uniform = 11.401   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.150  exp loss = 1.242  adjusted loss = 1.242  adv prob = 0.250000   acc = 0.745   grad norm = 10.168   grad norm uniform = 32.735   loss each uniform = 5.726   feat norm = 0.477  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.903  exp loss = 2.044  adjusted loss = 2.044  adv prob = 0.250000   acc = 0.624   grad norm = 12.797   grad norm uniform = 30.348   loss each uniform = 5.499   feat norm = 0.422  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.970   grad norm = 1.422   grad norm uniform = 38.790   loss each uniform = 11.899   feat norm = 0.453  
Current lr: 0.001000
Current validation accuracy: 0.8523769974708557


Epoch [292]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.031  
Average loss each uniform: 12.292  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.709   loss each uniform = 12.422   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.671   loss each uniform = 9.996   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.959   loss each uniform = 8.826   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.375   loss each uniform = 12.445   feat norm = 0.447  

Validation:
Average incurred loss: 0.659  
Average sample loss: 0.639  
Average acc: 0.866  
Average grad norm: 5.452  
Average grad norm uniform: 34.249  
Average loss each uniform: 8.881  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.011  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.998   grad norm = 0.240   grad norm uniform = 34.602   loss each uniform = 11.935   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.026  exp loss = 1.112  adjusted loss = 1.112  adv prob = 0.250000   acc = 0.783   grad norm = 9.315   grad norm uniform = 33.562   loss each uniform = 6.024   feat norm = 0.486  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.100  exp loss = 2.247  adjusted loss = 2.247  adv prob = 0.250000   acc = 0.602   grad norm = 13.962   grad norm uniform = 30.689   loss each uniform = 5.447   feat norm = 0.429  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.955   grad norm = 1.712   grad norm uniform = 38.977   loss each uniform = 11.603   feat norm = 0.460  
Current lr: 0.001000
Current validation accuracy: 0.8657214641571045


Epoch [293]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.038  
Average loss each uniform: 12.314  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.722   loss each uniform = 12.438   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 41.721   loss each uniform = 9.985   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.919   loss each uniform = 8.874   feat norm = 0.430  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 39.357   loss each uniform = 12.489   feat norm = 0.447  

Validation:
Average incurred loss: 0.659  
Average sample loss: 0.639  
Average acc: 0.860  
Average grad norm: 5.478  
Average grad norm uniform: 33.575  
Average loss each uniform: 8.632  
Average feat norm: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.012  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 0.996   grad norm = 0.247   grad norm uniform = 33.779   loss each uniform = 11.522   feat norm = 0.419  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.044  exp loss = 1.114  adjusted loss = 1.114  adv prob = 0.250000   acc = 0.768   grad norm = 9.462   grad norm uniform = 32.701   loss each uniform = 5.793   feat norm = 0.475  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.048  exp loss = 2.173  adjusted loss = 2.173  adv prob = 0.250000   acc = 0.609   grad norm = 13.731   grad norm uniform = 30.634   loss each uniform = 5.406   feat norm = 0.425  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.195  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.955   grad norm = 1.630   grad norm uniform = 38.860   loss each uniform = 11.660   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.859883189201355


Epoch [294]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.021  
Average loss each uniform: 12.264  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.003   grad norm uniform = 34.716   loss each uniform = 12.402   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.644   loss each uniform = 10.040   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.018   grad norm uniform = 36.804   loss each uniform = 8.473   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.319   loss each uniform = 12.396   feat norm = 0.447  

Validation:
Average incurred loss: 0.816  
Average sample loss: 0.800  
Average acc: 0.830  
Average grad norm: 6.628  
Average grad norm uniform: 34.114  
Average loss each uniform: 8.575  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.985   grad norm = 0.546   grad norm uniform = 33.976   loss each uniform = 10.974   feat norm = 0.426  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.579  exp loss = 1.709  adjusted loss = 1.709  adv prob = 0.250000   acc = 0.674   grad norm = 13.112   grad norm uniform = 33.074   loss each uniform = 5.539   feat norm = 0.489  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.550  exp loss = 1.708  adjusted loss = 1.708  adv prob = 0.250000   acc = 0.692   grad norm = 10.676   grad norm uniform = 31.546   loss each uniform = 6.076   feat norm = 0.427  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.158  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.970   grad norm = 1.215   grad norm uniform = 40.804   loss each uniform = 13.288   feat norm = 0.466  
Current lr: 0.001000
Current validation accuracy: 0.8298581838607788


Epoch [295]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.018  
Average loss each uniform: 12.252  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.691   loss each uniform = 12.414   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.014   grad norm uniform = 41.719   loss each uniform = 9.994   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 37.142   loss each uniform = 8.896   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.355   loss each uniform = 12.285   feat norm = 0.447  

Validation:
Average incurred loss: 0.618  
Average sample loss: 0.594  
Average acc: 0.875  
Average grad norm: 4.952  
Average grad norm uniform: 34.495  
Average loss each uniform: 9.155  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.003  exp loss = 0.002  adjusted loss = 0.002  adv prob = 0.250000   acc = 1.000   grad norm = 0.077   grad norm uniform = 34.751   loss each uniform = 12.542   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.721  exp loss = 0.780  adjusted loss = 0.780  adv prob = 0.250000   acc = 0.839   grad norm = 6.937   grad norm uniform = 34.862   loss each uniform = 6.566   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.758  exp loss = 2.902  adjusted loss = 2.902  adv prob = 0.250000   acc = 0.496   grad norm = 17.626   grad norm uniform = 28.803   loss each uniform = 5.168   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.282  exp loss = 0.281  adjusted loss = 0.281  adv prob = 0.250000   acc = 0.940   grad norm = 2.444   grad norm uniform = 38.002   loss each uniform = 10.323   feat norm = 0.458  
Current lr: 0.001000
Current validation accuracy: 0.8748957514762878


Epoch [296]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.012  
Average loss each uniform: 12.256  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.681   loss each uniform = 12.420   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.694   loss each uniform = 10.031   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.001  adjusted loss = 0.001  adv prob = 0.250000   acc = 1.000   grad norm = 0.028   grad norm uniform = 36.794   loss each uniform = 8.529   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 39.384   loss each uniform = 12.300   feat norm = 0.448  

Validation:
Average incurred loss: 0.631  
Average sample loss: 0.610  
Average acc: 0.868  
Average grad norm: 5.138  
Average grad norm uniform: 34.464  
Average loss each uniform: 9.036  
Average feat norm: 0.455  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.007  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.167   grad norm uniform = 34.813   loss each uniform = 12.221   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.896  exp loss = 0.970  adjusted loss = 0.970  adv prob = 0.250000   acc = 0.800   grad norm = 8.228   grad norm uniform = 34.080   loss each uniform = 6.240   feat norm = 0.485  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.294  exp loss = 2.429  adjusted loss = 2.429  adv prob = 0.250000   acc = 0.571   grad norm = 14.969   grad norm uniform = 30.194   loss each uniform = 5.369   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.230  exp loss = 0.232  adjusted loss = 0.232  adv prob = 0.250000   acc = 0.947   grad norm = 1.937   grad norm uniform = 38.854   loss each uniform = 11.317   feat norm = 0.461  
Current lr: 0.001000
Current validation accuracy: 0.8682235479354858


Epoch [297]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.024  
Average loss each uniform: 12.314  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.679   loss each uniform = 12.459   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 41.651   loss each uniform = 9.991   feat norm = 0.531  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.015   grad norm uniform = 37.076   loss each uniform = 8.860   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.439   loss each uniform = 12.419   feat norm = 0.448  

Validation:
Average incurred loss: 0.691  
Average sample loss: 0.671  
Average acc: 0.856  
Average grad norm: 5.677  
Average grad norm uniform: 33.955  
Average loss each uniform: 8.749  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.014  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.994   grad norm = 0.271   grad norm uniform = 34.173   loss each uniform = 11.717   feat norm = 0.425  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.126  exp loss = 1.231  adjusted loss = 1.231  adv prob = 0.250000   acc = 0.753   grad norm = 10.033   grad norm uniform = 33.373   loss each uniform = 5.833   feat norm = 0.484  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.046  exp loss = 2.194  adjusted loss = 2.194  adv prob = 0.250000   acc = 0.624   grad norm = 13.545   grad norm uniform = 30.181   loss each uniform = 5.444   feat norm = 0.423  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.192  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.962   grad norm = 1.521   grad norm uniform = 38.996   loss each uniform = 11.852   feat norm = 0.457  
Current lr: 0.001000
Current validation accuracy: 0.8557131290435791


Epoch [298]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.002  
Average grad norm uniform: 36.019  
Average loss each uniform: 12.285  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.001   grad norm uniform = 34.685   loss each uniform = 12.441   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.007   grad norm uniform = 41.804   loss each uniform = 9.958   feat norm = 0.532  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.016   grad norm uniform = 36.904   loss each uniform = 8.711   feat norm = 0.431  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.004   grad norm uniform = 39.377   loss each uniform = 12.363   feat norm = 0.447  

Validation:
Average incurred loss: 0.641  
Average sample loss: 0.619  
Average acc: 0.869  
Average grad norm: 5.211  
Average grad norm uniform: 33.932  
Average loss each uniform: 8.871  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.006  exp loss = 0.004  adjusted loss = 0.004  adv prob = 0.250000   acc = 0.998   grad norm = 0.154   grad norm uniform = 34.245   loss each uniform = 11.998   feat norm = 0.424  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.913  exp loss = 0.987  adjusted loss = 0.987  adv prob = 0.250000   acc = 0.800   grad norm = 8.389   grad norm uniform = 33.558   loss each uniform = 6.089   feat norm = 0.481  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.338  exp loss = 2.487  adjusted loss = 2.487  adv prob = 0.250000   acc = 0.571   grad norm = 15.217   grad norm uniform = 29.636   loss each uniform = 5.308   feat norm = 0.424  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.216  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.955   grad norm = 1.830   grad norm uniform = 38.434   loss each uniform = 11.199   feat norm = 0.456  
Current lr: 0.001000
Current validation accuracy: 0.8690575361251831


Epoch [299]:
Training:
Average incurred loss: 0.000  
Average sample loss: 0.000  
Average acc: 1.000  
Average grad norm: 0.003  
Average grad norm uniform: 36.014  
Average loss each uniform: 12.282  
Average feat norm: 0.436  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.002   grad norm uniform = 34.686   loss each uniform = 12.433   feat norm = 0.428  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.006   grad norm uniform = 41.675   loss each uniform = 10.063   feat norm = 0.530  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.001  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.021   grad norm uniform = 36.932   loss each uniform = 8.749   feat norm = 0.432  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.000  exp loss = 0.000  adjusted loss = 0.000  adv prob = 0.250000   acc = 1.000   grad norm = 0.005   grad norm uniform = 39.376   loss each uniform = 12.358   feat norm = 0.447  

Validation:
Average incurred loss: 0.730  
Average sample loss: 0.711  
Average acc: 0.849  
Average grad norm: 6.050  
Average grad norm uniform: 33.904  
Average loss each uniform: 8.622  
Average feat norm: 0.451  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.989   grad norm = 0.352   grad norm uniform = 33.898   loss each uniform = 11.421   feat norm = 0.423  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 1.259  exp loss = 1.352  adjusted loss = 1.352  adv prob = 0.250000   acc = 0.734   grad norm = 11.107   grad norm uniform = 33.087   loss each uniform = 5.650   feat norm = 0.483  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.936  exp loss = 2.076  adjusted loss = 2.076  adv prob = 0.250000   acc = 0.639   grad norm = 12.986   grad norm uniform = 30.950   loss each uniform = 5.593   feat norm = 0.426  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.970   grad norm = 1.403   grad norm uniform = 39.738   loss each uniform = 12.240   feat norm = 0.462  
Current lr: 0.001000
Current validation accuracy: 0.8490408658981323

