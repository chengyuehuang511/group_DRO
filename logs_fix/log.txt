Dataset: CUB
Shift type: confounder
Target name: waterbird_complete95
Confounder names: ['forest2water2']
Resume: False
Inference: False
Minority fraction: None
Imbalance ratio: None
Fraction: 1.0
Root dir: ./
Reweight groups: False
Augment data: False
Val fraction: 0.1
Robust: False
Alpha: 0.2
Generalization adjustment: 0.0
Automatic adjustment: False
Robust step size: 0.01
Use normalized loss: False
Btl: False
Hinge: False
Print grad loss: True
Print feat: True
Uniform loss: True
Model: resnet50
Train from scratch: False
N epochs: 300
Batch size: 128
Lr: 0.001
Scheduler: False
Weight decay: 0.0001
Gamma: 0.1
Minimum variational weight: 0
Seed: 0
Show progress: True
Log dir: ./logs_fix
Checkpoint dir: ./logs_a40
Log every: 50
Save step: 1000
Save best: True
Save last: True

Training Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 3498
    waterbird_complete95 = 0, forest2water2 = 1: n = 184
    waterbird_complete95 = 1, forest2water2 = 0: n = 56
    waterbird_complete95 = 1, forest2water2 = 1: n = 1057
Validation Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 467
    waterbird_complete95 = 0, forest2water2 = 1: n = 466
    waterbird_complete95 = 1, forest2water2 = 0: n = 133
    waterbird_complete95 = 1, forest2water2 = 1: n = 133
Test Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 2255
    waterbird_complete95 = 0, forest2water2 = 1: n = 2255
    waterbird_complete95 = 1, forest2water2 = 0: n = 642
    waterbird_complete95 = 1, forest2water2 = 1: n = 642

Epoch [0]:
Training:
Average incurred loss: 0.323  
Average sample loss: 0.321  
Average acc: 0.870  
Average grad norm: 8.241  
Average grad norm uniform: 23.191  
Average loss each uniform: 2.320  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.165  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.990   grad norm = 5.051   grad norm uniform = 25.830   loss each uniform = 2.532   feat norm = 0.440  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.521  exp loss = 0.614  adjusted loss = 0.614  adv prob = 0.250000   acc = 0.701   grad norm = 13.732   grad norm uniform = 14.804   loss each uniform = 1.659   feat norm = 0.460  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.503  exp loss = 1.545  adjusted loss = 1.545  adv prob = 0.250000   acc = 0.107   grad norm = 26.397   grad norm uniform = 18.274   loss each uniform = 1.839   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.749  exp loss = 0.457  adjusted loss = 0.457  adv prob = 0.250000   acc = 0.545   grad norm = 16.882   grad norm uniform = 16.177   loss each uniform = 1.759   feat norm = 0.446  

Validation:
Average incurred loss: 0.602  
Average sample loss: 0.590  
Average acc: 0.686  
Average grad norm: 11.873  
Average grad norm uniform: 24.018  
Average loss each uniform: 2.538  
Average feat norm: 0.442  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.076  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.985   grad norm = 2.319   grad norm uniform = 31.806   loss each uniform = 3.424   feat norm = 0.442  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.985  exp loss = 1.000  adjusted loss = 1.000  adv prob = 0.250000   acc = 0.429   grad norm = 19.705   grad norm uniform = 17.432   loss each uniform = 1.839   feat norm = 0.449  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.499  exp loss = 1.643  adjusted loss = 1.643  adv prob = 0.250000   acc = 0.263   grad norm = 23.997   grad norm uniform = 18.659   loss each uniform = 2.004   feat norm = 0.433  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.955   grad norm = 5.851   grad norm uniform = 25.101   loss each uniform = 2.406   feat norm = 0.431  
Current lr: 0.001000
Current validation accuracy: 0.6855713129043579
Best model saved at epoch 0


Epoch [1]:
Training:
Average incurred loss: 0.124  
Average sample loss: 0.124  
Average acc: 0.956  
Average grad norm: 3.101  
Average grad norm uniform: 31.318  
Average loss each uniform: 3.771  
Average feat norm: 0.441  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.041  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.998   grad norm = 1.336   grad norm uniform = 33.498   loss each uniform = 4.206   feat norm = 0.442  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.771  exp loss = 0.698  adjusted loss = 0.698  adv prob = 0.250000   acc = 0.565   grad norm = 16.343   grad norm uniform = 18.088   loss each uniform = 1.892   feat norm = 0.452  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.506  exp loss = 1.337  adjusted loss = 1.337  adv prob = 0.250000   acc = 0.286   grad norm = 23.853   grad norm uniform = 18.257   loss each uniform = 2.011   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.214  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.922   grad norm = 5.536   grad norm uniform = 27.099   loss each uniform = 2.752   feat norm = 0.436  

Validation:
Average incurred loss: 0.487  
Average sample loss: 0.472  
Average acc: 0.771  
Average grad norm: 9.221  
Average grad norm uniform: 26.710  
Average loss each uniform: 3.191  
Average feat norm: 0.444  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.994   grad norm = 1.198   grad norm uniform = 33.765   loss each uniform = 4.555   feat norm = 0.440  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.731  exp loss = 0.755  adjusted loss = 0.755  adv prob = 0.250000   acc = 0.618   grad norm = 15.049   grad norm uniform = 20.316   loss each uniform = 2.108   feat norm = 0.451  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.522  exp loss = 1.739  adjusted loss = 1.739  adv prob = 0.250000   acc = 0.338   grad norm = 22.096   grad norm uniform = 20.896   loss each uniform = 2.243   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.962   grad norm = 4.099   grad norm uniform = 30.153   loss each uniform = 3.145   feat norm = 0.443  
Current lr: 0.001000
Current validation accuracy: 0.7714762687683105
Best model saved at epoch 1


Epoch [2]:
Training:
Average incurred loss: 0.085  
Average sample loss: 0.085  
Average acc: 0.970  
Average grad norm: 2.149  
Average grad norm uniform: 32.711  
Average loss each uniform: 4.407  
Average feat norm: 0.440  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.026  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.998   grad norm = 0.867   grad norm uniform = 34.062   loss each uniform = 4.855   feat norm = 0.437  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.493  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.734   grad norm = 11.522   grad norm uniform = 21.076   loss each uniform = 2.131   feat norm = 0.457  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 1.043  exp loss = 1.217  adjusted loss = 1.217  adv prob = 0.250000   acc = 0.536   grad norm = 17.479   grad norm uniform = 18.693   loss each uniform = 2.034   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.159  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.940   grad norm = 3.947   grad norm uniform = 31.007   loss each uniform = 3.445   feat norm = 0.444  

Validation:
Average incurred loss: 0.422  
Average sample loss: 0.408  
Average acc: 0.822  
Average grad norm: 7.787  
Average grad norm uniform: 28.378  
Average loss each uniform: 3.604  
Average feat norm: 0.448  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.998   grad norm = 0.836   grad norm uniform = 34.410   loss each uniform = 5.128   feat norm = 0.439  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.581  exp loss = 0.609  adjusted loss = 0.609  adv prob = 0.250000   acc = 0.717   grad norm = 12.216   grad norm uniform = 22.828   loss each uniform = 2.389   feat norm = 0.458  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.505  exp loss = 1.733  adjusted loss = 1.733  adv prob = 0.250000   acc = 0.429   grad norm = 20.739   grad norm uniform = 22.636   loss each uniform = 2.441   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.962   grad norm = 3.724   grad norm uniform = 32.384   loss each uniform = 3.671   feat norm = 0.455  
Current lr: 0.001000
Current validation accuracy: 0.8215179443359375
Best model saved at epoch 2


Epoch [3]:
Training:
Average incurred loss: 0.060  
Average sample loss: 0.060  
Average acc: 0.981  
Average grad norm: 1.587  
Average grad norm uniform: 33.434  
Average loss each uniform: 4.876  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.020  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998   grad norm = 0.648   grad norm uniform = 34.275   loss each uniform = 5.283   feat norm = 0.435  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.369  exp loss = 0.402  adjusted loss = 0.402  adv prob = 0.250000   acc = 0.848   grad norm = 9.182   grad norm uniform = 23.154   loss each uniform = 2.362   feat norm = 0.463  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.775  exp loss = 0.678  adjusted loss = 0.678  adv prob = 0.250000   acc = 0.679   grad norm = 13.673   grad norm uniform = 20.327   loss each uniform = 2.138   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.103  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.963   grad norm = 2.731   grad norm uniform = 33.135   loss each uniform = 4.114   feat norm = 0.449  

Validation:
Average incurred loss: 0.418  
Average sample loss: 0.404  
Average acc: 0.832  
Average grad norm: 7.499  
Average grad norm uniform: 29.005  
Average loss each uniform: 3.808  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.998   grad norm = 0.784   grad norm uniform = 34.078   loss each uniform = 5.330   feat norm = 0.434  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.639  adjusted loss = 0.639  adv prob = 0.250000   acc = 0.727   grad norm = 12.169   grad norm uniform = 23.698   loss each uniform = 2.493   feat norm = 0.461  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.413  exp loss = 1.613  adjusted loss = 1.613  adv prob = 0.250000   acc = 0.481   grad norm = 19.203   grad norm uniform = 23.977   loss each uniform = 2.577   feat norm = 0.447  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.145  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.962   grad norm = 3.008   grad norm uniform = 34.815   loss each uniform = 4.299   feat norm = 0.468  
Current lr: 0.001000
Current validation accuracy: 0.8315262794494629
Best model saved at epoch 3


Epoch [4]:
Training:
Average incurred loss: 0.047  
Average sample loss: 0.047  
Average acc: 0.985  
Average grad norm: 1.272  
Average grad norm uniform: 33.876  
Average loss each uniform: 5.250  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.015  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.998   grad norm = 0.494   grad norm uniform = 34.394   loss each uniform = 5.662   feat norm = 0.433  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.254  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.908   grad norm = 6.770   grad norm uniform = 26.889   loss each uniform = 2.689   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.542  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.732   grad norm = 9.882   grad norm uniform = 23.551   loss each uniform = 2.445   feat norm = 0.440  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.090  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 0.970   grad norm = 2.432   grad norm uniform = 33.927   loss each uniform = 4.483   feat norm = 0.454  

Validation:
Average incurred loss: 0.442  
Average sample loss: 0.429  
Average acc: 0.819  
Average grad norm: 7.547  
Average grad norm uniform: 29.283  
Average loss each uniform: 3.970  
Average feat norm: 0.447  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.994   grad norm = 0.842   grad norm uniform = 33.726   loss each uniform = 5.421   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.720  exp loss = 0.775  adjusted loss = 0.775  adv prob = 0.250000   acc = 0.678   grad norm = 13.178   grad norm uniform = 24.002   loss each uniform = 2.555   feat norm = 0.459  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.237  exp loss = 1.424  adjusted loss = 1.424  adv prob = 0.250000   acc = 0.556   grad norm = 16.641   grad norm uniform = 25.288   loss each uniform = 2.747   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.122  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.962   grad norm = 2.261   grad norm uniform = 36.180   loss each uniform = 5.053   feat norm = 0.463  
Current lr: 0.001000
Current validation accuracy: 0.8190158605575562


Epoch [5]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.992  
Average grad norm: 0.929  
Average grad norm uniform: 34.370  
Average loss each uniform: 5.624  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 0.999   grad norm = 0.350   grad norm uniform = 34.548   loss each uniform = 6.024   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.165  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.946   grad norm = 5.027   grad norm uniform = 29.144   loss each uniform = 3.019   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.411  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.839   grad norm = 8.063   grad norm uniform = 24.780   loss each uniform = 2.601   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.061  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.985   grad norm = 1.754   grad norm uniform = 35.202   loss each uniform = 4.916   feat norm = 0.457  

Validation:
Average incurred loss: 0.385  
Average sample loss: 0.369  
Average acc: 0.859  
Average grad norm: 6.241  
Average grad norm uniform: 30.858  
Average loss each uniform: 4.481  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.013  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 0.998   grad norm = 0.398   grad norm uniform = 34.687   loss each uniform = 6.301   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.460  exp loss = 0.502  adjusted loss = 0.502  adv prob = 0.250000   acc = 0.813   grad norm = 9.081   grad norm uniform = 27.597   loss each uniform = 3.065   feat norm = 0.465  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.629  exp loss = 1.833  adjusted loss = 1.833  adv prob = 0.250000   acc = 0.451   grad norm = 19.703   grad norm uniform = 24.857   loss each uniform = 2.828   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.940   grad norm = 3.342   grad norm uniform = 34.841   loss each uniform = 4.707   feat norm = 0.467  
Current lr: 0.001000
Current validation accuracy: 0.8590492010116577
Best model saved at epoch 5


Epoch [6]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.024  
Average acc: 0.996  
Average grad norm: 0.686  
Average grad norm uniform: 34.802  
Average loss each uniform: 5.947  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000   grad norm = 0.293   grad norm uniform = 34.609   loss each uniform = 6.285   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.115  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.973   grad norm = 3.696   grad norm uniform = 31.545   loss each uniform = 3.203   feat norm = 0.478  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.291  exp loss = 0.375  adjusted loss = 0.375  adv prob = 0.250000   acc = 0.893   grad norm = 5.478   grad norm uniform = 28.710   loss each uniform = 2.982   feat norm = 0.437  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.041  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.992   grad norm = 1.208   grad norm uniform = 36.332   loss each uniform = 5.462   feat norm = 0.458  

Validation:
Average incurred loss: 0.488  
Average sample loss: 0.474  
Average acc: 0.811  
Average grad norm: 7.553  
Average grad norm uniform: 30.467  
Average loss each uniform: 4.471  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.987   grad norm = 0.762   grad norm uniform = 34.014   loss each uniform = 5.973   feat norm = 0.432  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.846  exp loss = 0.900  adjusted loss = 0.900  adv prob = 0.250000   acc = 0.655   grad norm = 13.809   grad norm uniform = 25.715   loss each uniform = 2.824   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.228  exp loss = 1.406  adjusted loss = 1.406  adv prob = 0.250000   acc = 0.586   grad norm = 15.275   grad norm uniform = 27.033   loss each uniform = 3.159   feat norm = 0.445  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.108  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.962   grad norm = 1.759   grad norm uniform = 38.097   loss each uniform = 6.278   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.8106756210327148


Epoch [7]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 0.997  
Average grad norm: 0.544  
Average grad norm uniform: 35.049  
Average loss each uniform: 6.245  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000   grad norm = 0.230   grad norm uniform = 34.668   loss each uniform = 6.585   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.076  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.989   grad norm = 2.652   grad norm uniform = 33.349   loss each uniform = 3.555   feat norm = 0.482  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.210  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.893   grad norm = 4.563   grad norm uniform = 29.146   loss each uniform = 3.157   feat norm = 0.438  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.995   grad norm = 1.002   grad norm uniform = 36.921   loss each uniform = 5.752   feat norm = 0.460  

Validation:
Average incurred loss: 0.453  
Average sample loss: 0.439  
Average acc: 0.837  
Average grad norm: 6.871  
Average grad norm uniform: 30.858  
Average loss each uniform: 4.691  
Average feat norm: 0.450  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.994   grad norm = 0.585   grad norm uniform = 33.985   loss each uniform = 6.325   feat norm = 0.427  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.731  exp loss = 0.794  adjusted loss = 0.794  adv prob = 0.250000   acc = 0.723   grad norm = 12.029   grad norm uniform = 26.757   loss each uniform = 3.027   feat norm = 0.469  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.326  exp loss = 1.499  adjusted loss = 1.499  adv prob = 0.250000   acc = 0.564   grad norm = 15.756   grad norm uniform = 27.312   loss each uniform = 3.202   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.962   grad norm = 1.988   grad norm uniform = 37.794   loss each uniform = 6.274   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.8373644351959229


Epoch [8]:
Training:
Average incurred loss: 0.014  
Average sample loss: 0.014  
Average acc: 0.998  
Average grad norm: 0.444  
Average grad norm uniform: 35.245  
Average loss each uniform: 6.482  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000   grad norm = 0.202   grad norm uniform = 34.704   loss each uniform = 6.782   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.066  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.995   grad norm = 2.358   grad norm uniform = 34.410   loss each uniform = 3.701   feat norm = 0.488  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.171  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 0.911   grad norm = 3.459   grad norm uniform = 31.373   loss each uniform = 3.432   feat norm = 0.436  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.024  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.997   grad norm = 0.755   grad norm uniform = 37.384   loss each uniform = 6.133   feat norm = 0.459  

Validation:
Average incurred loss: 0.460  
Average sample loss: 0.445  
Average acc: 0.841  
Average grad norm: 6.782  
Average grad norm uniform: 31.305  
Average loss each uniform: 4.874  
Average feat norm: 0.454  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994   grad norm = 0.539   grad norm uniform = 34.324   loss each uniform = 6.580   feat norm = 0.431  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.741  exp loss = 0.800  adjusted loss = 0.800  adv prob = 0.250000   acc = 0.730   grad norm = 11.864   grad norm uniform = 27.631   loss each uniform = 3.175   feat norm = 0.474  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.353  exp loss = 1.506  adjusted loss = 1.506  adv prob = 0.250000   acc = 0.579   grad norm = 15.704   grad norm uniform = 27.043   loss each uniform = 3.255   feat norm = 0.442  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.124  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.955   grad norm = 1.975   grad norm uniform = 37.836   loss each uniform = 6.458   feat norm = 0.473  
Current lr: 0.001000
Current validation accuracy: 0.840700626373291


Epoch [9]:
Training:
Average incurred loss: 0.011  
Average sample loss: 0.011  
Average acc: 0.999  
Average grad norm: 0.359  
Average grad norm uniform: 35.397  
Average loss each uniform: 6.751  
Average feat norm: 0.439  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 3498]:	loss = 0.005  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000   grad norm = 0.160   grad norm uniform = 34.738   loss each uniform = 7.047   feat norm = 0.430  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 184]:	loss = 0.042  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 1.000   grad norm = 1.566   grad norm uniform = 36.120   loss each uniform = 4.043   feat norm = 0.491  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 56]:	loss = 0.151  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.946   grad norm = 3.487   grad norm uniform = 30.219   loss each uniform = 3.455   feat norm = 0.434  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1057]:	loss = 0.020  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.999   grad norm = 0.640   grad norm uniform = 37.729   loss each uniform = 6.417   feat norm = 0.460  

Validation:
Average incurred loss: 0.468  
Average sample loss: 0.454  
Average acc: 0.839  
Average grad norm: 6.701  
Average grad norm uniform: 31.333  
Average loss each uniform: 5.012  
Average feat norm: 0.452  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.994   grad norm = 0.527   grad norm uniform = 34.127   loss each uniform = 6.742   feat norm = 0.429  
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.756  exp loss = 0.820  adjusted loss = 0.820  adv prob = 0.250000   acc = 0.725   grad norm = 11.724   grad norm uniform = 27.789   loss each uniform = 3.254   feat norm = 0.472  
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.377  exp loss = 1.531  adjusted loss = 1.531  adv prob = 0.250000   acc = 0.579   grad norm = 15.556   grad norm uniform = 27.401   loss each uniform = 3.373   feat norm = 0.441  
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.126  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.955   grad norm = 1.927   grad norm uniform = 37.877   loss each uniform = 6.731   feat norm = 0.471  
